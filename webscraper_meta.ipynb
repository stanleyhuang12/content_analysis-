{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "spSVq0H67mtm",
        "3Nod8v_t8Ki_",
        "N642e2nv_W2F"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3Th5OMIg0_Fz"
      },
      "outputs": [],
      "source": [
        "from bs4 import BeautifulSoup\n",
        "from google.colab import files\n",
        "import requests\n",
        "import numpy as np\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The goal of this project is to webscrape Meta's newsroom for articles tagged with\n",
        "\n",
        "* Safety and Expression\n",
        "* Combatting Misinformation\n",
        "* Data and Privacy"
      ],
      "metadata": {
        "id": "cG1t6dGI6G2o"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Safety and Expression"
      ],
      "metadata": {
        "id": "spSVq0H67mtm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Get article meta data: date, updated date, link, title of article\n",
        "\n",
        "data = []\n",
        "\n",
        "for i in range(0,21):\n",
        "  request = requests.get(url=f\"https://about.fb.com/news/category/safety-and-expression/page/{i}/\")\n",
        "  parser = BeautifulSoup(request.content, \"html.parser\")\n",
        "\n",
        "  area_section = parser.find(\"div\", class_=\"archive-articles-container\")\n",
        "  article_section = area_section.find_all(\"div\", class_=\"uk-width-3-5 article-excerpt\")\n",
        "  for article in article_section:\n",
        "    try:\n",
        "        header = article.find(\"header\", class_=\"entry-header\")\n",
        "        link_source = header.find(\"a\", href=True)\n",
        "\n",
        "        article_title = link_source.get_text()\n",
        "        link = link_source.get(\"href\")\n",
        "\n",
        "        date_source = header.find(\"time\", class_=\"entry-date published\")\n",
        "        date_source2 = header.find(\"time\", class_=\"updated\")\n",
        "        date = date_source.get_text()\n",
        "        date2 = date_source2.get_text()\n",
        "\n",
        "        data.append((link, article_title, date, date2))\n",
        "\n",
        "    except:\n",
        "        header = article.find(\"header\", class_=\"entry-header\")\n",
        "        link_source = header.find(\"a\", href=True)\n",
        "\n",
        "        article_title = link_source.get_text()\n",
        "        link = link_source.get(\"href\")\n",
        "\n",
        "        date_source = header.find(\"time\", class_=\"entry-date published updated\")\n",
        "        date = date_source.get_text()\n",
        "        date2 = None\n",
        "\n",
        "        data.append((link, article_title, date, date2))\n",
        "\n",
        "\n",
        "article_meta_ds = pd.DataFrame(data, columns=[\"Link\", \"Article Title\" , \"Date\", \"Updated Date\"])\n",
        "\n",
        "print(article_meta_ds)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "25aBAo061K8u",
        "outputId": "cf91c677-ec16-4318-acd1-e76575813a09"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                                  Link  \\\n",
            "0    https://about.fb.com/news/2024/09/instagram-te...   \n",
            "1    https://about.fb.com/news/2024/09/preventing-s...   \n",
            "2    https://about.fb.com/news/2024/07/combating-fi...   \n",
            "3    https://about.fb.com/news/2024/04/new-tools-to...   \n",
            "4    https://about.fb.com/news/2024/02/helping-teen...   \n",
            "..                                                 ...   \n",
            "205  https://about.fb.com/news/2019/01/a-discussion...   \n",
            "206  https://about.fb.com/news/2019/01/oversight-bo...   \n",
            "207  https://about.fb.com/news/2019/01/what-kind-of...   \n",
            "208  https://about.fb.com/news/2019/01/banning-twin...   \n",
            "209  https://about.fb.com/news/2018/12/content-revi...   \n",
            "\n",
            "                                         Article Title                Date  \\\n",
            "0    Introducing Instagram Teen Accounts: Built-In ...  September 17, 2024   \n",
            "1    Preventing Suicide and Self-Harm Content Sprea...  September 12, 2024   \n",
            "2    Combating Financial Sextortion Scams From Nigeria       July 24, 2024   \n",
            "3    New Tools to Help Protect Against Sextortion a...      April 11, 2024   \n",
            "4                 Helping Teens Avoid Sextortion Scams    February 6, 2024   \n",
            "..                                                 ...                 ...   \n",
            "205                       A Discussion with Nick Clegg    January 28, 2019   \n",
            "206  Charting a Course for an Oversight Board for C...    January 28, 2019   \n",
            "207                  What Kind of Internet Do We Want?    January 20, 2019   \n",
            "208  Banning Twinmark Media Enterprises in the Phil...    January 10, 2019   \n",
            "209             Facts About Content Review on Facebook   December 28, 2018   \n",
            "\n",
            "           Updated Date  \n",
            "0    September 17, 2024  \n",
            "1    September 12, 2024  \n",
            "2         July 24, 2024  \n",
            "3        April 10, 2024  \n",
            "4      February 5, 2024  \n",
            "..                  ...  \n",
            "205    January 31, 2021  \n",
            "206        May 19, 2021  \n",
            "207    January 31, 2021  \n",
            "208    November 7, 2019  \n",
            "209    November 7, 2019  \n",
            "\n",
            "[210 rows x 4 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get article body text and zip this with article_meta_ds\n",
        "# This process takes 2 minutes\n",
        "\n",
        "scraped_dataset_safety = [ ]\n",
        "\n",
        "for idx, row in article_meta_ds.iterrows():\n",
        "  article_request = requests.get(url=row['Link'])\n",
        "  parser = BeautifulSoup(article_request.content, \"html.parser\")\n",
        "\n",
        "  text_section = parser.find(\"div\", class_=\"uk-width-2-3@m article-container\")\n",
        "  paragraphs = text_section.find_all(\"p\")\n",
        "\n",
        "  cleaned_text = [para.get_text(strip=True) for para in paragraphs]\n",
        "  scraped_dataset_safety.append(cleaned_text)\n",
        "  print(idx, cleaned_text)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tML5vGwE1PcB",
        "outputId": "c4b37ef4-9c36-4755-894f-15c476f9852b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 ['Today, we’re introducing Instagram Teen Accounts, a new experience for teens, guided by parents. Teen Accounts have built-in protections which limit who can contact them and the content they see, and also provide new ways for teens to explore their interests. We’ll automatically place teens into Teen Accounts, and teens under 16 will need a parent’s permission to change any of these settings to be less strict.', 'We know parents want to feel confident that their teens can use social media to connect with their friends and explore their interests, without having to worry about unsafe or inappropriate experiences. We understand parents’ concerns, and that’s why we’re reimagining our apps for teens with new Teen Accounts. This new experience is designed to better support parents, and give them peace of mind that their teens are safe with the right protections in place. Teens will also get access to a new feature, made just for them, that lets them select topics they want to see more of in Explore and their recommendations so they can focus on the fun, positive content they love.', '', 'We developed Teen Accounts with parents and teens in mind. The new Teen Account protections are designed to address parents’ biggest concerns, including who their teens are talking to online, the content they’re seeing and whether their time is being well spent. These protections are turned on automatically, and parents decide if teens under 16 can change any of these settings to be less strict:', '', '“Given that parents today are grappling with the benefits and challenges of the internet and digital media for their teens, our association applauds Meta for launching Instagram Teen Accounts. With teens automatically placed in Teen Accounts and certain privacy settings turned on by default, this update demonstrates that Meta is taking steps to empower parents and deliver safer, more age-appropriate experiences on the platform.”', '– Yvonne Johnson, President, National PTA', 'Teens under 16 will need their parent’s permission to use less protective settings. To get permission, teens will need to set up parental supervision on Instagram. If parents want more oversight over their older teen’s (16+) experiences, they simply have to turn on parental supervision. Then, they can approve any changes to these settings, irrespective of their teen’s age.', 'Once supervision is established, parents can approve and deny their teens’ requests to change settings or allow teens to manage their settings themselves. Soon, parents will also be able to change these settings directly to be more protective. Learn more abouthow to manage Teen Accounts.', '“Instagram Teen Accounts reflect the importance of tailoring teens’ online experiences to their developmental stages, and implementing appropriate protections. Younger adolescents are more vulnerable as their skills are still emerging and require additional safeguards and protection. Overall, the settings are age-specific, with younger and older teens being offered different protections.”', '– Rachel Rodgers, PhD Associate Professor of Applied Psychology, Northeastern University', 'While Teen Accounts put new protections in place automatically, many parents want to be even more involved in their teen’s experiences, so we’re also adding to oursupervision feature.Updates include ways to:', '', 'Teens may lie about their age and that’s why we’re requiring them toverify their agein more places, like if they attempt to use a new account with an adult birthday. We’re also building technology to proactively find accounts belonging to teens, even if the account lists an adult birthday. This technology will allow us to proactively find these teens and place them in the same protections offered by Teen Account settings. We’ll start testing this change in the US early next year. You can read more about those detailshere.', 'We recognize parents are concerned that their teens might see mature or inappropriate content online, which is why we have stricter rules around the kinds of content teens see on our apps. We remove content that breaks our rules and avoid recommending potentially sensitive content – such as sexually suggestive content or content discussing suicide or self-harm. With Instagram Teen Accounts, teens will be placed into the strictest setting of our sensitive content control, so they’re even less likely to be recommendedsensitive content, and in many cases wehide this content altogetherfrom teens, even if it’s shared by someone they follow.', '“It’s important that safety and privacy protections are the default settings, both to improve teens’ online experience and to reduce some of the burden that has fallen to parents. We look forward to hearing from teens about their experience of these new Teen Accounts and associated features and settings.”', '– Dr. Megan Moreno, Co-Medical Director of the SAMHSA-Funded AAP Center of Excellence on Social Media and Youth Mental Health', 'Today, we’ll start placing teens who sign up for Instagram into Teen Accounts, and we’ll notify teens already using Instagram about these changes so we can begin moving them into Teen Accounts next week.', 'We plan to place teens into Teen Accounts within 60 days in the US, UK, Canada and Australia, and to start placing them in Teen Accounts in the European Union later this year. Teens around the world will start to get Teen Accounts in January. We’ll also bring Teen Accounts to other Meta platforms next year. These are big updates that will change the Instagram experience for millions of teens, and we need to make sure they work correctly.', '“These updates to Instagram’s Teen Accounts offer a balanced approach, empowering parents with essential oversight while respecting teens’ right to participate and explore. In an ever-evolving online world, this update ensures that young people can engage meaningfully and safely, fostering positive connections while still providing the protection they need.”', '– Lucy Thomas OAM, CEO & Co-Founder, Project Rockit']\n",
            "1 ['Suicide and self-harm are complex mental health issues that can have devastating consequences. At Meta, we’ve worked with experts for years – including our suicide and self-harm advisory group and members of Meta’s own safety teams – to develop an informed and thoughtful approach to suicide and self harm content shared on our apps.', 'Yet, like many other types of potentially problematic content, suicide and self-harm content is not limited to any one platform. To be truly effective in responding to this content, tech companies need to work together. That’s why we’ve worked with theMental Health Coalitionto establish Thrive, the first signal sharing program to share signals about violating suicide and self-harm content.', 'Through Thrive, participating tech companies will be able to share signals about violating suicide or self-harm content so that other companies can investigate and take action if the same or similar content is being shared on their platforms. Meta is providing the technical infrastructure that underpins Thrive – the same technology we provide to theTech Coalition’s Lantern program– which enables signals to be shared securely.', 'Participating companies will start by sharing hashes – numerical codes that correspond to violating content – of images and videos showing graphic suicide and self-harm, and of content depicting or encouraging viral suicide or self-harm challenges. We’re prioritizing this content because of its propensity to spread across different platforms quickly. These initial signals represent content only, and will not include identifiable information about any accounts or individuals.', 'Thrive builds on the work we already do at Meta to remove harmful content that shows graphic imagery or encourages suicide or self-harm, while still giving space for people to talk about their own experiences. We also provide support to those sharing and searching for content related to suicide or self-harm by connecting them to local organizations around the world, including Suicide and Crisis Lifeline and Crisis Text Line in the US.', 'Between April and June this year,we took actionon over 12 million pieces of suicide and self-harm content on Facebook and Instagram. While we allow people to discuss their experiences with suicide and self-harm – as long as it’s not graphic or promotional – this year we’ve takenimportant stepsto make this content harder to find in Search and to hide it completely from teens, even if it’s shared by someone they follow.', 'Thrive will help keep people safe not just on Meta’s apps, but across all the apps and services they use. We’re proud to work with the Mental Health Coalition and our industry partners Snap and TikTok on this vital work.']\n",
            "2 ['Financial sextortion is a horrific crime that can have devastating consequences. Our teams have deep experience in fighting this crime and work closely with experts to recognize the tactics scammers use, understand how they evolve and develop effective ways to help stop them. Like many crimes, financial sextortion crosses borders, and over recent years there’s been a growing trend of scammers — largely driven by cybercriminals known as Yahoo Boys — targeting people across the internet, both with these and other types of scams. We’ve banned Yahoo Boys under Meta’sDangerous Organizations and Individuals policy— one of our strictest policies — which means we remove Yahoo Boys’ accounts engaged in this criminal activity whenever we become aware of them.', 'Following our recentQ1 2024 Adversarial Threat Report, today we are announcing the strategic network disruption of two sets of accounts in Nigeria that were affiliated with Yahoo Boys and were attempting to engage in financial sextortion scams.', 'First, we removed around 63,000 Instagram accounts in Nigeria that attempted to directly engage in financial sextortion scams.These included a smaller coordinated network of around 2,500 accounts that we were able to link to a group of around 20 individuals. They targeted primarily adult men in the US and used fake accounts to mask their identities.', 'We found the coordinated network of around 2,500 accounts through a combination ofnew technical signals we’ve developedto help identify sextorters and in-depth investigations by our expert teams. The majority of these accounts had already been detected and disabled by our enforcement systems, and this investigation allowed us to remove the remaining accounts and understand more about the techniques being used to improve our automated detection.', 'While our investigation showed that the majority of these scammers’ attempts were unsuccessful and mostly targeted adults, we did see some also attempt to target minors, and we’ve reported those accounts to the National Center for Missing and Exploited Children (NCMEC). Since these criminals don’t limit themselves to any one platform, we also share relevant information with other tech companies through theTech Coalition’s Lantern program, so they can take action too.', 'Applying lessons learned from taking down terrorist groups and coordinated inauthentic behavior, we used our identification of this coordinated network to help us identify more accounts in Nigeria that were attempting to engage in similar sextortion scams, bringing the total to around 63,000 accounts removed.', 'Second, we removed around 7,200 assets, including 1,300 Facebook accounts, 200 Facebook Pages and 5,700 Facebook Groups, also based in Nigeria, that were providing tips for conducting scams.Their efforts included offering to sell scripts and guides to use when scamming people, and sharing links to collections of photos to use when populating fake accounts.', 'Since this disruption, our systems have been identifying and automatically blocking attempts from these groups to come back, and we continue to strengthen those systems to make them as effective as possible. We’ve also used the new tactics we observed to further improve our ability to detect accounts, Groups and Pages engaging in this activity.', 'While these investigations and disruptions are critical, they’re just one part of our approach. We continue to support law enforcement in investigating and prosecuting these crimes, including by responding to valid legal requests for information and by alerting them when we become aware of someone at risk of imminent harm, in accordance with our terms of service and applicable law. We also fund and support NCMEC and the International Justice Mission to runProject Boost, a program that trains law enforcement agencies around the world in processing and acting on NCMEC reports. We’ve conducted several training sessions so far, including in Nigeria and the Cote d’Ivoire, with our most recent session taking place just last month.', 'We also want to help people recognize and avoid these scams, while making it as difficult as possible for the criminals behind them to succeed. It’s why we default teens under 16 (under 18 in certain countries) into stricter message settings so they can’t be messaged by anyone — even other teens — they’re not connected to, and showSafety Noticesencouraging them to be cautious.', '', 'We also recently announced that we’ve developednew signals to identify accounts that arepotentiallyengaging in sextortion,and are taking steps to help prevent these accounts from finding and interacting with teens. Finally, we’ve started testingour on-device nudity protection featurein Instagram DMs, which will blur images detected as containing nudity, encourage people to be cautious when sending sensitive images and direct people to safety tips and resources, including NCMEC’sTake It Downplatform.', '', 'This is an adversarial space where criminals evolve to evade our ever-improving defenses. We will continue to focus on understanding how they operate so we can stay one step ahead, and will continue our vital cooperation with child safety experts, law enforcement and the tech industry to help disrupt these criminals across all the platforms they use.']\n",
            "3 ['Financial sextortionis a horrific crime. We’ve spent years working closely with experts, including those experienced in fighting these crimes, to understand the tactics scammers use to find and extort victims online, so we can develop effective ways to help stop them.', 'Today, we’re sharing an overview of our latest work to tackle these crimes. This includes new tools we’re testing to help protect people from sextortion and other forms of intimate image abuse, and to make it as hard as possible for scammers to find potential targets – on Meta’s apps and across the internet. We’re also testing new measures to support young people in recognizing and protecting themselves from sextortion scams.', 'These updates build on our longstanding work to help protect young people from unwanted or potentially harmful contact. Wedefault teens into stricter message settingsso they can’t be messaged by anyone they’re not already connected to, showSafety Noticesto teens who are already in contact with potential scam accounts, and offer a dedicated option for people to report DMs that are threatening to share private images. We alsosupportedthe National Center for Missing and Exploited Children (NCMEC) in developingTake It Down, a platform that lets young people take back control of their intimate images and helps prevent them being shared online – taking power away from scammers.', 'While people overwhelmingly use DMs to share what they love with their friends, family or favorite creators, sextortion scammers may also use private messages to share or ask for intimate images. To help address this, we’ll soon start testing our new nudity protection feature in Instagram DMs, which blurs images detected as containing nudity and encourages people to think twice before sending nude images. This feature is designed not only to protect people from seeing unwanted nudity in their DMs, but also to protect them from scammers who may send nude images to trick people into sending their own images in return.', 'Nudity protection will be turned on by default for teens under 18 globally, and we’ll show a notification to adults encouraging them to turn it on.', 'When nudity protection is turned on, people sending images containing nudity will see a message reminding them to be cautious when sending sensitive photos, and that they can unsend these photos if they’ve changed their mind.', '', 'Anyone who tries to forward a nude image they’ve received will see a message encouraging them to reconsider.', '', 'When someone receives an image containing nudity, it will be automatically blurred under a warning screen, meaning the recipient isn’t confronted with a nude image and they can choose whether or not to view it. We’ll also show them a message encouraging them not to feel pressure to respond, with an option to block the sender and report the chat.', 'This slideshow requires JavaScript.', 'When sending or receiving these images, people will be directed to safety tips, developed with guidance from experts, about the potential risks involved. These tips include reminders that people may screenshot or forward images without your knowledge, that your relationship to the person may change in the future, and that you should review profiles carefully in case they’re not who they say they are. They also link to a range of resources, includingMeta’s Safety Center,support helplines,StopNCII.orgfor those over 18, andTake It Downfor those under 18.', 'This slideshow requires JavaScript.', 'Nudity protection uses on-device machine learning to analyze whether an image sent in a DM on Instagram contains nudity. Because the images are analyzed on the device itself, nudity protection will work in end-to-end encrypted chats, where Meta won’t have access to these images – unless someone chooses to report them to us.', '“Companies have a responsibility to ensure the protection of minors who use their platforms. Meta’s proposed device-side safety measures within its encrypted environment is encouraging. We are hopeful these new measures will increase reporting by minors and curb the circulation of online child exploitation.”–John Shehan, Senior Vice President, National Center for Missing & Exploited Children.', '“As an educator, parent, and researcher on adolescent online behavior, I applaud Meta’s new feature that handles the exchange of personal nude content in a thoughtful, nuanced, and appropriate way. It reduces unwanted exposure to potentially traumatic images, gently introduces cognitive dissonance to those who may be open to sharing nudes, and educates people about the potential downsides involved. Each of these should help decrease the incidence of sextortion and related harms, helping to keep young people safe online.” –Dr. Sameer Hinduja, Co-Director of theCyberbullying Research Centerand Faculty Associate at the Berkman Klein Center at Harvard University.', 'We take severe action when we become aware of people engaging in sextortion: we remove their account, take steps to prevent them from creating new ones and, where appropriate, report them to the NCMEC and law enforcement. Our expert teams also work to investigate and disrupt networks of these criminals, disable their accounts and report them to NCMEC and law enforcement – including several networks in the last year alone.', 'Now, we’re also developing technology to help identify where accounts maypotentiallybe engaging in sextortion scams, based on a range of signals that could indicate sextortion behavior. While these signals aren’t necessarily evidence that an account has broken our rules, we’re taking precautionary steps to help prevent these accounts from finding and interacting with teen accounts. This builds on thework we already doto prevent other potentially suspicious accounts from finding and interacting with teens.', 'One way we’re doing this is by making it even harder for potential sextortion accounts to message or interact with people. Now, any message requests potential sextortion accounts try to send will go straight to the recipient’s hidden requests folder, meaning they won’t be notified of the message and never have to see it. For those who are already chatting to potential scam or sextortion accounts, we showSafety Noticesencouraging them to report any threats to share their private images, and reminding them that they can say no to anything that makes them feel uncomfortable.', 'For teens, we’re going even further. We already restrict adults from starting DM chats with teens they’re not connected to, and in January we announcedstricter messaging defaults for teens under 16(under 18 in certain countries), meaning they can only be messaged by people they’re already connected to – no matter how old the sender is. Now, we won’t show the “Message” button on a teen’s profile to potential sextortion accounts, even if they’re already connected.We’re also testing hiding teens from these accounts in people’s follower, following and like lists, and making it harder for them to find teen accounts in Search results.', 'We’re testing new pop-up messages for people who may have interacted with an account we’ve removed for sextortion. The message will direct them to our expert-backed resources, including ourStop Sextortion Hub,support helplines, the option to reach out to a friend,StopNCII.orgfor those over 18, andTake It Downfor those under 18.', 'We’re also adding new child safety helplines from around the world into our in-app reporting flows. This means when teens report relevant issues – such as nudity, threats to share private images or sexual exploitation or solicitation – we’ll direct them to local child safety helplines where available.', 'In November, we announced we werefounding members of Lantern, a program run by the Tech Coalition that enables technology companies to share signals about accounts and behaviors that violate their child safety policies.', 'This industry cooperation is critical, because predators don’t limit themselves to just one platform – and the same is true of sextortion scammers. These criminals target victims across the different apps they use, often moving their conversations from one app to another. That’s why we’ve started to share more sextortion-specific signals to Lantern, to build on this important cooperation and try to stop sextortion scams not just on individual platforms, but across the whole internet.']\n",
            "4 ['Having a personal intimate image shared with others can be devastating, especially for young people. It can feel even worse when someone threatens to share it if you don’t give them more photos, sexual contact or money — a crime known as sextortion.', 'That’s why, this Safer Internet Day, we’re announcing new efforts to help combat this kind of criminal activity. These include giving more teens control over their intimate images, helping teens\\xa0 — and their parents and teachers\\xa0 — feel better equipped against those trying to exploit them, and supporting creators and safety organizations around the world as part of a global campaign to raise awareness of ways to prevent sextortion.', 'Take It Downis a program from NCMEC, supported by Meta, which is designed to help teens take back control of their intimate images and help prevent people — whether it’s scammers, ex-partners, or anyone else — from spreading them online.First launched last yearin English and Spanish, Meta and NCMEC are now expanding the platform to many more countries and languages, making it accessible to millions more teens around the world.', 'There are several ways people can use Take It Down to find and remove intimate imagery, or help prevent people sharing them in the first place:', 'Take It Down was designed to respect young people’s privacy and data security. To start the process, people can go toTakeItDown.NCMEC.organd follow the instructions to assign a unique hash — a digital fingerprint in the form of a numerical code — to their image or video, privately and securely from their own device.', 'Teens only need to submit the hash, rather than the intimate image or video itself, which never leaves their device. Once the hash has been submitted to NCMEC, companies like Meta can find copies of the image, take them down and help prevent anyone who’s threatening them from posting them in the future.', '“Making Take it Down available in 25 languages is a pivotal step towards safeguarding children from the horrors of online exploitation all over the world,” saidJohn Shehan, a Senior Vice President with the National Center for Missing & Exploited Children.“We aspire to ensure that every child, regardless of language or location, has the opportunity to reclaim their dignity and privacy by having their illicit content removed from participating platforms.”', '', 'Take It Down builds off of the success of platforms likeStopNCII, which helps prevent those seeking to exploit people from sharing adults’ intimate images online.', 'These moments can be upsetting and isolating, especially for young people, who may feel too scared to ask for help. That’s why we’ve worked withThorn, a nonprofit that builds technology to defend children from sexual abuse,todevelop updated guidancefor teens on how to take back control if someone is sextorting them. It also includes advice for parents and teachers on how to support their teens or students if they’re affected by these scams. The new resources can be found in ourupdated Sextortion hubwithinMeta’s Safety Center.', 'Kelbi Schnabel, Senior Manager at Thorn, said:“Our work with Meta to provide targeted, robust sextortion resources has helped Thorn significantly enhance our efforts in combating sextortion. Our joint initiative is already empowering parents and teens to understand the risks and take action, which is a testament to the power of collaborative action in tackling complex challenges like sextortion. The result of our collaboration underscores the importance of accessible, comprehensive resources in the digital era.”', 'To help make sure teens and parents everywhere know about these scams and what they can do to avoid them, Meta is launching a global campaign, supporting safety organizations and working with creators around the world to help raise awareness.', 'Today’s updates build on the work we already do to help young people know there are steps they can take if someone has shared, or is threatening to share, their intimate images. We show Safety Notices to people on Instagram when they’re messaging someone who has shown potentially scammy or suspicious behavior. These Safety Notices urge people to be cautious, encourage them to report any account that threatens to share their private images, and remind people that they can say no to anything that makes them feel uncomfortable. We also direct teens to Take It Down at relevant moments when using Facebook and Instagram, such as if they report someone for sharing their private images, for nudity, or for sexual exploitation.', '', 'And we work to help protect teens from unwanted contact in the first place. We default teens under 16 (and under 18 in certain countries) into private Instagram accounts when they sign up, which hides their follower and following lists, and we restrict adults over 19 from messaging minors who don’t follow them. Last month,we announcedstricter default message settings, meaning teens under 16 (and under 18 in certain countries) won’t receive messages from anyone they don’t follow or aren’t already connected to, providing more protection against potential scammers.']\n",
            "5 ['We want teens to have safe, age-appropriate experiences on our apps. We’ve developed more than 30 tools and resources to support teens and their parents, and we’ve spent over a decade developing policies and technology to address content that breaks our rules or could be seen as sensitive. Today, we’re announcing additional protections that are focused on the types of content teens see on Instagram and Facebook.', 'We regularly consult with experts in adolescent development, psychology and mental health to help make our platforms safe and age-appropriate for young people, including improving our understanding of which types of content may be less appropriate for teens.', 'Take the example of someone posting about their ongoing struggle with thoughts of self-harm. This is an important story, and can help destigmatize these issues, but it’s a complex topic and isn’t necessarily suitable for all young people. Now, we’ll start to remove this type of content from teens’ experiences on Instagram and Facebook, as well as other types of age-inappropriate content. We already aim not to recommend this type of content to teens in places like Reels and Explore, and with these changes, we’ll no longer show it to teens in Feed and Stories,even if it’s shared by someone they follow.', '“Meta is evolving its policies around content that could be more sensitive for teens, which is an important step in making social media platforms spaces where teens can connect and be creative in age-appropriate ways. These policies reflect current understandings and expert guidance regarding teen’s safety and well-being. As these changes unfold, they provide good opportunities for parents to talk with their teens about how to navigate difficult topics.” – Dr. Rachel Rodgers, Associate Professor, Department of Applied Psychology, Northeastern University', 'We want people to find support if they need it, so we will continue toshare resourcesfrom expert organizations like the National Alliance on Mental Illness when someone posts content related to their struggles with self-harm or eating disorders. We’re starting to roll these changes out to teens under 18 now and they’ll be fully in place on Instagram and Facebook in the coming months.', 'Here’s more detail on how today’s updates expand on our existing protections, in line with feedback from experts:', 'This slideshow requires JavaScript.', '“Parents want to be confident their teens are viewing content online that’s appropriate for their age. Paired with Meta’s parental supervision tools to help shape their teens’ experiences online, Meta’s new policies to hide content that might be less age-appropriate will give parents more peace of mind.” – Vicki Shotbolt, CEO, ParentZone.org', 'We’re automatically placing teens into the most restrictive content control setting on Instagram and Facebook. We already apply this setting for new teens when they join Instagram and Facebook, and are now expanding it to teens who are already using these apps. Our content recommendation controls – known as “Sensitive Content Control” on Instagram and “Reduce” on Facebook – make it more difficult for people to come across potentially sensitive content or accounts in places like Search and Explore.', '', '', 'While we allow people to share content discussing their own struggles with suicide, self-harm and eating disorders, our policy is not to recommend this content and we have been focused on ways to make it harder to find. Now, when people search for terms related to suicide, self-harm and eating disorders, we’ll start hiding these related results and will direct them to expert resources for help. We already hide results for suicide and self harm search terms that inherently break our rules and we’re extending this protection to include more terms. This update will roll out for everyone over the coming weeks.', '', 'To help make sure teens are regularly checking their safety and privacy settings on Instagram, and are aware of the more private settings available, we’re sending new notifications encouraging them to update their settings to a more private experience with a single tap. If teens choose to “Turn on recommended settings”, we will automatically change their settings to restrict who can repost their content, tag or mention them, or include their content in Reels Remixes. We’ll also ensure only their followers can message them and help hide offensive comments.', '', 'Learn more aboutInstagram teen privacy and safety settingsandMeta’s teen privacy and safety settings.', '']\n",
            "6 ['Update on January 30, 2024 at 8:10AM PT:', 'We’re providing an update on the efficacy of our work enforcing our child safety policies.', 'Originally published on December 1, 2023:', 'Preventing child exploitation is one of the most important challenges facing our industry today. Online predators are determined criminals who use multiple apps and websites to target young people. They also test each platform’s defenses, and they learn to quickly adapt. That’s why now, as much as ever, we’re working hard to stay ahead. In addition to developing technology that roots out predators, we hire specialists dedicated to online child safety and we share information with our industry peers and law enforcement.', 'We take recent allegations about the effectiveness of our work very seriously, and we created a task force to review existing policies; examine technology and enforcement systems we have in place; and make changes that strengthen our protections for young people, ban predators, and remove the networks they use to connect with one another. The task force took immediate steps to strengthen our protections, and our child safety teams continue to work on additional measures. Today, we’re sharing an overview of the task force’s efforts to date.', 'Meta’s Child Safety Task Force focused on three areas:Recommendations and Discovery, Restricting Potential Predators and Removing Their Networks, and Strengthening Our Enforcement.', 'We make recommendations in places like Reels and Instagram Explore to help people discover new things on our apps, and people use features like Search and Hashtags to find things they might be interested in. Given we’re making suggestions to people in these places, we have protections in place to help ensure we don’t suggest something that may be upsetting or that may break our rules. We have sophisticated systems that proactively find, remove, or refrain from suggesting content, groups and pages, among other things, that break our rules or that may be inappropriate to recommend to people. Our Child Safety Task Force improved these systems by combining them and expanding their capabilities. This work is ongoing, and we expect it to come into effect fully in the coming weeks.', 'Here’s what we did:', 'We’ve developed technology that identifiespotentially suspicious adults, and we review more than 60 different signals to find these adults, such as if a teen blocks or reports an adult, or if someone repeatedly searches for terms that may suggest suspicious behavior. We already use this technology to limit potentially suspicious adults from finding, following or interacting with teens, and we’ve expanded it to prevent these adults from finding, following or interacting with one another.', 'Here’s what we did:', 'The task force also made a series of updates to strengthen our reporting and enforcement systems, and found new ways to root out and ban potentially predatory accounts.In August 2023 alone, we disabled more than 500,000 accounts for violating our child sexual exploitation policies.']\n",
            "7 ['My daughter was 12 years old when we gave her her first phone. It wasn’t an easy decision, and I agonized over whether it was the right time. As a former teacher, advisor to a state attorney general, and now an executive at Meta — I’ve dedicated my career to protecting children online. You’d think I would be confident of the right rules and guardrails to put in place for my daughter, but I worried all the same.', 'Being a parent is hard. Parents have always had the constant worry of how their children are doing in school, on the playground, on the sports field, but today’s generation of parents have a whole new world to navigate with their children: their online lives. I think about these challenges every day as we work to develop safe, positive experiences for young people on apps like Instagram, and as we think about making things simpler for parents.', 'Parents want to be involved in their teen’s online lives, and recent Pew research suggests that 81% of US adults support requiring parental consent for teens to create a social media account. But technology is constantly changing and keeping up with all the apps teens use can feel impossible. As an industry, we should come together with lawmakers to create simple, efficient ways for parents to oversee their teens’ online experiences.', 'Technology companies are developing distinct, age-appropriate experiences for teens, while lawmakers consider new legislation designed to protect their safety and privacy online. Legislation is needed so all apps teens use can be held to the same standard. But what’s happening is much more complicated than that.', 'US states are passing a patchwork of different laws, many of which require teens (of varying ages) to get their parent’s approval to use certain apps, and for everyone to verify their age to access them. Teens move interchangeably between many websites and apps, and social media laws that hold different platforms to different standards in different states will mean teens are inconsistently protected.', 'Why does this affect parents? If laws are passed as written, every time your teen wants to sign up for an app (assuming the app follows the rules) you will need to go through different methods to sign up, provide your and your teen’s potentially sensitive identification information to apps with inconsistent security and privacy practices, and repeat that process over and over again.', 'There’s a better way. Parents should approve their teen’s app downloads, and we support federal legislation that requires app stores to get parents’ approval whenever their teens under 16 download apps. With this solution, when a teen wants to download an app, app stores would be required to notify their parents, much like when parents are notified if their teen attempts to make a purchase. Parents can decide if they want to approve the download. They can also verify the age of their teen when setting up their phone, negating the need for everyone to verify their age multiple times across multiple apps.', 'This way parents can oversee and approve their teen’s online activity in one place. They can ensure their teens are not accessing adult content or apps, or apps they just don’t want their teens to use. And where apps like ours offer age-appropriate features and settings, parents can help ensure their teens use them.', 'This solution also helps to preserve privacy. By verifying a teen’s age on the app store, individual apps would not be required to collect potentially sensitive identifying information. Apps would only need the age from the app store to ensure teens are placed in the right experiences for their age group. Parents and teens won’t need to provide the hundreds of apps their teens use with sensitive information like government IDs.', 'The best way to help support parents and young people is a simple, industry-wide solution where all apps are held to the same, consistent standard. We are working with our industry peers and lawmakers directly to advocate for this concept, and to ease the burden on parents.']\n",
            "8 ['Protecting children online is one of the most important challenges facing the technology industry today. At Meta, we want young people to have safe, positive experiences online and we’ve spent a decade developing tools and policies designed to protect them. As a result, we find and report more child sexual abuse material to the National Center for Missing & Exploited Children (NCMEC) than any other service today.', 'Many in our industry recognize the need to work together to protect children and stop predators. We use technology likeMicrosoft’s PhotoDNAandMeta’s PDQto stop the spread of child sexual abuse material (CSAM) on the internet, but we need additional solutions to stop predators from using different apps and websites to target children.', 'Predators don’t limit their attempts to harm children to individual platforms. They use multiple apps and websites and adapt their tactics across them all to avoid detection. When a predator is discovered and removed from a site for breaking its rules, they may head to one of the many other apps or websites they use to target children.', 'This is behavior experts in online child safety understand well, and something we knew we could do more to address with our peers, so we worked with our partners at the Tech Coalition to establish Lantern. As described in theTech Coalition’s announcement today, Lantern enables technology companies to share a variety of signals about accounts and behaviors that violate their child safety policies. Lantern participants can use this information to conduct investigations on their own platforms and take action.', 'Meta was a founding member of Lantern. We provided the Tech Coalition with the technical infrastructure that sits behind the program and encouraged our industry partners to use it. We manage and oversee the technology with the Tech Coalition, ensuring it is simple to use and provides our partners with the information they need to track down potential predators on their own platforms.', 'One example of Lantern’s value is an investigation Meta conducted following information provided by Lantern partner MEGA during the program’s pilot phase. MEGA shared URLs with Lantern that they had previously removed for violating their child safety policies. Meta’s specialist child safety team used this information to conduct a wider investigation into potentially violating behaviors related to these URLs on our platforms. The team removed over 10,000 violating Facebook Profiles, Pages and Instagram accounts in the course of the investigation. In accordance with our legal obligations, we reported the violating profiles, pages and accounts to NCMEC. In addition, we shared details of our investigation back to Lantern, enabling participating companies to use the signals to conduct their own investigations.', 'We’re glad to partner with the Tech Coalition and our peers on the Lantern program, and we hope others in the industry will join us to expand this important work.']\n",
            "9 ['Hebrew translation,Arabic translation', 'Update on December 7, 2023 at 3:00AM PT:', 'Today Meta’s Oversight Boardannouncedit has selected two cases from user appeals related to the Israel-Hamas War forexpedited review, a process by which the board issues accelerated content decisions within 30 days in exceptional circumstances.The Oversight Board’s guidance in these cases, along with feedback from other experts, will help us to continue to evolve our policies and response to the ongoing Israel-Hamas War.We will implement the board’s decision in each case once it has finished deliberating and will update ourTransparency Centeraccordingly.', 'Update on December 5, 2023 at 9:00PM PT:', 'At the beginning of the war, we designated the October 7 attack by Hamas as a Terrorist Attack under ourDangerous Organization and Individualspolicy. Consistent with that designation, we removed all content showing identifiable victims at the moment of the attack.', 'Following that, people began sharing this type of footage in order to raise awareness and condemn the attacks. Meta’sgoalis to allow people to express themselves while still removing harmful content. In turn, we began allowing people to post this type of footage within that context only, with the addition of a warning screen to inform users that it may be disturbing. If the user’s intent in sharing the content is unclear, we err on the side of safety and remove it.', 'Under ourDangerous Organizations and Individuals policy, we continue to remove any imagery that is produced by a Dangerous Organization or Individual, unless it is clear that the user is sharing it in a news reporting or condemnation context, andno minorsunder thirteen years old are depicted.', 'Update on October 18, 2023 at 3:00AM PT:', 'After the terrorist attack by Hamas against Israel last week, and Israel’s response in Gaza, our teams introduced a series of measures to address the spike in harmful and potentially harmful content spreading on our platforms. Our policies are designed to keep people safe on our apps while giving everyone a voice. We apply these policies equally around the world and there is no truth to the suggestion that we are deliberately suppressing voice. However, content containing praise for Hamas, which is designated by Meta as aDangerous Organization, or violent and graphic content, for example, is not allowed on our platforms. We can make errors and that is why we offer an appeals process for people to tell us when they think we have made the wrong decision, so we can look into it.', 'Some additional updates and steps we are taking as this situation continues to unfold:', 'Fixing Bugs:We identified and fixed some bugs this past week.', 'Comment and Profile Settings:', 'Fundraising on Facebook and Instagram:Since October 7, people have raised more than $11.5 million for nonprofits on Facebook and Instagram to help with relief efforts in Israel and Palestine. This includes over 340,000 donations to 262 charities – providing disaster relief, ambulance and blood services, medical care and more.', 'Originally published on October 13, 2023 at 1:00AM PT:', 'Like many, we were shocked and horrified by the brutal terrorist attacks by Hamas, and our thoughts go out to civilians who are suffering in Israel and Gaza as the violence continues to unfold.', 'Since the terrorist attacks by Hamas on Israel on Saturday, and Israel’s response in Gaza, expert teams from across our company have been working around the clock to monitor our platforms, while protecting people’s ability to use our apps to shed light on important developments happening on the ground. The following are some of the specific steps we have taken:', 'We continue to providetoolsto help people control their experience on our apps and protect themselves from content they don’t want to see. These include, but aren’t limited to:', 'עדכון מה-7 בדצמבר, 2023 בשעה 3:00 (שעון החוף המערבי):', 'היום, המועצה המפקחת (Oversight Board) על Meta הודיעה שהיא בחרהלבחינה מזורזתשני מקרים הקשורים למלחמת ישראל-חמאס, מתוך ערעורים שמשתמשים הגישו\\xa0 – הליך במסגרתו המועצה מגישה החלטות מואצות בנושאי תוכן בתוך 30 יום, בנסיבות מיוחדות. הקווים המנחים שתספק המועצה המפקחת במקרים אלו, לצד המשוב ממומחים, יעזרו לנו להמשיך ולפתח את המדיניות שלנו, ואת התגובה שלנו למלחמת ישראל-חמאס. אנחנו ניישם את החלטת המועצה בכל אחד מהמקרים כאשר תסתיים הבחינה, ונעדכן את מרכז השקיפות שלנו בהתאם.', 'עדכון מה-5 בדצמבר, 2023 בשעה 9:00 (שעון החוף המערבי):', 'עם תחילת המלחמה, הגדרנו את מתקפת ה-7 באוקטובר של חמאס כמתקפת טרור, בהתאם למדיניות שלנו לגביארגונים ואנשים מסוכנים. בהתאם להגדרה זו, הסרנו את כל התוכן שמראה קורבנות שניתן לזהות מרגעי התקיפה.', 'בעקבות כך, אנשים החלו לשתף תיעודים כאלו על מנת להעלות את המודעות ולגנות את המתקפות.מטרתהשל Meta היא לאפשר לאנשים לבטא את עצמם, לצד הסרה של תוכן פוגעני. בהמשך, התחלנו לאפשר לאנשים לפרסם תיעודים אלו בתוך ההקשר הזה בלבד, בנוסף לאזהרה על המסך שתיידע משתמשים שתכנים אלו עלולים להיות מטרידים. אם הכוונה של המשתמש בשיתוף התוכן לא ברורה, בחרנו בצד של הבטיחות – והסרנו אותו.', 'בהתאםלמדיניותשלנו, אנחנו ממשיכים להסיר כל תיעוד המופק על ידי ארגונים ואנשים מסוכנים, אלא אם ברור שהמשתמש משתף את התוכן כדיווח חדשותי, או בהקשר של גינוי – כל עודקטיניםמתחת לגיל 13 אינם מוצגים בו.', 'פוסט מהניוז רום 18/10', 'לאחר מתקפת הטרור של חמאס נגד ישראל בשבוע שעבר, והתגובה של ישראל בעזה, הצגנו מספר שינויים, במטרה לתת מענה לעלייה החדה בכמות התכנים הפוגעניים והתכנים שעשויים להיות פוגעניים המופצים על הפלטפורמות שלנו.', 'המדיניות שלנו נבנתה בצורה כזו, שמצד אחד תשמור על בטיחותם של אנשים על הפלטפורמה שלנו ומצד שני תאפשר להם להשמיע את קולם.', 'מדיניות זו חלה באופן שווה בכל העולם, ואין אמת בטענה שאנחנו משתיקים קולות באופן מכוון.', 'למרות זאת, תוכן שמשבח את החמאס, שהוגדר על ידי Meta כארגון מסוכן, או תוכן אלים וכזה שמציג אלימות בצורה גרפית, לדוגמה, אסור על הפלטפורמות שלנו. אנחנו עלולים לעשות טעויות וזו הסיבה שאנחנו מאפשרים תהליכי ערעור, כדי שאנשים יוכלו להגיד לנו אם הם חושבים שקיבלנו החלטה לא נכונה ונוכל לבדוק זאת בצורה מעמיקה יותר.', 'כמה עדכונים וצעדים נוספים שאנחנו לוקחים תוך כדי התפתחות המצב –', 'תיקון תקלות (באגים) – זיהינו ותיקנו כמה באגים בשבוע האחרון.', 'תגובות והגדרות פרופיל –', 'גיוס תרומות בפייסבוק ואינסטגרם –', 'מאז ה7/10, אנשים גייסו יותר מ11.5 מיליון דולר לעמותות בפייסבוק ובאינסטגרם כדי לסייע למאמצי הסיוע בישראל ובעזה. הסכום הזה כולל למעלה מ-340,000 תרומות ל-262 ארגוני סיוע – שמאפשרים סיוע באסון, אמבולנסים, תרומות דם, ציוד רפואי ועוד.', '', 'עדכון על הפעולות שאנחנו נוקטים בהן סביב מלחמת ישראל – חמאס', 'כמו רבים מכם, גם אנחנו המומים ומזועזעים לנוכח מתקפת הטרור הברוטלית של חמאס, ומחשבותינו נמצאות עם התושבים הסובלים מהאלימות המתמשכת.', 'מאז החלו התקפות הטרור של חמאס על ישראל ביום שבת ותגובתה של ישראל בעזה, צוותי מומחים שלנו מרחבי החברה עובדים מסביב לשעון על מנת לנטר את המתרחש על הפלטפורמות במטרה להגן על יכולתם של אנשים לעשות שימוש באפליקציות שלנו ולשפוך אור על ההתרחשויות בשטח.', 'להלן כמה מהצעדים בהם נקטנו:', 'מאבק בהפצת תוכן פוגעני', 'ביטחון ובטיחות', 'צמצום של התפשטות המידע המטעה', 'כלי בקרה', 'אנו ממשיכים להציע כלים ויכולות המסייעים לאנשים לשלוט בחוויה שלהם באפליקציות שלנו, ולהגן על עצמם מפני תוכן שהם אינם מעוניינים לראות. בין כלים אלה, ניתן למצוא את הבאים:', '', 'تحديث بتاريخ 5 ديسمبر 2023، الساعة 9:00 مساءً بتوقيت المحيط الهادئ:', 'في بداية الحرب، قمنا بتصنيف هجوم حماس في السابع من أكتوبر كهجوم إرهابي بموجب سياستنا بشأنالمنظمات الخطرة والأفراد الخطرين. وتماشيًا مع هذا التصنيف، أزلنا كل المحتوى الذي يتضمن صورًا أو مقاطع فيديو لضحايا يمكن التعرف عليهم في لحظة الهجوم.', 'في أعقاب ذلك، بدأ الأشخاص مشاركة هذا النوع من المحتوى بهدف تعزيز الوعي وإدانة الهجمات. ويتمثلهدفMeta في السماح للأشخاص بالتعبير عن أنفسهم وإزالة المحتوى الضار في الوقت ذاته. ومن هذا المنطلق، بدأنا السماح للأشخاص بنشر هذا النوع من المحتوى ولكن فقط في هذا السياق، مع إضافة شاشة تحذيرية لإخبار المستخدمين بأن المحتوى قد يكون مزعجًا للبعض. وما لم تكن نية المستخدم من نشر المحتوى واضحة، ننحاز إلى جانب السلامة ونزيل هذا المحتوى.', 'بموجبسياسة المنظمات الخطرة والأفراد الخطرينالتي نتبعها، نواصل إزالة أي صور أو مقاطع فيديو من إنتاج المنظمات الخطرة والأفراد الخطرين، إلا إذا كان من الواضح أن المستخدم يشاركها في إطار تقديم التقارير الإخبارية أو في سياق الإدانة، بشرطعدم ظهور قاصرينأقل من ثلاثة عشر عامًا في الصور أو مقاطع الفيديو.', 'تحديث بتاريخ 7 ديسمبر 2023، الساعة 3:00 صباحًا بتوقيت المحيط الهادئ:', 'أعلن مجلس الإشراف الذي يتولى الإشراف على شركة Meta تحديد حالتين من الطعون المقدمة من المستخدمين بشأن الحرب بين إسرائيل وحماس لإجراءمراجعة عاجلة، وهي عملية يُصدِر المجلس من خلالها قرارات سريعة بشأن المحتوى في غضون 30 يومًا في الظروف الاستثنائية.إن إرشادات المجلس في هذه الحالات، إلى جانب ملاحظات الخبراء الآخرين، من شأنها مساعدتنا على مواصلة الارتقاء بسياساتنا واستجابتنا للحرب الدائرة بين إسرائيل وحماس.وسنقوم بتنفيذ قرار المجلس في كل حالة من الحالات بمجرد أن ينتهي من مداولاته وسنقوم بتحديث مركز الشفافية الخاص بنا وفقًا لذلك.', 'منذ بداية الهجمات الإرهابية التي شنتها حماس على إسرائيل يوم السبت، ورد الفعل من إسرائيل على غزة، شرعت فرقنا في تقديم سلسلة من الإجراءات التي من شأنها معالجة ارتفاع معدل المحتوى الضار والمحتوى الذي يُحتمل أن يكون ضارًا المنتشر على منصاتنا. لقد تم تصميم سياساتنا للحفاظ على سلامة الأشخاص عبر تطبيقاتنا مع منح الجميع القدرة على التعبير عن آرائهم. نحن نحرص على تطبيق هذه السياسات بصورة متساوية في جميع أنحاء العالم وبالتالي لا صحة للتلميح بأننا نقوم بقمع القدرة على التعبير عمدًا. ولكننا، لا نسمح بالمحتوى الذي يتضمن إشادة بحماس، حيث تم تصنيفها على أنهامنظمة خطرةمن قبل Meta أو بالمحتوى العنيف والصادم، مثلاً، على منصاتنا. قد نرتكب أخطاء ولهذا نوفر للأشخاص عملية تقديم الطعون لإخبارنا عندما يعتقدون أننا اتخذنا قرارًا خاطئًا، حتى نتمكن من التحقق من الأمر.', 'نحن بصدد إجراء بعض التحديثات واتخاذ خطوات إضافية مع استمرار توالي فصول هذا الوضع:', '.تصحيح الأخطاء:لقد تمكنا من تحديد بعض الأخطاء وإصلاحها خلال الأسبوع الماضي', 'التعليق وإعدادات الملف الشخصي:', 'حملات جمع التبرعات على فيسبوك وInstagram:منذ 7 أكتوبر، بادر الأشخاص بجمع ما يزيد عن 11.5 مليون دولار للمنظمات غير الهادفة للربح على فيسبوك وInstagram للمساعدة في جهود الإغاثة في إسرائيل وفلسطين. ويشمل ذلك أكثر من 340 ألف تبرع لـ 262 مؤسسة خيرية – تقدم الإغاثة لمنكوبي الكوارث وخدمات الإسعاف والدم والرعاية الطبية وغير ذلك المزيد.', 'جهود Meta المستمرة فيما يتعلق بالحرب بين إسرائيل وحماس', 'شأننا شأن الكثيرين، شعرنا بالصدمة والرعب إزاء الهجمات الإرهابية الغاشمة التي شنتها حماس، وقلوبنا مع المدنيين الذين يعانون في إسرائيل وغزة مع استمرار أحداث العنف.', 'منذ بداية الهجمات الإرهابية التي شنتها حماس على إسرائيل يوم السبت، ورد الفعل من إسرائيل على غزة، تعمل فرق الخبراء في كل قطاعات شركتنا على مدار الساعة لمراقبة منصاتنا، والحفاظ على قدرة الأشخاص في استخدام تطبيقاتنا لتسليط الضوء على التطورات المهمة التي تحدث على أرض الواقع. وفيما يلي بعض الخطوات المحددة التي اتخذناها:', 'اتخاذ الإجراءات اللازمة بشأن المحتوى المخالف', 'السلامة والأمن', 'الحد من انتشار المعلومات المضللة', 'عناصر تحكم المستخدم', 'نواصل توفيرالأدواتلمساعدة الأشخاص على التحكم في تجربتهم على تطبيقاتنا وحماية أنفسهم من المحتوى الذي لا يريدون رؤيته. وتشمل هذه، على سبيل المثال لا الحصر:']\n",
            "10 ['Today, we’re introducing Instagram Teen Accounts, a new experience for teens, guided by parents. Teen Accounts have built-in protections which limit who can contact them and the content they see, and also provide new ways for teens to explore their interests. We’ll automatically place teens into Teen Accounts, and teens under 16 will need a parent’s permission to change any of these settings to be less strict.', 'We know parents want to feel confident that their teens can use social media to connect with their friends and explore their interests, without having to worry about unsafe or inappropriate experiences. We understand parents’ concerns, and that’s why we’re reimagining our apps for teens with new Teen Accounts. This new experience is designed to better support parents, and give them peace of mind that their teens are safe with the right protections in place. Teens will also get access to a new feature, made just for them, that lets them select topics they want to see more of in Explore and their recommendations so they can focus on the fun, positive content they love.', '', 'We developed Teen Accounts with parents and teens in mind. The new Teen Account protections are designed to address parents’ biggest concerns, including who their teens are talking to online, the content they’re seeing and whether their time is being well spent. These protections are turned on automatically, and parents decide if teens under 16 can change any of these settings to be less strict:', '', '“Given that parents today are grappling with the benefits and challenges of the internet and digital media for their teens, our association applauds Meta for launching Instagram Teen Accounts. With teens automatically placed in Teen Accounts and certain privacy settings turned on by default, this update demonstrates that Meta is taking steps to empower parents and deliver safer, more age-appropriate experiences on the platform.”', '– Yvonne Johnson, President, National PTA', 'Teens under 16 will need their parent’s permission to use less protective settings. To get permission, teens will need to set up parental supervision on Instagram. If parents want more oversight over their older teen’s (16+) experiences, they simply have to turn on parental supervision. Then, they can approve any changes to these settings, irrespective of their teen’s age.', 'Once supervision is established, parents can approve and deny their teens’ requests to change settings or allow teens to manage their settings themselves. Soon, parents will also be able to change these settings directly to be more protective. Learn more abouthow to manage Teen Accounts.', '“Instagram Teen Accounts reflect the importance of tailoring teens’ online experiences to their developmental stages, and implementing appropriate protections. Younger adolescents are more vulnerable as their skills are still emerging and require additional safeguards and protection. Overall, the settings are age-specific, with younger and older teens being offered different protections.”', '– Rachel Rodgers, PhD Associate Professor of Applied Psychology, Northeastern University', 'While Teen Accounts put new protections in place automatically, many parents want to be even more involved in their teen’s experiences, so we’re also adding to oursupervision feature.Updates include ways to:', '', 'Teens may lie about their age and that’s why we’re requiring them toverify their agein more places, like if they attempt to use a new account with an adult birthday. We’re also building technology to proactively find accounts belonging to teens, even if the account lists an adult birthday. This technology will allow us to proactively find these teens and place them in the same protections offered by Teen Account settings. We’ll start testing this change in the US early next year. You can read more about those detailshere.', 'We recognize parents are concerned that their teens might see mature or inappropriate content online, which is why we have stricter rules around the kinds of content teens see on our apps. We remove content that breaks our rules and avoid recommending potentially sensitive content – such as sexually suggestive content or content discussing suicide or self-harm. With Instagram Teen Accounts, teens will be placed into the strictest setting of our sensitive content control, so they’re even less likely to be recommendedsensitive content, and in many cases wehide this content altogetherfrom teens, even if it’s shared by someone they follow.', '“It’s important that safety and privacy protections are the default settings, both to improve teens’ online experience and to reduce some of the burden that has fallen to parents. We look forward to hearing from teens about their experience of these new Teen Accounts and associated features and settings.”', '– Dr. Megan Moreno, Co-Medical Director of the SAMHSA-Funded AAP Center of Excellence on Social Media and Youth Mental Health', 'Today, we’ll start placing teens who sign up for Instagram into Teen Accounts, and we’ll notify teens already using Instagram about these changes so we can begin moving them into Teen Accounts next week.', 'We plan to place teens into Teen Accounts within 60 days in the US, UK, Canada and Australia, and to start placing them in Teen Accounts in the European Union later this year. Teens around the world will start to get Teen Accounts in January. We’ll also bring Teen Accounts to other Meta platforms next year. These are big updates that will change the Instagram experience for millions of teens, and we need to make sure they work correctly.', '“These updates to Instagram’s Teen Accounts offer a balanced approach, empowering parents with essential oversight while respecting teens’ right to participate and explore. In an ever-evolving online world, this update ensures that young people can engage meaningfully and safely, fostering positive connections while still providing the protection they need.”', '– Lucy Thomas OAM, CEO & Co-Founder, Project Rockit']\n",
            "11 ['Suicide and self-harm are complex mental health issues that can have devastating consequences. At Meta, we’ve worked with experts for years – including our suicide and self-harm advisory group and members of Meta’s own safety teams – to develop an informed and thoughtful approach to suicide and self harm content shared on our apps.', 'Yet, like many other types of potentially problematic content, suicide and self-harm content is not limited to any one platform. To be truly effective in responding to this content, tech companies need to work together. That’s why we’ve worked with theMental Health Coalitionto establish Thrive, the first signal sharing program to share signals about violating suicide and self-harm content.', 'Through Thrive, participating tech companies will be able to share signals about violating suicide or self-harm content so that other companies can investigate and take action if the same or similar content is being shared on their platforms. Meta is providing the technical infrastructure that underpins Thrive – the same technology we provide to theTech Coalition’s Lantern program– which enables signals to be shared securely.', 'Participating companies will start by sharing hashes – numerical codes that correspond to violating content – of images and videos showing graphic suicide and self-harm, and of content depicting or encouraging viral suicide or self-harm challenges. We’re prioritizing this content because of its propensity to spread across different platforms quickly. These initial signals represent content only, and will not include identifiable information about any accounts or individuals.', 'Thrive builds on the work we already do at Meta to remove harmful content that shows graphic imagery or encourages suicide or self-harm, while still giving space for people to talk about their own experiences. We also provide support to those sharing and searching for content related to suicide or self-harm by connecting them to local organizations around the world, including Suicide and Crisis Lifeline and Crisis Text Line in the US.', 'Between April and June this year,we took actionon over 12 million pieces of suicide and self-harm content on Facebook and Instagram. While we allow people to discuss their experiences with suicide and self-harm – as long as it’s not graphic or promotional – this year we’ve takenimportant stepsto make this content harder to find in Search and to hide it completely from teens, even if it’s shared by someone they follow.', 'Thrive will help keep people safe not just on Meta’s apps, but across all the apps and services they use. We’re proud to work with the Mental Health Coalition and our industry partners Snap and TikTok on this vital work.']\n",
            "12 ['Financial sextortion is a horrific crime that can have devastating consequences. Our teams have deep experience in fighting this crime and work closely with experts to recognize the tactics scammers use, understand how they evolve and develop effective ways to help stop them. Like many crimes, financial sextortion crosses borders, and over recent years there’s been a growing trend of scammers — largely driven by cybercriminals known as Yahoo Boys — targeting people across the internet, both with these and other types of scams. We’ve banned Yahoo Boys under Meta’sDangerous Organizations and Individuals policy— one of our strictest policies — which means we remove Yahoo Boys’ accounts engaged in this criminal activity whenever we become aware of them.', 'Following our recentQ1 2024 Adversarial Threat Report, today we are announcing the strategic network disruption of two sets of accounts in Nigeria that were affiliated with Yahoo Boys and were attempting to engage in financial sextortion scams.', 'First, we removed around 63,000 Instagram accounts in Nigeria that attempted to directly engage in financial sextortion scams.These included a smaller coordinated network of around 2,500 accounts that we were able to link to a group of around 20 individuals. They targeted primarily adult men in the US and used fake accounts to mask their identities.', 'We found the coordinated network of around 2,500 accounts through a combination ofnew technical signals we’ve developedto help identify sextorters and in-depth investigations by our expert teams. The majority of these accounts had already been detected and disabled by our enforcement systems, and this investigation allowed us to remove the remaining accounts and understand more about the techniques being used to improve our automated detection.', 'While our investigation showed that the majority of these scammers’ attempts were unsuccessful and mostly targeted adults, we did see some also attempt to target minors, and we’ve reported those accounts to the National Center for Missing and Exploited Children (NCMEC). Since these criminals don’t limit themselves to any one platform, we also share relevant information with other tech companies through theTech Coalition’s Lantern program, so they can take action too.', 'Applying lessons learned from taking down terrorist groups and coordinated inauthentic behavior, we used our identification of this coordinated network to help us identify more accounts in Nigeria that were attempting to engage in similar sextortion scams, bringing the total to around 63,000 accounts removed.', 'Second, we removed around 7,200 assets, including 1,300 Facebook accounts, 200 Facebook Pages and 5,700 Facebook Groups, also based in Nigeria, that were providing tips for conducting scams.Their efforts included offering to sell scripts and guides to use when scamming people, and sharing links to collections of photos to use when populating fake accounts.', 'Since this disruption, our systems have been identifying and automatically blocking attempts from these groups to come back, and we continue to strengthen those systems to make them as effective as possible. We’ve also used the new tactics we observed to further improve our ability to detect accounts, Groups and Pages engaging in this activity.', 'While these investigations and disruptions are critical, they’re just one part of our approach. We continue to support law enforcement in investigating and prosecuting these crimes, including by responding to valid legal requests for information and by alerting them when we become aware of someone at risk of imminent harm, in accordance with our terms of service and applicable law. We also fund and support NCMEC and the International Justice Mission to runProject Boost, a program that trains law enforcement agencies around the world in processing and acting on NCMEC reports. We’ve conducted several training sessions so far, including in Nigeria and the Cote d’Ivoire, with our most recent session taking place just last month.', 'We also want to help people recognize and avoid these scams, while making it as difficult as possible for the criminals behind them to succeed. It’s why we default teens under 16 (under 18 in certain countries) into stricter message settings so they can’t be messaged by anyone — even other teens — they’re not connected to, and showSafety Noticesencouraging them to be cautious.', '', 'We also recently announced that we’ve developednew signals to identify accounts that arepotentiallyengaging in sextortion,and are taking steps to help prevent these accounts from finding and interacting with teens. Finally, we’ve started testingour on-device nudity protection featurein Instagram DMs, which will blur images detected as containing nudity, encourage people to be cautious when sending sensitive images and direct people to safety tips and resources, including NCMEC’sTake It Downplatform.', '', 'This is an adversarial space where criminals evolve to evade our ever-improving defenses. We will continue to focus on understanding how they operate so we can stay one step ahead, and will continue our vital cooperation with child safety experts, law enforcement and the tech industry to help disrupt these criminals across all the platforms they use.']\n",
            "13 ['Financial sextortionis a horrific crime. We’ve spent years working closely with experts, including those experienced in fighting these crimes, to understand the tactics scammers use to find and extort victims online, so we can develop effective ways to help stop them.', 'Today, we’re sharing an overview of our latest work to tackle these crimes. This includes new tools we’re testing to help protect people from sextortion and other forms of intimate image abuse, and to make it as hard as possible for scammers to find potential targets – on Meta’s apps and across the internet. We’re also testing new measures to support young people in recognizing and protecting themselves from sextortion scams.', 'These updates build on our longstanding work to help protect young people from unwanted or potentially harmful contact. Wedefault teens into stricter message settingsso they can’t be messaged by anyone they’re not already connected to, showSafety Noticesto teens who are already in contact with potential scam accounts, and offer a dedicated option for people to report DMs that are threatening to share private images. We alsosupportedthe National Center for Missing and Exploited Children (NCMEC) in developingTake It Down, a platform that lets young people take back control of their intimate images and helps prevent them being shared online – taking power away from scammers.', 'While people overwhelmingly use DMs to share what they love with their friends, family or favorite creators, sextortion scammers may also use private messages to share or ask for intimate images. To help address this, we’ll soon start testing our new nudity protection feature in Instagram DMs, which blurs images detected as containing nudity and encourages people to think twice before sending nude images. This feature is designed not only to protect people from seeing unwanted nudity in their DMs, but also to protect them from scammers who may send nude images to trick people into sending their own images in return.', 'Nudity protection will be turned on by default for teens under 18 globally, and we’ll show a notification to adults encouraging them to turn it on.', 'When nudity protection is turned on, people sending images containing nudity will see a message reminding them to be cautious when sending sensitive photos, and that they can unsend these photos if they’ve changed their mind.', '', 'Anyone who tries to forward a nude image they’ve received will see a message encouraging them to reconsider.', '', 'When someone receives an image containing nudity, it will be automatically blurred under a warning screen, meaning the recipient isn’t confronted with a nude image and they can choose whether or not to view it. We’ll also show them a message encouraging them not to feel pressure to respond, with an option to block the sender and report the chat.', 'This slideshow requires JavaScript.', 'When sending or receiving these images, people will be directed to safety tips, developed with guidance from experts, about the potential risks involved. These tips include reminders that people may screenshot or forward images without your knowledge, that your relationship to the person may change in the future, and that you should review profiles carefully in case they’re not who they say they are. They also link to a range of resources, includingMeta’s Safety Center,support helplines,StopNCII.orgfor those over 18, andTake It Downfor those under 18.', 'This slideshow requires JavaScript.', 'Nudity protection uses on-device machine learning to analyze whether an image sent in a DM on Instagram contains nudity. Because the images are analyzed on the device itself, nudity protection will work in end-to-end encrypted chats, where Meta won’t have access to these images – unless someone chooses to report them to us.', '“Companies have a responsibility to ensure the protection of minors who use their platforms. Meta’s proposed device-side safety measures within its encrypted environment is encouraging. We are hopeful these new measures will increase reporting by minors and curb the circulation of online child exploitation.”–John Shehan, Senior Vice President, National Center for Missing & Exploited Children.', '“As an educator, parent, and researcher on adolescent online behavior, I applaud Meta’s new feature that handles the exchange of personal nude content in a thoughtful, nuanced, and appropriate way. It reduces unwanted exposure to potentially traumatic images, gently introduces cognitive dissonance to those who may be open to sharing nudes, and educates people about the potential downsides involved. Each of these should help decrease the incidence of sextortion and related harms, helping to keep young people safe online.” –Dr. Sameer Hinduja, Co-Director of theCyberbullying Research Centerand Faculty Associate at the Berkman Klein Center at Harvard University.', 'We take severe action when we become aware of people engaging in sextortion: we remove their account, take steps to prevent them from creating new ones and, where appropriate, report them to the NCMEC and law enforcement. Our expert teams also work to investigate and disrupt networks of these criminals, disable their accounts and report them to NCMEC and law enforcement – including several networks in the last year alone.', 'Now, we’re also developing technology to help identify where accounts maypotentiallybe engaging in sextortion scams, based on a range of signals that could indicate sextortion behavior. While these signals aren’t necessarily evidence that an account has broken our rules, we’re taking precautionary steps to help prevent these accounts from finding and interacting with teen accounts. This builds on thework we already doto prevent other potentially suspicious accounts from finding and interacting with teens.', 'One way we’re doing this is by making it even harder for potential sextortion accounts to message or interact with people. Now, any message requests potential sextortion accounts try to send will go straight to the recipient’s hidden requests folder, meaning they won’t be notified of the message and never have to see it. For those who are already chatting to potential scam or sextortion accounts, we showSafety Noticesencouraging them to report any threats to share their private images, and reminding them that they can say no to anything that makes them feel uncomfortable.', 'For teens, we’re going even further. We already restrict adults from starting DM chats with teens they’re not connected to, and in January we announcedstricter messaging defaults for teens under 16(under 18 in certain countries), meaning they can only be messaged by people they’re already connected to – no matter how old the sender is. Now, we won’t show the “Message” button on a teen’s profile to potential sextortion accounts, even if they’re already connected.We’re also testing hiding teens from these accounts in people’s follower, following and like lists, and making it harder for them to find teen accounts in Search results.', 'We’re testing new pop-up messages for people who may have interacted with an account we’ve removed for sextortion. The message will direct them to our expert-backed resources, including ourStop Sextortion Hub,support helplines, the option to reach out to a friend,StopNCII.orgfor those over 18, andTake It Downfor those under 18.', 'We’re also adding new child safety helplines from around the world into our in-app reporting flows. This means when teens report relevant issues – such as nudity, threats to share private images or sexual exploitation or solicitation – we’ll direct them to local child safety helplines where available.', 'In November, we announced we werefounding members of Lantern, a program run by the Tech Coalition that enables technology companies to share signals about accounts and behaviors that violate their child safety policies.', 'This industry cooperation is critical, because predators don’t limit themselves to just one platform – and the same is true of sextortion scammers. These criminals target victims across the different apps they use, often moving their conversations from one app to another. That’s why we’ve started to share more sextortion-specific signals to Lantern, to build on this important cooperation and try to stop sextortion scams not just on individual platforms, but across the whole internet.']\n",
            "14 ['Having a personal intimate image shared with others can be devastating, especially for young people. It can feel even worse when someone threatens to share it if you don’t give them more photos, sexual contact or money — a crime known as sextortion.', 'That’s why, this Safer Internet Day, we’re announcing new efforts to help combat this kind of criminal activity. These include giving more teens control over their intimate images, helping teens\\xa0 — and their parents and teachers\\xa0 — feel better equipped against those trying to exploit them, and supporting creators and safety organizations around the world as part of a global campaign to raise awareness of ways to prevent sextortion.', 'Take It Downis a program from NCMEC, supported by Meta, which is designed to help teens take back control of their intimate images and help prevent people — whether it’s scammers, ex-partners, or anyone else — from spreading them online.First launched last yearin English and Spanish, Meta and NCMEC are now expanding the platform to many more countries and languages, making it accessible to millions more teens around the world.', 'There are several ways people can use Take It Down to find and remove intimate imagery, or help prevent people sharing them in the first place:', 'Take It Down was designed to respect young people’s privacy and data security. To start the process, people can go toTakeItDown.NCMEC.organd follow the instructions to assign a unique hash — a digital fingerprint in the form of a numerical code — to their image or video, privately and securely from their own device.', 'Teens only need to submit the hash, rather than the intimate image or video itself, which never leaves their device. Once the hash has been submitted to NCMEC, companies like Meta can find copies of the image, take them down and help prevent anyone who’s threatening them from posting them in the future.', '“Making Take it Down available in 25 languages is a pivotal step towards safeguarding children from the horrors of online exploitation all over the world,” saidJohn Shehan, a Senior Vice President with the National Center for Missing & Exploited Children.“We aspire to ensure that every child, regardless of language or location, has the opportunity to reclaim their dignity and privacy by having their illicit content removed from participating platforms.”', '', 'Take It Down builds off of the success of platforms likeStopNCII, which helps prevent those seeking to exploit people from sharing adults’ intimate images online.', 'These moments can be upsetting and isolating, especially for young people, who may feel too scared to ask for help. That’s why we’ve worked withThorn, a nonprofit that builds technology to defend children from sexual abuse,todevelop updated guidancefor teens on how to take back control if someone is sextorting them. It also includes advice for parents and teachers on how to support their teens or students if they’re affected by these scams. The new resources can be found in ourupdated Sextortion hubwithinMeta’s Safety Center.', 'Kelbi Schnabel, Senior Manager at Thorn, said:“Our work with Meta to provide targeted, robust sextortion resources has helped Thorn significantly enhance our efforts in combating sextortion. Our joint initiative is already empowering parents and teens to understand the risks and take action, which is a testament to the power of collaborative action in tackling complex challenges like sextortion. The result of our collaboration underscores the importance of accessible, comprehensive resources in the digital era.”', 'To help make sure teens and parents everywhere know about these scams and what they can do to avoid them, Meta is launching a global campaign, supporting safety organizations and working with creators around the world to help raise awareness.', 'Today’s updates build on the work we already do to help young people know there are steps they can take if someone has shared, or is threatening to share, their intimate images. We show Safety Notices to people on Instagram when they’re messaging someone who has shown potentially scammy or suspicious behavior. These Safety Notices urge people to be cautious, encourage them to report any account that threatens to share their private images, and remind people that they can say no to anything that makes them feel uncomfortable. We also direct teens to Take It Down at relevant moments when using Facebook and Instagram, such as if they report someone for sharing their private images, for nudity, or for sexual exploitation.', '', 'And we work to help protect teens from unwanted contact in the first place. We default teens under 16 (and under 18 in certain countries) into private Instagram accounts when they sign up, which hides their follower and following lists, and we restrict adults over 19 from messaging minors who don’t follow them. Last month,we announcedstricter default message settings, meaning teens under 16 (and under 18 in certain countries) won’t receive messages from anyone they don’t follow or aren’t already connected to, providing more protection against potential scammers.']\n",
            "15 ['We want teens to have safe, age-appropriate experiences on our apps. We’ve developed more than 30 tools and resources to support teens and their parents, and we’ve spent over a decade developing policies and technology to address content that breaks our rules or could be seen as sensitive. Today, we’re announcing additional protections that are focused on the types of content teens see on Instagram and Facebook.', 'We regularly consult with experts in adolescent development, psychology and mental health to help make our platforms safe and age-appropriate for young people, including improving our understanding of which types of content may be less appropriate for teens.', 'Take the example of someone posting about their ongoing struggle with thoughts of self-harm. This is an important story, and can help destigmatize these issues, but it’s a complex topic and isn’t necessarily suitable for all young people. Now, we’ll start to remove this type of content from teens’ experiences on Instagram and Facebook, as well as other types of age-inappropriate content. We already aim not to recommend this type of content to teens in places like Reels and Explore, and with these changes, we’ll no longer show it to teens in Feed and Stories,even if it’s shared by someone they follow.', '“Meta is evolving its policies around content that could be more sensitive for teens, which is an important step in making social media platforms spaces where teens can connect and be creative in age-appropriate ways. These policies reflect current understandings and expert guidance regarding teen’s safety and well-being. As these changes unfold, they provide good opportunities for parents to talk with their teens about how to navigate difficult topics.” – Dr. Rachel Rodgers, Associate Professor, Department of Applied Psychology, Northeastern University', 'We want people to find support if they need it, so we will continue toshare resourcesfrom expert organizations like the National Alliance on Mental Illness when someone posts content related to their struggles with self-harm or eating disorders. We’re starting to roll these changes out to teens under 18 now and they’ll be fully in place on Instagram and Facebook in the coming months.', 'Here’s more detail on how today’s updates expand on our existing protections, in line with feedback from experts:', 'This slideshow requires JavaScript.', '“Parents want to be confident their teens are viewing content online that’s appropriate for their age. Paired with Meta’s parental supervision tools to help shape their teens’ experiences online, Meta’s new policies to hide content that might be less age-appropriate will give parents more peace of mind.” – Vicki Shotbolt, CEO, ParentZone.org', 'We’re automatically placing teens into the most restrictive content control setting on Instagram and Facebook. We already apply this setting for new teens when they join Instagram and Facebook, and are now expanding it to teens who are already using these apps. Our content recommendation controls – known as “Sensitive Content Control” on Instagram and “Reduce” on Facebook – make it more difficult for people to come across potentially sensitive content or accounts in places like Search and Explore.', '', '', 'While we allow people to share content discussing their own struggles with suicide, self-harm and eating disorders, our policy is not to recommend this content and we have been focused on ways to make it harder to find. Now, when people search for terms related to suicide, self-harm and eating disorders, we’ll start hiding these related results and will direct them to expert resources for help. We already hide results for suicide and self harm search terms that inherently break our rules and we’re extending this protection to include more terms. This update will roll out for everyone over the coming weeks.', '', 'To help make sure teens are regularly checking their safety and privacy settings on Instagram, and are aware of the more private settings available, we’re sending new notifications encouraging them to update their settings to a more private experience with a single tap. If teens choose to “Turn on recommended settings”, we will automatically change their settings to restrict who can repost their content, tag or mention them, or include their content in Reels Remixes. We’ll also ensure only their followers can message them and help hide offensive comments.', '', 'Learn more aboutInstagram teen privacy and safety settingsandMeta’s teen privacy and safety settings.', '']\n",
            "16 ['Update on January 30, 2024 at 8:10AM PT:', 'We’re providing an update on the efficacy of our work enforcing our child safety policies.', 'Originally published on December 1, 2023:', 'Preventing child exploitation is one of the most important challenges facing our industry today. Online predators are determined criminals who use multiple apps and websites to target young people. They also test each platform’s defenses, and they learn to quickly adapt. That’s why now, as much as ever, we’re working hard to stay ahead. In addition to developing technology that roots out predators, we hire specialists dedicated to online child safety and we share information with our industry peers and law enforcement.', 'We take recent allegations about the effectiveness of our work very seriously, and we created a task force to review existing policies; examine technology and enforcement systems we have in place; and make changes that strengthen our protections for young people, ban predators, and remove the networks they use to connect with one another. The task force took immediate steps to strengthen our protections, and our child safety teams continue to work on additional measures. Today, we’re sharing an overview of the task force’s efforts to date.', 'Meta’s Child Safety Task Force focused on three areas:Recommendations and Discovery, Restricting Potential Predators and Removing Their Networks, and Strengthening Our Enforcement.', 'We make recommendations in places like Reels and Instagram Explore to help people discover new things on our apps, and people use features like Search and Hashtags to find things they might be interested in. Given we’re making suggestions to people in these places, we have protections in place to help ensure we don’t suggest something that may be upsetting or that may break our rules. We have sophisticated systems that proactively find, remove, or refrain from suggesting content, groups and pages, among other things, that break our rules or that may be inappropriate to recommend to people. Our Child Safety Task Force improved these systems by combining them and expanding their capabilities. This work is ongoing, and we expect it to come into effect fully in the coming weeks.', 'Here’s what we did:', 'We’ve developed technology that identifiespotentially suspicious adults, and we review more than 60 different signals to find these adults, such as if a teen blocks or reports an adult, or if someone repeatedly searches for terms that may suggest suspicious behavior. We already use this technology to limit potentially suspicious adults from finding, following or interacting with teens, and we’ve expanded it to prevent these adults from finding, following or interacting with one another.', 'Here’s what we did:', 'The task force also made a series of updates to strengthen our reporting and enforcement systems, and found new ways to root out and ban potentially predatory accounts.In August 2023 alone, we disabled more than 500,000 accounts for violating our child sexual exploitation policies.']\n",
            "17 ['My daughter was 12 years old when we gave her her first phone. It wasn’t an easy decision, and I agonized over whether it was the right time. As a former teacher, advisor to a state attorney general, and now an executive at Meta — I’ve dedicated my career to protecting children online. You’d think I would be confident of the right rules and guardrails to put in place for my daughter, but I worried all the same.', 'Being a parent is hard. Parents have always had the constant worry of how their children are doing in school, on the playground, on the sports field, but today’s generation of parents have a whole new world to navigate with their children: their online lives. I think about these challenges every day as we work to develop safe, positive experiences for young people on apps like Instagram, and as we think about making things simpler for parents.', 'Parents want to be involved in their teen’s online lives, and recent Pew research suggests that 81% of US adults support requiring parental consent for teens to create a social media account. But technology is constantly changing and keeping up with all the apps teens use can feel impossible. As an industry, we should come together with lawmakers to create simple, efficient ways for parents to oversee their teens’ online experiences.', 'Technology companies are developing distinct, age-appropriate experiences for teens, while lawmakers consider new legislation designed to protect their safety and privacy online. Legislation is needed so all apps teens use can be held to the same standard. But what’s happening is much more complicated than that.', 'US states are passing a patchwork of different laws, many of which require teens (of varying ages) to get their parent’s approval to use certain apps, and for everyone to verify their age to access them. Teens move interchangeably between many websites and apps, and social media laws that hold different platforms to different standards in different states will mean teens are inconsistently protected.', 'Why does this affect parents? If laws are passed as written, every time your teen wants to sign up for an app (assuming the app follows the rules) you will need to go through different methods to sign up, provide your and your teen’s potentially sensitive identification information to apps with inconsistent security and privacy practices, and repeat that process over and over again.', 'There’s a better way. Parents should approve their teen’s app downloads, and we support federal legislation that requires app stores to get parents’ approval whenever their teens under 16 download apps. With this solution, when a teen wants to download an app, app stores would be required to notify their parents, much like when parents are notified if their teen attempts to make a purchase. Parents can decide if they want to approve the download. They can also verify the age of their teen when setting up their phone, negating the need for everyone to verify their age multiple times across multiple apps.', 'This way parents can oversee and approve their teen’s online activity in one place. They can ensure their teens are not accessing adult content or apps, or apps they just don’t want their teens to use. And where apps like ours offer age-appropriate features and settings, parents can help ensure their teens use them.', 'This solution also helps to preserve privacy. By verifying a teen’s age on the app store, individual apps would not be required to collect potentially sensitive identifying information. Apps would only need the age from the app store to ensure teens are placed in the right experiences for their age group. Parents and teens won’t need to provide the hundreds of apps their teens use with sensitive information like government IDs.', 'The best way to help support parents and young people is a simple, industry-wide solution where all apps are held to the same, consistent standard. We are working with our industry peers and lawmakers directly to advocate for this concept, and to ease the burden on parents.']\n",
            "18 ['Protecting children online is one of the most important challenges facing the technology industry today. At Meta, we want young people to have safe, positive experiences online and we’ve spent a decade developing tools and policies designed to protect them. As a result, we find and report more child sexual abuse material to the National Center for Missing & Exploited Children (NCMEC) than any other service today.', 'Many in our industry recognize the need to work together to protect children and stop predators. We use technology likeMicrosoft’s PhotoDNAandMeta’s PDQto stop the spread of child sexual abuse material (CSAM) on the internet, but we need additional solutions to stop predators from using different apps and websites to target children.', 'Predators don’t limit their attempts to harm children to individual platforms. They use multiple apps and websites and adapt their tactics across them all to avoid detection. When a predator is discovered and removed from a site for breaking its rules, they may head to one of the many other apps or websites they use to target children.', 'This is behavior experts in online child safety understand well, and something we knew we could do more to address with our peers, so we worked with our partners at the Tech Coalition to establish Lantern. As described in theTech Coalition’s announcement today, Lantern enables technology companies to share a variety of signals about accounts and behaviors that violate their child safety policies. Lantern participants can use this information to conduct investigations on their own platforms and take action.', 'Meta was a founding member of Lantern. We provided the Tech Coalition with the technical infrastructure that sits behind the program and encouraged our industry partners to use it. We manage and oversee the technology with the Tech Coalition, ensuring it is simple to use and provides our partners with the information they need to track down potential predators on their own platforms.', 'One example of Lantern’s value is an investigation Meta conducted following information provided by Lantern partner MEGA during the program’s pilot phase. MEGA shared URLs with Lantern that they had previously removed for violating their child safety policies. Meta’s specialist child safety team used this information to conduct a wider investigation into potentially violating behaviors related to these URLs on our platforms. The team removed over 10,000 violating Facebook Profiles, Pages and Instagram accounts in the course of the investigation. In accordance with our legal obligations, we reported the violating profiles, pages and accounts to NCMEC. In addition, we shared details of our investigation back to Lantern, enabling participating companies to use the signals to conduct their own investigations.', 'We’re glad to partner with the Tech Coalition and our peers on the Lantern program, and we hope others in the industry will join us to expand this important work.']\n",
            "19 ['Hebrew translation,Arabic translation', 'Update on December 7, 2023 at 3:00AM PT:', 'Today Meta’s Oversight Boardannouncedit has selected two cases from user appeals related to the Israel-Hamas War forexpedited review, a process by which the board issues accelerated content decisions within 30 days in exceptional circumstances.The Oversight Board’s guidance in these cases, along with feedback from other experts, will help us to continue to evolve our policies and response to the ongoing Israel-Hamas War.We will implement the board’s decision in each case once it has finished deliberating and will update ourTransparency Centeraccordingly.', 'Update on December 5, 2023 at 9:00PM PT:', 'At the beginning of the war, we designated the October 7 attack by Hamas as a Terrorist Attack under ourDangerous Organization and Individualspolicy. Consistent with that designation, we removed all content showing identifiable victims at the moment of the attack.', 'Following that, people began sharing this type of footage in order to raise awareness and condemn the attacks. Meta’sgoalis to allow people to express themselves while still removing harmful content. In turn, we began allowing people to post this type of footage within that context only, with the addition of a warning screen to inform users that it may be disturbing. If the user’s intent in sharing the content is unclear, we err on the side of safety and remove it.', 'Under ourDangerous Organizations and Individuals policy, we continue to remove any imagery that is produced by a Dangerous Organization or Individual, unless it is clear that the user is sharing it in a news reporting or condemnation context, andno minorsunder thirteen years old are depicted.', 'Update on October 18, 2023 at 3:00AM PT:', 'After the terrorist attack by Hamas against Israel last week, and Israel’s response in Gaza, our teams introduced a series of measures to address the spike in harmful and potentially harmful content spreading on our platforms. Our policies are designed to keep people safe on our apps while giving everyone a voice. We apply these policies equally around the world and there is no truth to the suggestion that we are deliberately suppressing voice. However, content containing praise for Hamas, which is designated by Meta as aDangerous Organization, or violent and graphic content, for example, is not allowed on our platforms. We can make errors and that is why we offer an appeals process for people to tell us when they think we have made the wrong decision, so we can look into it.', 'Some additional updates and steps we are taking as this situation continues to unfold:', 'Fixing Bugs:We identified and fixed some bugs this past week.', 'Comment and Profile Settings:', 'Fundraising on Facebook and Instagram:Since October 7, people have raised more than $11.5 million for nonprofits on Facebook and Instagram to help with relief efforts in Israel and Palestine. This includes over 340,000 donations to 262 charities – providing disaster relief, ambulance and blood services, medical care and more.', 'Originally published on October 13, 2023 at 1:00AM PT:', 'Like many, we were shocked and horrified by the brutal terrorist attacks by Hamas, and our thoughts go out to civilians who are suffering in Israel and Gaza as the violence continues to unfold.', 'Since the terrorist attacks by Hamas on Israel on Saturday, and Israel’s response in Gaza, expert teams from across our company have been working around the clock to monitor our platforms, while protecting people’s ability to use our apps to shed light on important developments happening on the ground. The following are some of the specific steps we have taken:', 'We continue to providetoolsto help people control their experience on our apps and protect themselves from content they don’t want to see. These include, but aren’t limited to:', 'עדכון מה-7 בדצמבר, 2023 בשעה 3:00 (שעון החוף המערבי):', 'היום, המועצה המפקחת (Oversight Board) על Meta הודיעה שהיא בחרהלבחינה מזורזתשני מקרים הקשורים למלחמת ישראל-חמאס, מתוך ערעורים שמשתמשים הגישו\\xa0 – הליך במסגרתו המועצה מגישה החלטות מואצות בנושאי תוכן בתוך 30 יום, בנסיבות מיוחדות. הקווים המנחים שתספק המועצה המפקחת במקרים אלו, לצד המשוב ממומחים, יעזרו לנו להמשיך ולפתח את המדיניות שלנו, ואת התגובה שלנו למלחמת ישראל-חמאס. אנחנו ניישם את החלטת המועצה בכל אחד מהמקרים כאשר תסתיים הבחינה, ונעדכן את מרכז השקיפות שלנו בהתאם.', 'עדכון מה-5 בדצמבר, 2023 בשעה 9:00 (שעון החוף המערבי):', 'עם תחילת המלחמה, הגדרנו את מתקפת ה-7 באוקטובר של חמאס כמתקפת טרור, בהתאם למדיניות שלנו לגביארגונים ואנשים מסוכנים. בהתאם להגדרה זו, הסרנו את כל התוכן שמראה קורבנות שניתן לזהות מרגעי התקיפה.', 'בעקבות כך, אנשים החלו לשתף תיעודים כאלו על מנת להעלות את המודעות ולגנות את המתקפות.מטרתהשל Meta היא לאפשר לאנשים לבטא את עצמם, לצד הסרה של תוכן פוגעני. בהמשך, התחלנו לאפשר לאנשים לפרסם תיעודים אלו בתוך ההקשר הזה בלבד, בנוסף לאזהרה על המסך שתיידע משתמשים שתכנים אלו עלולים להיות מטרידים. אם הכוונה של המשתמש בשיתוף התוכן לא ברורה, בחרנו בצד של הבטיחות – והסרנו אותו.', 'בהתאםלמדיניותשלנו, אנחנו ממשיכים להסיר כל תיעוד המופק על ידי ארגונים ואנשים מסוכנים, אלא אם ברור שהמשתמש משתף את התוכן כדיווח חדשותי, או בהקשר של גינוי – כל עודקטיניםמתחת לגיל 13 אינם מוצגים בו.', 'פוסט מהניוז רום 18/10', 'לאחר מתקפת הטרור של חמאס נגד ישראל בשבוע שעבר, והתגובה של ישראל בעזה, הצגנו מספר שינויים, במטרה לתת מענה לעלייה החדה בכמות התכנים הפוגעניים והתכנים שעשויים להיות פוגעניים המופצים על הפלטפורמות שלנו.', 'המדיניות שלנו נבנתה בצורה כזו, שמצד אחד תשמור על בטיחותם של אנשים על הפלטפורמה שלנו ומצד שני תאפשר להם להשמיע את קולם.', 'מדיניות זו חלה באופן שווה בכל העולם, ואין אמת בטענה שאנחנו משתיקים קולות באופן מכוון.', 'למרות זאת, תוכן שמשבח את החמאס, שהוגדר על ידי Meta כארגון מסוכן, או תוכן אלים וכזה שמציג אלימות בצורה גרפית, לדוגמה, אסור על הפלטפורמות שלנו. אנחנו עלולים לעשות טעויות וזו הסיבה שאנחנו מאפשרים תהליכי ערעור, כדי שאנשים יוכלו להגיד לנו אם הם חושבים שקיבלנו החלטה לא נכונה ונוכל לבדוק זאת בצורה מעמיקה יותר.', 'כמה עדכונים וצעדים נוספים שאנחנו לוקחים תוך כדי התפתחות המצב –', 'תיקון תקלות (באגים) – זיהינו ותיקנו כמה באגים בשבוע האחרון.', 'תגובות והגדרות פרופיל –', 'גיוס תרומות בפייסבוק ואינסטגרם –', 'מאז ה7/10, אנשים גייסו יותר מ11.5 מיליון דולר לעמותות בפייסבוק ובאינסטגרם כדי לסייע למאמצי הסיוע בישראל ובעזה. הסכום הזה כולל למעלה מ-340,000 תרומות ל-262 ארגוני סיוע – שמאפשרים סיוע באסון, אמבולנסים, תרומות דם, ציוד רפואי ועוד.', '', 'עדכון על הפעולות שאנחנו נוקטים בהן סביב מלחמת ישראל – חמאס', 'כמו רבים מכם, גם אנחנו המומים ומזועזעים לנוכח מתקפת הטרור הברוטלית של חמאס, ומחשבותינו נמצאות עם התושבים הסובלים מהאלימות המתמשכת.', 'מאז החלו התקפות הטרור של חמאס על ישראל ביום שבת ותגובתה של ישראל בעזה, צוותי מומחים שלנו מרחבי החברה עובדים מסביב לשעון על מנת לנטר את המתרחש על הפלטפורמות במטרה להגן על יכולתם של אנשים לעשות שימוש באפליקציות שלנו ולשפוך אור על ההתרחשויות בשטח.', 'להלן כמה מהצעדים בהם נקטנו:', 'מאבק בהפצת תוכן פוגעני', 'ביטחון ובטיחות', 'צמצום של התפשטות המידע המטעה', 'כלי בקרה', 'אנו ממשיכים להציע כלים ויכולות המסייעים לאנשים לשלוט בחוויה שלהם באפליקציות שלנו, ולהגן על עצמם מפני תוכן שהם אינם מעוניינים לראות. בין כלים אלה, ניתן למצוא את הבאים:', '', 'تحديث بتاريخ 5 ديسمبر 2023، الساعة 9:00 مساءً بتوقيت المحيط الهادئ:', 'في بداية الحرب، قمنا بتصنيف هجوم حماس في السابع من أكتوبر كهجوم إرهابي بموجب سياستنا بشأنالمنظمات الخطرة والأفراد الخطرين. وتماشيًا مع هذا التصنيف، أزلنا كل المحتوى الذي يتضمن صورًا أو مقاطع فيديو لضحايا يمكن التعرف عليهم في لحظة الهجوم.', 'في أعقاب ذلك، بدأ الأشخاص مشاركة هذا النوع من المحتوى بهدف تعزيز الوعي وإدانة الهجمات. ويتمثلهدفMeta في السماح للأشخاص بالتعبير عن أنفسهم وإزالة المحتوى الضار في الوقت ذاته. ومن هذا المنطلق، بدأنا السماح للأشخاص بنشر هذا النوع من المحتوى ولكن فقط في هذا السياق، مع إضافة شاشة تحذيرية لإخبار المستخدمين بأن المحتوى قد يكون مزعجًا للبعض. وما لم تكن نية المستخدم من نشر المحتوى واضحة، ننحاز إلى جانب السلامة ونزيل هذا المحتوى.', 'بموجبسياسة المنظمات الخطرة والأفراد الخطرينالتي نتبعها، نواصل إزالة أي صور أو مقاطع فيديو من إنتاج المنظمات الخطرة والأفراد الخطرين، إلا إذا كان من الواضح أن المستخدم يشاركها في إطار تقديم التقارير الإخبارية أو في سياق الإدانة، بشرطعدم ظهور قاصرينأقل من ثلاثة عشر عامًا في الصور أو مقاطع الفيديو.', 'تحديث بتاريخ 7 ديسمبر 2023، الساعة 3:00 صباحًا بتوقيت المحيط الهادئ:', 'أعلن مجلس الإشراف الذي يتولى الإشراف على شركة Meta تحديد حالتين من الطعون المقدمة من المستخدمين بشأن الحرب بين إسرائيل وحماس لإجراءمراجعة عاجلة، وهي عملية يُصدِر المجلس من خلالها قرارات سريعة بشأن المحتوى في غضون 30 يومًا في الظروف الاستثنائية.إن إرشادات المجلس في هذه الحالات، إلى جانب ملاحظات الخبراء الآخرين، من شأنها مساعدتنا على مواصلة الارتقاء بسياساتنا واستجابتنا للحرب الدائرة بين إسرائيل وحماس.وسنقوم بتنفيذ قرار المجلس في كل حالة من الحالات بمجرد أن ينتهي من مداولاته وسنقوم بتحديث مركز الشفافية الخاص بنا وفقًا لذلك.', 'منذ بداية الهجمات الإرهابية التي شنتها حماس على إسرائيل يوم السبت، ورد الفعل من إسرائيل على غزة، شرعت فرقنا في تقديم سلسلة من الإجراءات التي من شأنها معالجة ارتفاع معدل المحتوى الضار والمحتوى الذي يُحتمل أن يكون ضارًا المنتشر على منصاتنا. لقد تم تصميم سياساتنا للحفاظ على سلامة الأشخاص عبر تطبيقاتنا مع منح الجميع القدرة على التعبير عن آرائهم. نحن نحرص على تطبيق هذه السياسات بصورة متساوية في جميع أنحاء العالم وبالتالي لا صحة للتلميح بأننا نقوم بقمع القدرة على التعبير عمدًا. ولكننا، لا نسمح بالمحتوى الذي يتضمن إشادة بحماس، حيث تم تصنيفها على أنهامنظمة خطرةمن قبل Meta أو بالمحتوى العنيف والصادم، مثلاً، على منصاتنا. قد نرتكب أخطاء ولهذا نوفر للأشخاص عملية تقديم الطعون لإخبارنا عندما يعتقدون أننا اتخذنا قرارًا خاطئًا، حتى نتمكن من التحقق من الأمر.', 'نحن بصدد إجراء بعض التحديثات واتخاذ خطوات إضافية مع استمرار توالي فصول هذا الوضع:', '.تصحيح الأخطاء:لقد تمكنا من تحديد بعض الأخطاء وإصلاحها خلال الأسبوع الماضي', 'التعليق وإعدادات الملف الشخصي:', 'حملات جمع التبرعات على فيسبوك وInstagram:منذ 7 أكتوبر، بادر الأشخاص بجمع ما يزيد عن 11.5 مليون دولار للمنظمات غير الهادفة للربح على فيسبوك وInstagram للمساعدة في جهود الإغاثة في إسرائيل وفلسطين. ويشمل ذلك أكثر من 340 ألف تبرع لـ 262 مؤسسة خيرية – تقدم الإغاثة لمنكوبي الكوارث وخدمات الإسعاف والدم والرعاية الطبية وغير ذلك المزيد.', 'جهود Meta المستمرة فيما يتعلق بالحرب بين إسرائيل وحماس', 'شأننا شأن الكثيرين، شعرنا بالصدمة والرعب إزاء الهجمات الإرهابية الغاشمة التي شنتها حماس، وقلوبنا مع المدنيين الذين يعانون في إسرائيل وغزة مع استمرار أحداث العنف.', 'منذ بداية الهجمات الإرهابية التي شنتها حماس على إسرائيل يوم السبت، ورد الفعل من إسرائيل على غزة، تعمل فرق الخبراء في كل قطاعات شركتنا على مدار الساعة لمراقبة منصاتنا، والحفاظ على قدرة الأشخاص في استخدام تطبيقاتنا لتسليط الضوء على التطورات المهمة التي تحدث على أرض الواقع. وفيما يلي بعض الخطوات المحددة التي اتخذناها:', 'اتخاذ الإجراءات اللازمة بشأن المحتوى المخالف', 'السلامة والأمن', 'الحد من انتشار المعلومات المضللة', 'عناصر تحكم المستخدم', 'نواصل توفيرالأدواتلمساعدة الأشخاص على التحكم في تجربتهم على تطبيقاتنا وحماية أنفسهم من المحتوى الذي لا يريدون رؤيته. وتشمل هذه، على سبيل المثال لا الحصر:']\n",
            "20 ['Fentanyl use is a potentially lethal issue that requires a whole-of-society approach. According to the United States’ Drug Enforcement Agency, drug cartels are exploring every way possible to distribute this relatively new drug in the United States; whether it be open-air drug markets, one-to-one drug deals, or online marketing, this is among today’s most dangerous and urgent issues.Since 1999, drug overdoses have killed approximately1 million Americans.\\xa0 Synthetic opioids, such as fentanyl, are now theleading cause of deathfor Americans under 50 — tragically taking more lives than heart disease, cancer, homicide, suicide, or accidents.', 'Awareness and education are two ways to combat the dangers of drug misuse, and on this Fentanyl Awareness Day, we wanted to highlight some of the work that we and our partners are doing to address this public health crisis and to help prevent potential harm.', 'Thanks to expert feedback, we know how vital it is to give people – especially anyone personally impacted by this issue — platforms where they can feel safe to discuss the dangers of drugs and the ways to overcome addiction. That’s why we allow people to talk about their recovery or that of a loved one to raise awareness, provide education, and connect to resources that can help.', 'For years, we’ve been working with expert organizations to help prevent and combat the misuse of drugs. We know that people mostly find drug content by searching for it. So when people search for drugs on Facebook and Instagram, we direct them to theSubstance Abuse and Mental Health Services Administration(SAMHSA)National Helplineto help educate them about the risks.', 'We support several partners working in this space to help educate the public about the potential harm of misusing drugs, reduce stigma and provide resources related to recovery. Examples of recent partnerships include:', 'We’ve also been working to combat drug trafficking online. Considering this challenge is bigger than any single platform, we’re collaborating with othersocial media companies to tackle these issues. For example,we recentlystarted a pilot with Snapchat to identify patterns and signs of illicit drug-related content and activity. This work strengthens our ability to find and remove illicit drugs if they come onto our platforms. As the program develops, we hope to engage additional companies to help protect people and combat this industry-wide issue.', 'We also recently updated our Community Standards to clarify our long-standing prohibition of the sale or purchase of dangerous non-medical drugs on our platforms. The definition of non-medical drugs now includes precursor chemicals, including those that could potentially help manufacture dangerous drugs like fentanyl.', 'We remove content related to drug sales and misuse, and take action against anyone attempting to organize illegal drug sales on our platforms.Furthermore,content that violates our policies, including dangerous individuals and organizations or the sale of drugs, remains subject to stronger consequences — including user account removals.\\xa0 We don’t allow criminal organizations to use Facebook and Instagram, and we remove these organizations from our platforms when we’re made aware of them. We will continue to take action against anyone, including cartels, who use our platforms in an attempt to organize the sale of illegal drugs.', 'We routinely respond to valid law enforcement requests for information andwork closely with law enforcement and emergency responders to help people on our platforms stay safe. We also provide information to law enforcement that will help them respond to emergencies, including providing information where we see a risk of immediate harm. For more information on how we work with law enforcement, visit ourTransparency Center.']\n",
            "21 ['One billion avatars. Yesterday, we got to publicly announce and celebrate that incredible milestone. More than one billion avatars have been created across our technologies. That’s a billion times people have reimagined how they show up online — like showing up to meetings in a suit and tie while wearing pajamas in real life. Respect.', 'Today, we’re announcing some improvements to Meta Avatars that will help freshen up your look just in time for spring. We’re adding a handful of new avatar body shapes to help you better express yourself — especially if expressing yourself means dancing along to “Hips Don’t Lie.” We’ve also partnered with PUMA to bring seven outfits to the Meta Avatars Store.', 'And we’re continuing to make your avatar look better in smaller and subtler ways as well, because those details help your personality shine through. Literally shine, as we’re adding a bit more sparkle to your eyes, brushing some volume into your hair and making clothes look more realistic and textured. You’ll see these changes when you use your avatar outside of virtual reality (VR).', '', 'Everybody’s different, and every body’s different. Until now, though, the body shape options available when creating your avatar were all pretty similar. Maybe a little rectangular.', 'We created them as a good jumping-off point when we launched this iteration of avatars back in 2021. But, we’ve heard feedback that not all of you can see yourselves in the current options.', 'So we’re adding more choices, simple as that. Starting this month, you’ll be able to choose from a wider range of body shape options, including two curvier body shapes. We’re refining some of our existing options to help differentiate them as well.', 'Self-expression and representation matter — it’s what makes your avatar feel like you — and we’ll continue adding more options over time, working toward a future where everyone can create an avatar they love.', 'Last year weintroduced the Avatars Store, a one-stop shop for customizing your avatar across Facebook, Messenger, Instagram and in VR. Since launch, we’ve brought in outfits from some of the world’s leading fashion, sports, and lifestyle brands — including Madhappy, the NBA, Prada and Thom Browne.', 'Add PUMA to the list. We’ve partnered with the sports brand to offer seven of its lifestyle looks starting May 1.', '', 'Lastly, we’ve overhauled how your avatar’s hair, clothing and eyes appear in stickers, profile pictures, cover photos and more.', 'Sparing you the nitty-gritty technical breakdown, we’ve added additional detail and realism to both hair and clothing — meaning whether you’re rocking a clean fade and suit or bedhead and sweats, your avatar should pop a little better than before. Solid glow-up, right? We’ve also tweaked our lighting model to add a little more of a reflective gleam to your eyes, making them sparkle and bring your personality to life.', 'Keep an eye out for more changes. We have a lot of improvements coming to avatars this year, and we can’t wait to share more!', 'As a reminder, when you create an avatar and share it across our technologies it will be public to other people. Learn more aboutcontrolling your avatar permissions.']\n",
            "22 ['Update on February 6, 2024 at 1:00AM PT:', 'Meta has worked with NCMEC to expand Take It Down to more languages. Millions more teens around the world will now be able to more easily use Take It Down to take back control of their intimate images and help prevent them from spreading online.', 'Originally published on February 27, 2023 at 6:00AM PT:', 'Today, we’re announcing that Instagram and Facebook are founding members ofTake It Down— a new platform by NCMEC to help prevent young people’s intimate images from being posted online in the future.', 'Having a personal intimate image shared with others can be scary and overwhelming, especially for young people. It can feel even worse when someone tries to use those images as a threat for additional images, sexual contact or money — a crime known as sextortion.', 'Take It Down lets young people take back control of their intimate images. People can go toTakeItDown.NCMEC.organd follow the instructions to submit a case that will proactively search for their intimate images on participating apps. Take It Down assigns a unique hash value — a numerical code — to their image or video privately and directly from their own device. Once they submit the hash to NCMEC, companies like ours can use those hashes to find any copies of the image, take them down and prevent the content from being posted on our apps in the future.', 'Built in a way that respects young peoples’ privacy and data security, Take It Down allows people to only submit a hash — rather than the intimate image or video itself — to NCMEC. Hashing turns images or videos into a coded form that can no longer be viewed, producing hashes that are secure digital fingerprints.', 'With the launch of Take It Down, people ofallages can stop the spread of their intimate images online, including:', 'Take It Down was designed with Meta’s financial support. We are working with NCMEC to promote Take It Down across our platforms, in addition to integrating it into Facebook and Instagram so people can easily access it when reporting potentially violating content. Take It Down builds off of the success of platforms likeStopNCII, a platformwe launchedin 2021 with South West Grid for Learning (SWGfL) and more than 70 NGO’s worldwide, which helps adults stop the spread of their intimate images online, a practice commonly referred to as “revenge porn.”', 'Metadoesn’t allow content or behavior that exploits young people, including the posting of intimate images or sextortion activities. Wework to preventthis content as well as inappropriate interactions between young people and suspicious accounts attempting to take advantage of them. For example, we default teens into the most private settings on Facebook and Instagram, we work to restrict suspicious adults from connecting with teens on those apps, and we educate teens about the dangers of engaging with adults they do not know online. We’ve also made it easier for people to report potentially harmful content, particularly if it involves a child.', 'On Instagram, we recently introduced new features to make it even more difficult for suspicious adults to interact with teens. Now, these adults will no longer be able to see teen accounts when scrolling through the list of people who have liked a post or when looking at an account’s Followers or Following list. If a suspicious adult follows a teen account, we will send that teen a notification prompting them to review and remove the new follower. We are also prompting teens to review and restrict their privacy settings. When someone comments on a teen’s post, tags/mentions them in another post, or includes their content in Reels Remixes or Guides, the teen will receive a notification to review their privacy settings, and will have the option to stop people from interacting with them.', 'This slideshow requires JavaScript.', 'We’ve developedmore than 30 toolsto support the safety of teens and families across our apps, includingsupervision toolsfor parents andage-verification technologythat helps teens have age-appropriate experiences online. We also provideresources for teensthat inform them of the potential harms of taking intimate images, and the other ways they can find help if they want to stop the spread of that content. There are more resources for parents so they can talk to their teens about how to be safe online in ourSafety CenterandFamily Center.']\n",
            "23 ['At times of war and social unrest, apps like Facebook, Instagram, WhatsApp and Messenger give people a way to connect within and across borders to share information and make their voices heard. In a number of regions around the world, we’ve seen attempts by governments to silence citizens, control the flow of information, and manipulate public debate. Nowhere has this been more apparent over the last year than in the Russian invasion of Ukraine and during the mass protests in Iran.', 'We go to great lengths to protect people’s ability to use our apps when they’re needed the most. Of course, there are times when we have to take action against content that doesn’t otherwise violate our policies in order to comply with local laws. But our starting point is always to defend people’s ability to make their voices heard and to resist attempts to clamp down on the use of our services — especially during times of war and social unrest.', 'As part of our commitment to transparency, we also publish quarterly reports that give insights into our work in this area, including the adversarial threats we’ve identified and taken action against, and our enforcement of Meta’s policies. Alongside today’s publication of these and other transparency reports covering Q4 2022, we’re also providing updates on our actions relating to the Russia-Ukraine war and the protests in Iran.', 'It is nearly a year since Russia’s full scale invasion of Ukraine. Within days, Russia attempted to block or restrict access to Facebook and Instagram as part of a wider attempt to cut Russian citizens off from the open internet, silence people and independent media, and manipulate public opinion. Since the invasion began,we’ve provided updates on our response, including the measures we’ve taken to help keep Ukrainians and Russians safe, our approach to misinformation, state-controlled media and ensuring reliable access to trusted information.', 'Throughout the war, our teams have been on high alert to identify emerging threats and respond as quickly as we can. As it has progressed, we have observed changes in both overt and covert Russian influence operations on our platform and on the internet more broadly.', 'After we applied new and stronger enforcements to Russian state-controlled media, including demotingtheir posts and providing labels to users so they know the source of information, the most recentresearchhas found that there was a substantial drop in the activity of these Pages around the world, as well as a substantial drop in people’s engagements with the content they posted.', 'In total, we labeled more than 450 Pages and Instagram accounts. In response, we saw state-controlledmedia shifting to other platforms and using new domains to try to escape the additional transparency on (and demotions against) links to their websites. We observed this behavior around the world, not only in places where Russian state media faced government restrictions.', 'While overt activity by Russian state-controlled media on our platforms has decreased, attempts at covert activity have increased sharply. Russian covert networks have historicallytargeted Ukrainemore than any other country. Last year, we took down two Russian covert influence campaigns that focused on the war. Rather than trying to build up convincing fake personas, these campaigns resembled “smash-and-grab” operations that used thousands of fake accounts across social media — not Meta platforms alone — in an attempt to overwhelm the conversation with their content. In both cases, our automated systems detected and disabled the majority of these accounts soon after they were created.', 'Since taking these two networks down we’ve seen thousands of recidivist attempts to create fake accounts. This covert activity is aggressive and persistent, constantly probing for weak spots across the internet, including setting up hundreds of new spoof news organization domains.', 'The work of hundreds of humanitarian organizations and volunteer groups gets impacted when information is cut off or limited. Through our Data for Good program, established in 2017, Meta has been part of an unprecedented collaboration between technology companies, the public sector, universities, nonprofits and others to aid disaster relief, support economic recovery, and inform policy and decision making. Data for Good datasets informed the work of humanitarian partners, including Direct Relief, who provided 650 tons of medical aid and $14.7 million in direct financial assistance to support Ukrainian refugees. They also inform the work of large UN agencies like International Organization for Migration, United Nations High Commissioner on Refugees and others, as they support medical relief, housing and resettlement efforts.', 'Displacement estimates fromData for Goodhave helped fill gaps in official statistics on where displaced populations ultimately resettle after leaving Ukraine. For example, many people leave Ukraine and immediately enter Poland but then may move on to Germany or the Czech Republic, which official statistics may not report. Information from Data for Good has uncovered demographic insights on thesepopulations, including age and gender breakdowns, which have helped inform the type of medical services needed, as well as employment support. These insights also informed the World Bank’s support to governments. They pivoted some of their resource allocations around food and housing in favor of registration and employment services as a result.', 'We’ve also seen a huge outpouring of generosity and solidarity for the people of Ukraine from Facebook and Instagram users all over the world. So far, people have raised nearly $70 million on Facebook and Instagram for nonprofits in support of humanitarian efforts for Ukraine on Facebook and Instagram.', 'The widespread protests that began in the wake of the awful killing of Mahsa Amini led to the Iranian authorities clamping down aggressively on speech and freedom of assembly, as well as limiting the use of the internet and apps like Instagram which are widely used by Iranians. We’ve followed events closely and taken a number of steps to try and keep people connected and safe.', 'Despite attempts to block Instagram, we’re seeing tens of millions of people still finding ways to access it via VPNs and other means, including with a more stable connection through Instagram Lite, which we launched in Iran last year to help people access Instagram when bandwidth is reduced. In January, we alsointroducedablocking circumvention tool into WhatsAppthat allows people to access WhatsApp through proxy servers set up by volunteers around the world.', 'Instagram has been widely used by Iranians to shed light on the protests and the brutal response of the regime. Since Mahsa Amini’s death, hashtags related to the protests in Iran have been used on Instagram more than 160 million times. #Mahsaamini was the fifth top hashtag globally during the first three months of protests, demonstrating the power of social media to help create awareness in these critical moments. Protestors have shared their Instagram footage of the protests with international media outlets, many of whom can’t report from Iran.', 'When the protests began we moved quickly to set up a dedicated team focusing on addressing any issues stemming from them. This team is made up of Farsi speakers, as well as experts on our policies, products, operations, and human rights, who are working round the clock to make sure we apply our policies correctly and address any mistakes as quickly as possible.', 'We responded to over-enforcement at the start of protests when we saw accounts suddenly postingunusually high volume of videos and triggering our spam detection to temporarily restrict them from posting. We can’t turn off our spam detection that protects our global community, so our teams have been working on other ways to prevent over-enforcement.', 'Social media accounts of activists and journalists are often targeted during protests. We’vedesigned policies to give these groups more protections from threats of violence, includingremoving content that “outs” people as activists in situations that could put them in danger. And when we become aware of human rights defenders who have been arrested or detained as a result of their work, we take steps to thwart unauthorized access to their accounts. To help people condemn and raise awareness of human rights abuses, we allow graphic content — often with a warning label — while still removing particularly violent content.', 'Today we are also publishing our regular quarterly transparency reports covering Q4 2022. This includes ourAdversarial Threat Reportwith details of three Coordinated Inauthentic Behavior networks we took down in the last quarter. The networks targeted domestic audiences inCuba, Serbia and Boliviaand were all linked to these countries’ governments or ruling parties. They used a range of tactics to influence public debate, including deceptive campaigns, attempts to criticize and intimidate the opposition and activists into silence, and to falsely report people with opposing views in an attempt to get Meta to remove their accounts.', 'As these reports demonstrate, these aren’t issues any one company can tackle alone. These campaigns — and the tactics used in Russia, Iran and elsewhere — target a range of platforms and services across the internet. Tactics will adapt and change, and new threats will emerge. As they do, we will continue investigating and removing covert influence operations like these and sharing our findings with industry peers, researchers and the public to help inform our collective defenses.', 'You can find the reports here:']\n",
            "24 ['Today, we’re publishing our quarterly reports for the fourth quarter of 2022 including theCommunity Standards Enforcement Report,theWidely Viewed Content Report,Oversight Board Quarterly Updateand theAdversarial Threat Report. All reportsare available in theTransparency Center.', 'Our report highlights include:', 'Over the past five years, we’ve shared our findings about threats we detect and remove from our platforms. In today’s threat report, we’re sharing information about three networks we took down for violating our policies against coordinated inauthentic behavior (CIB) and mass reporting (or coordinated abusive reporting) during the last quarter to make it easier for people to see the progress we’re making in one place. We’re also providing an update on our work against influence operations — both covert and overt — in a year since Russia began its full-scale invasion of Ukraine. We have shared information about our findings with industry partners, researchers and policymakers.', 'In the fourth quarter,we continue to make progress on removing content that violates our Community Standards with prevalence remaining relatively consistent across a wide range of violation areas.Separately, we’ve updated ourcross-problem AI system, combining several models so that we’re consolidating learnings across hate speech, bullying and harassment and violence and incitement. This and other continued improvements or adjustments to proactive detection technology, in many instances, lead to improved accuracy.', 'We also consistently refine our methodology for this report in an effort to improve the metrics we provide. This quarter we’veupdatedhow we calculate proactive rate. As a result of these improvements, we’re seeing several shifts in the proactive rates across different areas. This methodology update only changes how we measure the proactive rate metric, but not our approach to proactively identifying violating content.', 'This quarter’s report includes one case of engagement bait and one piece of content removed because it was posted by a Page that was taken down for repeatedly violating our Community Standards. We rigorously work to understand the content ecosystem and evaluate how effective our policies and integrity measures are so we can close the gaps we find along the way.', 'The Oversight Board is a valuable source of external perspective and accountability for Meta that people can appeal to if they disagree with content enforcement decisions on Facebook and Instagram. We’re committed to implementing all of the Board’s content decisions and responding to all of their recommendations publicly, having already committed to implement — or explore the feasibility of implementing — 78% of their recommendations to date.', 'Q4 marked two years since the Oversight Board’s first decision and we closed the quarter with building a framework to expand the Board’s scope and impact. This collaboration with the Board resulted in finalizing a series ofupdatesthat will streamline the Board’s operations and allow them to more efficiently select, deliberate and make decisions on tough issues.', 'Over the past two years the Oversight Board has given us valuable feedback on our policies and processes which has led to real changes. For example, we recently completed a global rollout of more informative user messaging tolet people knowwhether human or automated review was responsible for the removal of their content.', 'Also prompted by feedback from the Oversight Board, we aresharing more detailsabout steps we’re taking to update Facebook’s penalty system. We continue to invest in refining our policies and improving our enforcement, and as part of that work,we are updating our penalty system to make it more fair and effective.Under the new system, we will focus on helping people understand why we have removed their content, which is shown to be more effective at preventing re-offending, rather than so quickly restricting their ability to post.', 'We are still removing violating content just as we did before, but now we’re also giving people the chance to change their behavior while still applying stronger penalties to more severe violations: posting content that includes terrorism, child exploitation, human trafficking, serious suicide promotion, sexual exploitation, the sale of non-medical drugs, or the promotion of dangerous individuals and organizations. This leads to faster and more impactful actions for those that continuously violate our policies. These changes followfeedback from our community — including ourcivil rights auditors, the Oversight Board and independent experts — who noted that our current systems needed better balance between punishing and encouraging remediation through education.', 'Our commitment to integrity is ongoing,and we will continue to update,improve and evolve our policy enforcement in an ever-changing environment.We are focused on preserving people’s ability to connect with each other around the world, particularly during times of crisis.We also want to ensure businesses that rely on our apps to reach customers have access to the support they need. From global brands to the local coffee shop, we know that businesses can be targets for adversarial activity which can disrupt their operations. So we will continue to focus heavily on improving overall support for business users.']\n",
            "25 ['Today, as prompted by feedback from the Oversight Board’s continued push to ensure our penalty system is more proportionate, we’re taking steps to update Facebook’spenalty systemto make it more effective and fair.Since nothing is changing about the underlying content removal, we do not anticipate this penalty system refinement to have a material effect on prevalence. With this update we will still be able to keep our app safe while also allowing people to express themselves.', 'Under the new system, we will focus on helping people understand why we have removed their content, which is shown to be more effective at preventing re-offending, rather than so quickly restricting their ability to post. We will still apply account restrictions to persistent violators, typically beginning at the seventh violation, after we’ve given sufficient warnings and explanations to help the person understand why we removed their content. We will also restrict people from posting in groups at lower thresholds where warranted. For more serious violations: posting content that includes terrorism, child exploitation, human trafficking, suicide promotion, sexual exploitation, the sale of non-medical drugs or the promotion of dangerous individuals and organizations, we will continue to apply immediate consequences, including account removal in severe cases.', 'The vast majority of people on our apps are well-intentioned. Historically, some of those people have ended up in “Facebook jail” without understanding what they did wrong or whether they were impacted by a content enforcement mistake.', 'Our analysis has found that nearly 80% of users with a low number of strikes do not go on to violate our policies again in the next 60 days. This means that most people respond well to a warning and explanation since they don’t want to violate our policies. But at the same time, some people are determined to post violating content regardless of our policies. Our analysis suggests that applying more severe penalties at the seventh strike is a more effective way to give well-intentioned people the guidance they need while still removing bad actors.', 'As well as being more effective, these changes will be fairer to those people who may have been disproportionately impacted by our old system, particularly when we made an incorrect moderation decision or missed context. For example, someone may jokingly post, “I’m on my way to kidnap you,” not knowing that this statement could violate our violence and incitement policy, when really it was a post about taking a friend out for dinner after that person had a rough day.Someone else might post a friend’s name and address as a way of sharing information for a party, and without that context, that post might appear to be sharing personally identifiable information in violation of our policies. The implications of overenforcement are real — when people are unintentionally caught up in this system, they may find it hard to run their business, connect with their communities or express themselves.', 'Our previous system resorted quickly to long penalties, such as a 30-day block on a person’s ability to create content. These long blocks were frustrating for well-intentioned people who had made mistakes, and they did little to help those people understand our policies. The blocks also made it harder for us to spot violation trends and sometimes had the effect of letting bad actors stay on the site longer. Our new system, which reduces the number of restriction periods, will allow us to detect persistent violators in less time, leading to faster and more impactful actions.', 'Today’s changes, while based on our own analysis and feedback of the Oversight Board, are also responsive to feedback fromour community — including ourcivil rights auditors— who noted that our current enforcement system needs more focus on proportionality. Independent experts who offered their guidance on this topic have routinely noted that our penalty system should have a better balance between punishing and encouraging remediation through education.', '“…It is positive that Meta has introduced further transparency and coherence in this area as a result of implementing prior Oversight Board recommendations, moving towards what should be a more proportionate and transparent approach with higher strike-to-penalty thresholds. Meta’s plans to issue more comprehensive penalty notifications should ensure that users are better placed to understand the reasons for the consequences of strikes and the reasons for feature-limits in the future.”– Oversight Board Iran protest slogan Case Decision', 'External guidance is an important part of this process, and we’ll continue to work with experts in academia, civil society and the policy community to continue to improve and evolve our policy enforcement in an ever changing environment. We will provide more updates as this process continues.']\n",
            "26 ['Update on July 12, 2024 at 1:00PM PT:', 'Today we are making a change to theupdated protocolwe announced in January 2023. To ensure people can hear from political candidates on our platforms, we will review accounts subject to this protocol on a periodic basis to determine whether heightened suspension penalties for Community Standards violations remain appropriate.\\xa0 We will make this determination by weighing our responsibility, as outlined by the Oversight Board, to “allow political expression” against our responsibility “to avoid serious risks to other human rights.”', 'With the party conventions taking place shortly, including the Republican convention next week, the candidates for President of the United States will soon be formally nominated. In assessing our responsibility to allow political expression, we believe that the American people should be able to hear from the nominees for President on the same basis. As a result, former President Trump, as the nominee of the Republican Party, will no longer be subject to the heightened suspension penalties. In reaching this conclusion, we also considered that these penalties were a response to extreme and extraordinary circumstances, and have not had to be deployed. All US Presidential candidates remain subject to the same Community Standards as all Facebook and Instagram users, including those policies designed to prevent hate speech and incitement to violence.', 'Originally published on January 25, 2023 at 2:00PM PT:', 'Social media is rooted in the belief that open debate and the free flow of ideas are important values, especially at a time when they are under threat in many places around the world. As a general rule, we don’t want to get in the way of open, public and democratic debate on Meta’s platforms — especially in the context of elections in democratic societies like the United States. The public should be able to hear what their politicians are saying — the good, the bad and the ugly — so that they can make informed choices at the ballot box. But that does not mean there are no limits to what people can say on our platform. When there is a clear risk of real world harm — a deliberately high bar for Meta to intervene in public discourse — we act.', 'Two years ago, we took action in what were extreme and highly unusual circumstances. We indefinitely suspended then-US President Donald Trump’s Facebook and Instagram accounts following his praise for people engaged in violence at the Capitol on January 6,2021. We then referred that decision to the Oversight Board — an expert body established to be an independent check and balance on our decision-making.The Board upheld the decisionbut criticized the open-ended nature of the suspension and the lack of clear criteria for when and whether suspended accounts will be restored, directing us to review the matter to determine a more proportionate response.', 'In response to the Board, we imposed atime-bound suspensionof two years from the date of the original suspension on January 7,2021 — an unprecedented length of time for such a suspension. We also clarified the circumstances in which accounts of public figures could be restricted during times ofcivil unrest and ongoing violence, and introduced a newCrisis Policy Protocolto guide our assessment of on and off-platform risks of imminent harm so we can respond with specific policy and product actions. In our response to the Oversight Board, we also said that before making any decision on whether or not to lift Mr. Trump’s suspension, we would assess whether the risk to public safety has receded.', 'The suspension was an extraordinary decision taken in extraordinary circumstances. The normal state of affairs is that the public should be able to hear from a former President of the United States, and a declared candidate for that office again, on our platforms. Now that the time period of the suspension has elapsed, the question is not whether we choose to reinstate Mr. Trump’s accounts, but whether there remain such extraordinary circumstances that extending the suspension beyond the original two-year period is justified.', 'To assess whether the serious risk to public safety that existed in January 2021 has sufficiently receded, we have evaluated the current environment according to our Crisis Policy Protocol, which included looking at the conduct of the US 2022 midterm elections, and expert assessments on the current security environment. Our determination is that the risk has sufficiently receded, and that we should therefore adhere to the two-year timeline we set out. As such, we will be reinstating Mr. Trump’s Facebook and Instagram accounts in the coming weeks. However, we are doing so with new guardrails in place to deter repeat offenses.', 'Like any other Facebook or Instagram user, Mr. Trump is subject to our Community Standards. In light of his violations, he now also faces heightened penalties for repeat offenses — penalties which will apply to other public figures whose accounts are reinstated from suspensions related to civil unrest under ourupdated protocol. In the event that Mr. Trump posts further violating content, the content will be removed and he will be suspended for between one month and two years, depending on the severity of the violation.', 'Our updated protocol also addresses content that does not violate our Community Standards but that contributes to the sort of risk that materialized on January 6, such as content that delegitimizes an upcoming election or is related to QAnon. We may limit the distribution of such posts, and for repeated instances, may temporarily restrict access to our advertising tools. This step would mean that content would remain visible on Mr. Trump’s account but would not be distributed in people’s Feeds, even if they follow Mr. Trump. We may also remove the reshare button from such posts, and may stop them being recommended or run as ads. In the event that Mr. Trump posts content that violates the letter of the Community Standards but, under ournewsworthy content policy, we assess there is a public interest in knowing that Mr. Trump made the statement that outweighs any potential harm, we may similarly opt to restrict the distribution of such posts but leave them visible on Mr. Trump’s account. We are taking these steps in light of the Oversight Board’s emphasis on high-reach and influential users and its emphasis on Meta’s role“to create necessary and proportionate penalties that respond to severe violations of its content policies.”', 'There is a significant debate about how social media companies should approach content posted on their platforms. Many people believe that companies like Meta should remove much more content than we currently do. Others argue that our current policies already make us overbearing censors. The fact is people will always say all kinds of things on the internet. We default to letting people speak, even when what they have to say is distasteful or factually wrong. Democracy is messy and people should be able to make their voices heard. We believe it is both necessary and possible to draw a line between content that is harmful and should be removed, and content that, however distasteful or inaccurate, is part of the rough and tumble of life in a free society.', 'We publish ourCommunity Standardspublicly so that everyone can see where we draw that line. Our policies sometimes require reconsideration and revision — as the introduction of our Crisis Policy Protocol and the additional elements announced today reflect. We are highlighting these rules today because we anticipate that should Mr. Trump choose to resume activity on our platforms, many people will call for us to take action against his account and the content he posts, while many others will be upset if he is suspended again, or if some of his content is not distributed on our platforms. We want to be as clear as possible now about our policies, so that even in those instances where people will disagree with us, they still understand the rationale for our responses.', 'We know that any decision we make on this issue will be fiercely criticized. Reasonable people will disagree over whether it is the right decision. But a decision had to be made, so we have tried to make it as best we can in a way that is consistent with our values and the process we established in response to the Oversight Board’s guidance.']\n",
            "27 ['Today, we’re launching Quiet mode on Instagram to help people focus and to encourage people to set boundaries with their friends and followers. Once it’s enabled, you won’t receive any notifications, your profile’s activity status will change to let people know and we’ll automatically send an auto-reply when someone sends you a DM.', 'Teens have told us that they sometimes want to take time for themselves and might be looking for more ways to focus at night, while studying and during school. You can easily customize your Quiet mode hours to fit your schedule and once the feature is turned off, we’ll show you a quick summary of notifications so you can catch up on what you missed.', 'Anyone can use Quiet mode, but we’ll prompt teens to do so when they spend a specific amount of time on Instagram late at night. Quiet mode is available to everyone in the US, United Kingdom, Ireland, Canada, Australia, and New Zealand starting today, and we hope to bring it to more countries soon.', '', '', '', 'We want to give people more control over the content they see on Instagram, so we’re introducing new features that allow people to tell us what content they don’t want recommended to them.', 'First, you can now choose to hide multiple pieces of content in Explore that you aren’t interested in at one time. Additionally, when you select Not interested on a post seen in Explore, we’ll aim to avoid showing you this kind of content going forward in other places where we make recommendations, like Reels, Search and more.', '', '', 'Next, whileyou can already hide comments and DMs containing specific words, we’re now expanding this feature to apply to recommended posts you might see across Instagram. Add a word or list of words, emojis or hashtags that you want to avoid — like “fitness” or “recipes” —\\xa0 and we’ll work to no longer recommend content with those words in the caption or the hashtag. You can access this in the Hidden Words section of Privacy settings.', '', 'In addition to providing teens with more ways to manage their time and experiences on Instagram, we want to help parents be more aware of the choices their teens make, and make it easier for them to have discussions with their teens about their settings throughFamily Center and supervision tools.', 'Recently, we added the ability for parents to see their teen’s Instagram settings, includingprivacy and account settings. If their teen updates a setting, parents will receive a notification so they can talk to their teen about the change. Parents can now also view accounts their teen has blocked.', 'VisitFamily Centerfor conversation starters and to learn more about the available parental supervision tools, including how to set time limits, schedule breaks, be notified when teens share a report and more.', 'These updates are part of our ongoing work to ensure people have experiences that work for them, and that they have more control over the time they spend online and the types of content they see.']\n",
            "28 ['Update on December 13, 2023 at 2:10PM PT:', 'Today, the United States Department of Justice (DOJ)sharedthe second third-party reviewer report verifying that the Variance Reduction System (VRS) has met the compliance standards that Meta agreed upon with the DOJ. Moving forward, reports will be postedhereon an ongoing basis.', 'Update on October 26, 2023 at 10:00 AM PT:', 'Earlier this year, we launched the Variance Reduction System (VRS) – an update to our ad delivery system that helps ensure more equitable delivery of housing ads in the US. We have now launched the VRS for US employment and credit ads, and we will soon launch the VRS for housing and employment ads in Canada by the end of this month. This is another important step to help advance fairness and equity in our advertising system, and we will continue our work to improve this technology.', 'Update on July 19, 2023 at 2:57PM PT:', 'Earlier this year, we launched the Variance Reduction System (VRS) — an update to our ad delivery system that helps advance more equitable delivery of housing ads in the US. As part of our settlement with the United States Department of Justice (DOJ) and the Department of Housing and Urban Development (HUD) last year, weagreedto have an independent, third-party reviewer regularly verify the VRS’s compliance with the agreed-upon metrics in the June settlement. As theDOJ shared today, thereviewer verifiedthat the VRS has met the compliance standards that Meta agreed upon with the DOJ. This important report is another step to help advance fairness and equity in our ads system, and later this year, we plan to extend the VRS to US employment and credit ads.', 'Originally published on January 9, 2023 at 12:06PM PT:', 'As a part of our settlement with the Department of Justice (DOJ), representing the US Department of Housing and Urban Development (HUD), weannouncedour plan to create the Variance Reduction System (VRS) to help advance the equitable distribution of ads on Meta technologies. After more than a year of collaboration with the DOJ, we have now launched the VRS in the United States for housing ads. Over the coming year, we will extend its use to USemploymentandcredit ads. Additionally, we discontinuedthe use of Special Ad Audiences, an additional commitment in the settlement.', 'The VRS uses new machine learning technology inad deliveryso that the actual audience that sees an ad more closely reflects the eligible target audience for that ad. After the ad has been shown to a large enough group of people, the VRS measures aggregate demographic distribution of those who have seen the ad to understand how that audience compares with the demographic distribution of the eligible target audience selected by the advertiser. To implement this technology in a way that respects people’s privacy, the VRS relies on awidely used method of measurement called Bayesian Improved Surname Geocoding(BISG) – informed by publicly available US Census statistics – to measure estimated race and ethnicity. This method is built with added privacy enhancements includingdifferential privacy, a technique that can help protect against re-identification of individuals within aggregated datasets.', 'Throughout the course of an ad campaign, the VRS will keep measuring the audience’s demographic distribution and continue working to reduce the difference between the audiences.', 'Learn more about this new technology in ourtechnical paperand on ourAI blog.', 'Meta embeds civil rights and responsible AI principles into our product development process to help advance our algorithmic fairness efforts while protecting privacy.', 'The VRS builds on our longstanding efforts to help protect against discrimination. This includes restrictingcertain targeting optionsfor campaigns that advertise housing, employment or credit ads. For example, we don’t allow advertisers that are either based in or trying to reach people in the US, Canada and certain European countries from targeting their housing, employment or credit ads based on age, gender or ZIP code.', 'Across the industry, approaches to algorithmic fairness are still evolving, particularly as it relates to digital advertising. But we know we cannot wait for consensus to make progress in addressing important concerns about the potential for discrimination — especially when it comes to housing, employment, and credit ads, where the enduring effects of historically unequal treatment still have the tendency to shape economic opportunities. We will continue to make this work a priority as we collaborate with stakeholders to support important industry-wide discussions around how to make progress toward more fair and equitable digital advertising.']\n",
            "29 ['Over the past several years, we’ve developed more than 30 tools to support teens and families on our apps. Last month, we held our first Meta Summit focused on Youth Safety and Well-Being to discuss this work. Safety advocates, mental health experts, educators, think tank researchers, policy writers and parents — many of whom helped inform the development of these tools — gathered in Washington, D.C. to discuss challenges families face in the digital age and explore opportunities to better serve teens and families:', 'Watch afull recordingof the Summit.', 'At the Summit, Nick Clegg, Meta’s President of Global Affairs, called for global policymakers and regulators to work together on clear, consistent regulation when it comes to providing safe, age-appropriate experiences for young people online.', 'Nick said: “I think everybody has a role… social media companies have a role, families have a role, parents have a role, governments have a role, regulators have a role. This is a space where I think it is totally legitimate and normal for regulators to act.”', 'He continued: “The European Union and the United States have tried to establish various fora by which key decision makers of the regulatory agencies in DC and the regulatory agencies in Brussels meet together (…)\\xa0 the more they could do that with their counterparts, like India, it would be a very good thing for this agenda.”', 'We support regulators across the globe working together to establish clear, consistent laws that adapt to ever-evolving technologies, so they can be implemented successfully by companies across our industry. We’re hopeful that continued regulation in this area will seek to preserve teens’ rights to be online, while creating safe, supportive environments for them to express themselves.', 'We haven’t waited for regulation to continue making progress on our apps. Over the past several years, we’ve taken significant steps, including:', 'While we continue this work in the absence of consistent and clear regulation, we also advocate for industry working together on these issues so that all tech companies across the internet adhere to certain principles when it comes to young people. For youth specifically, we have consistently called for an industry body to address at least three key challenges:', 'We believe parents and teens should have consistent experiences across all apps, not just on Meta’s. As our work on this is never done, we hope to continue working with other tech companies — as we have done on other initiatives like those preventing the proliferation of child sexual abuse material or the sale of illicit drugs — so teens can expect online experiences that are safe and supportive across the internet.', 'We want social media to be a positive force in teens’ lives, so we’re listening to feedback from experts and our community to build apps where teens can discover and create in an age-appropriate way. As we embark on a new year, we will continue building experiences so young people can foster their relationships in a safer, more supportive environment.', 'This slideshow requires JavaScript.', 'This slideshow requires JavaScript.']\n",
            "30 ['As we close out this year, we’re sharing a number ofupdateson our work to protect people around the world against various threats.', 'Since 2017, we’ve taken down and reported on more than 200 covert influence operations, providing details on each network’s behavior so that people know about the threats we see — whether they come from nation states, commercial firms or unattributed groups. Sharing this information has enabled our teams, investigative journalists, government officials and industry peers to better understand and expose internet-wide security risks, including ahead of critical elections.', 'Here are insights that have stood out to us this year as we look back at our 200-plus CIB enforcements:', 'The CIB networks we’ve taken down came from 68 countries. They operated in at least 42 languages from Amharic to Urdu to Russian and Chinese.', '', 'More than 100 different countries, from Afghanistan to Zimbabwe, have been targeted by at least one CIB network — foreign or domestic — since we began our public reporting. The United States was the most targeted country by 34 operations, followed by Ukraine targeted by 20 CIB networks, and the United Kingdom targeted by 16 operations. Notably, we often saw these covert networks focus on more than one country at a time. For example, one network from Iran we disrupted inApril 2020targeted 18 countries on four continents.', '', 'Russia (34 networks), Iran (29 networks) and Mexico (13 networks) were the three most prolific geographic sources of CIB activity — whether by state actors, political groups or commercial firms.', '', 'The differences between CIB networks in these countries illustrate the complexity of influence operations globally.', 'Russia:We often hear about the so-called “Russian influence operations playbook,” though our investigations have shown that there is in fact no single playbook relied on by CIB networks originating in the country. The operations we’ve investigated since 2017 varied widely in tactics, targets, complexity, scale and the actors behind them. Since 2017, we’ve disrupted networks run by people linked to theRussian militaryandmilitary intelligence,marketingfirmsandentitiesassociated with a sanctioned Russian financier. The smallest CIBnetworkwe’ve seen with three accounts only and one of thelargestoperations we ever disrupted came from Russia: their tactics ranged fromspammy commentsto running fictitious cross-platformmedia entitiesthathiredreal journalists to write for them. And while most public reporting has focused on various Russian operations targeting America, our investigations found that more operations from Russia targeted Ukraine and Africa.', 'Notably, both our first takedown and our 200th takedown were of CIB networks originating from Russia. The latter takedown targeted Ukraine and other countries in Europe, which we were able to attribute to two companies in Russia: Structura National Technology and Social Design Agency (Агентство Социального Проектирования), as part of today’s update to ourThreat Report from September 27, 2022.', 'Iran:We’ve seen a diversification in Iranian operations, particularly when it comes to the actors behind the activity. Networks we took down between 2018 and 2020 were mostly linked to government-related entities, particularly state media. Those operations were often centered around websites that promoted content about the Iranian government. Starting early 2021, deceptive campaigns focused more on politics in the target countries and were linked to smaller groups, like academics or people with a background in teaching English as a foreign language, without an apparent link to any larger state entity. This coincides with the US Treasuryseizureof domains linked to earlier Iranian operations. This could be a sign of different groups in Iran attempting to run CIB campaigns or change in operational security designed to obfuscate attribution.', 'Mexico:Most CIB networks originating in Mexico focused primarily on regional or local audiences, often in the context of regional elections. These networks tended to be less tactically sophisticated, and many were linked to PR or marketing firms including instances where one network supported two rivals for the same electoral post. This illustrates the danger of covert “IO-for-hire” services that provide inauthentic support to not just the highest bidder, but multiple bidders at once, polluting the information environment.', 'While public discourse around global influence operations often focuses on foreign interference, we found that CIB networks worldwide most frequently targeted people in their own country. For example, we’ve reported on a number of government agencies targeting their own population inMalaysia,Nicaragua,ThailandandUganda. In fact, two-thirds of the operations we’ve disrupted since 2017 focused wholly or partially on domestic audiences.', '', 'The balance between foreign and domestic operations varied dramatically by region. Around 90% of CIB operations in Asia-Pacific, sub-Saharan Africa and Latin America were wholly or partly focused on domestic audiences. By contrast, over two-thirds of CIB networks that originated in Europe and the Middle East and North Africa (MENA) were wholly or partly focused on foreign audiences.', 'Uniquely, the Gulf region was where we saw covert influence operations from many different countries target each other, signaling these attempts at influence as an extension of geopolitics by other means. For example, we removed: anIranian networkcriticizing Saudi Arabia and the US; a network fromSaudi Arabiacriticizing Iran, Qatar, and Turkey; an operation fromEgypt, Turkey and Morocco supporting Qatar and Turkey and criticizing Saudi Arabia, the United Arab Emirates (UAE) and the Egyptian government; and a network fromEgyptsupporting the UAE and criticizing Qatar and Turkey.', 'We’ve continued to expose operations running on many different internet services at once, with even the smallest networks following the same diverse approach. For example, in2020we took down 10 accounts from Russia that targeted Turkey and Europe. In2021, we took down four accounts from Iran. InJanuarywe took down three accounts from Russia. In each case, while their activity on our platforms was minimal, they each ran “news” websites and targeted other internet services. We’ve seen these networks operate across Twitter, Telegram, TikTok, Blogspot, YouTube, Odnoklassniki, VKontakte, Change[.]org, Avaaz, other petition sites and even LiveJournal.', 'Since 2019, we’ve seen a rapid rise in the number of networks that used profile photos generated using artificial intelligence techniques like generative adversarial networks (GAN). This technology is readily available on the internet, allowing anyone — including threat actors — to create a unique photo. More than two-thirds of all the CIB networks we disrupted this year featured accounts that likely had GAN-generated profile pictures, suggesting that threat actors may see it as a way to make their fake accounts look more authentic and original in an effort to evade detection by open source investigators, who might rely on reverse-image searches to identify stock photo profile photos. However, our CIB enforcements focus on behaviorrather than the content posted by these networks, including their photos. In fact, in our CIB investigations, we look at a combination of behavioral signals which means that the use of GAN faces does not help threat actors to evade enforcement.', '', 'For more information, see our pastthreat reporting.']\n",
            "31 ['Next month, Meta assumes the chair of theGlobal Internet Forum to Counter Terrorism(GIFCT)’s Operating Board. GIFCT is an NGO that brings together technology companies to tackle terrorist content online through research, technical collaboration and knowledge sharing. Meta is a founding member of GIFCT, which was established in 2017 and has evolved into a nonprofit organization followingthe 2019 Christchurch Call, which brings together member companies, governments and civil society organizations to tackle terrorist and violent extremist content online.', 'Meta is also making available a free open source software tool it has developed that will help platforms identify copies of images or videos and take action against them en masse. We hope the tool — calledHasher-Matcher-Actioner (HMA)— will be adopted by a range of companies to help them stop the spread of terrorist content on their platforms, and will be especially useful for smaller companies who don’t have the same resources as bigger ones. HMA builds on Meta’sprevious open source image and video matching software, and can be used for any type of violating content.', '', 'Member companies of the GIFCT often use what’s called ahash sharing databaseto help keep their platforms free of terrorist content. Instead of storing harmful or exploitative content like videos from violent attacks or terrorist propaganda, GIFCT stores a hash, or unique digital fingerprintfor each image and video. The more companies participate in the hash sharing database the better and more comprehensive it is — and the better we all are at keeping terrorist content off the internet, especially since people will often move from one platform to another to share this content. But many companies do not have the in-house technology capabilities to find and moderate violating content in high volumes, which is why HMA is a potentially valuable tool.', 'Meta spent approximately $5 billion globally on safety and security last year, and has more than 40,000 people working on it. Within that, we have a team of hundreds of people dedicated to counter-terror work specifically, with expertise ranging from law enforcement and national security, to counterterrorism intelligence and academic studies in radicalization.', 'Meta’s commitment to tackling terrorist content is part of a wider approach to protecting users from harmful content on our services. We’re a pioneer in developing AI technology to remove hateful content at scale. Hate speech is now viewed two times for every 10,000 views of content on Facebook, down from 10-11 times per 10,000 views less than three years ago. We also block millions of fake accounts every day so they can’t spread misinformation, and have taken down more than 150 networks of malicious accounts worldwide since 2017\\u200b.', 'We’ve learned over many years that if you run a social media operation at scale, you have to create rules and processes that are as transparent and evenly applied as possible. That’s why we have detailed Community Standards setting out what isn’t acceptable on our services, which are published openly and reviewed consistently. We publish reports every quarter detailing the progress we’re making on things like detecting hate speech and other harmful content, the malicious networks we disrupt, and showing what content is the most viewed on our services.', 'Of course, we’re not perfect, and fair-minded people will disagree as to whether the rules and processes we have are the right ones. But we take these issues seriously, try to act responsibly and transparently, and invest huge amounts in keeping our platform safe. Many of these issues go way beyond any one company or institution. No one can solve them on their own, which is why cross-industry and cross-government collaborations like GIFCT and the Christchurch Call are so important.']\n",
            "32 ['We’re committed to making sure people have age-appropriate experiences across our technologies, and as part of this work, we’ve been testing age verification tools and using age detection technology to stop people under the age of 18 from accessing experiences meant for adults.', 'Starting today, we’re expanding our age verification test to Facebook Dating in the US. We require people to be at least 18 years old in order to sign up for and access Facebook Dating, and age verification tools will help verify that only adults are using the service and\\xa0 help prevent minors from accessing it. We’re also continuing our partnership with Yoti, a company that specializes in online age verification, so that people have more than one option to choose from to verify their age.', 'We want to make sure people are placed in experiences that are appropriate for their ages, so we use technology to understand where people have misrepresented how old they are. That’s why we’ve invested inage detection technologyto find potential discrepancies in the ages people provide us and the age we think they may be based on our technology. If we detect someone may be under the age of 18 and trying to use Facebook Dating, we will prompt them to verify their age. They will have two options to choose from:', '', '', '', 'Providing people with more than one option to verify their age allows them to select a method that best fits their needs and preferences. For example, many people don’t always have access to the forms of ID that make verifying age clear.', 'Our age verification tests show that our tools are working to help keep people within age-appropriate experiences. Since we began testing newage verification tools on Instagramin June, we’ve found that approximately four times as many people were more likely to complete our age verification requirements (when attempting to edit their date of birth from under 18 to over 18), equating to hundreds of thousands of people being placed in experiences appropriate for their age. We also were able to stop 96% of the teens who attempted to edit their birthdays from under 18 to 18 or over on Instagram from doing so. And we have found that 81% of people presented with our menu of options chose to use Yoti’s video selfie to verify their age.', 'As we learn more, we plan to bring our age detection technology and verification tools to other countries globally where Facebook Dating is available, and to more experiences that require people to be over 18 to access them.']\n",
            "33 ['Today, we’re sharing an update on how we protect young people from harm and seek to create safe, age-appropriate experiences for teens on Facebook and Instagram.', 'Last year, we shared some of the measures we take to protect teens from interacting with potentially suspicious adults. For example, we restrict adults over 18 years old from starting private chats with teens they’re not connected to on Instagram and Messenger.(Updated on August 9, 2024 at 8:52AM PT to reflect our latest policies.)', 'In addition to our existing measures, we’re now testing ways to protect teens from messaging suspicious adults they aren’t connected to, and we won’t show them in teens’ People You May Know recommendations. A “suspicious” account is one that belongs to an adult that may have recently been blocked or reported by a young person, for example. As an extra layer of protection, we’re also testing removing the message button on teens’ Instagram accounts when they’re viewed by suspicious adults altogether.', 'We’ve developed a number of tools so teens can let us know if something makes them feel uncomfortable while using our apps, and we’re introducing new notifications that encourage them to use these tools.', 'For example, we’re prompting teens to report accounts to us after they block someone, and sending them safety notices with information on how to navigate inappropriate messages from adults. In just one month in 2021, more than 100 million people saw safety notices on Messenger. We’ve also made it easier for people to find our reporting tools and, as a result, we saw more than a 70% increase in reports sent to us by minors in Q1 2022 versus the previous quarter on Messenger and Instagram DMs.', '', '', 'Starting today, everyone who is under the age of 16 (or under 18 in certain countries) will be defaulted into more private settings when they join Facebook, and we’ll encourage teens already on the app to choose these more private settings for:', '', '', 'This move comes on the heels of us rolling out similar privacy defaults for teens onInstagramand aligns with our safety-by-design and‘Best Interests of the Child’ framework.', 'We’re also sharing an update on the work we’re doing to stop the spread of teens’ intimate images online, particularly when these images are used to exploit them — commonly known as “sextortion.” The non-consensual sharing of intimate images can be extremely traumatic and we want to do all we can to discourage teens from sharing these images on our apps in the first place.', 'We’re working with the National Center for Missing and Exploited Children (NCMEC) to build a global platform for teens who are worried intimate images they created might be shared on public online platforms without their consent. This platform will be similar to work we have done toprevent the non-consensual sharing of intimate images for adults. It will allow us to help prevent a teen’s intimate images from being posted online and can be used by other companies across the tech industry. We’ve been working closely with NCMEC, experts, academics, parents and victim advocates globally to help develop the platform and ensure it responds to the needs of teens so they can regain control of their content in these horrific situations. We’ll have more to share on this new resource in the coming weeks.', 'We’re also working with Thorn and their NoFiltr brand to createeducational materialsthat reduce the shame and stigma surrounding intimate images, and empower teens to seek help and take back control if they’ve shared them or are experiencing sextortion.', '', '', 'We found thatmore than 75%of people that we reported to NCMEC for sharing child exploitative content shared the content out of outrage, poor humor, or disgust, and with no apparent intention of harm. Sharing this content violates our policies, regardless of intent. We’re planning to launcha new PSA campaignthat encourages people to stop and think before resharing those images online and to report them to us instead.', 'Anyone seeking support and information related to sextortion can visit our education and awareness resources, including theStop Sextortion hubon the Facebook Safety Center, developed with Thorn. We also have our guide for parents onhow to talk to their teens about intimate imageson the Education hub of ourFamily Center.']\n",
            "34 ['Updated on July 18, 2023 at 12:00PM PT:', 'Over the next month, fans across the globe will use our apps to connect around the FIFA Women’s World Cup. In addition to the protections we put in place for the Men’s World Cup — including Hidden Words and Limits — today we’re highlighting additional policies and safety features that will help protect players and fans from abusive behavior on our apps.', 'Rules to Help Protect Women From Abuse', 'We developed many of ourrules— like those against bullying and harassment, threats and hate speech — in consultation with women’s safety groups in order to address the types of harmful content that can disproportionately affect women. We remove and take action on a wide range of abusive content under these rules, from violent or dehumanizing attacks against women based on their sex or gender identity and threats of physical or sexual violence to attacks that use gendered or misogynistic language. While our bullying and harassment policies distinguish between public figures and private individuals to make sure we’re allowing legitimate discourse around those in the public eye, weexpandedthese policies in 2021 to give more protection to public figures, including footballers, who shouldn’t be subjected to degrading or sexualized attacks. We will remove content that breaks these rules during the tournament — as we do all year round.', 'Features to Help Keep Footballers Safe', 'Last month,we began testingnew features on Instagram to better protect people from unwanted images and videos in DMs — something we know can disproportionately impact women, especially those in the public eye.', 'Our goal is for everyone — including women footballers — to feel confident and in control when they open their DMs.', 'Educating Footballers and Partners About Our Safety Tools and Policies', 'Just as we did ahead of the Men’s World Cup last year, we partnered with FIFA in the lead up to the event to provide participating players, teams and associations around the world, as well as media partners and rights holders, with the latest information and training on our safety tools and policies. And we’re reminding participating footballers to check their safety tools with a prompt at the top of their Instagram Feed.', 'While we know no one thing will prevent or fix abusive behavior, we’re committed to continuing to develop tools to protect our community and help keep our apps safe for footballers and fans, so they can celebrate and support each other during FIFA’s Women’s World Cup and beyond.', 'Originally published on November 17, 2022 at 3:00AM PT:', 'Over the next month, football fans across the globe will use our apps to connect around the FIFA World Cup.While most will be rooting for the teams and players competing for the championship, unfortunately there will likely be some who want to be abusive towards others — just like we see offline.Before the competition kicks off, we’re sharing more details about our policiesagainst abuse, and the range of tools we’ve developed to help keep footballers — and everyone else — safe.', 'We have clear rules against bullying, violent threats and hate speech — and we don’t want it on our apps. As well as responding to reports from our community, outside of private messages we also use technology to proactively look for content that might break these rules. Where our technology thinks a piece of content may be violating it will take action, whether that’s sending it to our teams for review or — if it’s really confident — deleting it automatically.Between April and June this year, we took action on more than 17 million pieces of hate speech on Facebook and Instagram, and found more than 90% of that before anyone reported it.', 'In response to feedback from our community, we’ve developed new features — and updated existing ones — to help footballers and fans alike stay safe on our apps and protect them from abuse.', 'People can turn direct message (DM) requests off completely on Instagram, meaning they won’t receive messages from anyone they don’t follow. They can also choose who can comment on their posts or turn off comments altogether, on a post-by-post basis. But some public figures have told us they don’t want to turn off DM requests completely, because they like hearing from fans and other members of their community. That’s why we developedHidden Words.', 'When turned on, this feature automatically sends DM requests — including Story replies — containing offensive words, phrases and emojis to a hidden folder so you don’t have to see them. It also hides comments with these terms under your posts. Since launching Hidden Words last year, more than one in five people with more than 10,000 followers have turned it on. We’re also testing turning it on by default for people with creator accounts, which includes many footballers playing in the World Cup.', '', 'We launchedLimitslast year, which, when turned on, hides comments and DM requests from people who don’t follow you or who only followed you recently. Limits is particularly useful for public figures who experience sudden spikes of comments and DMs — after a football game, for example — as our research shows that most negativity towards them comes from non-followers or recent followers. When we detect that someone may be experiencing a rush of comments or DM requests, we’ll prompt them to turn on Limits.', '', '', 'Blocking is a quick and effective way to stop someone from interacting with you. Now when you block someone on Instagram, you can also block any other accounts they may already have, or may create in the future, making it even harder for them to contact you.', '', '', 'We’re also continuing to explore ways to prevent people from posting abusive content in the first place. We already use artificial intelligence to detect when someone is trying to post a comment that might be offensive, and warn them it may break our rules. In a given week, people edit or delete their comment 50% of the time after seeing these warnings. We also recently introduced new nudges that encourage people to pause and rethink before replying to a potentially offensive comment. These nudges are live now for people whose apps are set to English, Portuguese, Spanish, French, Chinese or Arabic.', '', 'When people send a DM request to a creator or public figure for the first time, we’ll remind them to be respectful, so they remember there’s a real person on the other side of their message.', '', 'We regularly speak to football players, teams and associations around the world — including FIFA — to make sure they know about our latest safety policies and features, and we listen carefully to their feedback. We’re also working closely with teams competing in the World Cup to help their players turn on our safety tools — for example Hidden Words — and we’re reminding footballers in the tournament to check them with a prompt at the top of their Instagram Feed.', '', 'We cooperate with law enforcement in their investigations and respond to valid legal requests for information in accordance with our terms of service and applicable law. As with all law enforcement requests, we’ll push back if they’re too broad, inconsistent with human rights or not legally valid.', 'While we know no one thing will fix abusive behavior, we’re committed to continuing to develop tools to protect our community, and to working closely with the football industry to help keep our apps a safe place for footballers and fans.']\n",
            "35 ['We want to make it as hard as possible for someone you’ve blockedon Instagramto contact you again. Now when you block someone, you’ll also have the option to block other accounts they may have or create, making it more difficult for them to interact with you.', 'Last year, we updated how blocking workson Instagram to give you the ability to not only block a single account, but also any new accountssomeonemay create. This update allows you to also block existing accounts that person may already have. Based on initial test results from this new change, we expectthat four million fewer accounts will need to be blocked every weeksince these accounts will now be blocked automatically.', '', 'Sincelaunching Hidden Wordslast year, more than one in five people withmore than 10,000 followershave turned on the feature, giving them a powerful tool to automatically filter harmful content from their comments and message requests. We’ve seen that Hidden Words has beeneffective at keeping people safe. When people with more than 10,000 followers turn on Hidden Words for comments, on average, they see 40% fewer comments that might be offensive.', 'We want to help more creators benefit from this protection, so we’re starting to test automatically turning on Hidden Words forCreator accounts. Everyone will continue to be able to turn these settings on or off at any time and build a custom list with additional words, phrases and emojis they may want to hide.', 'We’re also continuing to improve Hidden Words to offer more protections, including:', '', 'We’ve learned that there are cases where people mean well but may misjudge how their words could negatively impact others — especially when they’re interacting online.', 'We’ve seen thatnudges can reduce the amount of hurtful remarks on Instagram, which is why we’re introducing more of them. Now,a new notification will encourage people to pause and consider how they want to respond before replying to a comment that our systems tell us could be offensive. These nudges are live now for people whose apps are set to English, Portuguese, Spanish, French, Chinese or Arabic.', '', 'We’ve also started reminding people to be respectful in DMs when sending a message request to a creator. This nudge helps people remember that there’s a real person on the other side of their DM request, and encourages more respectful outreach to people they may not know. We’re rolling out this reminder globally in the coming weeks.', '', 'We’ll continue to work on more ways to protect people from abuse on Instagram, while encouraging supportive and respectful conversations.']\n",
            "36 ['Today, we’re publishing the Widely Viewed Content Report (WVCR) for the second quarter of 2022. This report highlights the most-viewed organic content in Feed on Facebook in the US, including domains, links, Pages and posts. It includes contentrecommended by Facebookand excludes advertising content. See thefull reportandCompanion Guidefor more information.', 'This report shows five links and one post that we removed from Facebook for violating our Inauthentic Behavior (IB) policy.Content with links to the domains responsible for these violations can no longer be created/shared on Facebook. Similarly, the Page responsible for the post and its content are no longer accessible on Facebook for violating our Inauthentic Behavior policy', 'We also note in this report that we’ve removed one of the top posts for violating ourIntellectual Propertypolicy.We removed it after receiving a complete copyright report for the content. Learn more abouthow we protect intellectual property rights.', 'Insights from the WVCR help inform how we update our existing policies and products, and develop new ones to address harmful or otherwise objectionable content. For example, we’ve been testing new ways to reduce clickbait, engagement bait and spam. While we’re seeing improvements from these tests,we will need to continually evaluate and refine our approachgiven how spam operators try to adapt their tactics to evade our new ways of detecting them. We’ll continue to test and improve solutions to reduce engagement bait,misinformation and content from Pages that repeatedly violate our Community Standards.', 'In ourprevious WVCR report, we shared that the ninth-most viewed link on Facebook with over 33 million views in the first quarter of this year was alltrendytees[.]com. After the Integrity Institute had flagged it to us, we investigated andblockedthis domain for violating our IB policy. Our investigation linked this domain toGearLaunch, a Bangladesh-based e-commerce firm.', 'In total, we removed over 500 inauthentic and authentic accounts, Pages and Groups run by these spammers. We also blocked additional domains that engaged in the same behavior and were linked to GearLaunch.We will keep taking action against this activity because we know that adversarial actors like this may try to come back and create new websites.', 'In addition to running fake accounts to spam people with links and drive them to off-platform domains selling print-on-demand t-shirts, they also engaged in what we call “guiding adversarial activity” where they facilitated and coached people on how to evade detection and enforcement.They generated “how-to” YouTube videos where they taught people how to deceptively build their audience while posing as Americans and monetize by selling topical t-shirts through their print-on-demand websites. T-shirt designs ranged from hobby-related images like fishing to professional areas like accounting to political slogans and images.', 'This case continues the trend we’ve previouslyreportedwhere IB operators pretend that they’re based in one country, when in reality, they’re running their monetization schemes out of a different one. This often includes foreign spammers and scammers flocking to any relevant everyday interests or hot-button issues that are relevant in a particular country or region — like an election or a socio-political crisis — to amass an audience and monetize their attention. For example, we’ve seen financially-motivated actors from around the world leverage significant events — like the Canadian trucker protests, the US 2020 elections, the war in Ukraine and the recent election in the Philippines — to build audiences and make money. We expect to see attempts at this kind of activity increase in the US as we get closer to the midterms. So we will stay vigilant to it and respond whenever we see it, while also fine tuning our detection and enforcement systems to make sure we stay ahead of it.', '', '', '', '', '', '', '', '', '', 'Images: Examples of Facebook and Instagram posts by spammers', '']\n",
            "37 ['Today, we’re sharing highlights of our integrity work for the second quarter of 2022, which can all be found in theTransparency Center.This update includes:', 'Earlier this month we also released our QuarterlyAdversarial Threat Report, which provides an in-depth, qualitative view into the different types of adversarial threats we tackle globally as well as our approach to the upcoming elections inBraziland theUnited States.', 'We continue to make steady progress on a number of areas, including bullying and harassment. As we continue to improve our AI technology, the proactive detection rate of bullying and harassment content on Facebook increased from 67% in Q1 2022 to 76.8% in Q2 2022 and on Instagram from 83.8% in Q1 2022 to 87.4% in Q2 2022.', 'On Facebook in Q2:', 'On Instagram in Q2:', '', 'As part of our work to constantly improve the metrics we share in this report, we have updated ourappeals methodologyto account for all instances where content was submitted for additional review, including times when people told us they disagreed with our decision.', 'As new regulations continue to roll out around the globe, we are focused on the obligations they create for us and how those obligations might affect our ability to keep prevalence of violating content on our apps low, minimize enforcement mistakes and conduct sufficient due-diligence as part of our safety and security processes.', 'Expansion of the Board’s Scope:The board will soon issue a new type of binding judgment on cases: whether or not we should apply a warning screen to some pieces of content. While the board has already been able to apply binding decisions on whether to take down or leave up pieces of content, this expansion will empower them further by giving them more input on how content appears and is distributed to people across our platforms.', 'Newsworthiness:As a result of a recommendation from the Oversight Board, we’re releasing data on the number of newsworthy allowances we made over a calendar year. We’re committing to release these numbers on a regular basis moving forward. From June 2021 to June 2022, we documented 68 newsworthiness allowances, of which, 13 (~20%) of those were issued for posts by politicians. This data, along with examples of and details on these allowances, are now available in ourTransparency Center.', 'Crisis Policy Protocol:During crises, we assess on and off-platform risks of imminent harm and respond with specific policy and product actions. Based on a recommendation from the Oversight Board — and to strengthen our existing work — we are publishing our Crisis Policy Protocol (CPP) to codify our content policy response to crises. This framework helps to assess crisis situations that may require a new or unique policy response. The CPP guides our use of targeted crisis policy interventions in a timely manner that is consistent with observed risks and past interventions. As a result, this helps our crisis policy response to be more calibrated and sustainable, as we seek to balance a consistent global response with adapting to quickly changing conditions. Protocol development included original research, consultations with over 50 global external experts in national security, conflict prevention, hate speech, humanitarian response and human rights. Learn morehereandhere.', 'We are always refining our policies and enforcement so that we’re both supporting people’s ability to express themselves and protecting safety across our platforms. We know we don’t always get it right, and we’re looking into ways we can improve our proactive enforcement, like through applyingAI technology.', 'We found that usingwarning screensto discourage hate speech or bullying and harassment content prevented some of this content — which could have violated our community standards — from being posted.', 'We’re also expanding a test ofFlagged by Facebook,which allows some group admins tobetter shape their group culture and take context into account by keeping some content in their groups that might otherwise be flagged for bullying and harassment.For example, through this test an admin for a group of fish tank enthusiasts allowed a flagged comment that called a fish “fatty,” which was not intended to be offensive.', 'We have built the largestglobal fact-checking networkof any platform, with more than 90 fact-checking partners around the world who review and rate viral misinformation. InQ2, we displayed warnings on over 200 million distinct pieces of content on Facebook (including re-shares) globally based on over 130,000 debunking articles written by our fact-checking partners.', 'In the US, we partner with 10 fact-checking organizations, five of which cover content in Spanish. We’re adding TelevisaUnivision as another US partner to cover Spanish language content.', 'We’ve also launched a pilot program on Facebook that aims to show people more reliable information and empower them to decide what to read, trust and share. A small group of our US third-party fact-checking partners has the ability to comment in English and Spanish to provide more information on public Facebook posts that they determine could benefit from more context. This effort is separate from ourthird-party fact-checking program. The comments aren’tfact-check ratings. They won’t result in any enforcement penalties for content owners, nor will they impact a post’s distribution or the overall status of a Page. Also, unlike fact-checks, these comments will appear on Facebook posts that may not be verifiably false but that people may find misleading.', '']\n",
            "38 ['Update on March 2, 2023 at 6:00 AM PT:', 'Starting today, we’re beginning to expand our age verification test on Instagram to more countries in Europe, Mexico, Canada, South Korea, Australia and Japan. We plan to make our age verification tools available in even more countries globally within the next few months.', 'Update on October 13, 2022 at 5:00 AM PT:', 'Starting today, we’re expanding this test to additional countries including India and Brazil. We plan to expand to the UK and EU before the end of the year. We’re also removing Social Vouching as an option to verify age from the test to make some improvements.', 'Originally published on June 23, 2022 at 3:00 AM PT:', 'Starting today, we’re testing new options for people on Instagram to verify their age, starting with people based in the US. If someone attempts to edit their date of birth on Instagram from under the age of 18 to 18 or over, we’ll require them to verify their age using one of three options: upload their ID, record a video selfie or ask mutual friends to verify their age. We’re testing this so we can make sure teens and adults are in the right experience for their age group.\\xa0 We are also partnering with Yoti, a company that specializes in online age verification, to help ensure people’s privacy.', 'In 2019, we began asking people toprovide their agewhen signing up for Instagram. Since then,we’ve made this a requirement. Knowing people’s age allows us to provide appropriate experiences to different age groups, specifically teens.', 'We require people to be at least 13 years old to sign up for Instagram. In some countries, our minimum age is higher. When we know if someone is a teen (13-17), we provide them with age-appropriate experiences like defaulting them into private accounts, preventing unwanted contact from adults they don’t know and limiting the options advertisers have to reach them with ads.', 'In addition to having someone upload their ID, we’re testing two new ways to verify a person’s age:', 'You will still be able to upload your ID to verify your age withforms of identificationlike a driver’s license or ID card.We will use your ID to confirm your age and help keep our community safe. Your ID will be stored securely on our servers and is deleted within 30 days.', '', '', 'We worked with international youth, privacy and safetyexpertsto inform our approach. You can learn more about these three options andhow to set them up.', 'We’re partnering withYoti, a company that offers privacy-preserving ways to verify age. Yoti is verifiedby theAge Check Certification Schemeand is the leading age verification provider for several industries around the world includingsocial media, gaming and age restricted e-commerce.Expert and governmental organizations in youth and privacy, includingthe German regulator KJM,have publicly endorsed Yoti for their approach and expertise in responsible artificial intelligence (AI).', 'Yoti notes that it trains its dataseton anonymous images of diverse people from around the world who have transparently allowed Yoti to use their data and who can ask Yoti to delete their data at any time. For people under the age of 13, Yoti collected data using specific data collection exercises where parents or guardians have given explicit consent.', '', 'In addition to testing the new menu of options to verify people’s ages, we also useAI to understand if someone is a teen or an adult.AI helps us prevent teens from accessing Facebook Dating, adults from messaging teens and helps teens from receivingrestricted ad content, for example. Our goal is to expand the use of this technology more widely across our technologies. To learn more about how our technology works, and the advancements we’re making in artificial intelligence, you can review ourAI blog post.', 'The information provided in each age verification option is used to confirm your age and won’t be visible on your profile, to friends or other people on Instagram. If you choose to upload a video selfie to verify your age,Metaand Yoti delete itonceyour age is confirmed. Your video is not used for anything else other than to verify your age. If you choose to upload an ID,after you send us a copy of your ID, it’ll be encrypted and stored securely.', 'Understanding someone’s age online is a complex, industry-wide challenge. We want to work with others in our industry, and with governments, to set clear standards for age verification online. Many people, such as teens, don’t always have access to the forms of ID that make age verification clear and simple. As an industry, we have to explore novel ways to approach\\xa0 the dilemma of verifying someone’s age when they don’t have an ID.', 'We still believe an effective way of addressing this problem is for devices or app stores to provide apps with people’s ages, allowing teens to be placed in age-appropriate experiences across all the apps they use. In the absence of industry standards or regulation on how to effectively verify age online, we’ve invested in a combination of technologies that are more equitable, provide more options to verify age and that protect the privacy of people using our technologies.']\n",
            "39 ['Update on September 14, 2022 at 6:00PM PT:', 'Today, we’re beginning to roll out parental supervision tools on Instagram globally. Parents around the world will be able to access Family Center and set up tools with their teen to supervise their Instagram experience. With these tools, parents and guardians can:', 'Originally published on June 14, 2022 at 3:00AM PT:', 'We’re beginning to roll outparental supervision tools to all Quest headsets. In the Parent Dashboard, parents and guardians can:', 'For parents to link to their teen’s account, the teen must initiate the process, and both the parent and teen have to agree.', '', 'We’re also launching our newParent education hub, including a guide to our VR parental supervision tools from ConnectSafely to help parentsdiscuss virtual reality with their teens.', 'This is just a starting point, informed by careful collaboration with industry experts, and we’ll continue to grow and evolve our parental supervision tools over time.', 'On Instagram, parents and guardians can now:', 'If you already have supervision set up on Instagram in the US, these updates are now available in addition toour other supervision tools. Starting this month, these tools will begin rolling out to other countries including the UK, Japan, Australia, Ireland, Canada, France and Germany, with plans to roll out globally before the end of the year. Visit ourFamily Centerto learn more.', 'On Instagram, teens will start to see new nudges. Teens in certain countries will see a notification that encourages them to switch to a different topic if they’re repeatedly looking at the same type of content on Explore. This nudge is designed to encourage teens to discover something new and excludes certain topics that may be associated with appearance comparison.', 'We designed this new feature because research suggests that nudges can be effective for helping people — especially teens — be more mindful of how they’re using social media in the moment. In an externalstudyon the effects of nudges on social media use, 58.2% of respondents agreed or strongly agreed that nudges made their social media experience better by helping them become more mindful of their time on-platform.Our own research shows they’re working too: during a one-week testing period, one in five teens who saw our new nudges switched to a different topic.', '', 'We launched ourTake a Break featureto remind people to take time off Instagram. Soon, we’ll launch new reminders for teens to turn on Take a Break when they’ve been scrolling in Reels for a period of time. The reminders will feature Reels developed by young creators like@foodwithsoy,@abraxaxsand@mayasideaswho share their own tips for taking a break and why it’s a good idea to get off social media for a bit. These are being tested in the US, UK, Ireland, Canada, Australia and New Zealand now, and they’ll launch in those and additional countries later this summer.', 'We’re also empowering US-based young creators through funding and education to share more content on Instagram that inspires teens and supports their well-being. An Expert Steering Committee of experts in child psychology and digital literacy will provide guidance on evidence-based ways for creators in the program to use language that strengthens emotional well-being and self image, how to create responsible content online and how creators can look after themselves and their communities on and offline.', '', 'We’re addingnew articles to the Family Centereducation hubfrom organizations likeParentZone, Media Smarts, National Association for Media Literacy Education and Cyberbullying Research Center. These articlesgive parents helpful tips on how to talk to teens about different online topics such asconnecting safely with othersandhow to be more self-aware online. We’ll continue working with experts and organizations to make even more resources for parents and guardians available.We also are adding a newprivacy pagewith more information for teens about privacy settings, defaults and features across Quest, Instagram, Facebook and Messenger.', 'To build products and experiences that help keep young people safe, we work directly with teens, parents and experts. Over the past few years, we’ve incorporated best practices from the United Nations (UN), the Organization for Economic Co-operation and Development (OECD) and children’s rights groups.', 'Today, we’re sharing more detail on an internal process we created to help us apply theUN’s Convention on the Rights of the Child(UNCRC) in our product development. The Convention emphasizes that the “best interests of the child” should steer the creation of services, products, and experiences for young people. Our process guides our teams on how to apply this standard when developing digital experiences for people under 18 using our technologies.Read more about ourBest Interests of the Child work, and how it informs the experiences we create for young people.', '“It is really encouraging to know that Meta has been listening to young people and their parents and creating tools that encourage timely conversations. At Parent Zone, we know how difficult it can be for parents when they feel locked out of their children’s digital worlds. With these new tools, we are seeing a shift to greater partnership between families and platforms and that is an incredibly positive step.” –Vicki Shotbolt,founder and CEO of Parent Zone', '', '“With VR technologies increasingly gaining traction, and the Quest becoming a favorite product of many youth, parents and guardians will now have access to a suite of tools to safeguard and stay involved with their teen’s participation and experiences. We’re glad that Meta continues to seek out data-driven insight from scholars and practitioners in various social scientific fields to build solutions that seek to equip youth, families and educators with the tools and resources they need to safely enjoy exploring and interacting on their favorite platforms.” –Dr. Sameer Hinduja, Co-Director of theCyberbullying Research Center']\n",
            "40 ['This Pride month, we’re celebrating the LGBTQ+ communities who are shaping culture and influencing how gender identity is expressed across our technologies.', 'Later this month,we will be exploring the future of LGBTQ+ chosen family and community safety in immersive spaces as part of the Metaverse Culture Series. We’re building out a custom experience in Horizon Worlds, while hosting a candid conversation with an exclusive group of community leaders as we build towards a more equitable metaverse.', 'On Meta Quest, check out the newest episode ofWeird Times, which explores the experience of coming out as teen in the current political climate when LGBTQ+ rights are under attack.', 'In Horizon Venues,\\xa0 you can watch “March for Dignity” on June 2, a documentary that follows a small group of LGBTQ+ activists in Tbilisi, Georgia as they attempt to conduct the first Pride march in the country.', 'In Horizon Worlds, we collaborated with Mastercard and LGBTQIA+ world creators RhondaX and SKitter_ to launch Mastercard’s True Self World,\\xa0 an ongoing virtual space in a canopy set high above the clouds. In this space, members of the LGBTQIA+ community and their allies can meet and share their stories, visit an immersive museum of letters, celebrate on the dance floor and more. True Self World is available for Meta Quest 2 users in the US and Canada to explore starting June 21.(Updated on June 21, 2022 at 9:15AM PT to reflect updated programming.)', 'Starting today,\\xa0 you can use Pride-themed avatars and stickers in Feed and on Stories on Facebook and Messenger. They will be available year-round.', '', 'We’re rolling out camera stickers on Instagram, designed in partnership with queer, Brooklyn-based artist and creatorShanée Benjamin. Also on Messenger, you can use custom word effects with our Pride Chat theme, plus check out additional camera stickers releasing later this month from London-based, non-binary artist and creatorWednesday Holmes(they/them).', 'And, we’re launching an exclusive new AR Effect in partnership with Broadway’s Tony Award-nominee & Pulitzer Prize-winnerA Strange Loop. The AR effect “Show Your Skills” guides fans through the audition process with fun twists and prompts aimed to bring out your inner star. You can use this effect on Reels, Stories and feed posts.', '', '', '', 'In the Philippines, we’re launching a Pride AR Filter on Instagram in partnership with queer artistBrent Sabasand Meta Spark Spark AR creatorMitsuko Ono.(Updated on June 21, 2022 at 9:00AM PT to reflect updated programming.)', '', 'This month, we’re introducing ourLGBTQ+ Safety Center Hubon Facebookto provide easy access to resources that can help the community feel safe. In the hub, you’ll find a range of safety features, including guides to improve account security, tools to prevent bullying and harassment and details on how to report harmful content.', '', 'On June 21, we’re hosting an in-person Pride Skate Day with queer skaterBriana Kingfeaturing emerging and established LGBTQ+ skate creators at the intersection of sports, fashion and culture. Alongside invited press, public figures, food vendors/trucks and content activations, we’ll acknowledge and celebrate the LGBTQ+ youth community through an established holiday for the skate community.', 'On Facebook, we’re highlighting how the LGBTQ+ community uses Facebook Groups to find a sense of belonging in a portrait series entitled “My Chosen Family,” featuring diverse, intersectional communities where people have found connection,such as Thailand’sYoung Pride Cluband Philippines’Queer Safe Spaces. (Updated on June 21, 2022 at 9:15AM PT to reflect updated programming.)', '', '', '', '', '', 'The LGBTQ+ community using our technologies spans worldwide. In Brazil, we’re renewing the bi-weekly video series\\xa0 #OrgulhoFamília (#FamilyPride in English) on June 28. The series tells the stories of LGBTQ+ love and how non-biological family can be chosen for people seeking community. We will also be hosting Pride Gaming in Brazil, an event on June 12th that will bring together over 30 gaming creators to celebrate the LGBTQ+ community and live broadcast 3-hours of content on Facebook Gaming Pages, You can watch the live broadcast onFacebook Gaming.In Thailand, we are hostingPride Life,a variety show with Facebook Gaming creators such asRoger Films Studio,Rilinnz,InxTpxand many more to celebrate their authentic selves through fun activities and gaming sessions.Updated on June 21, 2022 at 9:15AM PT to reflect updated programming.)', 'We’re amplifying LGBTQ+ owned SMBs across all of our technologies to help grow their community through education and connection.', 'During the first week of June, we’re publishing theGlobal LGBTQ+ Cultural Guideas a resource designed to educate and inspire authentic ways to support the LGBTQ+ community.', 'And on@instagramforbusiness, we’re hosting a#shopwithPride Live Shopping event later this month, focused on highlighting AAPI LGBTQ+ SMBs.', 'In the Philippines and Thailand, we’re launching #MakeItWithPride, a social media campaign which shines a light on LGBTQ+ owned SMBs across different industriesand celebrates the dynamic people across the community who are shaping the future of\\xa0 culture and gender expression.(Updated on June 21, 2022 at 9:15AM PT to reflect updated programming.)', '']\n",
            "41 ['Today,we’re bringing AMBER Alerts to Instagram for the first time. This feature was developed in partnership with organizations like the National Center for Missing & Exploited Children (NCMEC) in the US, the International Centre for Missing & Exploited Children, the National Crime Agency in the UK, the Attorney General’s Office in Mexico, the Australian Federal Police and more.', 'We know that the chances of finding a missing child increase when more people are on the lookout, especially in the first few hours. With this update, if an AMBER Alert is activated by law enforcement and you are in the designated search area, the alert will now appear in your Instagram feed.', '', 'The alert will include important details about the child such as a photo, description, location of the abduction and any other available information that can be provided. People can also share the alert with friends to further spread the word.', 'These alerts are rare and specific to the search area. If you get one, it means there is an active search for a missing child nearby. In order to know who to show these alerts to, we use a variety of signals, including the city you list on your profile, your IP address and location services (if you have it turned on).', '“Instagram is a platform based on the power of photos, making it a perfect fit for the AMBER Alert program. We know that photos are a critical tool in the search for missing children and by expanding the reach to the Instagram audience, we’ll be able to share photos of missing children with so many more people.” – Michelle DeLaune, President and CEO at the National Center for Missing & Exploited Children', 'AMBER Alerts on Instagram will start rolling out today, and be fully available in the next couple of weeks in 25 countries: Argentina, Australia, Belgium, Bulgaria, Canada, Ecuador, Greece, Guatemala, Ireland, Jamaica, Korea, Lithuania, Luxembourg, Malaysia, Malta, Mexico, the Netherlands, New Zealand, Romania, South Africa, Taiwan, Ukraine, the UK, the United Arab Emirates and the US. We’re working to expand and bring them to more countries.', 'In 2015, we launched AMBER Alerts on Facebook. Since then, the alerts have assisted in hundreds of successful child endangerment cases in the US and around the world.', 'For example, in 2020,Amanda Disley and her husbandhelped rescue 11-year-old Charlotte Moccia of Springfield, Massachusetts after seeing an AMBER Alert on Facebook. And in 2016, an AMBER Alert was issued after a four-year-old girl was abducted in Lakeland, Florida.Kaytlin Brown, an anesthesia technician at Baptist East Hospital in Memphis, Tennessee was on her lunch break when she saw the alert on Facebook, recognized the missing child and quickly took action.', 'AMBER Alerts are an important way we can support our communities in keeping children safe, and we look forward to continuing this work.']\n",
            "42 ['As an avid outdoor enthusiast and firefighter, Carly P. has always loved being active. After a life-changing injury paralyzed her from the waist down, she felt lost. Carly recaptured her passion for being outside and found a community of people like her through the nonprofit organization Catalyst Sports. Now, she uses Catalyst Sports’ Facebook page to spread awareness and share local recreational opportunities for people with physical disabilities.', 'In addition to providing community to people with disabilities, we’re also working to make the digital world more accessible.', 'We will demonstrate our latest accessibility features today at ourannualAccessibility Summit. Join us at 10:00AM PT for this livestream on theMeta Accessibility Facebook Page. In addition to product demos and updates, we will host an interview with Molly Burke, a digital creator and blind advocate.', 'Through a video series on the Meta Accessibility Facebook Page, we’re highlighting how people with disabilities connect and build communities through our technologies, much like Carly. We’ve created both thecaptionedandaudio describedversions of these stories.', 'Today, we’re recapping advances we’ve made over the past year to make our technologies more inclusive.', '', '', '', '']\n",
            "43 ['Today we’re publishing our Community Standards Enforcement Report for the first quarter of 2022. It shows how we enforced our policies from January through March of 2022 across 14 policy areas on Facebook and 12 on Instagram. We’re also sharing several other reports in ourTransparency Centerincluding:', 'We’re also releasing the findings fromEY’s independent assessmentof our enforcement reporting. Last year, we asked EY to verify the metrics of our Community Standards Enforcement Report since we don’t believe we should grade our own homework. EY’s assessment concluded that the calculation of the metrics have been prepared based on the specified criteria and the metrics are fairly stated, in all material respects. As we keep growing this report, we will also keep working on ways to make sure that it’s accurately presented and independently verified.', 'The prevalence of violating content on Facebook and Instagram remained relatively consistent but decreased in some of our policy areas from Q4 2021 to Q1 2022.', 'On Facebook in Q1 we took action on:', 'On Instagram in Q1 we took action on:', 'We also saw an increase in the proactive detection rate of bullying and harassment content from 58.8% in Q4 2021 to 67% in Q1 2022 thanks to improvement and expansion of our proactive detection technology. We also continued to see a slight decrease in prevalence on Facebook from 0.11-0.12% in Q4 2021 to 0.09% in Q1 2022.', '', 'Over the years we’ve invested in building technology to improve how we can detect violating content. With this progress we’ve known that we’ll make mistakes, so it’s been equally important along the way to also invest in refining our policies, our enforcement and the tools we give to users.', 'For example, we’ve improved our transparency over the years to better inform people why we took down a post and we’ve improved the ability to appeal and ask us to take another look. We include metrics about appeals in this report. Recently we’ve begun to evaluate the effectiveness of our penalty system more deeply, for example testing the impact of giving people additional warnings before triggering more severe penalties for violating our policies.', 'Last year we saw how policy refinements can ensure that we aren’t over enforcing beyond what we intend. Updates we made to ourbullying and harassment policybetter accounted for language that can be easily misunderstood without context. Enforcement systems also play a role: we recently began testing new AI technology that identifies and prevents potential over-enforcement by better learning from content that’s appealed and subsequently restored. For example, the same word that is an offensive slur in the U.S. is also a common British term for cigarette which would not violate our policies. We’re also testing a number of improvements to our proactive enforcement, to enable some admins of Groups to better shape group culture and take context into account around what is and isn’t allowed in their space; or to better reflect the context in which people write comments between friends, where sometimes good-natured banter could be mistaken as violating content.', 'For a long time, our work has focused on measuring and reducing the prevalence of violating content on our services. But we’ve worked just as hard to improve the accuracy of our enforcement decisions. While prevalence helps us measure what we miss, we’ve also been working on developing robust measurements around mistakes, which will help us better understand where we act on content incorrectly. We believe sharing metrics around both prevalence and mistakes will provide a more complete picture of our overall enforcement system and help us improve, so we are committed to providing this in the future.', 'Finally, as new regulations continue to roll out around the globe, we are focused on the obligations they create for us. So we are adding and refining processes and oversight across many areas of our work. This will enable us to make continued progress on social issues while also meeting our regulatory obligations more effectively.']\n",
            "44 ['Today, we’re publishing the Widely Viewed Content Report (WVCR) for the first quarter of 2022. This report highlights the most-viewed organic content in Feed in the US, including domains, links, Pages and posts. It includes contentrecommended by Facebookand excludes advertising content. See thefull reportandCompanion Guidefor more information.', 'Based on feedback from several academic and civil society organizations, we are improving our link and domain data methodologies. Previously, we counted a link view as any time a post or video containing a link was viewed, even if the link was not front and center. However, the feedback from these organizations was that our data would be more meaningful if we only counted link or domain views that rendered a preview. Moving forward, links will need to render a preview in order to be counted as a view, as that more accurately represents what people are seeing. As part of the transition, the Q1 2022 report includes top viewed links using both our old and new methodologies. Starting next quarter, the WVCR will use only the new methodology.', 'In this report, there were pieces of content that have since been removed from Facebook for violating our policies of Inauthentic Behavior. The removed links were all from the same domain, and links to that domain are no longer allowed on Facebook. During the last reporting cycle, we took seriously the feedback criticizing our approach to disclosing additional details about the content removed from Facebook that appears in this report. We have updated our removal disclosure framework in the report and Companion Guide. We will aim to disclose as much information as possible about removed content, including Inauthentic Behavior, that appears in the report moving forward. However, in instances where disclosing specific details on removed content would cause harm to our community, we will err on the side of keeping the community safe.', 'Some lower-quality posts ended up amongst our most viewed last quarter, although it is important to note that the top 20 links in this report represent only 0.03% of all Feed content views in the US during the quarter. The fourth URL in the report linked to a YouTube video of a panel discussion held by a U.S. Senator that was rated False by one of our fact-checking partners. When that happened, we took a number of steps to limit the reach of this link, including adding a warning screen that shared more information about the claim, showing a notification warning to someone when they try to share the link and reducing the distribution of the link in Feed. Our strategy mirrors therecommendationsof experts and academics in this field: deeper investments in outreach by trusted organizations online, as well as fact-checking as a primary approach to misinformation, since removing certain false claims about COVID-19 can exacerbate feelings of distrust with authorities and further marginalize populations. And without these features, this link would likely have reached more people, and those who viewed it would not have seen additional information and context from the false fact check.', 'Insights from the WVCR help inform how we update our existing policies and products, and develop new ones, to address harmful or otherwise objectionable content. For example, we’ve been testing new ways to reduce clickbait, engagement bait and spam. While we’re seeing improvements from these tests,we will need to continually evaluate and refine our approachbefore seeing consistent results. We’ll continue to test alternative solutions to reduce engagement bait,misinformation and content from Pages that repeatedly violate our Community Standards.']\n",
            "45 ['Today, we’re sharing an update on our work to help keep our community safe and protect the integrity of the upcoming Philippine General election on May 9.', 'For some time, we have had a dedicated team focused on the election and as we get closer to May, we will activate anElections Operation Centerfor this election. It will bring together subject matter experts from across the company on critical issues including misinformation, safety, human rights, cybersecurity, and others to monitor and respond to emerging risks in real time. This team includes local experts who can speak the language and who have a deep understanding of the context on the ground in the Philippines.', 'We use artificial intelligence technology that we’ve trained in Filipino to help us proactively detect and remove hate speech, bullying and harassment, and content that violates ourviolence and incitementpolicies.\\xa0 In addition, we reduce the distribution of content that our technology identifies as likely to be violating those policies, to prevent it from spreading quickly. Following our review, if we determine that this content violates our policies, we remove it. We have content moderators who can review content in both Filipino and Cebuano – in addition to Filipinos working across the company.', 'We have dedicated teams that areconstantly working to find and stop coordinated campaigns that seek to target people with malicious activities on our platforms.', 'Recently we identified and removed a network that violated our policies againstdangerous organizations. This included a network of Facebook Pages, groups and accounts maintained by the New People’s Army (NPA), a banned terrorist organization, for violating our policies prohibiting groups that have a violent mission or are engaging in violence.', 'As part of tackling otheremerging harms,we also removed a network of over 400 accounts, Pages, and Groups in the Philippines that worked together to systematically violate our Community Standardsand evade enforcement.', 'The people behind this activity claimed to be hacktivists and relied primarily on authentic and duplicate accounts to post and amplify content about Distributed Denial of Service (DDoS) attacks, account recovery and defacing and compromising of primarily news entities’ websites in the Philippines.', 'As with any major civic event, we’ve also seen Inauthentic Behaviour operators from various countries become active on the margins of the upcoming Philippines elections.\\xa0 Here are some of the notable insights:', 'Weremove misinformationwhere it is likely to put people at risk for imminent physical harm. We also remove content that is likely to keep normal political processes from functioningsuch as content intended to suppress voting, as well as certain highly deceptive manipulated media.', 'For content which does not violate our policies,independent third-party fact-checking partners in the Philippines— AFP, Rappler, and Vera Files — review and rate the accuracy of such content and provide additional context. We provided funding support to help them increase their capacity to promote reliable information in the lead up to the elections. All our fact-checking partners are certified by the nonpartisanInternational Fact-Checking Network(IFCN) and review content in English andFilipino.', 'When a fact-checker rates a piece of content as false, we reduce its distribution, notify people who share the content — or who have previously shared it — that the information is false or misleading, and we add a warning label that links to the fact-checker’s article disproving the claim. We are also adding these labels to fact-checked content that appears in Messenger in the Philippines in the coming weeks. For Pages, groups, profiles, websites and Instagram accounts that repeatedly share content rated False or Altered, we will reduce the distribution of everything they post,\\xa0 remove them and their posts from the recommendations we show people, and their ability to monetise and advertise on our platforms.', 'We also launched thePhilippine Fact-Checker Incubator program with Internewsto support capacity-building for fact checking in the Philippines.\\xa0 Participating organizations are encouraged to become IFCN certified to help bolster the fact checking industry in the Philippines. Their fact-checks can be foundhere.', 'To help Filipinos easily find credible voter registration information, we launched a pop up notification on Facebook feed last year. Itgenerated over 10 million clicks and led people to more information on how and where to register in COMELEC’s official partners’ websites:Vote PilipinasandMagparehistro ka!.According to COMELEC, they received 1.9 million new registrants during the run of the campaign – more than double the daily average of registrations received before the campaign. We will also launch voting day reminders in people’s Facebook feeds in the Philippines.', 'Together with theInternational Center for Journalistsand theBorder Center for Journalists and Bloggers, we rolled out afree digital security and safety programto help journalists and human rights defenders protect their digital assets andcounter online harassment. Meta’sJournalist Safety Hubcentralizes all resources and tools available on our platforms.', 'We have made severalupdates to our Community Standards,including expandingprotections for public figuressuch as journalists and human rights defenders. We now remove more types of harmful content such as claims about sexual activity, comparisons to animals and attacks through negative physical descriptions. Our policies now also providestronger protections against gender-based harassmentfor everyone, including public figures.', 'Last year we launched new policies againstmass harassment and brigading, and we now remove coordinated efforts of mass harassment that target individuals at heightened risk of offline harm. This includes attacks against dissidents — even if the content on its own wouldn’t violate our policies. We also remove state-linked and adversarial networks of accounts, Pages and Groups that work together to harass or try to silence people.These efforts and updates to policies are informed by ourindependent Human Rights Impact Assessment Report on the Philippinespublished in 2021.', 'We want people to know who is behind the ads they see on our apps, so they can make informed decisions at polling day.', 'Advertisers in the Philippines are now required to complete our ad authorizations process and include “Paid for by” disclaimers on ads about elections, politics, and certain categories of social issues. Last month, we began requiring anyone running ads about certain categories of social issues in the Philippines toget authorizedand show the organization or person who is running the ad with disclaimers.', 'Ads about social issues, elections or politics that run in the Philippines will also appear in theAds Libraryso that everyone can see what ads are running, who saw them and how much was spent. This fully searchable archive stores these ads for seven years.', 'Our work to help protect the integrity of the upcoming Philippine election builds on ourlongstanding effortsin understanding and addressing how social media is used in the Philippines and will continue in the lead up to, during, and after the vote.']\n",
            "46 ['Today, we’re publishing the findings and recommendations of an independent human rights impact assessment (HRIA) on our plans to expand end-to-end encryption (E2EE). The assessment was conducted byBusiness for Social Responsibility(BSR) in line with theUN Guiding Principles on Business and Human Rightsand Meta’sCorporate Human Rights Policy.¹ We are taking the exceptional step to publish this HRIA in full as a standalone product because we believe it represents a groundbreaking contribution to the ongoing conversation on implementing E2EE while meaningfully advancing the field of human rights.', 'Privacy is a fundamental human right. End-to-end encryption is a widely-used technology that protects the privacy and many other human rights of billions of people every day. E2EE keeps people and their personal communications safe from hackers, criminals and authoritarian regimes. That’s why in 2016 we implemented this technology by default on WhatsApp and as an option on Messenger, and in March 2019 we announced plans to extend this protectionby default across our messaging apps.', 'Since then, we’ve witnessed a global pandemic push more of our lives online, leading to an increased threat of cybercrime and invasion of people’s private communications. At the same time, the threat of authoritarianism is on the rise. That’s why, following Russia’s invasion of Ukraine, weaccelerated the deployment of E2EE optionson Instagram and promoted our disappearing messaging features on Messenger so that people in the affected countries would have more secure communication. Safe and secure messaging is more important than ever.', 'This comprehensive rights-based analysis of implementing E2EE is the first of its kind. By analyzing encryption acrossall rightsrecognized in theUniversal Declaration of Human Rightsand a range of other human rights instruments, the HRIA expands existing rights-based analyses and underscores why encryption is important today and in the future.', 'The report found that:', 'Read the full report.', 'BSR’s recommendations are designed to help us maximize the positive human rights impacts of E2EE, while mitigating potential adverse impacts. The report includes 45 recommendations broken down into four sections: product, process, product policy and public policy.Our responsedetails our commitment to implementing 34 of the recommendations, partly implementing four, assessing the feasibility of another six and taking no further action on one. We’re committed to implementing the vast majority of the recommendations and working diligently towards our plans for expanding E2EE as a means to help protect people and support their human rights. We’ve already made progress on many of the recommendations, but our work in this area is never done.', 'Over the years we’ve invested billions of dollars, hired thousands of people and collaborated with experts around the world to help keep people safe without compromising their sensitive and personal information. The recommendations will help guide ourapproach to safer private messagingfor Messenger and Instagram DMs as we implement E2EE by default on these messaging apps: helping to prevent abuse and to safeguard people’s privacy, giving people controls to help them stay safe and not reading people’s personal messages unless they report them to us.', 'To monitor for harmful or illegal content, many messaging platforms — including Messenger and Instagram DMs — have historically relied on the ability to proactively access people’s messages. With end-to-end encryption, however, only the sender and recipient can access the content of those messages. Scanning technologies that seek to proactively access message content, whether on a person’s device or otherwise, without the person’s consent and control could be abused by criminals, hackers or authoritarian regimes, putting people’s safety at risk. While other reasonable mitigations can and should be enacted, we do not believe such approaches, often called “client-side scanning,” can be developed and implemented in a manner that is rights-respecting, nor can such technologies meet the expectations people have of end-to-end encrypted messaging services.', 'As we make these major enhancements to our messaging apps, we want to be thoughtful in our approach, comply with our human rights policy and evaluate how our decisions can help respect and support human rights. While we expect to make significant progress this year, implementing E2EE on Messenger and Instagram messaging continues to be a long-term project and we’re taking our time to get this right.', 'The report emphasizes the need for collaboration across industry, academia, civil society and government to implement end-to-end encryption in a deliberate way that’s consistent with our commitment to people’s privacy, safety and security. We will continue engaging with these partners in promoting the vital human rights end-to-end encryption protects, while remaining mindful of the need to help safeguard all human rights.', '', '1. This assessment was conducted by BSR from 2019-2021 using methodologies based upon the UN Guiding Principles on Business and Human Rights (UNGPs), including a consideration of the various human rights principles, standards, and methodologies upon which the UNGPs were built. BSR engaged with a diverse range of rights holders and stakeholders when undertaking this assessment and supplemented the stakeholder inputs with their own insights into the human rights concerns of rights holders and stakeholders gathered in a variety of contexts, including previous HRIAs undertaken for Meta.']\n",
            "47 ['Update June 14, 2022 at 7:30AM PT:', 'We’re beginning to roll out parental supervision tools to all Quest headsets. We’re also launching our newParent Education Hub, includinga guide to our VR parental supervision tools from ConnectSafelyto help parents and guardians discuss virtual reality with their teens.Click herefor more information.', '', 'Update May 16, 2022 at 5:00PM PT:', 'Today, we’re rolling out the ability for people to use theunlock patternon their Quest headsets to lock specific apps directly from VR. Once a given app is locked, you’ll need to draw your unlock pattern to unlock and launch it. This update lets parents and guardians prevent teens 13+ from accessing games and experiences they feel aren’t age-appropriate by using an unlock pattern to lock access to those apps.', 'This is an important step toward giving parents and teens 13+ more control over their VR experience. For more information on today’s software update, pleaseclick here.', '', 'Originallypublished on March 16, 2022 at 6:00AM PT:', 'Today, we’re announcing parental supervision tools for VR, which will begin rolling out to all Quest headsets over the coming months. This is an early look at our plans to provide platform-level controls for parents and teens ages 13+.', 'As a first step to giving people more customized control over their experience in VR, we’ll expand the functionality of our existingunlock patternon Quest headsets. Today, you can create an unlock pattern as an extra layer of security to prevent others from accessing your device or saved passwords. Beginning in April, we’ll introduce the ability for people to use the unlock pattern to lock specific apps directly from VR. Once a given app is locked, you’ll need to draw your unlock pattern to unlock and launch it. This will allow parents to prevent teens 13+ from accessing games and experiences they feel aren’t age-appropriate by using an unlock pattern to lock access to those apps.', 'Next, in May 2022, we’ll begin automatically blocking teens 13+ from downloading or purchasing apps rated age-inappropriate by theInternational Age Rating Coalition, as well as launch our initial suite of parental supervision tools. Different teens have different maturity levels, and parents know their teens best, so we’ll offer the ability for parents to override app blocks on a case-by-case basis. We also know that customizable controls, teen autonomy and adjustable settings are important to our community. Only teens with parental supervision tools enabled will be able to request permission to override blocks, and parents will be able to approve or deny each request.', 'We’ve been working with industry experts Larry Magid atConnect Safely, Dr. Michael Rich atDigital Wellness Lab, Janice Richardson atInsight SA, and Jutta Kroll atStiftung Digitale Chancento help inform our approach and better understand how we can best meet our community’s needs.', 'Our initial suite of parental supervision tools, which includes a Parent Dashboard accessible from the Oculus mobile app, will allow parents to link to their teen’s account via a process initiated by the teen and with consent from both sides. This is just a starting point, informed by collaboration with industry experts, and we’ll continue to grow and evolve our parental supervision tools over time.To start:', '', '', 'Quest devices are only intended for use by people ages 13+ and are not designed for younger children. This is stated in ourTerms of Service, product onboarding andSafety Center. Our parental supervision features are designed to serve the needs of teens ages 13+. Learn more aboutadditional tips and toolsparents can use to help keep teens 13+ safe in VR.', 'Read more about ourparental supervision tools in VRand our newFamily Center.']\n",
            "48 ['Parents and guardians know what’s best for their teens, andin DecemberI committed to developing new supervision tools that allow them to be more involved in their teens’ experiences.', 'Today, we’re making these supervision tools available in our new Family Center.We worked closely withexperts, parents, guardians and teens to developFamily Center, a new place for parents to oversee their teens’ accounts within Meta technologies, set up and use supervision tools, and access resources on how to communicate with their teens about internet use.', 'This is just one step on a longer path — our vision for Family Center is to eventually allow parents and guardians to help their teens manage experiences across Meta technologies, all from one central place.', 'Family Center includes a neweducation hubwhere parents and guardians can access resources from experts and review helpful articles, videos and tips on topics like how to talk to teens about social media. Parents can also watch video tutorials on how to use the new supervision tools available on Instagram today. We worked closely with groups likeConnect SafelyandNet Family Newsto develop these resources, and we’ll continue to add new information to Family Center’s education hub.', '', 'Supervision tools on Instagram are available in the US today, with plans to roll out globally in the coming months.Our first set of parental supervision tools on Instagram will allow parents and guardians to:', 'Learn more abouthow to set up supervision on Instagram. Teens will need to initiate supervision for now in the app on mobile devices, and we will add the option for parents to initiate supervision in the app and on desktop in June. Teens will need to approve parental supervision if their parent or guardian requests it.', '', 'Over the next few months we’ll add additional features, including letting parents set the hours during which their teen can use Instagram and the ability for more than one parent to supervise a teen’s account.', 'We’re also announcingVR parental supervision toolsthat will roll out to Quest in the coming months.As a first step to giving people more customized control over their VR experience, we’ll expand the functionality of our existingunlock patternon Quest headsets, starting in April.This will allow parents to prevent teens 13+ from accessing experiences they feel aren’t age-appropriate by using an Unlock Pattern to lock access to those apps. And in May, we’ll start automatically blocking teens 13+ from downloading IARC rated age-inappropriate apps. We’ll also launch a Parent Dashboard, hosting a suite of supervision tools that will link to the teen’s account based on consent from both sides.', 'While we have involved young people, parents and experts in our product design process for a long time, we always look for more ways to incorporate their feedback directly. One way we’re doing this is through theTrust, Transparency and Control (TTC) Labsand our global co-design program — a multidisciplinary research program that engages and empowers young people, parents, guardians and experts to collaborate with us in the product design process. We used insights from this program to inform how we built our supervision tools, and will continue to do so as we introduce more features for families over time.', 'As always, we appreciate the input from experts who help us deepen our understanding of this area, so we can continue protecting teens, supporting families and preserving all the good that young people derive from the internet.', '“The co-design process has clearly shown that teens like to be able to call on their parents for support and guidance, but often don’t know where or how to begin. By proposing parental supervision tools across apps, Meta will help overcome this hurdle. Especially since the tools are unobtrusive, respectful of privacy, and offer the ideal training wheels for younger teens building their competence and confidence in the online social environment.”–Janice Richardson, International Advisor at Insights SA', '“Encouraging informed parental engagement in their children’s digital presence is an important way to support young people’s wellness online. Parents can model and mentor the use of these powerful tools for their children, engaging in these spaces alongside their children to provide opportunities for learning. Parents can support and monitor their children’s gradual increase in independence as they demonstrate responsible and safe use, with respect for others and for themselves. By engaging parents as co-learners with their children, we can support their parenting in the digital ecosystem in ways consistent with their parenting in the physical world, setting their children up for long-term physical, mental, and social wellness.” –Dr. Michael Rich, Director and Founder at Boston Children’s Hospital’s Digital Wellness Lab', '“We’re happy to see the new tools Meta is launching to support parents in helping their children navigate the various social apps. Our research shows that regular parental supervision and co-participation is the best way to inoculate kids from the worst aspects of the internet. We’re hopeful that parents will take advantage of these new resources, and will continue to collaborate with Meta in their efforts to make their products safer and more enjoyable for families.” –Justin Patchin, Co-founder and Co-director at Cyberbullying Research Center']\n",
            "49 ['Today we’re publishing ourCommunity Standards Enforcement Reportfor the fourth quarter of 2021 and provides metrics on how we enforced our policies from October 2021 through December 2021 across 14 policy areas on Facebook and 12 on Instagram.', 'We’re also sharing:', 'All of these reports are available in theTransparency Center.', 'Prevalence of harmful content on Facebook and Instagram remained relatively consistent — and decreased in some of our policy areas — from Q3 to Q4, meaning the vast majority of content that users generally encounter does not violate our policies.', 'We continued to see steady numbers on content we took action on across many areas.', 'On Facebook in Q4 we took action on:', 'On Instagram in Q4 we took action on:', 'In the Q3 report, we began reporting prevalencemetrics on bullying and harassmentfor the first time. In Q4, bullying and harassment prevalence on Instagram remained relatively consistent over last quarter at 0.05-0.06%. On Facebook, prevalence of bullying & harassment was at 0.11-0.12% in Q4, down from 0.14-0.16% in Q3. The reduction in prevalence was in part due to policy updates accounting for language that, without additional context, could be considered offensive, but in reality is used in a familiar or joking way between friends.', 'Our steady improvement can be attributed to a holistic approach including our policies, the technology that helps us enforce them, the operational piece of global content moderation and a product design process that focuses on safety and integrity', 'With advancements in AI technologies, like ourFew Shot Learnerand shift togeneralized AI, we’ve been able to correctly take action on harmful content more quickly.', '', 'Our product design teams play an important role in our effort to reduce harmful content. By carefully designing our social media products, we can promote greater safety while providing people with context, control and the room to share their voice.For example, when applied, informative overlays and labels provide more context and limit exposure to misinformation or graphic content.Read more about ourintegrity design process.', '', 'Last fall, we launchedAccount Statuson Instagram, whichhelps people understand why content has been removed and what policies it violates.We know this kind of transparency is important, because it helps people better understand our policies, and it also helps our systems by giving us indications when we’ve gotten things wrong.Following this launch, we saw an increase of restored content on Instagram across several policy areas, including violence and incitement, hate speech, bullying and harassment and adult nudity and sexuality.', '', 'We’re always trying to identify policies we may be under- or over-enforcing so that we can improve. For example, in 2020 during Breast Cancer Awareness Month, there was an influx of breast cancer-related content on Instagram, including images containing adult nudity that were medical in nature. While these don’t violate our policies, many were enforced on incorrectly by our systems, which led to content being taken down from breast cancer support accounts and individual cancer survivors. We heard from our community thatwe needed to improve on how we enforce this type of content.The Oversight Board also heard a case related tobreast cancer symptoms and nudityand asked us to improve our enforcement accuracy.', 'Since then, we’ve been working to improve the accuracy of enforcement on health content, including content related to breast cancer and surgeries. We defined and clarified our exception for medical nudity by training our AI systems to better recognize exposed chests with mastectomy scars and escalating content flagged as medical nudity for human review to further improve accuracy. We also send content with frequently-used keywords for human review. Finally, we trained our systems to better recognize benign and non-violating images and avoid overenforcement in the future. As a result, we saw significantly less overenforcement during last year’s Breast Cancer Awareness Month, which empowered our community to share content openly.', 'We’re constantly looking for new ways to improve our transparency and the integrity of our platforms.For many years, we’ve publishedbiannual transparency reports,which include the volume ofcontent restrictionswe make when content is reported as violating local law but doesn’t go against our Community Standards.We’ve now agreed to contribute toLumen, an independent research project hosted by Harvard’s Berkman Klein Center for Internet & Society, which studies cease-and-desist letters from governments and private actors concerning online content. We’re joining Project Lumen because itallows us to hold governments, courts, regulators and ourselves accountable for the content they request to be removed under local law.We hope to scale up our participation in Lumen over time.', 'We’ll continue building on our progress to enforce our policies in 2022, as we’re always working to improve, be transparent and share meaningful data.']\n",
            "50 ['Today, we’re publishing the Widely Viewed Content Report (WVCR) for the fourth quarter of 2021. This report highlights the most-viewed organic (non-ad) content in Feed, including domains, links, Pages and posts in the US. It also includes contentrecommended by Facebookand excludes advertising content. See thefull reportandCompanion Guidefor more information. Changes since our last report include the appearance of Reels, which were launched in the US in late September 2021.', 'Insights from the WVCR inform how we update our existing policies and products, as well as develop new ones to remove and reduce objectionable content that may violate our policies. In this report, content and Pages were removed for violating our policies involving personal information bait, inauthentic behavior, phishing and harassment. We generally don’t publicly share additional identifying information about Pages or profiles that have been removed. As we look for ways to be more transparent about our most widely viewed content, we are exploring how best to provide more details going forward.(Updated on March 1, 2022 at 7:45PM PT to clarify our approach to identifying pages we’ve previously removed.)', 'We’ve also seen promising results from our tests to reduce engagement bait — spammy posts that explicitly request reactions for purposes other than a specific call to action. These efforts included expanding our identifiers and introducing spacing rules to help prevent multiple posts that are identified as engagement bait from showing up one after the other in Feed. Our approach will continue to evolve over time.', 'By releasing the WVCR, we have the opportunity to shed new light on the content that is widely seen in Feed. We’ll continue to expand the scope of this report in the coming months. Our goal is to keep working with external stakeholders to improve and refine these reports and we will share more information as this develops.']\n",
            "51 ['Jump to latest newsUkrainian\\xa0translation,Russian translation', 'Update on March 17, 2022 at 9:00AM PT:', 'We’re continuing to see our community come together to help people fleeing the war in Ukraine. Today, we’re sharing a few updates to make it easier for people to get information and offer support.', '', 'Update on March 11, 2022 at 4:00PM PT:', 'Head of Instagram Adam Mosseri responded to Russia’s decision to block access to Instagram:', '', 'A post shared by Adam Mosseri (@mosseri)', '', 'Update on March 11, 2022 at 3:30PM PT:', 'President, Global Affairs Nick Clegg’s statement to reports that the Russian government is considering designating Meta as an extremist organization for its policies in support of speech:', 'There has been a lot of coverage and discussion of how we are applying our policies to speech in the context of Putin’s invasion of Ukraine.', 'I want to be crystal clear: our policies are focused on protecting people’s rights to speech as an expression of self-defense in reaction to a military invasion of their country. The fact is, if we applied our standard content policies without any adjustments we would now be removing content from ordinary Ukrainians expressing their resistance and fury at the invading military forces, which would rightly be viewed as unacceptable.', 'To be clear, we are only going to apply this policy in Ukraine itself. We have no quarrel with the Russian people. There is no change at all in our policies on hate speech as far as the Russian people are concerned. We will not tolerate Russophobia or any kind of discrimination, harassment or violence towards Russians on our platform.', 'This is a temporary decision taken in extraordinary and unprecedented circumstances. We will be keeping the situation under review in the period ahead.', 'Update on March 8, 2022 at 9:00PM PT:', 'As the humanitarian crisis deepens, today we are announcing additional steps to help our community access crucial resources and take action to support people in need.', 'Helping People Access Resources', 'This slideshow requires JavaScript.', 'Helping People Show Support for Ukraine', '', 'Update on March 8, 2022 at 8:00AM PT:', 'Today, we’re sharing updates that we’re making on Instagram to help keep people in Ukraine and Russia safe and reduce the spread of misinformation.', 'Keeping Information and Associations Private on Instagram:To help protect our communities in Ukraine and Russia, we’ll now be hiding information about people’s followers, who they’re following, and people who are following each other for private accounts based in these two countries.', 'This means that people following private accounts based in Ukraine and Russia will no longer be able to see who those accounts are following, or who follows them. We’re also not showing these accounts in other people’s follower or following lists, or in our “mutual follows” feature. We notified private accounts in Ukraine and Russia letting them know about this change.', 'We’re also highlighting tools likeYour ActivityandDownload Your Informationto accounts in Ukraine and Russia. Your Activity \\u200b\\u200ballows people to bulk delete content they’ve posted like photos and videos, as well as their previous likes and comments.Download Your Informationallows people to get a copy of their Instagram data.', '', 'Addressing Russian State-Controlled Media on Instagram:Following last week’s announcement that we’ve begun demoting posts containing links to Russian state-controlled media on Facebook, starting today, Stories that contain a link sticker pointing to a Russian state-controlled media website on Instagram will be placed lower in the Stories tray. We’ll also label these Stories to let people know that they lead to Russian state-controlled media websites.', '', 'These changes are in addition to steps we’ve already taken to make content from accounts run by Russian state-controlled media harder to find on Instagram, and to provide more transparency if people try to share content from these accounts.', 'Specifically, we’re downranking posts from Russian state-controlled media in Feed, and placing them lower in the Stories tray. We’re also showing people a notice before they reshare content from these accounts in their Stories, letting them know that the content comes from Russian state-controlled media. If people still choose to reshare these posts to their Stories, we will place those Stories lower in the tray.', '', 'Lastly, we’re not recommending posts from Russian state-controlled media accounts in Explore and Reels, and we’re making these accounts harder to find in Search.', 'Update on March 4, 2022 at 3:00PM\\xa0 PT:', 'Despite the Russian government’s announcement that they will be blocking Facebook, we are working to keep our services available to the greatest extent possible. However, due to the difficulties of operating in Russia at this time, ads targeting people in Russia will be paused, and advertisers within Russia will no longer be able to create or run ads anywhere in the world, including within Russia.', 'Update on March 4, 2022 at 11:15AM PT:', 'Update on Russia’s Decision to Block Access to Facebook:As a result of the Russian government’s decision to block access to Facebook in the Russian Federation, soon millions of ordinary Russians will find themselves cut off from reliable information, deprived of their everyday ways of connecting with family and friends and silenced from speaking out. We will continue to do everything we can to restore our services so they remain available to people to safely and securely express themselves and organize for action.', 'Update on Restricting Access to RT and Sputnik:Earlier this week, we announced that we’d be restricting access to RT and Sputnik across the EU given the exceptional circumstances. Consistent with that action, and following a request from the UK government, we will also be restricting access to RT and Sputnik in the UK at this time.', 'Update on March 3, 2022 at 4:50PM PT:', 'Increasing Our Support for Humanitarian Efforts: Today, we’re committing $15 million to support humanitarian efforts in Ukraine and neighboring countries. This includes $5 million in direct donations to UN agencies and more than a dozen nonprofits, including International Medical Corps who will be using these funds to deploy mobile medical units to Ukraine and Internews to support at-risk journalists and human rights defenders in the region. We’re also donating to UNICEF to scale up lifesaving support for children and families in Ukraine and the region.The remaining $10 million will be provided as ad credits, helping nonprofit organizations raise the funds they need to respond and deliver essential information to people impacted by the violence.', 'Update on March 1, 2022 at 6:05PM PT:', 'Update on State-Controlled Media Outlets:In addition to restricting access to RT and Sputnik across the EU, we are now globally demoting content from Facebook Pages and Instagram accounts from Russian state-controlled media outlets and making them harder to find across our platforms.', 'We have also begun to demote posts that contain links to Russian state-controlled media websites on Facebook. In the days ahead, we will label these links and provide more information to people before they share or click on them to let them know that they lead to Russian state-controlled media websites. We plan on putting similar measures in place on Instagram.', 'We already label Facebook Pages and Instagram accounts from Russian state-controlled media outlets so people know where this information comes from. By providing this additional transparency, we aim to give people more context if they want to share direct links to Russian state-controlled media websites or when others see someone’s post that contains a link to one of these sites.', 'Reliable Access to Trusted Information:Ukraine’s State Emergency Services has launched an information helpline on WhatsApp. The free service will connect users to critical updates, reliable and trustworthy information, as well as details about emergency response procedures. To use the free helpline on WhatsApp, simply save the number+380676785917in your phone contacts and then text the word почати (begin) in a WhatsApp message to get started.', 'How Our Community Is Helping:Throughout this war and humanitarian crisis, we’ve seen people across the world use our tools to make their voices heard and support each other. For example, since February 23, more than $20 million has been raised for nonprofits on Facebook and Instagram in support of humanitarian efforts for Ukraine.(Updated on March 2, 2022 at 10AM PT to reflect the latest fundraising amount.)We’ve also seen Facebook Groups created to help those in need, including a group of 200,000 Romanian volunteers and donors coordinating transportation and accommodations for refugees. And a group of more than 300,000 in Poland is offering housing, clothing, medication and rides from the border to help those in need.', 'Today, we’re also announcing that as part of ourData for Good program, we’re making aggregated data on social connections available to trusted organizations working to provide medical services and support to refugees, like Direct Relief, which is using this data to better understand where people might be going so they can best support communities in need.', 'Update on February 28, 2022 at 5:55PM PT:', 'We have received requests from a number of governments and the European Union to take further steps in relation to Russian state-controlled media. Given the exceptional nature of the current situation, we will be restricting access to RT and Sputnik across the EU at this time.', 'As of this morning, we’ve made encrypted one-to-one chats available on Instagram for all adults in Ukraine and Russia. We’ll also show notifications at the top of people’s direct message inboxes to let them know they can switch to an encrypted conversation if they want to. End-to-end encrypted chats are already available as an option on Messenger and by default on WhatsApp. This update is not available to business accounts on Instagram.', 'Update on February 27, 2022 at 9:00PM PT:', 'We took down a network run by people in Ukraine and Russia targeting Ukraine for violating our policy againstcoordinated inauthentic behavior. They ran websites posing as independent news entities and created fake personas across many social media platforms including Facebook, Instagram, Twitter, YouTube, Telegram, Odnoklassniki and VK.', 'We’ve also seen increased targeting of Ukrainian military and public figures by Ghostwriter, a threat actor that has beentrackedfor some time by the security community. We encourage people in Ukraine and Russia to adopt stronger account security measures — like two-factor authentication — to protect their information in the midst of this invasion. We continue to roll out privacy and security measures to help people in Ukraine and Russia protect their accounts from being targeted.', 'Learn more about oursecurity updates in Ukraine.', 'Update on February 27, 2022 at 11:45AM PT:', 'We have been in contact with the government of Ukraine. At their request, we have restricted access to several accounts in Ukraine, including those belonging to some Russian state media organizations. We are also reviewing other government requests to restrict Russian state-controlled media.', 'Originally published on February 26, 2022 at 11:50AM PT:', 'Our thoughts are with everyone affected by the war in Ukraine. We are taking extensive steps across our apps to help ensure the safety of our community and support the people who use our services — both in Ukraine and around the world.', 'The following are some of the specific steps we have taken regarding Russia’s invasion of Ukraine:', 'We’ve added several safety features in Ukraine in response to the situation on the ground.', 'We are taking additional steps to enforce our Community Standards and Community Guidelines, not only in Ukraine and Russia but also in other countries globally where content may be shared.', 'We are taking extensive steps to fight the spread of misinformation on our services and continuing to consult with outside experts.', 'We providegreater transparencyon accounts from state-controlled media outlets, including Russian-based RT and Sputnik, because they combine the influence of a media organization with the strategic backing of a state, and we believe people should know if the news they read is coming from a publication that may be under the influence of a government.', 'We remain vigilant to emerging trends and stand ready to take additional action to meet the demands of this ongoing conflict.', 'Оновлено 17 березня 2022 року о 9:00AM PT:', 'Ми продовжуємо спостерігати за об’єднанням нашої спільноти, що має на меті допомагати людям, які тікають від війни в Україні. Сьогодні ми хочемо поділитися деякими оновленнями, які допоможуть людям легше отримувати інформацію та надавати підтримку.', '', 'Оновлено 11 березня 2022 року о 4:00PM PT:', 'Глава Instagram Адам Моссері відповів на рішення Росії заблокувати доступ до Instagram:', '', 'A post shared by Adam Mosseri (@mosseri)', '', 'Оновлено 11 березня 2022 року о 3:30PM PT:', 'Заява Ніка Клегга, президента відділу з міжнародних справ у Мета, у відповідь на повідомлення про те, що російський уряд розглядає можливість включення компанії Мета в список екстремістських організацій за її політику на підтримку деяких висловлювань:', 'Було багато повідомлень і дискусій про те, як ми застосовуємо нашу Політику щодо свободи слова в контексті вторгнення Путіна в Україну.', 'Я хочу бути щирим: наша політика спрямована на захист прав людей на свободу слова, яка є одним з проявів самооборони, у відповідь на військове вторгнення в їхню країну. Справа в тому, що якби ми застосовували нашу стандартну політику щодо контенту без будь-яких коригувань, ми б зараз видаляли контент простих українців, які виражають свій опір і лють по відношенню до військових сил, які вторглися в їхню державу. Такі наші дії були б справедливо розцінені як неприйнятні.', 'Для ще більшої ясності, ми збираємося застосовувати цю політику тільки на території України. У нас немає ніяких непорозумінь з російським народом. У нашій політиці щодо мови ворожнечі немає ніяких змін в тому, що стосується росіян. Ми не потерпимо русофобії або будь-якого виду дискримінації, переслідування або насильства по відношенню до росіян на нашій платформі.', 'Це тимчасове рішення, прийняте в надзвичайних і безпрецедентних обставинах. Ми будемо стежити за розвитком цієї ситуації в майбутньому.', 'Оновлено 8 березня о 9:00PM PT:', 'Сьогодні ми оголошуємо про запровадження додаткових заходів, які допоможуть нашій спільноті отримати доступ до найважливіших ресурсів, а також вжити заходів для підтримки людей, які цього потребують, у зв’язку із подальшим розвитком\\xa0 гуманітарної кризи.', 'Допомога людям у доступі до ресурсів', 'Допомагаємо людям демонструвати їхню підтримку Україні', 'Оновлено 8 березня 2022 року о 8:00AM PT:', 'Сьогодні ми ділимося нашими оновленнями в Instagram, які мають допомогти захистити людей в Україні та Росії, а також зменшити поширення дезінформації.', 'Збереження конфіденційності інформації та зв’язків в Instagram:з метою захисту наших спільнот в Україні та Росії, відтепер ми будемо приховувати інформацію про Ваших підписників, підписки та взаємні підписки. Ці зміни стосуються приватних облікових записів людей, які проживають на території цих двох країн.', 'Це означає, що люди, які стежать за приватними акаунтами користувачів з України та Росії, більше не зможуть побачити, за ким стежать ці акаунти або хто стежить за ними. Ми також не будемо показувати ці облікові записи серед підписників інших людей, а також у нашій функції “взаємні підписки”. Ми вже повідомили власників приватних акаунтів з України та Росії про ці зміни.', 'Власникам акаунтів в Україні та Росії ми також нагадуємо про існування таких функцій як: “Ваша активність” та “Завантажити інформацію”. Функція “Ваша активність” дозволяє людям масово видаляти розміщений ними контент, наприклад, фотографії та відео, а також попередні лайки і коментарі. “Завантажити\\xa0 інформацію” дозволяє людям отримати копію своїх даних в Instagram.', 'Наша відповідь російським державним ЗМІ в Instagram:Минулого тижня ми оголосили про початок зниження рейтингів постів, що містять посилання на російські державні ЗМІ у Facebook. А вже від сьогодні Stories, що містять стікер з посиланням на сайт російського державного ЗМІ в Instagram, будуть розміщуватися в кінці стрічки. Ми також будемо відповідним чином позначати ці Stories для інформування людей про те що ці посилання ведуть на сайти російських державних ЗМІ.', 'Ці зміни доповнюють кроки, які ми вже встигли зробити, щоб контент від російських державних ЗМІ було складніше знайти в Instagram. Крім цього, це було зроблено для забезпечення більшої прозорості, якщо люди намагатимуться поділитися інформацією, розміщеною на сторінках цих ЗМІ.', 'Зокрема, ми знижуємо рейтинг постів від російських державних ЗМІ у загальній стрічці, а також розміщуємо їх далі у стрічці Stories. Крім цього, перш ніж люди захочуть зробити репост будь-якої інформації з цих сторінок до себе у Stories, ми сповіщатимемо їх, що інформація належить російським державним ЗМІ. Якщо люди все ж вирішать зробити репост з тих сторінок до себе у Stories, ми розмістимо ці історії далі в стрічці.', 'Підсумовуючи, ми не рекомендуємо публікувати інформацію зі сторінок російських державних ЗМІ в Explore і Reels, а також ускладнюємо пошук таких акаунтів.', 'Оновлено 4 березня 2022 року о 3.00PM PT:', 'Незважаючи на оголошення російського уряду про блокування Facebook на території країни, ми працюємо над тим, щоб наші послуги залишалися доступними якомога довше. Однак через труднощі в функціонуванні на території Росії, рекламу орієнтовану на її мешканців, буде призупинено. Крім цього, російські рекламодавці більше не матимуть змогу створювати або показувати рекламу в будь якій точці світу, в тому числі в Росії.', 'Оновлено 4 березня 2022 року о 11:15PM PT:', 'Актуальна інформація щодо рішення Росії про блокування доступу до Facebook: У результаті рішення російського уряду про блокування доступу до Facebook на території Російської Федерації, незабаром мільйони звичайних росіян будуть відрізані від достовірної інформації, позбавлені своїх повсякденних способів спілкування з родиною та друзями та не матимуть можливості вільно висловити свої думки. Ми продовжуватимемо робити все можливе задля відновлення наших послуг в країні, щоб вони залишалися доступними для людей, які хочуть безпечно та вільно висловлювати свою думку та організовуватись до дій.', 'Актуальна інформація щодо обмеження доступу до RT і Sputnik: Раніше цього тижня ми вже оголосили, що обмежимо доступ до RT і Sputnik на території всього Європейського Союзу з огляду на виняткові обставини. Відповідно до цього рішення та на прохання уряду Великобританії, на цей час ми також обмежимо доступ до RT і Sputnik у Великій Британії.', 'Оновленo 3 березня 2022 року о 4:50 PM PT:', 'Збільшуємо нашу гуманітарну допомогу:Сьогодні ми виділяємо 15 мільйонів доларів на гуманітарну допомогу для України та сусідніх країн. З них 5 мільйонів доларів у вигляді прямих пожертвувань будуть перераховані понад десятьом некомерційним організаціям, а також агенціям ООН.\\xa0 До цих організацій належать Міжнародний медичний корпус, який використовуватиме ці кошти для розгортання мобільних медичних підрозділів в Україні, та Інтерньюз, що підтримуватиме\\xa0 журналістів і правозахисників, які перебувають в зонах ризику. Ми також надамо кошти для ЮНІСЕФ з метою збільшення життєво необхідної допомоги дітям та сім’ям в Україні і в цілому регіоні. 10 мільйонів доларів у вигляді рекламних купонів будуть надані некомерційним організаціям, щоб допомогти їм зібрати необхідні кошти для реагування на потреби людей та надання необхідної інформації тим, хто постраждав від жорстокостих подій.', 'Оновлено 1 березня 2022 року о 6:05 PM PT:', 'Актуальна інформація щодо державних ЗМІ: Ми обмежуємо доступ до RT і Sputnik на території ЄС. Крім того, ми глобально знижуємо рейтинг сторінок Facebook і акаунтів Instagram, що належать російським державним ЗМІ, тому їх складніше знайти на наших платформах.', 'Ми також почали знижувати рейтинг дописів на Facebook, що містять посилання на сайти російських державних ЗМІ. У найближчі дні ми будемо відповідно позначати ці посилання і надавати людям більше інформації про те, що дані веб-адреси ведуть на сайти російських державних ЗМІ, ще перед тим, як користувачі вирішать перейти за посиланнями, або поділитись ними з іншими. Ми плануємо вжити аналогічних заходів також в Instagram.', 'Ми вже позначаємо сторінки в Facebook і акаунти в Instagram російських державних ЗМІ, щоб люди знали, звідки надходить інформація. З метою забезпечення прозорості, ми прагнемо надавати людям більше контексту в моменті, коли вони хочуть поділитися посиланнями російських державних ЗМІ, або ж коли бачать публікації, що містять ці посилання.', 'Надійний доступ до достовірної інформації:Державна служба з надзвичайних ситуацій України запустила інформаційну гарячу лінію в WhatsApp. Ця безкоштовна послуга дозволяє користувачам отримувати важливі сповіщення, надійну і достовірну інформацію, а також детальні інструкції про те,як варто реагувати в надзвичайних ситуаціях. Щоб скористатися безкоштовною гарячою лінією в WhatsApp, просто збережіть номер +380676785917 в контактах телефону, а потім напишіть слово “почати”(або“begin”)в чаті WhatsApp, для того, щоб її активувати.', 'Допомога від нашої спільноти:протягом цієї кризи ми бачимо, як люди по всьому світу використовують наші інструменти, щоб підтримувати один одного і давати про себе знати. Наприклад, на підтримку некомерційних організацій, що надають гуманітарну допомогу Україні, з 23 лютого на Facebook і Instagram було зібрано понад 20 мільйонів доларів. Ми також помітили численні групи в Facebook, створені для надання\\xa0 допомоги людям, котрим вона необхідна. До цих груп належить спільнота з 200 000 румунських волонтерів та донорів, які координують надання транспорту та житла для біженців, а також польська група з більш ніж 300 000 учасників, що забирає постраждалих людей з кордону, пропонує їм житло, одяг та медикаменти.', 'Сьогодні ми оголошуємо, що в рамках нашої програми “Data for Good” ми ділимося доступом\\xa0 до збору даних\\xa0 з довіреними організаціями, які працюють над тим, щоб надати біженцям допомогу, зокрема медичну. Серед них є організація Direct Relief, яка використовує наші дані з метою дізнатися більше про те, куди саме направляються біженці, щоб допомогти їм.', 'Оновлено 28 лютого 2022 року о 5:55PM PT:', 'Ми отримали низку запитів від ряду урядів і Європейського Союзу про вжиття подальших заходів по відношенню до російських ЗМІ, контрольованих державою. Враховуючи винятковий характер даної ситуації, ми будемо обмежувати доступ до таких ЗМІ, як RT і Sputnik на всій території ЄС.', 'Починаючи від сьогоднішнього ранку, ми зробиличати з наскрізним шифруваннямдоступними в Instagram для всіх дорослих користувачів в Україні та в Росії. Сповіщення про можливість створення чатів з наскрізним шифруванням, люди зможуть побачити зверху своєї скриньки для\\xa0 приватних повідомлень. Наскрізні зашифровані чати вже доступні в Messenger та за замовчуванням WhatsApp. Але це оновлення не буде доступним для бізнес-акаунтів в Instagram.', 'Оновлено 27 лютого 2022 року о 9:00 PM PT:', 'Ми видалили мережу націлену на Україну, якою керували люди Росії та України, за порушення нашої політики протискоординованої неавтентичної поведінки.Ці люди керували веб-сайтами, видаючи себе за незалежні ЗМІ, та створювали фальшиві облікові засоби на багатьох платформах в соціальних мережах, включаючи Facebook, Instagram, Twitter, YouTube, Telegram, “Однокласники” та Вконтакті.', 'Ми також спостерігаємо активізацію атак на українських військових та громадських діячів з боку Ghostwriter – злочинної кіберорганізації, яка вже деякий часвідстежуєтьсяспільнотою безпеки. Ми закликаємо жителів України та Росії вжити жорсткіших заходів щодо безпеки своїх облікових записів – наприклад, двофакторну аутентифікацію – для захисту своєї інформації в ситуації\\xa0 вторгнення.Ми продовжуємо впроваджувати заходи щодо конфіденційності та безпеки для допомоги людям в Україні та Росії, в цілях захиститу їх облікових записів від атак.', 'Дізнайтесь більше про нашіоновлення щодо безпеки в Україні.', 'Оновлено 27 лютого 2022 року о 11:45AM PT:', 'Ми знаходимося в контакті з урядом України. На його прохання ми обмежили доступ до декількох облікових записів в Україні, включаючи облікові записи, що належать деяким російським державним ЗМІ. Ми також розглядаємо інші запити українського уряду про обмеження доступу до інших російських державних ЗМІ.', '26 лютого 2022 року', 'Ми разом в думках з усіма, хто постраждав від війни в Україні. Ми впроваджуємо значні заходи в наших додатках, щоб забезпечити нашу спільноту і підтримати людей, які користуються нашими послугами — як в Україні, так і по всьому світу.', 'Нижче наведені деякі з конкретних дій, які були впроваджені у зв’язку з вторгненням Росії в Україну.', 'Зважаючи на ситуацію в Україні\\xa0 ми додали декілька функцій безпеки:', 'Ми вживаємо додаткових заходів, щоб забезпечити дотримання наших Стандартів та основних принципів спільноти не лише в Україні та Росії, а й в інших країнах світу, де контент може бути поширеним.', 'Ми вживаємо широких заходів для боротьби з поширенням неправдивої інформації на наших сервісах і продовжуємо консультуватись в справі цього з зовнішніми експертами.', 'Ми забезпечуємобільшу прозорістьоблікових записів державних ЗМІ, включаючи російські RT і Sputnik, оскільки вони поєднують в собі вплив медійної організації і стратегічну підтримку держави. Ми також вважаємо, що люди повинні знати, чи надходять новини, з якими вони ознайомлюються, від ЗМІ, перебуваючого під впливом уряду.', 'Ми як і раніше пильно стежимо за виникаючими тенденціями і готові зробити додаткові дії відповідно до вимог ситуації, що склалася.', 'Ми знаходимося в контакті з урядом України. На їх прохання ми обмежили доступ до кількох облікових засо\\xa0 в Україні, включаючи рахунк, що належать деяким російським державним ЗМІ. Ми також розглядаємо інші запити уряду про обмеження доступу до російських державних ЗМІ.', 'Обновление от 17 марта 2022, 9:00AM PT:', 'Мы по-прежнему наблюдаем, что наше сообщество объединяется, чтобы помочь людям, которые спасаются от войны в Украине. Сегодня мы делимся несколькими обновлениями, которые помогут людям еще проще получать информацию и оказывать поддержку.', '', 'Обновление от 11 марта 2022 года в 4:00PM PT:', 'Глава Instagram Адам Моссери отреагировал на решение российских властей заблокировать доступ к платформе:', '', 'A post shared by Adam Mosseri (@mosseri)', '', 'Обновление от 11 марта 2022 года в 3:30PM PT:', 'Заявление Ника Клегга, President, Global Affairs, Meta, в ответ на сообщения о том, что российское правительство рассматривает вопрос о включении Meta в список экстремистских организаций за ее политику в поддержку высказываний:', 'Было много освещения в СМИ и обсуждений того, как мы применяем нашу политику в отношении высказываний, касающихся вторжения Путина в Украину.', 'Я хочу быть предельно ясным: наша политика направлена на защиту прав людей на свободу слова как выражения самообороны в ответ на военное вторжение в их страну. Дело в том, что если бы мы применяли нашу стандартную политику в отношении контента без каких-либо корректировок, мы бы сейчас удаляли контент простых украинцев, выражающих свое сопротивление и ярость в отношении вторгшихся военных сил, что справедливо было бы расценено как неприемлемый подход.', 'Для ясности, мы собираемся применять эту политику только в самой Украине. У нас нет вражды с российским народом. В нашей политике в отношении языка ненависти нет никаких изменений в том, что касается россиян. Мы не потерпим русофобии или любого вида дискриминации, преследования или насилия по отношению к россиянам на нашей платформе.', 'Это временное решение, принятое в чрезвычайных и беспрецедентных обстоятельствах. Мы будем следить за предстоящим развитием ситуации.', 'Обновление от 8 марта 9:00PM PT:', 'В связи с усугублением гуманитарного кризиса, сегодня мы объявляем о дополнительных шагах, которые помогут нашему сообществу получить доступ к важнейшим ресурсам и поддержать тех, кто нуждается в этом.', 'Помощь с доступом к ресурсам', 'Обновление раздела “Помощь сообщества”: Мы обновляем раздел “Помощь сообщества” как центральный ресурс на Facebook, где украинцы и другие жители региона могут найти достоверную информацию от местных агентств ООН и обществ Красного Креста. Сюда входит информация о том, куда обращаться за медицинской помощью, как оставаться в безопасности и как получить помощь – как в Украине, так и после пересечения границы с соседними странами. Также существует информационная горячая линия Государственной службы по чрезвычайным ситуациям Украины в WhatsApp, которая позволяет людям получать важную информацию, включая процедуры реагирования на чрезвычайные ситуации. Ссылка на “Помощь сообщества” появится в верхней части лент Facebook и Instagram для людей в Украине или тех, кто недавно выехал в соседние страны, чтобы они знали, что этот ресурс доступен. Он также будет доступен во всем мире на страницеfacebook.com/community_help_ukraine, а также в топе результатов для соответствующих поисковых запросов в Facebook.', 'Добавление ресурсов для ментального здоровья:Мы добавим новые советы и ресурсы от международных организаций, включая Всемирную организацию здравоохранения (ВОЗ) и Международный медицинский корпус (ММК), связанные с психическим здоровьем, в разделеЦентра эмоционального здоровья в Facebook. Эти ресурсы будут доступны по всему миру на украинском, русском и английском языках и будут предлагать информацию о том, что делать во время стресса, и как оказать поддержку детям во время кризиса.', 'Мы поддерживаем организации в их стремлении донести важные сообщения до тех, кто пострадал от кризиса, с помощью бесплатных рекламных кампаний на наших платформах. Вот один из примеров: ВОЗ распространяет информацию о грудном вскармливании для перемещенных матерей, а Международный медицинский корпус (ММК) делится советами о том, как поддержать психическое здоровье.', 'Помощь пользователям в выражении поддержки Украине', 'Обновление от 8 марта 2022 года, 8:00 AM PT:', 'Сегодня мы делимся обновлениями в Instagram, которые помогут обеспечить безопасность людей в Украине и России и уменьшить распространение дезинформации.', 'Сохранение конфиденциальности информации и связей в Instagram:Чтобы помочь защитить наши сообщества в Украине и России, мы будем скрывать информацию о подписчиках, подписках, и о людях, которые друг на друга подписаны, для закрытых аккаунтов из этих двух стран.', 'Это означает, что люди, подписанные на закрытые аккаунты из Украины и России, больше не смогут видеть, кто подписан на эти аккаунты и на кого подписаны они. Мы также не будем показывать эти аккаунты в списках подписчиков и подписок других людей, а также во “взаимных подписках”. Мы уведомили закрытые аккаунты в Украине и России, чтобы они знали об этом изменении.', 'Мы также обращаем внимание аккаунтов в Украине и России на такие инструменты, как “Ваша активность” и “Скачать вашу информацию”. Первый позволяет пользователям массово удалять размещенный ими контент, например, фотографии и видео, а также их лайки и комментарии. Второй инструмент позволяет людям получить копию своих данных Instagram.', 'Российские СМИ, контролируемые государством, в Instagram:В продолжение наших действий по понижению в выдаче постов со ссылками на российские государственные СМИ в Facebook, с сегодняшнего дня Stories в Instagram, содержащие стикер со ссылкой на сайт российского государственного СМИ, будут размещаться ниже в панели Stories. Мы также будем маркировать эти Stories, чтобы люди знали, что они ведут на сайты российских государственных СМИ.', 'Эти изменения дополняют шаги, которые мы уже предприняли, чтобы сделать контент с аккаунтов российских государственных СМИ более трудно обнаруживаемым в Instagram и обеспечить большую прозрачность, когда пользователи пытаются делиться контентом с этих аккаунтов.', 'В частности, мы понижаем в выдаче посты российских государственных СМИ в новостной ленте и размещаем их ниже в панели Stories. Мы также показываем людям уведомление перед репостом контента с этих аккаунтов в Stories, сообщая им, что это контент российских государственных СМИ. Если пользователи все же решат репостнуть эти посты в свои Stories, мы поместим эти Stories ниже в выдаче.', 'Наконец, мы не будем рекомендовать посты российских государственных СМИ во вкладках “Интересное” и Reels, а также усложним поиск этих аккаунтов.', 'Обновление от 4 марта 2022 в 3:00PM PT:', 'Несмотря на заявление российских\\xa0 властей о блокировке Facebook, мы работаем над тем, чтобы наши услуги были доступны, насколько это возможно. Однако, в связи с трудностями работы в России в настоящее время, показ рекламы, таргетированной на людей в России, будет приостановлен, а рекламодатели в России больше не смогут создавать или запускать рекламу для любой точки мира, включая Россию.', 'Обновление от 4 марта 2022 в 11:15AM PT:', 'Обновление касательно решения российских властей заблокировать доступ к Facebook:В результате решения российских властей заблокировать доступ к Facebook на территории Российской Федерации, вскоре миллионы простых россиян окажутся отрезанными от достоверной информации, лишенными повседневных способов связи с семьей и друзьями и возможности высказывать свое мнение. Мы будем продолжать делать все возможное для восстановления наших сервисов, чтобы люди могли безопасно выражать свое мнение и координировать действия.', 'Обновление касательно ограничения доступа к RT и Sputnik:Ранее мы объявили о том, что ограничим доступ к RT и Sputnik на территории ЕС, учитывая исключительные обстоятельства. В соответствии с этим решением и по просьбе правительства Великобритании мы также ограничиваем доступ к RT и Sputnik в Великобритании.', 'Обновление от 3 марта 2022 в 4:50PM PT:', 'Увеличение гуманитарной помощи: Сегодня мы выделяем 15 миллионов долларов на поддержку гуманитарных усилий в Украине и соседних странах. Это включает 5 миллионов долларов в виде прямых пожертвований агентствам ООН и более чем десятку некоммерческим организациям, включая Международный медицинский корпус, который будет использовать эти средства для развертывания мобильных медицинских пунктов в Украине. Помощь также будет направлена Internews для поддержки подвергающихся риску журналистов и правозащитников в регионе. Мы также предоставляем средства ЮНИСЕФ для расширения усилий по оказанию жизненно важной помощи детям и семьям в Украине и регионе. Остальные 10 миллионов долларов будут предоставлены в виде рекламных купонов. Они помогут некоммерческим организациям в сборе средств, необходимых для реагирования и предоставления важной информации людям, пострадавшим в результате военных действий.', 'Обновление от 1 марта 2022 года 6:05 PM PT:', 'Обновление информации о СМИ, контролируемых государством:В дополнение к ограничению доступа к RT и Sputnik на территории ЕС, теперь во всем мире мы также понижаем в выдаче контент со страниц Facebook и аккаунтов Instagram российских государственных СМИ, а также затрудняем их поиск на наших платформах.', 'Мы также начали понижать в выдаче посты, содержащие ссылки на сайты российских государственных СМИ в Facebook. В ближайшие дни мы будем помечать эти ссылки и предоставлять людям больше контекста об источнике информации, прежде чем они поделятся ими или нажмут на них, чтобы они знали, что они ведут на сайты российских государственных СМИ. Мы планируем принять аналогичные меры в Instagram.', 'Мы уже маркируем страницы в Facebook и Instagram аккаунты российских СМИ, контролируемых государством, чтобы люди знали, откуда поступает эта информация. Обеспечивая дополнительную прозрачность, мы стремимся дать людям больше контекста, если они хотят поделиться прямыми ссылками на сайты российских государственных СМИ или когда другие видят чей-то пост, содержащий ссылку на один из этих сайтов.', 'Надежный доступ к достоверной информации: Государственная служба Украины по чрезвычайным ситуациям запустила информационную горячую линию в WhatsApp. Бесплатная услуга позволит пользователям получать важные обновления, надежную и достоверную информацию, а также подробные сведения о процедурах реагирования на чрезвычайные ситуации. Чтобы воспользоваться бесплатным телефоном доверия в WhatsApp, просто сохраните номер +380676785917 в контактах телефона, а затем напишите слово “почати” (начать) в сообщении WhatsApp, чтобы начать общение.', 'Как наше сообщество помогает:На протяжении всего этого кризиса мы видим, как люди по всему миру используют наши инструменты, чтобы быть услышанными и поддержать друг друга. Например, с 23 февраля на платформах Facebook и Instagram было собрано более 20 миллионов долларов для некоммерческих организаций в поддержку гуманитарной помощи для Украины. Мы также видели группы в Facebook, созданные для помощи нуждающимся, включая группу из 200 000 румынских волонтеров и доноров, координирующих транспортировку и размещение беженцев, или польскую группу из более чем 300 000 участников, предлагающую пострадавшим помощь слогистикой после пересечения границы,а также с жильем, одеждой и медикаментами.', 'Сегодня мы также объявляем, что в рамках нашей программы “Data for Good” мы предоставляем агрегированные данные о социальных связях доверенным организациям, работающим над предоставлением медицинских услуг и поддержки беженцам. Например, таким как Direct Relief, которая использует эти данные для лучшего понимания того, куда могут направляться люди, чтобы лучше поддерживать нуждающиеся сообщества.', 'Обновление28 февраля 2022в5:55 PM PT:', 'Мы получили запросы от ряда государств и Европейского союза о принятии дальнейших мер в отношении российских СМИ, контролируемых государством. Учитывая исключительный характер ситуации, мы будем ограничивать доступ к RT и Sputnik на всей территории ЕС в настоящее время.', 'Начиная с сегодняшнего утра, мы сделали зашифрованные приватные чаты доступными в Instagram для всех взрослых пользователей из Украины и России. Мы также будем показывать уведомления в верхней части чатов в Instagram Direct, чтобы дать пользователям знать, что они могут переключиться на зашифрованный чат, если захотят. Сквозные зашифрованные чаты уже доступны в качестве опции в Messenger и по умолчанию в WhatsApp. Это обновление недоступно для бизнес-аккаунтов в Instagram.', 'Обновление 27 февраля 2022 в 9:00PM PT:', 'Мы удалили сеть аккаунтов, которая таргетировалась на Украину и управлялась людьми из Украины и России, за нарушение нашей политики противскоординированного недостоверного поведения. Они управляли веб-сайтами, которые выдавали себя за независимые новостные организации, и создавали фальшивые личности во многих социальных сетях, включая Facebook, Instagram, Twitter, YouTube, Telegram, “Одноклассники” и VK.', 'Мы также наблюдаем активизацию атак на украинских военных и общественных деятелей со стороны Ghostwriter – агента угроз, которого уже некоторое времяотслеживаетсообщество экспертов по безопасности. Мы призываем жителей Украины и России принять более высокие меры безопасности учетных записей – например, двухфакторную аутентификацию – для защиты своей информации в условиях этого вторжения.Мы продолжаем внедрять меры по обеспечению конфиденциальности и безопасности, чтобы помочь жителям Украины и России защитить свои аккаунты от атак.', 'Узнайте большео наших обновлениях безопасности в Украине.', 'Обновление от 27 февраля 2022 г. в 11:45 AM PT:', 'Мы находимся в контакте с правительством Украины. По их просьбе мы ограничили доступ к нескольким аккаунтам в Украине, в том числе принадлежащим некоторым российским государственным СМИ. Мы также рассматриваем запрос других правительств об ограничении российских СМИ, контролируемых государством.', 'От 26 февраля 2022 г. в 11:50 AM PT:', 'Наши мысли с теми, кого затронула война в Украине. Мы предпринимаем целый ряд мер на всех наших приложениях, чтобы обеспечить безопасность нашего сообщества и поддержать людей, которые пользуются нашими услугами – как в Украине, так и по всему миру.', 'Ниже перечислены конкретные шаги, предпринятые нами в связи с вторжением России в Украину.', 'В ответ на складывающуюся обстановку, мы добавили несколько функций безопасности в Украине', 'Мы предпринимаем дополнительные шаги по контролю за соблюдением наших Норм сообщества и Принципов сообщества не только в Украине и России, но и в других странах мира, где может распространяться контент.', 'Мы предпринимаем масштабные меры по борьбе с распространением дезинформации на наших сервисах и продолжаем консультироваться со сторонними экспертами.', 'Мы обеспечиваембольшую прозрачностьаккаунтов государственных СМИ, включая российские RT и Sputnik, поскольку они сочетают в себе влияние медийных организаций со стратегической поддержкой государства. Мы считаем, что люди должны знать, поступают ли новости, которые они читают, от издания, которое может находиться под влиянием правительства.', 'Мы по-прежнему бдительно следим за развитием событий и готовы предпринять дополнительные действия в соответствии с требованиями сложившейся ситуации.']\n",
            "52 ['As part of our ongoing efforts to fight violent extremism and organized hate, we’re announcing the expansion of one of our flagship counterspeech initiatives,The Redirect Initiative, into Pakistan and the UK. Now when someone in Pakistan or the UK searches on Facebook using words associated with organized hate or violent extremism, the top search result will be a link to resources and support for how to leave violence and extremism behind. We’re partnering withShaoor Foundationin Pakistan andExit UKin the UK.', 'Research showsthat challenging violent, extremist views with positive counterspeech is one of the most effective ways to combat hate and extremism. Counterspeech involves responding to hateful, extremist narratives with empathy and alternative perspectives, rather than shutting these conversations down. Counterspeech is only effective if it comes from credible voices, so we’ve partnered with various NGOs and community groups on multiplecounterspeech initiativesaround the world including community programs, toolkits and research.', '“At Shaoor Foundation, we have worked for many years designing and implementing peace development programs in Pakistan. Building a society that is inclusive, respectful and peaceful and involves engaging the entire community, enabling people to speak up and providing a safe, accessible space to get support. We are pleased to partner with Meta on the Redirect Initiatve to help us scale our efforts and reach more people in need in Pakistan.”– Syed Ali Hameed, Executive Director at Shaoor Foundation', 'The Redirect Initiative is already available in Australia, USA, Germany and Indonesia. A study by Moonshot CVE, an organization that works to counter extremism, found that the Redirect Initiative issuccessful at disruptingthe connection between followers and the violent, extreme content they seek.', '“Working in partnership with technology companies like Meta will help ensure the safety and well-being of the public and those that might be vulnerable online. At Exit UK, we help people involved in the far-right leave, and we also support wider members of the community, many of whom feel they have no-one to talk to. We understand the importance of offering non-judgemental advice and support so that over time we can help people improve their critical thinking skills and develop positive counter narratives to challenge hate online.” –Nigel Bromage, Founder of Exit UK', 'Counterspeech is just one part of our multi-faceted strategy to tackle violent extremism, terrorism and organized hate. Our policies clearly state thatdangerous individuals and organizationsthemselves have no place on our platforms. We’ve banned thousands of individuals and organizations across the ideological spectrum under our rules, and we prohibit praise and support of these groups and their leaders on our platforms. We have a team of more than 350 dedicated specialists and sophisticated proactive detection technology to help us find and remove this content quickly. We’ll continue to work with diverse partners around the world to address extremism across society.']\n",
            "53 ['Update on December 13, 2023 at 10:00AM PT:', 'Last year, we introduced personal boundary to prevent avatars from coming too close and to limit unwanted interactions. Since then, we’ve heard feedback from the community on how people use personal boundary to enhance their experience. We’ve made updates to personal boundary so avatars will now fade faster, increasing the feeling of comfort and control within your personal boundary. We’ve also made adjustments to the physical barrier while still maintaining roughly a few feet of distance, so you can now more easily participate in positive social gestures like high fives.', 'Update on March 15, 2022 at 8:15AM PT:', 'Today, we’re announcing an update to our recently launched Personal Boundary forHorizon Worldsthat will give people more control over their experience. Personal boundary is an invisible boundary that creates more space between people so others can’t come too close and to make it easier to avoid unwanted interactions. Personal Boundary will remain on by default for non-followers, and now you’ll be able to adjust your Personal Boundary from the Settings menu in Horizon Worlds.', 'Based on community feedback, you can now choose from three options that give our community more customized controls so they can decide how they want to interact in their experiences:', '', 'These new options should make it easier to high-five, fist-bump, and take selfies with other avatars while in Horizon Worlds. And when two people meet, Personal Boundary will default to the more restrictive setting (for example, if your Personal Boundary is Off but the avatar you’re interacting with has Personal Boundary set to On for Everyone, there will be a roughly few feet distance between you). In Horizon Venues, Personal Boundary will be default on at a roughly few feet distance for everyone.', 'Developing for VR presents what are perhaps some of the hardest challenges we’ve tackled in a generation of computing now that we’re no longer limited by fixed viewpoints and traditional flatscreen devices. By preventing avatars from coming within a set distance of each other, Personal Boundary creates more personal space for people and makes it easier to avoid unwanted interactions. We’ll continue to iterate and make improvements as we learn more about how Personal Boundary impacts people’s experiences in VR.', 'Originally published on February 4, 2022 at 10:10AM PT:', 'Today, we’re announcing Personal Boundary forHorizon WorldsandHorizon Venues. Personal Boundary prevents avatars from coming within a set distance of each other, creating more personal space for people and making it easier to avoid unwanted interactions. Personal Boundary will begin rolling out today everywhere inside of Horizon Worlds and Horizon Venues, and will by default make it feel like there is an almost 4-foot distance between your avatar and others. Over time, we’ll continue to make improvements as we learn how this affects people’s experiences.', 'A Personal Boundary prevents anyone from invading your avatar’s personal space. If someone tries to enter your Personal Boundary, the system will halt their forward movement as they reach the boundary. You won’t feel it — there is no haptic feedback. This builds upon our existing hand harassment measures that were already in place, where an avatar’s hands would disappear if they encroached upon someone’s personal space.', '', 'We are intentionally rolling out Personal Boundary as always on, by default, because we think this will help to set behavioral norms — and that’s important for a relatively new medium like VR. In the future, we’ll explore the possibility of adding in new controls and UI changes, like letting people customize the size of their Personal Boundary.', 'Note that because Personal Boundary is the default experience, you’ll need to extend your arms to be able to high-five or fist bump other people’s avatars in Horizon Worlds or in Horizon Venues.', 'Virtual reality can and should be for everyone. And we’re constantly working to improve people’s experience in VR, gathering feedback from the community to inform our work as we continue to iterate and make improvements.', 'We believe Personal Boundary is a powerful example of how VR has the potential to help people interact comfortably. It’s an important step, and there’s still much more work to be done.We’ll continue to test and explore new ways to help people feel comfortable in VR.']\n",
            "54 ['Today we’re launching Pledge Planets on Messenger Kids. This interactive in-app activity helps kids learn and practice how to make healthy decisions online, stay safe and build resilience. Kids can explore different planets based on the tenets of theMessenger Kids Pledge: Be Kind, Be Respectful, Be Safe and Have Fun.', 'In each episode, kids help characters navigate various social situations and make decisions that lead to positive outcomes. By completing the games, kids will see that their respectful, safe and fun actions have a big impact on those around them.', 'The first episode, “Be Kind,” is rolling out today to allcountries where Messenger Kids is available, with new episodes that focus on the other pledges coming soon. In this episode, players are introduced to the owner of a sandwich shop. Through two games, kids will learn and practice how to act with kindness:', '', 'To kick off the Pledge Planets adventure, tap the Explore tab in Messenger Kids and select Pledge Planets.', 'We developed the Messenger Kids Pledge and the Pledge Planets activities in close partnership with Meta’s Youth Advisors. This group of experts in the fields of online safety, child development and children’s media help us develop new products, features and policies for young people by sharing their expertise, research and guidance. We meet regularly with the group, which includes the Family Online Safety Institute, Digital Wellness Lab, MediaSmarts, Project Rockit and the Cyberbullying Research Center.', 'Learn more aboutPledge PlanetsandMessenger Kids.']\n",
            "55 ['In 2021, we made significant progress in providing greater transparency intohow the News Feed ranking process works, what gets distributed and why. We released new features toincorporate direct feedbackwe get from people who use Facebook by giving them more control over their feeds and reducing negative experiences.', 'Here are some of the biggest changes and tests we launched this year:', 'We continually evaluate the effectiveness of News Feed ranking signals and update or remove them when it makes sense. This month, weremoved the transparent authorship signalbecause it did not have a significant effect on the news ecosystem. We still prioritize original reporting in News Feed and will continue to boost quality news by improving more impactful News Feed signals.', 'News Feed uses personalized ranking, which takes into account thousands of unique signals to understand what’s most meaningful to you. Our aim isn’t to keep you scrolling on Facebook for hours on end, but to give you an enjoyable experience that you want to return to. It’s not in our interest to show you hateful or inflammatory content — our advertisers don’t want their ads shown next to it and our users tell us they don’t want it. We’re incentivized\\xa0 to reduce it. The prevalence of hate speech is now just about 0.03% of content viewed, or about 3 views per every 10,000 and continuing to drop. In the US, nearly 90% of the content people see is from friends, pages and groups they follow or are connected to because we use algorithmic ranking.', 'We understand concerns people have about the lack of transparency over how algorithmic ranking systems work, so we’ve introduced new measures to give people more control over, and insight into, how content appears in their News Feed. Heading into the new year, we’ll continue to share updates on our tests and features that aim to give you more control and connect you to meaningful content.']\n",
            "56 ['Harmful content continues to evolve rapidly — whether fueled by current events or by people looking for new ways to evade our systems — and it’s crucial for AI systems to evolve alongside it. But it typically takes several months to collect and label thousands, if not millions, of examples necessary to train each individual AI system to spot a new type of content.', 'To tackle this, we’ve built and recently deployed Few-Shot Learner (FSL), an AI technology that can adapt to take action on new or evolving types of harmful content withinweeksinstead of months. This new AI system uses a method called “few-shot learning,” in which models start with a general understanding of many different topics and then use much fewer — or sometimes zero — labeled examples to learn new tasks. FSL can be used in more than 100 languages and learns from different kinds of data, such as images and text. This new technology will help augment our existing methods of addressing harmful content.', 'Our new system works across three different scenarios, each of which require varying levels of labeled examples:', 'We’ve tested FSL on a few recent events. For example, one recent task was to identify content that shares misleading or sensationalized information discouraging COVID-19 vaccinations (such as “Vaccine or DNA changer?”). In a separate task, the new AI system improved an existing classifier that flags content that comes close to inciting violence (for example, “Does that guy need all of his teeth?”). The traditional approach may have missed these types of inflammatory posts since there aren’t many labeled examples that use “DNA changer” to create vaccine hesitancy or references to teeth to imply violence. We’ve also seen that,in combination with existing classifiersalong withefforts to reduce harmful content, ongoing improvements in our technology and changes we made to reduce problematic content in News Feed, FSL has helped reduce the prevalence of other harmful content likehate speech.', '', 'We believe that FSL can, over time, enhance the performance of all of our integrity AI systems by letting them leverage a single, shared knowledge base and backbone to deal with many different types of violations. There’s a lot more work to be done, but these early production results are an important milestone that signals a shift toward more intelligent, generalized AI systems.', 'Learn more about our Meta AI Few-Shot Learner onour AI blog.']\n",
            "57 ['Every day I see the positive impact that Instagram has for young people everywhere. I’m proud that our platform is a place where teens can spend time with the people they care about, explore their interests, and explore who they are.', 'I want to make sure that it stays that way, which means above all keeping them safe on Instagram. We’ll continue doing research, consulting with experts, and testing new concepts to better serve teens.', 'Today, I’d like to clarify some of the work that we’ve been doing for a long time, and also lay out a few new things that we’ve been developing to meaningfully improve the experience on Instagram for teens, parents and guardians. This includes developing new tools for parents and guardians and launching Take A Break.', 'Parents and guardians know what’s best for their teens, so we plan to launch our first tools in March to help them guide and support their teens on Instagram. Parents and guardians will be able to view how much time their teens spend on Instagram and set time limits. We’ll also give teens a new option to notify their parents if they report someone, giving their parents the opportunity to talk about it with them. This is the first version of these tools; we’ll continue to add more options over time.', 'We’re also developing a new educational hub for parents and guardians that will include additional resources, like product tutorials and tips from experts, to help them discuss social media use with their teens.', '', 'It’s important to me that people feel good about the time they spend on Instagram, so today we’re launching Take A Break to empower people to make informed decisions about how they’re spending their time. If someone has been scrolling for a certain amount of time, we’ll ask them to take a break from Instagram and suggest that they set reminders to take more breaks in the future. We’ll also show them expert-backed tips to help them reflect and reset.', 'To make sure that teens are aware of this feature, we’ll show them notifications suggesting they turn these reminders on. We’re encouraged to see that teens are using Take A Break. Early test results show that once teens set the reminders, more than 90% of them keep them on. We’re launching this feature in the US, UK, Ireland, Canada, Australia, and New Zealand today, and we’ll bring it to everyone by early next year.', '', 'The Take a Break reminders build on our existing time management tools includingDaily Limit, which lets people know when they’ve reached the total amount of time they want to spend on Instagram each day, and offers the ability to mute notifications from Instagram.', 'We’re encouraged that experts see the value of these features, includingBoris Radanović, UK Safer Internet Centre, who said, “We welcome Instagram’s new Take A Break feature, which we hope will be a meaningful way to encourage healthy social media use, particularly among younger users. Whilst taking regular breaks from screens has been challenging recently, it has been good advice for many years, and initiatives that encourage this are to be supported. We will continue to work with Instagram in this regard and hope that this represents a step in the right direction.”', 'Anne Collier at The Net Safety Collaborative, who said,“I love ‘Take a Break’ because it gives young users better control over their experiences on Instagram. Because we know that agency – the power to make choices and take action – is vital to adolescent wellbeing and mental health,”andDr. Alfiee M. Breland-Noble, a psychologist and founder of mental health nonprofit the AAKOMA project,who said,“It is imperative that we equip a diverse population of Gen Z and Gen Alpha youth with the necessary coping skills and tech tools to help them effectively manage their social media use. The well-being of diverse teens, including marginalized youth who face a host of unique societal challenges, is an imperative for me. It was therefore my pleasure to contribute my 25+ years of scientific and clinical knowledge to the development of the ‘Take a Break’ feature for Instagram. This feature is one necessary positive tool to support young people’s well-being within the context of healthy social media engagement.”', 'We’re also starting to test a new experience for people to see and manage their Instagram activity. We know that as teens grow up, they want more control over how they show up both online and offline so, for the first time, they will be able to bulk delete content they’ve posted like photos and videos, as well as their previous likes and comments. While available to everyone, I think this tool is particularly important for teens to more fully understand what information they’ve shared on Instagram, what is visible to others, and to have an easier way to manage their digital footprint. This new experience will be available to everyone in January.', '', 'Earlier this year, we began defaulting teens into private accounts when they signed up for Instagram, and we stopped adults from being able to DM teens who don’t follow them.', 'Now, we’ll also switch off the ability for people to tag or mention teens who don’t follow them, or to include their content in Reels Remixes or Guides by default when they first join Instagram. We’re testing these changes to further minimize the possibility that teens will hear from those they don’t know, or don’t want to hear from, and plan to make them available to everyone early next year.', '', 'In July, we launched theSensitive Content Control, which allows people to decide how much sensitive content shows up in Explore. The control has three options: Allow, Limit and Limit Even More. “Limit” is the default state for everyone and based on ourRecommendation Guidelines, “Allow” enables people to see more sensitive content, whereas “Limit Even More” means they see less of this content than the default state. The “Allow” option has always been unavailable to people under the age of 18.', '', 'We’re exploring expanding the “Limit Even More” state beyond Explore for teens. This will make it more difficult for teens to come across potentially harmful or sensitive content or accounts in Search, Explore, Hashtags, Reels and Suggested Accounts. We’re in the early stages of this idea and will have more to share in time.', 'Lastly, our research shows — and external experts agree— that if people are dwelling on one topic for a while, it could be helpful to nudge them towards other topics at the right moment. That’s why we’re building a new experience that will nudge people towards other topics if they’ve been dwelling on one topic for a while. We’ll have more to share on this, and changes we’re making when it comes to content and accounts we recommend to teens, soon.', '', 'Dr. Phillippa Diedrichs, a Professor of Psychology at the Centre for Appearance Research at the University of West England Bristol,agreed that nudging techniques show promise, saying“over the past eight months, I’ve been working with the Instagram team to brainstorm ways to help users have a positive experience and avoid social comparisons. Nudges are a behaviour change technique studied by behavioural economists for over a decade. They’ve been applied successfully to issues like climate change, employee well-being and altruism. More recently, digital nudges have been studied as a way to improve users’ experiences online without compromising their freedom and personal choice.”', 'This is just a snapshot of our work. We’re also continuing to develop innovative new solutions toverify people’s ages on Instagram, for example.', 'As always, I’m grateful to the experts and researchers who lend us their expertise in critical areas like child development, teen mental health and online safety, and I continue to welcome productive collaboration with lawmakers and policymakers on our shared goal of creating an online world that both benefits and protects many generations to come.']\n",
            "58 ['Our technologies offer a critically important space for people to exercise their human rights, where they can express themselves, shine a light on important issues and hold those in power to account. And, we know that people can misuse technology to heighten existing social tensions and suppress people’s fundamental rights. In line with ourCorporate Human Rights Policy, we conduct human rights impact assessments to better understand the role our technologies play in society, including how to help prevent and mitigate related risks.', 'Today, we’re publishing thefindings of the independent human rights impact assessmentwe commissioned in the Philippines, along with details onhow we’ve respondedto the recommendations in the assessment. We recognize that complex challenges outlined in the report may continue to evolve, and so will our approach and strategies to build systems that help promote human rights.', 'The assessment found that Meta technologies, in addition to being widely used in the Philippines, do play an important and positive role in providing access to economic opportunities, giving voice to people and being essential tools for monitoring and defending human rights during the COVID-19 pandemic. It also highlights salient human rights risks in the Philippines, including concerns about the misuse of our technologies formisinformation and disinformation, online harassment and incitement of violence.We’vetaken concrete steps to mitigate these risks and others identified in the report, and we’ll continue to do so to help keep people safe.', 'Article One, a specialized human rights and ethics consulting firm, completed the assessment in accordance with theUN Guiding Principles on Business and Human Rights. The research methodology included qualitative interviews with journalists, child protection specialists and civil society activists, as well as a survey of 2,000 people that use Facebook in the Philippines. The assessment also used an innovative methodology of combining traditional methods of stakeholder consultation with a quantitative survey that captured the experiences of a wide range of Filipino citizens. It was also framed to understand the experiences and risks of a variety of vulnerable groups, including LGBTQ+, journalists and others.', 'The Meta Response outlines our response to Article One’s recommendations. We are committing to implement, or have implemented, 24 recommendations; partly implement 7 recommendations; and we’re assessing feasibility of another 9. We’re sharing these insights and actions from our due diligence, aligned with our human rights policy.', 'As our response notes, we’ve made progress towards many of the recommendations in the report, and we know there is more to do. Here’s an update on our work to address some of the key areas identified in the report:', 'This assessment is an important step forward for us and our work in the Philippines. How we address safety, security and human rights is not static. We’re constantly working to evolve our products, policies and processes to create better outcomes.']\n",
            "59 ['Update on May 4, 2022 at 9:00AM PT:', 'We are continuing to expand Facebook Protect and have enrolled more than 9 million people globally so far. This is a required program for people who are at the highest risk of being targeted, so we’re sending emails and Facebook notifications to help make sure they’re aware of the requirement. People who receive the notification will have 14 days to enroll or they’ll be asked to enroll upon login if they miss the deadline. No action is required unless you receive this prompt. Learn more about thedetails on the program and how to enroll.', 'Originally published on December 6, 2021 at 6:00AM PT:', 'As part of our ongoing improvements to security, we’re expanding Facebook Protect, a program designed for people that are likely to be highly targeted by malicious hackers, including human rights defenders, journalists, and government officials.', 'These people are at the center of critical communities for public debate. They enable democratic elections, hold governments and organizations accountable, and defend human rights around the world. Unfortunately this also means that they are highly targeted by bad actors.', 'Facebook Protect helps these groups of people adopt stronger account security protections, like two-factor authentication, and monitors for potential hacking threats.', 'We first tested Facebook Protect in 2018 and expanded it ahead of the2020 US election. We began our global expansion in September of this year. Since then, more than 1.5 million accounts have enabled Facebook Protect, and of those, nearly 950K accounts newly enrolled in two-factor authentication. We are on track to expand the program to more than 50 countries by the end of the year, including the United States, India, and Portugal.', 'No action is required unless you get a notification on Facebook that you’re eligible to enroll.', 'Two-factor authentication — particularly by usingthird-party authentication apps— significantly improves the security of your online accounts. Right now, anyone can enroll in two-factor authentication and everyone should.', 'However, this important feature has been historically underutilized across the internet — even by people that are more likely to be targeted by malicious hackers, such as journalists, activists, political candidates and others.', 'With Facebook Protect, we worked to make enrollment and use of two-factor authentication as frictionless as possible for these groups of people by providing better user experience and support. We’re also starting to require that they use it. We know that there will always be a small subset of users that won’t immediately enroll, for example those that happen to be less active on our platform at the time of a given mandate. However, we believe this is an important step forward for these highly targeted communities. What we’ve seen so far is encouraging: in early testing, simplifying our enrollments flows, improving customer support, and mandating Facebook Protect brought adoption rates to over 90 percent in one month for these groups.', 'Over the next several months, we’re going to carefully expand this requirement globally. We’re encouraged by our early findings and will continue to improve Facebook Protect over time.']\n",
            "60 ['The non-consensual sharing of intimate images (NCII) — sometimes unfortunately referred to as “revenge porn” — can have a devastating impact on a person’s life. We do not allow this content on our apps, and today, we’re building on our industry-leading efforts to combat the spread of NCII on our platforms and beyond.', 'Today, Meta and Facebook Ireland are supporting the launch of StopNCII.org with the UK Revenge Porn Helpline and more than 50 organizations across the world. This platform is the first global initiative of its kind to safely and securely help people who are concerned their intimate images (photos or videos of a person which feature nudity or are sexual in nature) may be shared without their consent. The UK Revenge Porn Helpline, in consultation with Meta, has developed this platform with privacy and security at every step thanks to extensive input from victims, survivors, experts, advocates and other tech partners.', 'When someone is concerned their intimate images have been posted or might be posted to online platforms like Facebook or Instagram, they can create a case through StopNCII.org to proactively detect them.', 'The tool features hash-generating technology that assigns a unique hash value (a numerical code) to an image, creating a secure digital fingerprint. Tech companies participating in StopNCII.org receive the hash and can use that hash to detect if someone has shared or is trying to share those images on their platforms.', 'While participating companiesuse the hashthey receive from StopNCII.org to identify images that someone has shared or is trying to share on their platforms, the original image never leaves the person’s device. Only hashes, not the images themselves, are shared with StopNCII.org and participating tech platforms. This feature prevents further circulation of that NCII content and keeps those images securely in the possession of the owner.', 'StopNCII.org is for adults over 18 years old who think an intimate image of them may be shared, or has already been shared, without their consent. For people who are under 18, there are other resources and organizations that can offer support, including theNational Center for Missing & Exploited Children(NCMEC).', 'StopNCII.org is available to people all over the world. It will be operated by the UK Revenge Porn Helpline, an organization that has helped thousands of NCII survivors and removed over 90% of the content reported to it since its founding in 2015. International NGO partners are critical to expanding the fight against this abuse and supporting victims wherever they are, and there are more than 50 joining us today. These organizations will now utilize StopNCII.org to help local victims take back control of their intimate images online.', '“StopNCII.org represents a sea-change in the way those affected by intimate image abuse can protect themselves. At the heart of the work developing this tool have been the needs of victims and survivors by putting them in control without having to compromise their privacy. StopNCII.org has been designed to be simple and easy to use, with detailed signposting to additional support and advice, giving back agency at a time when someone may feel utterly powerless. The team at the Revenge Porn Helpline have brought their years of experience working with victims in the UK to the development of StopNCII.org and we are very grateful for the support of Meta in funding and technical expertise to support this new platform. We are looking forward to welcoming new partners to the platform and seeing it evolve, ensuring that for millions around the world, what was intended to be private, stays private.” – Sophie Mortimer, Revenge Porn Helpline Manager, SWGfL', 'StopNCII.org builds on technology developed by Facebook and Instagram’s NCII Pilot, which began in 2018 to help victims proactively stop the proliferation of their intimate images — not just remove them after the fact. For years, we’ve been using photo- and video-matching technology toremove intimate imagesshared without consent, encouraging people who use our services to report this type of behavior or content, and offeringresourcesto better support victims. Throughout this time, we’ve heard from victims and experts about the need for a stronger platform adopted across the tech industry that puts the victim first. By allowing potential victims to access the hashing technology directly, StopNCII.org gives them more agency, protects the privacy of their images and opens the door for other companies to participate in this effort. This new platform features even greater safety, privacy and security to help victims take back control.', '“At Bumble, we believe the internet should be safe and empowering for all people. Meta’s initiative and support for NGOs on the frontlines in the fight against intimate image abuse is a concrete step toward that goal.” – Lisa Roman, Vice President of Public Policy, Bumble(Updated on December 6, 2021 at 1:10PM PT to include additional third-party support.)', 'We will continue to build on these tools to address user feedback and work with partners to ensure the effectiveness of this technology and approach. To learn more, visit StopNCII.org.']\n",
            "61 ['Our messaging apps help billions of people stay connected to those who matter most to them. When they connect, they expect their conversations to be private and secure, as most of us do.', 'We want people to have a trusted private space that’s safe and secure, which is why we’re taking our time to thoughtfully build and implement end-to-end encryption (E2EE) by default across Messenger and Instagram DMs. E2EE is designed to protect people’s private messages so that only the sender and recipient can access their messages. So if you’re sharing photos or banking details with family and friends, encryption allows that sensitive information to be shared safely.', 'And while most people use messaging services to connect with loved ones, a small minority use them to do tremendous harm. We have a responsibility to protect our users and that means setting a clear, thorough approach to safety. We also need to help protect people from abuse without weakening the protections that come with encryption. People should have confidence in their privacy while feeling in control to avoid unwanted interactions and respond to abuse. Privacy and safety go hand-in-hand, and our goal is to provide people with the safest private messaging apps.', 'While the complex build of default E2EE is underway, today we’re sharing an update on our approach to help keep people safe when messaging through Messenger or Instagram by:', 'Preventing abuse from happening in the first place is the best way to keep people safe. In an end-to-end encrypted environment, we will use artificial intelligence to proactively detect accounts engaged in malicious patterns of behavior instead of scanning your private messages.Our machine learning technology will look across non-encrypted parts of our platforms — like account information and photos uploaded to public spaces — to detect suspicious activity and abuse.', 'For example, if an adult repeatedly sets up new profiles and tries to connect with minors they don’t know or messages a large number of strangers, we can intervene to take action, such as preventing them from interacting with minors. We can also default minors into private or “friends only” accounts. We’ve started to do this on Instagram and Facebook.', '', 'We also educate young people with in-app advice on avoiding unwanted interactions. We’ve seen tremendous success with oursafety noticeson Messenger, which are banners that provide tips on spotting suspicious activity and taking action to block, report or ignore/restrict someone when something doesn’t seem right. We developed these safety tips using machine learning to help people avoid scams, spot impersonations and, most urgently, flag suspicious adults attempting to connect to minors. In the past month alone, more than 100 million people have seen safety notice banners on Messenger. And, this feature works with end-to-end encryption.', 'In addition to our efforts to prevent harm, we are giving users more controls of their messaging inbox to account for the variety of experiences people want. Emerging creators often want increased reach, while other people want tight-knit circles. For example, we recentlyannouncedHidden Words on Instagramso people can determine for themselves what offensive words, phrases and emojis they want to filter into a Hidden Folder. This is also part of our effort to take a broader approach to safety. We filter a list of potentially offensive words, hashtags and emojis by default, even if they don’t break our rules.', 'Over the past few years, we’ve improved the options for reviewing chat requests and recently built delivery controls that let people choose who can message their Chats list, who goes to their requests folder and who can’t contact them at all. To help people review these requests in the safest way possible, we blur images and videos, block links and let people delete requests to chat in bulk.(Note: some features may not beavailable to everyone.)', '', 'People can already block unwanted contacts in Messenger, so we’re introducing the ability to block unwanted contacts seamlessly across Instagram DMs and Messenger. We are making it easy to block contacts from strangers, a feature that is switched on by default for any user we identify as a potential minor.', 'Reporting is an essential tool for people to stay safe and help us respond to abuse effectively. We’re making it much easier to report harm and educating people on how to spot scammers and impersonators by redesigning our reporting feature to be more prominent in Messenger. We also recently made it easier toreport content for violating our child exploitation policies. People can select “involves a child” as an option when reporting harm, which, in addition to other factors, prioritizes the report for review and action. Our goal is to encourage significantly more reporting by making it more accessible, especially among young people. As a result, we’re seeing close to 50% year-over-year growth in reporting, and we’re taking action to keep Messenger and Instagram DMs safe.', '', 'We’ll continue to enforce ourCommunity Standardson Messenger and Instagram DMs with end-to-end encryption. Reporting decrypts portions of the conversation that were previously encrypted and unavailable to us so that we can take immediate action if violations are detected — whether it’s scams, bullying, harassment or violent crimes. In child exploitation cases,we’ll continue toreport these accounts to NCMEC. Whether the violation is found on or through non-encrypted parts of our platform or through user reports, we’re able to share data like account information, account activity and inbox content from user reported messages for compliance with our Terms of Service and Community Standards.', 'We also want to educate more people to act if they see something and avoid sharing harmful content, even in outrage. We have begun sending alerts informing people about the harm that sharing child exploitation content, even in outrage, can cause by warning them that it’s against our policies and will have legal consequences. We’ll continue to share these alerts in an end-to-end encrypted environment, in addition to reporting this content to NCMEC. We’ve also launched a global “Report it, Don’t Share it” campaign reminding people of the harm caused by sharing this content and the importance of reporting this content.', 'Even in the context of encrypted systems, there is additional data we can provide to law enforcement to investigate when requested, such as who users contact, where they were when they sent a message and when they sent it.', 'Preventing abuse on our apps requires constant iteration, so we regularly review our policies and features, listen to feedback from experts and people using our apps to stay ahead of people who may not have the best intentions.', 'While building a trusted space requires ongoing innovation, flexibility and creativity, we believe that this approach ofprevention, controlandresponseoffers a framework to get people the protection they need and deserve. Privacy and safety go hand-in-hand, and we’re committed to making sure they are integral to people’s messaging experiences.']\n",
            "62 ['Update on July 28, 2022 at 6:00 AM PT:', 'We’re following through on requests made by the civil rights community, academics and regulators to look at the experiences people from historically and systemically marginalized communities have on our platforms and how our technologies may impact them. Over the next few months, people usingInstagramin the US may see a survey prompt asking them for their race or ethnicity. This survey is part ofMeta’s broader, long-term effortto help ensure that our products are built responsibly and that our products benefit the people who use them. For example, analysis we conduct with this information might help us better understand experiences different communities may have when it comes to how we rank content on Instagram.', 'We partnered with YouGov that will serve as a survey administrator and Northeastern University (NU), Texas Southern University (TSU), the University of Central Florida (UCF) and Oasis Labs (OL) as third-party data facilitators. OL also helped develop the approach that draws on the secure multi-party computation (SMPC) method that preserves privacy. We’ve partnered with a Historically Black College and University (HBCU), TSU, and a Hispanic-Serving Institution (HSI), UCF, because they primarily serve communities that have been historically and systemically marginalized. We are committed to understanding how people from marginalized communities experience our technologies and will continue to partner with HBCUs and HSIs.', 'Originally published on November 18, 2021 at 11:00AM PT:', 'The intersection of technology and civil rights is an emerging space that requires further attention from the entire industry, especially given the perceived rise of digital discrimination and bias. As questions have been raised about technology’s potential effects on members of marginalized communities, we’ve heard the calls for more research.', 'Today, I want to explain more about our approach to understanding how people from marginalized communities experience Meta technologies. Some people have said that\\xa0 their opportunities are limited or that they’re having a different experience than others, but we don’t have the data to fully understand what may be happening and why. We can’t address what we can’t measure, so establishing a more accurate measurement framework is vital to create more inclusive products, policies and operations across the company.', 'To do this right, we can’t work alone. We’re consulting with the civil rights community, privacy experts, academics, regulators and other organizations on the best way to measure these potential differences in people’s experiences. As we’ve explored options for measurement, experts reaffirmed that any work we do must take into account privacy, security and transparency.', 'To start, we plan to introduce a framework for studying our platforms and identifying opportunities to increase fairness when it comes to race in the United States. We have explored using aggregate US Census and ZIP code data, which is an accepted way of measuring demographics in the US. However, this approach has some limitations. To that end, we plan to augment that approach with two methodologies that will produce more accurate insights. We will do this in a way that allows important measurement while honoring people’s privacy:', 'Learn more about these methodologies in ourtechnical paper. While this work will initially focus on race in the US, it will help us lay the groundwork for how to address concerns from other marginalized communities here and around the world, consistent with ourcorporate human rights policy.', 'I joined the company at the beginning of the year to establish a new civil rights organization as part of our commitment following an independent audit of our policies and practices. As civil rights expert Laura Murphy stated in the audit, Meta has a “responsibility to ensure that the algorithms and machine learning models that can have important impacts on billions of people do not have unfair or adverse consequences.” We know that this journey will not be easy, however, we remain committed to this work, doing it thoughtfully, and being transparent about our efforts.']\n",
            "63 ['Today, just more than one year after the Civil Rights Team was established, we’re releasingMeta’s Progress on Civil Rights Audit Commitments. This report marks the beginning of the Civil Rights Team’s path to enhance protections for marginalized communities and demonstrates our commitment to move toward increased equity, safety and dignity on our platforms. Meta is committed to that evolution and its long-term progress.', 'I joined Meta, formerly known as Facebook, in January 2021 as the head of the Civil Rights Team, and as of just a few weeks ago, my team has grown to nine full-time employees. This team was created as a result of the audit that the company voluntarily undertook. The Auditors conducted their review over the course of two years and published a final report in July 2020.', 'The audit covered seven substantive issue areas under the leadership of Laura Murphy, a veteran civil rights and civil liberties leader, and was supported by Megan Cacace, a civil rights attorney and partner at Relman Colfax PLLC at the time of the audit.', '', 'The auditors described 117 actions and recommendations. 65 have been implemented, and 42 are either in progress or are ongoing, given the nature of the recommendation. We will continue to evaluate the feasibility of eight, and there are two recommendations that will not be implemented.', 'Some key highlights from the report include:', 'To become a better company, we have to meaningfully engage in how we can strengthen and advance civil rights at every level, and we remain committed to doing this industry-leading work.', 'Read thefull reportfor more information.']\n",
            "64 ['Today we’re publishing ourCommunity Standards Enforcement Reportfor the third quarter of 2021. This report provides metrics on how we enforced our policies from July 2021 through September 2021. With these additional metrics we now report on 14 policy areas on Facebook and 12 on Instagram.', 'We’re also sharing:', 'In July, we shared our firstOversight Board quarterly updatecovering the first quarter of 2021. In this update, we’re reporting on the details of cases we referred to the board and updates on our responses to the board about the recommendations and decisions they made. Moving forward, we will include these updates along with the Community Standards Enforcement Report.', 'All of these reports are available in theTransparency Center.', 'Prevalence of hate speech on Facebook has continued to decrease for the fourth quarter in a row. In Q3, it was 0.03% or 3 views of hate speech per 10,000 views of content, down from 0.05%, or 5 views of hate speech per 10,000 views of content in Q2. We continue to see a reduction in hate speech due toour improvements in our technology andranking changes that reduce problematic content in News Feed, including through improved personalization.', '', 'Hate speech prevalence on Instagram was 0.02% for Q3, and this is our first time reporting this number.', '', 'In Q3, the prevalence of violence and incitement on Facebook was 0.04-0.05%, or between 4 and 5 views per 10,000 views of content, and it was 0.02%, or 2 views per 10,000 views of content, on Instagram. We removed 13.6 million pieces of content on Facebook for violating our violence and incitement policy, and we proactively detected 96.7% of this content before anyone reported it to us. On Instagram, we removed 3.3 million pieces of this content with a proactive detection rate of 96.4%. There is a range of content that we might remove under ourviolence and incitement policywhere someone may advocate for violence or has made a statement of intent to commit violence.\\xa0 Due to the potentially harmful nature of content attempting to incite violence, we over-index on safety and remove such content even if it is unclear whether the content is in jest.This could range from something serious such as instructions on how to use weapons to cause injury to a joke where one friend says to another “I’ll kill you!”.In instances where necessary, we also work with law enforcement when we believe there is a genuine risk of physical harm or direct threats to public safety.', 'In Q3, the prevalence of bullying and harassment content was 0.14-0.15% or between 14 and 15 views of bullying and harassment content per 10,000 views of content on Facebook, and 0.05-0.06% or between 5 and 6 views per 10,000 views of content on Instagram. We removed 9.2 million pieces of bullying and harassment content on Facebook, with a proactive rate of 59.4%. And we removed 7.8 million pieces of bullying and harassment content on Instagram with a proactive rate of 83.2%. Bullying and harassment is a unique challenge and one of the most complex issues to address because context is critical. Read more about our approach and efforts tolower the prevalence of bullying and harassment.', 'We scale our enforcement to review millions of pieces of content across the world every day and use our technology to help detect andprioritize content that needs review.We have global review teams that review content in over 70 languages and AI technology for hate speech in over 50 languages and we continue to build technologies likeRIO,WPIEandXLM-Rthat can help us identify harmful content faster, across languages and content type (i.e. text, image, etc.). These efforts and our continued focus on AI research help our technology scale quickly to keep our platforms safe.Forcountries that are experiencing or at risk for conflict, we have made multi-year investments to build teams that work with local communities, develop policies, improve our technologies, and respond to real-world developments.', 'We reduce prevalence of violating content in a number of ways, including improvements in detection and enforcement andreducing problematic content in News Feed. These tactics have enabled us to cut hate speech prevalence by more than half on Facebook in the past year alone, and we’re using these same tactics across policy areas like violence and incitement and bullying and harassment. To better address hate speech, bullying and harassment and violence and incitement — all of which require understanding of language, nuance and cultural norms — we deployed anew cross-problem AI systemto consolidate learnings for all three to better address each violation area.', '', 'We’re also using warning screens to educate and discourage people from posting something that may include hostile speech such as bullying and harassment violating our Community Standards. The screens appear after someone has typed a post or comment explaining that the content may violate our rules and may be hidden or distribution reduced. Repeatedly posting this content could result in an account being disabled or deleted.', '', 'Abuse of our products isn’t static — and neither is the way we approach our integrity work. We’re continuing to evolve how we approach integrity, embedding integrity teams with product teams across Facebook, Instagram, Messenger, WhatsApp and teams that are going to build the metaverse in the years to come. Product teams tackleintegrity issuesas part of building and launching new products, and that includesbuilding the metaverse.', 'We also remain committed to research and have just launchedaFacebook Open Research and Transparency (FORT) early access programfor an API designed for academic researchers, to givethem more access to data on our platforms in a secure way.', 'We know we’re never going to be perfect in catching every piece of harmful content. But we’re always working to improve, share more meaningful data and continue to ground our decisions in research.']\n",
            "65 ['Today we’re publishing theWidely Viewed Content Report(WVCR) for the third quarter of 2021. This is the second edition of this report, which highlights the most viewed organic content in News Feed, including domains, links, Pages and posts in the US. This report includes content recommended by Facebook and excludes advertising content. Read more about its scope and methodology in ourCompanion Guide.', 'There’s been a lot written about polarizing content dominating News Feed, so this report sheds more light on the types of content that reaches the most people, which includes posts about people’sfavorite moviesand Pages dedicated toentertainment,cookingandfamily. Still, these reports have highlighted gaps in our enforcements and demotions, which we’re taking immediate steps to address.', 'Since releasing our inaugural WVCR, we have engagedwith academics, civil society groups and researchers to identify the parts of our first report they found most valuable, which metrics needed more context and how we can best support their understanding of content distribution on Facebook. Based on these discussions, we’ve provided more clarity into our methodology and included more context in the Companion Guide. Moving forward, we’ll continue to work with external stakeholders to refine and improve these reports.', 'We remove content from Facebook when it poses a real risk of harm, like graphic violence, hate speech or fake COVID cures. Our Community Standards prohibit hateful or harmful content, and we invest heavily in developing ways of identifying it and acting on it quickly. Learnings from our first WVCR have led to better applications and development of existing policies, including the removal of a network of more than a hundred Pages, profiles and domains forinauthentic behavior.', 'We also use News Feed ranking to reduce the distributionof posts that may contain content people find objectionable, but don’t necessarily meet the bar of removal under our policies. In creating these reports, we learned that our efforts to reduceengagement baitand low quality content needed to be refined to address more of it, which has led to changes in how we identify and reduce it. For example, we’re expanding our engagement bait identifiers, evaluating the impact that comments from friends can have on showing unconnected posts in News Feed, and experimenting with reducing that impact. We’re also exploring new experiments toreduce posts with unrelated links. We anticipate that these changes may lead to a reduction of low-quality content in future reports; however, it may take several reporting cycles for our reduction efforts to make a noticeable impact.', 'We are committed to sharing more about the changes we’re making based on what we’ve learned from the WVCR. We will also continue to meet with academics and experts to discuss these reports in detail and consider their input when exploring new tests or product changes tied to this work.', 'Learn more in thefull reportandCompanion Guide.']\n",
            "66 ['As a social technology company, helping people feel safe to connect and engage with others is central to what we do. But one form of abuse that has unfortunately always existed when people interact with each other is bullying and harassment. While this challenge isn’t unique to social media, we use new technologies to reduce it on our own platform, give people tools to protect themselves and also measure how we are doing. Here is how we approach it.', 'When it comes to bullying and harassment, \\u200b\\u200bcontext and intent matter. Bullying and harassment are often very personal — it shows up in different ways for different people, from making threats to make personally identifiable information public, to making repeated and unwanted contact.Our Bullying and Harassment policyprohibits this type of content and behavior. Our policy also distinguishes between public figures and private individuals, since we want to allow free and open discussions about public figures. We permit more critical commentary of public figures than we do for private individuals, but any content must still remain within the limits outlined by ourCommunity Standards.', 'We have developed AI systems that can identify many types of bullying and harassment across our platforms. However,bullying and harassment is a unique issue area because determining harm often requires context, including reports from those who may experience this behavior. It can sometimes be difficult for our systems to distinguish between a bullying comment and a light-hearted joke without knowing the people involved or the nuance of the situation. For example, a female friend posting “hi slut” on another female friend’s profile may not be perceived as bullying between those close friends. But on the other hand, someone posting that on another person’s page when the two are not close friends or several people posting “hi slut” on that person’s page can be harmful. Derogatory terms related to sexual activity, like “slut,” violate ourCommunity Standardsfor bullying and harassment because we want to ensure a baseline of safety for all members of our community, regardless of intent.', 'As a result, detecting such bullying can be more challenging than other types of violations. While we are always working to improve our technology, our metrics, particularly those for proactive rate and prevalence reflect the reality of having to rely on reports from our community.', 'In the third quarter this year, theprevalence of bullying and harassmentwas 0.14-0.15% on Facebook and 0.05-0.06% on Instagram. This means bullying and harassment content was seen between 14 and 15 times per every 10,000 views of content on Facebook and between 5 and 6 times per 10,000 views of content on Instagram. This metric captures only bullying and harassment where we do not need additional information such as a report from the person experiencing it to determine if it violates ourpolicy. Additionally,we removed 9.2 million pieces of content on Facebook, and of what we removed, we found 59.4% proactively. On Instagram, we removed 7.8 million pieces of content on Instagram, and of what we removed, we found 83.2% of it proactively.', 'Prevalence metrics allow us to track, both internally and externally, how much violating content people are seeing on our apps. Prevalence, in turn, helps us determine the right approaches to driving that metric down, whether it’s through updating our policies, products or tools for our community. When we first released the prevalence of hate speech, for example, it was between 0.10-0.11% and it is now 0.03% today. This year, we’veupdated our AI technologyto train across three different but related violations: bullying and harassment, hate speech and violence and incitement. We also deploy several approaches to reduce the prevalence of violating content, such as: removing accounts, Pages, Groups and events for violating our Community Standards or Guidelines; filtering problematic Groups, Pages and content from recommendations across our services; or reducing the distribution of likely violating content or content borderline to our Community Standards.', 'To reduce the prevalence of bullying and harassment on our platforms we use tactics that are specific to the unique nature of this violation type, and some that bridge learnings across numerous policy issues. In further studying prevalence, we expect to make continued refinements to our bullying and harassment policies and tools to better identify and enforce on this content. For example, we recentlyupdated our policiesto increase enforcement against harmful content and behavior for both private individuals and public figures. These updates came after years of consultation with free speech advocates, human rights experts, women’s safety groups, cartoonists and satirists, female politicians and journalists, representatives of the LGBTQ+ community, content creators and other types of public figures.', 'We are working hard to reduce this type of content on our platforms, but we also want to equip our community with tools to protect themselves from potentially offensive content in ways that work best for them.', 'One recent tool we’ve deployed on both Facebook and Instagram is adding warning screens to educate and discourage people from posting or commenting in ways that could be bullying and harassment.OnInstagram,about 50% of the time the comment was edited or deleted by the user based on these warnings. We’ve made investments in our bullying and harassment tools on Instagram, working to reduce the number of times this type of content is seen particularly by our younger user base.', 'We have a number of resources where you can learn more about the bullying and harassment prevention work we do on our platform, including ourBullying Prevention Hubon the Safety Center, a resource for teens, parents and educators seeking support and help for issues related to bullying and other conflicts.']\n",
            "67 ['Recent events have focused the world’s attention on the conflict in Ethiopia. Our thoughts are with the people of Ethiopia, both in the country and in the diaspora, during this difficult time. But while the international attention that these events are getting may be new, our work to prevent our platform from being abused in Ethiopia is not.', 'For more than two years, we’ve been implementing a comprehensive strategy to keep people in the country safe on our platform given the severe, longstanding risks of conflict.', 'Two years ago we moved Ethiopia to the category of countries that we believe are at the highest risk for conflict and violence, enabling the development of both proactive solutions that we can implement when crises arise, and a long-term strategy to keep people safe. We’ve been doing this despite the fact that the country’s lower internet adoption means that less than 10% of the population uses Facebook. For the millions of Ethiopians who rely on our services as a source of information and communication, our focus is threefold:', 'Ethiopia is an especially challenging environment to address these issues, in part because there are multiple languages spoken in the country.\\xa0 Over the past two years, we’ve significantly improved our reporting and enforcement tools. We can now review content in the top four languages spoken and those central to the conflict (Amharic, Oromo, Somali, Tigrinya). We’ve also made it easier for Ethiopians as well as specialized international and local human rights and civil society organizations to tell us when they see potentially violating content, so we can investigate it for possible violations.\\xa0 We also have technology to identify hate speech in Amharic and Oromo before anyone reports it to us. These efforts are industry-leading.', 'As a result of these efforts, between May and October 2021, we took action on more than 92,000 pieces of content in Ethiopia on Facebook and Instagram for violations of our Community Standards prohibiting hate speech, about 98% of which was detected before it was reported by people to us.', 'In June 2021, we alsoremoveda network of fake accounts posting critical commentary of opposition politicians/groups in Amharic.\\xa0 The people behind these posts used coordinated, inauthentic accounts as a central part of their efforts to mislead people about who they were and what they were up to. In March 2021, weremovedaccounts in Egypt that targeted Ethiopia, Sudan, and Turkey.', 'As the local situation deteriorated, and as weapproached electionsin June and again in September, we took a number of additional steps:', 'Then as now, our teams are working around the clock and we’ve activated our Integrity Operation Center — bringing togethersubject matter experts from across the company to respond in real time to problems and abuses.', 'Given the rapidly evolving situation, and informed by conversations we’ve had with human rights activists, journalists and civil society groups in Ethiopia and the diaspora about security concerns, we’ve taken additional steps in recent days. We recently launched a new safety feature in Ethiopia calledLock Profilethat allows people to restrict anyone who isn’t their friend from downloading, enlarging, or sharing their profile photo. It also prevents non-friends from seeing posts or other photos on their timeline, regardless of when they may have posted it. We’ve also put temporary measures in place to restrict views of peoples’ Friends List on their profile pages and remove results from “Search this profile.”', 'While safety work in Ethiopia has been going on for a long time, we know that the risks on the ground right now are higher. And since we recognize that local context and language-specific expertise is essential for this work, we will remain in close communication with people on the ground, along with partner institutions and non-governmental organizations as the days and weeks progress. This will help us take the right actions and make the right calls. We remain vigilant to emerging trends and stand ready to take additional action to meet the demands of this ongoing human rights situation.']\n",
            "68 ['During an event at the European Parliament this week, MEPs will hear about leaked internal documents and criticism that Meta putsprofit over the safety of our users.At the heart of this claim is a false premise. Yes, we’re a business and we make profit, but the idea that we do so at the expense of people’s safety or well-being misunderstands where our own commercial interests lie.', 'I spent more than a decade as a criminal prosecutor in the US before joining Meta, and for the past nine years I’ve helped our company develop and enforce our content standards. These policies seek to protect people from harm while also protecting freedom of expression. Our team includes former prosecutors, law enforcement officers, human rights lawyers, counter-terrorism specialists, teachers and child safety advocates, and we work with hundreds of independent experts around the world to help us get the balance right. While people often disagree about exactly where to draw the line, regulation like the EU’s Digital Services Act can establish standards all companies should meet.', 'Companies should also be judged on how their rules are enforced. Three years ago we began publishing figures on our removal of violating content, including the amount of it people actually see and how much we take down. We publish these reports every quarter and we’re subjecting them to independent audit.', 'Contrary to recent claims about our company, we’ve always had the commercial incentive to remove harmful content from our platform. People don’t want to see it when they use our apps and advertisers don’t want their ads next to it. That’s why we have clear rules about what isn’t allowed on our platforms, are on track to spend more than $5 billion this year alone on safety and security — more than any other tech company, even adjusted for scale — and have over 40,000 people to do one job: keep people safe on our apps. As a result, we’ve almost halved the amount of hate speech people see on Facebook over the last three quarters. Hate speech now represents only 0.05% of content views, or around 5 views per every 10,000. We’ve also got better at detecting it. Of the hate speech we removed, we found 97% before anyone reported it to us — up from just 23% a few years ago. While we have further to go, the enforcement reports show that we are making progress.', 'Central to many of the charges by our critics is the idea that our algorithmic systems actively encourage the sharing of sensational content and are designed to keep people scrolling endlessly. Of course, on a platform built around people sharing things they are interested in or moved by, content that provokes strong emotions is invariably going to be shared. But the argument that we deliberately push content that makes people angry for profit is deeply illogical. Helping people have positive experiences on our apps by seeing content that is more relevant and valuable to them is in the best interests of our business over the long term.', 'Our systems are not designed to reward provocative content. In fact, key parts of those systems are designed to do just the opposite. We reduce the distribution of many types of content — meaning that content appears lower in your News Feed — because they are sensational, misleading, gratuitously solicit engagement or are found to be false by our independent fact checking partners. We agree a better understanding of the relationship between people and the algorithms is in everyone’s interest, and that anyone who uses our platforms should have more control over the content that they see. That’s why we rolled out a chronological News Feed years ago, which turns off algorithmic ranking for anyone who wants that instead as well as tools such as Favorites and Why Am I Seeing This.', 'The rise of polarization, another issue social media companies are being held accountable for, has been the subject of serious academic research in recent years but without a great deal of consensus. But what evidence there is simply does not support the idea that Facebook, or social media more generally, is the primary cause of polarization. Recent election results in Germany and in the Netherlands point in the same direction. Facebook is used broadly in these countries and democratic center parties gained in popularity while support for more divisive parties remained stagnant or decreased.', 'We know there is more to do and we’ll keep making improvements, but regulation, especially the Digital Services Act, has to be part of the solution. European policymakers are leading the way in helping to embed European values like free expression, privacy, transparency and the rights of individuals into the day-to-day workings of the internet. The DSA can be the foundation for making the internet safer while keeping the vast social and economic benefits it brings.']\n",
            "69 ['Over the past two decades, Facebook has empowered people around the world with a wealth of social and economic benefits. It has made social connection and free expression possible on a massive scale. This can be especially important for people who are in places that are experiencing conflict and violence.', 'Facebook supports people’s right to express themselves freely, regardless of where they are in the world. Freedom of expression is a foundational human right and enables many other rights.\\xa0 But we know that technologies for free expression, information and opinion can also be abused to spread hate and misinformation — a challenge made even worse in places where there is a heightened risk of conflict and violence. This requires developing both short-term solutions that we can implement when crises arise and having a long-term strategy to keep people safe. Here is our approach.', 'Since 2018, we’ve haddedicated teams spanning product, engineering, policy, research and operations to better understand and address the way social media is used in countries experiencing conflict.Many of these individuals have experience working on conflict, human rights and humanitarian issues, as well as addressing areas like misinformation, hate speech and polarization. Many have lived or worked in the countries we’ve identified as highest risk and speak relevant languages. They are part of the over 40,000 people we have working on safety and security, including global content review teams in over 20 sites around the world reviewing content in over 70 languages.', 'In the last two years, we’ve hired more people with language, country and topic expertise. For example, we’ve increased the number of team members with work experience in Myanmar and Ethiopia to include former humanitarian aid workers, crisis responders and policy specialists. And we’ve hired more people who can review content in Amharic, Oromo, Tigrinya, Somali and Burmese. Adding more language expertise has been a key focus area for us. This year alone, we’ve hired content moderators in 12 new languages, including Haitian Creole, Kirundi, Tswana and Kinyarwanda.', 'Our teams have developed an industry-leading process for reviewing and prioritizing which countries have the highest risk of offline harm and violence every six months. We make these determinations in line with the UN Guiding Principles on Business and Human Rights and following a review of these factors:', 'Using this prioritization process, wedevelop longer-term strategies to prepare for, respond to and mitigate the impacts of harmful offline events in the countries we deem most at risk.This allows us to act quickly to remove content that violates our policies and take other protective measures while still protecting freedom of expression and other human rights principles. Recent examples include our preparations forelections inMyanmar,Ethiopia,Indiaand Mexico.', 'In a crisis, we will determine what kind of support and teams we need to dedicate to a particular country or language, and for how long we need to keep them in place. This might include deploying our Integrity Product Operations Centers model to monitor and respond to threats in real time. It can also include seeking to ensure our integrity systems and resources are robust and ready where there may be ongoing risk of political unrest, or building temporary product levers ahead of a protest or a culturally sensitive event — all while ensuring that we have teams ready to support unplanned events, suchresponding to thecoupin Myanmar.', 'We know that we face a number of challenges with this work and it is a complex and often adversarial space — there is no one-size-fits-all solution. Many of these offline issues have existed for decades or longer, and media services have a long history of being abused by those seeking to assert or maintain power or incite violence. But, we know our work to keep our global community safe will never be finished and it requires ongoing vigilance and investments. That’s what we’ve done for many years and we will continue doing it going forward.']\n",
            "70 ['Long before the US election period began last year, we expected that the 2020 election would be one of the most contentious in history — and that was before we even knew it would be conducted in the midst of a pandemic. We worked since 2016 to invest in people, technologies, policies and processes to ensure that we were ready, and began our planning for the 2020 election itself two years in advance. We built our strategy to run all the way through Inauguration Day in 2021, knowing that there was a high likelihood that the election results would be contested. So we planned specifically for that scenario. This election planning was built upon all of our otherintegrity work and investments we’ve made since 2016.', 'These included:', 'While that last point is important, as you can see, it was only one part of a much longer series of steps that we took well before, during and after Election Day. When preparing for the election, we planned for multiple potential outcomes and considered many societal factors to understand and respond to violence.', 'That’s a big part of the reason why we developed these additional product levers for extraordinary circumstances, which we called internally “break the glass” measures. That’s also why we kept our full suite of systems including many of the “break the glass” measures in place well after Election Day and even after we saw specific signals about potential threats leveling off and more than a month had passed since major news outlets called the election for now-President Joe Biden.', 'To blame what happened on January 6 on how we implemented just one item of the above list is absurd.We are a significant social media platform so it’s only natural for content about major events like that to show up on Facebook.But responsibility for the insurrection itself falls squarely on the insurrectionists who broke the law and those who incited them.We worked with law enforcement in the days and weeks after January 6 with the goal of ensuring that information linking the people responsible for it to their crimes is available.Of course there are always lessons to be learned from the work we do to protect elections and respond to immediate threats and longer-term challenges. We will apply these lessons as we continue doing all of this work.']\n",
            "71 ['Data pulled from leaked documents is being used to create a narrativethat the technology we use to fight hate speech is inadequate and that we deliberately misrepresent our progress. This is not true. We don’t want to see hate on our platform, nor do our users or advertisers, and we are transparent about our work to remove it.What these documents demonstrate is that our integrity work is a multi-year journey. While we will never be perfect, our teams continually work to develop our systems, identify issues and build solutions.', 'Recent reporting suggests that our approach to addressing hate speech is much narrower than it actually is, ignoring the fact that hate speech prevalence has dropped to 0.05%, or 5 views per every 10,000 on Facebook.We believe prevalence is the most important metric to use because it showshow much hate speech is actually seen on Facebook.', '', 'Focusing just on content removals is the wrong way to look at how we fight hate speech. That’s because using technology to remove hate speech is only one way we counter it. We need to be confident that something is hate speech before we remove it. If something might be hate speech but we’re not confident enough that it meets the bar for removal, ourtechnology mayreduce the content’s distribution or won’t recommend Groups, Pages or people that regularly post content that is likely to violate our policies. We also use technology to flag content for more review.', 'We have a high threshold for automatically removing content. If we didn’t, we’d risk making more mistakes on content that looks like hate speech but isn’t, harming the very people we’re trying to protect,such as those describing experiences with hate speech or condemning it.', 'Another metric being misconstrued is our proactive detection rate, which tells us how good our technology is at finding content before people report it to us. It tells us, of the content we remove, how muchwe found ourselves. In 2016, the vast majority of our content removals were based on what users reported to us. We knew we needed to do better and so we began building technology to identify potentially violating content without anyone flagging it to us.', 'When we began reporting our metrics on hate speech, only 23.6% of content we removed was detected proactively by our systems; the majority of what we removed was found by people. Now, that number is over 97%. But our proactive rate doesn’t tell us what we are missing and doesn’t account for the sum of our efforts, including what we do toreduce the distributionof problematic content. That’s why we focus on prevalence and consistently describe it as the most important metric. Prevalence tells us what violating content people see because we missed it. It’s how we most objectively evaluate our progress, as it provides the most complete picture.We talk about prevalence in our Community Standards Enforcement Report report every quarter anddescribe it in our Transparency Center.', 'Prevalence is how we measure our work internally, and that’s why we share the same metric externally. While we know our work will never be done in this space, the fact that prevalence hasbeen reduced by almost 50% in the last three quartersshows that taken together, our efforts are having an impact.As reported in ourCommunity Standards Enforcement Report, we can attribute a significant portion of the drop to our improved and expanded AI systems.', '', 'We’ve worked with international experts to develop our metrics. We’re also the only company which has volunteered to have them independently audited.', 'We include many metrics in our quarterly reports, which are the most comprehensive of their kind, to give people a more complete picture.We have worked withinternational expertsin measurement, statistics and other areas to providean independent, public assessmentto make sure we are measuring the right things. While they broadly agreed with our approach, they also provided recommendations for how we can improve. You can read their full reporthere.We have also committed to undergoing anindependent audit, with global auditing firm EY, to make sure we are measuring and reporting our metrics accurately.', '', '']\n",
            "72 ['It’s important that everyone on our apps feels safe to engage and connect with their communities. We do not allow bullying and harassment on our platform, but when it does happen, we act. We remove content that violates our policies and disable the accounts of people who repeatedly break our rules. We also regularly pressure test these policies with our safety experts, making changes as needed.', 'On National Bullying Prevention and Awareness Day in the US, we’re announcing updates to our globalbullying and harassment policiesto better protect members of our community, particularly those who may be vulnerable to online abuse.', 'We’ve launched a new policy that helps protect people from mass harassment and intimidation from multiple accounts. We will now remove coordinated efforts of mass harassment that target individuals at heightened risk of offline harm, for example victims of violent tragedies or government dissidents — even if the content on its own wouldn’t violate our policies. We will also remove objectionable content that is considered mass harassment towards any individual on personal surfaces, such as direct messages in inbox or comments on personal profiles or posts. We will require additional information or context to enforce this new policy.', 'In addition, we will also remove state-linked and adversarial networks of accounts, Pages and Groups that work together to harass or silence people, for example a state-sponsored organization using closed private groups to coordinate mass posting on dissident profiles.', 'Public figures — whether they’re politicians, journalists, celebrities or creators — use Facebook and Instagram to engage directly with their followers. We’re always trying to strike the right balance between protecting them from abuse and allowing open dialogue about them on our apps. Our bullying and harassment policy differentiates between public figures and private individuals to enable freedom of expression and legitimate public discourse around those in the public eye.', 'Public figures shouldn’t be subjected to degrading or sexualized attacks. Wecurrently remove attacks on public figuresthat encompass a wide range of harms. Based on feedback from a large number of global stakeholders, we will now also remove:', 'In addition, we will remove unwanted sexualized commentary and repeated content which is sexually harassing. Because what is “unwanted” can be subjective, we’ll rely on additional context from the individual experiencing the abuse to take action. We made these changes because attacks like these can weaponize a public figure’s appearance, which is unnecessary and often not related to the work these public figures represent.', 'We also recognize that becoming a public figure isn’t always a choice, and that this fame can increase the risk of bullying and harassment — particularly if the person comes from an underrepresented community, including women, people of color or the LGBTQ community. Consistent with the commitments made in ourcorporate human rights policy, we’ll now offer more protections for public figures like journalists and human rights defenders who have become famous involuntarily or because of their work. These groups will now have protections from harmful content, for example content that ranks their physical looks, as other involuntary public figures do. The full list of protections for public figures, including involuntary public figures, can be found in ourCommunity Standards.', 'In updating our policies, we consulted a diverse set of global stakeholders including free speech advocates, human rights experts, women’s safety groups and our Women’s Safety Expert Advisors, cartoonists and satirists, female politicians and journalists, representatives of the LGBTIQ+ community, content creators and public figures. We will continue to work with experts and listen to members of our community to ensure our platforms remain safe.', 'Our policies complement tools we’ve built in our apps to prevent, stop and report bullying and harassment online. These tools empower people to manage unwanted or abusive interactions like blocking or unfollowing someone on Facebook and Instagram and Restrict, Hidden Words and Limits on Instagram. To learn more about this work and the resources we’ve developed with experts to reduce this type of behavior online generally, visit ourBullying Prevention Hubon our Safety Center, developed in partnership with the Yale Center for Emotional Intelligence.', 'To learn more about how these policy changes were developed, check out our Product Policy Forum Minutes:']\n",
            "73 ['Today, the Wall Street Journal again questioned our motives in carrying out research into young people’s social media use. This is nothing more than an attempt to recycle previous reporting. As the Journal itself reported four years ago, we’ve had a product in the market in the form of Messenger Kids that is intended for younger users. We developed it with input from parents to make sure that it provides a safer experience for younger kids that is supervised and controlled by parents. There is nothing nefarious or secretive about this work.', 'The article featured an image of an internal slide that is attention grabbing because it’s presented with no context; in actuality, it’s simply a framework that international policymakers have been advocating we use. These are age bands used by the Age Appropriate Design Code and other policy experts. The “where we’re going” title reflects industry and policymakers’ move toward this taxonomy, not Facebook’s product plans, as the internal note’s context makes clear.', 'Companies that operate in a highly competitive space — includingthe Wall Street Journal— make efforts to appeal to younger generations. Considering that our competitors are doing the same thing, it would actually be newsworthy if Facebookdidn’tdo this work. The Journal also lifts a phrase from an internal presentation titled, “Exploring playdates as a growth lever.” Unfortunately the language we used was an insensitive way to pose a serious question and doesn’t reflect our approach to building the app. It was part of research to better understand how families and kids were using the Messenger Kids app to improve their experiences with it. We built Messenger Kids to create a safer, parent-managed experience for kids.And as we have heard from parents worldwide,virtual playdates on Messenger Kids have become a lifeline for many families during the pandemic.', 'We want to keep young people safe on our apps, and that includes making sure that those who aren’t old enough to be using them, don’t. We’ll continue investing in research to make sure that we do this work even more effectively.']\n",
            "74 ['We wanted to provide an update on our work to build an Instagram experience for people under the age of 13, often referred to as “Instagram Kids.” We started this project to address an important problem seen across our industry: kids are getting phones younger and younger, misrepresenting their age, and downloading apps that are meant for those 13 or older.', 'We firmly believe that it’s better for parents to have the option to give their children access to a version of Instagram that is designed for them —\\xa0where parents can supervise and control their experience — than relying on an app’s ability to verify the age of kids who are too young to have an ID.', 'While we stand by the need to develop this experience, we’ve decided to pause this project. This will give us time to work with parents, experts, policymakers and regulators, to listen to their concerns, and to demonstrate the value and importance of this project for younger teens online today.', 'Critics of “Instagram Kids” will see this as an acknowledgement that the project is a bad idea. That’s not the case. The reality is that kids are already online, and we believe that developing age-appropriate experiences designed specifically for them is far better for parents than where we are today.', 'We’re not the only company to think so. Our peers recognized these issues and built experiences for kids. YouTube and TikTok have versions of their app for those under 13.', 'Our intention is not for this version to be the same as Instagram today. It was never meant for younger kids, but for tweens (aged 10-12). It will require parental permission to join, it won’t have ads, and it will have age-appropriate content and features. Parents can supervise the time their children spend on the app and oversee who can message them, who can follow them and who they can follow. The list goes on.', 'An important part of what we’ve been developing for “Instagram Kids” is a way for parents to supervise their child’s use of Instagram. While we’re pausing our development of “Instagram Kids”, we’ll continue our work to allow parents to oversee their children’s accounts by expanding these tools to teen accounts (aged 13 and over) on Instagram.', 'These new features, which parents and teens can opt into, will give parents the tools to meaningfully shape their teen’s experience. We’ll have more to share on this in the coming months.', 'Recent reporting from the WSJ on our research into teen’s experiences on Instagram has raised a lot of questions for people. To be clear, I don’t agree with how the Journal has reported on our research. My colleague Pratiti goes into this morehere.', 'We do research like this so we can make Instagram better. That means our insights often shed light on problems, but they inspire new ideas and changes to Instagram. Examples include our industry leading anti-bullying work such asRestrict,Hidden WordsandLimits, and ourrecent changesto make Instagram accounts private by default for those under 16.', 'Research also informs our work on issues likenegative body image.We announcedlast weekthat we’re exploring two new ideas: encouraging people to look at other topics if they’re dwelling on content that might contribute to negative social comparison, and a feature tentatively called “Take a Break,” where people could put their account on pause and take a moment to consider whether the time they’re spending is meaningful.', 'I have three children and their safety is the most important thing in my life. I hear the concerns with this project, and we’re announcing these steps today so we can get it right.']\n",
            "75 ['Update on September 29, 2021 at 4:43PM PT:Earlier today, we provided Congress with the two full research decks that were the primary focus of the Wall Street Journal’s mischaracterization of internal Instagram research into teenagers and well-being. We added annotations to each slide that give more context because this type of research is designed to inform internal conversations and the documents were created for and used by people who understood the limitations of the research.Now, we’re publicly releasing these two research decks with annotations.', 'Instagram Teen Annotated Research Deck 1Instagram Teen Annotated Research Deck 2', 'Originally published on September 26, 2021 at 4:00PM PT:', 'In advance of Facebook’s Global Head of Safety Antigone Davis appearing before a Senate Commerce Subcommittee on Thursday, we want to be clear about what the researchrecently characterizedby The Wall Street Journal shows, and what it does not show.', 'It is simply not accurate that this research demonstrates Instagram is “toxic” for teen girls. The research actually demonstrated that many teens we heard from feel that using Instagram helps them when they are struggling with the kinds of hard moments and issues teenagers have always faced. In fact, in 11 of 12 areas on the slide referenced by the Journal — including serious areas like loneliness, anxiety, sadness and eating issues — more teenage girls who said they struggled with that issue also said that Instagram made those difficult timesbetterrather than worse. Body image was the only area where teen girls who reported struggling with the issue said Instagram made it worse as compared to the other 11 areas. But here also, the majority of teenage girls who experienced body image issues still reported Instagram either made it better or had no impact. We go into more details below on how the research actually lines up with what The Wall Street Journal claimed.', 'In addition to putting specific findings in context, it is also critical to make the nature of this research clear. This research, some of which relied on input from only 40 teens, was designed to inform internal conversations about teens’ most negative perceptions of Instagram. It did not measure causal relationships between Instagram and real-world issues. These documents were also created for and used by people who understood the limitations of the research, which is why they occasionally used shorthand language, particularly in the headlines, and do not explain the caveats on every slide.', 'Studying these big societal issues and what impacts them is nuanced and complex. The Journal article implied that we were hiding this research and that the results are surprising, but that is simply not accurate. Not only have we talked about thestrengths and weaknessesof social media and well-beingpubliclyformore thana decade, external researchers have, too. For example,a survey and interviewsfrom Harvard found that teens viewed social media “predominantly” positively, though they reported both positive and negative impacts on their relationships and self-expression. And aPew Internetsurvey reported the majority of teens credit social media for positive outcomes, like 81% said it helps them connect, while some also pointed to its negative impacts, like 43% said they felt pressure to post things that make them “look good.”', 'Our internal research is part of our effort to minimize the bad on our platforms and maximize the good. We invest in this research to proactively identify where we can improve — which is why the worst possible results are highlighted in the internal slides. That’s why the most important thing about this research is what we’ve done with it. We have a long track record of using our research — as well as external research and close collaboration with ourSafety Advisory Board,Youth Advisorsand additional experts and organizations — to inform changes to our apps and provideresourcesfor the people who use them. For example on Instagram:', 'Below, we contrast what The Wall Street Journal said versus what the research showed:', 'WSJ said:“Repeatedly, the company’s researchers found that Instagram is harmful for a sizable percentage of them [young users], most notably teenage girls. ‘We make body image issues worse for one in three teen girls,’ said one slide from 2019, summarizing research about teen girls who experience the issues.”', 'What the data shows:The slide in question, which The Wall Street Journal did not publish as part of their report and we’re releasing below, shows that Instagram helps many teens who are struggling with some of the hardest issues they experience. On 11 of the 12 issues in the slide referenced by the Journal, such as eating issues, loneliness, anxiety and sadness, teenage girls who said they experienced these challenges were more likely to say that Instagram madethese issuesbettervs. worse.¹The one exception was body image. While the headline in the internal slide does not explicitly state it, the research shows one in three of those teenage girls who told us they were experiencing body image issues reported that using Instagram made them feel worse — not one in three ofallteenage girls. This is an important difference that is not explicit in the Journal’s reporting. And, among those same girls who said they were struggling with body image issues, 22% said that using Instagram made them feel better about their body image issues and 45.5% said that Instagram didn’t make it either better or worse (no impact).', 'WSJ said:“Teen boys aren’t immune. In the deep dive Facebook’s researchers conducted into mental health in 2019, they found that 14% of boys in the US said Instagram made them feel worse about themselves. In their report on body image in 2020, Facebook’s researchers found that 40% of teen boys experience negative social comparison.”', 'What the data shows:What the study also said was that 50% of US and 36% of UK teenage boys (who use Instagram and filled out a survey) say they feel better about themselves after using Instagram, including 18% of US teenage boys saying they felt “much better.” In fact, on 12 out of the 12 issues in the slide referenced above — such as eating issues, loneliness, anxiety and sadness — teenage boys who said they experienced some of these challenges were more likely to say that Instagram madethese issuesbettervs. worse.', \"WSJ said:“‘Teens blame Instagram for increases in the rate of anxiety and depression,’ said another slide. ‘This reaction was unprompted and consistent across all groups.'”\", 'What the data shows:This finding comes from a set of focus groups of a small sample of 40 teenage Instagram users in the US and UK who struggle with body image, self-esteem, negative mood and/or other issues. What the Journal left out was another key finding from the same study: that the same teenage users say the overall effects of Instagram arepositivefor them. Additionally, based on the research the Journal left out, 8 out of 10 US teens who use Instagram and filled out a survey said Instagram either made them feel better about themselves or had no effect on how they feel about themselves. Here are some other important details from the slide above:', 'WSJ said:“Among teens who reported suicidal thoughts, 13% of British users and 6% of American users traced the desire to kill themselves to Instagram, one presentation showed.”', 'What the data shows:When we take a step back and look at the full data set, about1%of the entire group of teens who took the survey said they had suicidal thoughts that they felt started on Instagram.²Of course, even one person who feels this started on Instagram is one too many. That is why we have invested so heavily in support, resources and interventions for people using our services. In addition, some of the same research cited by the Journal in the slide above shows that 38% of teenage girls who said they struggled with suicidal thoughts and self harm said Instagram made these issues better for them, and 49% said it has no impact.', 'WSJ said:“But a mounting body of Facebook’s own evidence shows Instagram can be damaging for many. In one study of teens in the US and UK Facebook found that more than 40% of Instagram users who reported feeling ‘unattractive’ said the feeling began on the app. About a quarter of the teens who reported feeling ‘not good enough’ said the feeling started on Instagram. Many also said the app undermined their confidence in the strength of their friendships.”', 'What the data shows:One of the studies cited by the Journal highlights that teens using Instagram in the US and UK are roughly 3 times more likely to say that Instagram makes them feel better about their life rather than worse about it.³But that’s exactly why we’ve invested in this research — and because we’ve made these investments, we’ve been able to set up a specific effort to work on these issues to minimize the bad and maximize the good. Suggesting that Instagram is toxic for teens is simply not backed up by the facts.']\n",
            "76 ['September is National Suicide Prevention and Awareness Month, and people around the world focused on the theme of “Creating Hope Through Action.” We know that this kind of collective action is needed to provide support online and offline for individuals considering suicide or self-harm. It’s part of why, since 2006, we’ve worked with experts around the world to shape our policies, practices and products that support those expressing thoughts of suicide or self-harm on our platform.', 'For the past 15 years, these experts have helped Facebook become a space where people can share their experiences, raise awareness about these issues and seek support from one another. Since our last update in 2020, many expert and advocate organizations throughout the world have made great strides in their efforts to support people at risk for or recovering from suicide and self-harm:', 'We’ve been tapping into the expertise of organizations like these to improve how we handle discussions of suicide and self-harm on our platform. In consultationsour Suicide and Self Injury Advisory Group, we’ve refined our policy for a specific type of content that doesn’t break our rules, but may trivialize themes around suicide, death or depression. Experts agree it’s important we allow these kinds of posts — to make sure people can talk about how they’re feeling and friends and family have the chance to reach out — but that we need to balance this with protecting others from potentially upsetting content. Rather than removing it completely, we’llaim to not recommend this content in places like Explore on Instagram, making it harder to discover. We hope this helps strike this delicate balance, and we’ll continue to consult with experts as research in this area develops.', 'We’re also releasing our new Responding to Suicide Challenges toolkit. Developed in partnership with experts, the guide provides resources for parents, educators, youth and media on how to safely discuss viral suicide challenges, understand their impacts and reduce the sharing of challenges online. These resources were developed in partnership with Samaritans UK and 10 of our global suicide crisis response partners, including SAVE, Orygen, Embrace and Spunout, among others. The toolkit is available on theSafety Center resource pageand will be available in 20 languages.', 'The more we innovate and work together, the better we can support our community.In the year ahead,we’ll continue to improve our technology, policies and partnerships relating to suicide and self-harm, keeping up with the latest research and trends to make our platform a safe and supportive place for everyone.To learn more, visit Facebook’ssuicide prevention hub.']\n",
            "77 ['How technology companies grapple with complex issues is being heavily scrutinized, and often, without important context. There is a lot more to the story. What is getting lost in this discussion is some of the important progress we’ve made as a company and the positive impact that it is having across many key areas.', 'We firmly believe that ongoing research and candid conversations about our impact are some of the most effective ways to identify emerging issues and get ahead of them. This doesn’t mean we find and fix every problem right away. But because of this approach, together with other changes, we have made significant progress across a number of important areas, including privacy, safety and security, to name a few. Just as the world has changed a lot, so has Facebook.', 'In the past, we didn’t address safety and security challenges early enough in the product development process. Instead, we made improvements reactively in response to a specific abuse. But we have fundamentally changed that approach. Today, we embed teams focusing specifically on safety and security issues directly into product development teams, allowing us to address these issues during our product development process, not after it. Products also have to go through an Integrity Review process, similar to thePrivacy Review process, so we can anticipate potential abuses and build in ways to mitigate them. Here are a few examples of how far we’ve come.', 'Some of the most important changes we’ve made in recent years have been in prioritizing safety and security. As a result:', 'We have alsochanged our approach to protecting people’s privacyas a company. This includes investing in and expanding ourPrivacy Checkup, which today is used by tens of millions of people every month to manage their settings and control their experience on Facebook,and launching tools likeOff-Facebook ActivityandWhy Am I Seeing This?that show people how their information is used and let them more easily manage settings.', 'Misinformation has been a challenge on and off the internet for many decades. People are understandably concerned about how it will be handled for future internet technologies. At Facebook, we’ve begun addressing this comprehensively — rather than treating it as a single problem with a single solution. This means we’ve gotten better at addressing this complex challenge. We’ve worked to develop and expand our systems to reduce misinformation and promote reliable information. As a result:', 'Most importantly, we’ve also changed not justwhatwe build buthowwe build so that when we launch new products, they are more likely to have effective privacy, security and safety protections already built in. For example:', '', 'You canread moreabout the direction of our responsible innovation efforts fromMargaret Stewart, VP of Product Design & Responsible Innovation at Facebook.', 'Yes, we’ve made progress. But we also know that there will always be examples of things we miss and things we take down by mistake. There is no perfect here. Collaborating with experts, policymakers and others has made us better, and continued collaboration will be key to making sure our progress continues. And that’s our plan.', 'Read more about our efforts on ournew page, which features updated information and figures, to give a sense of where things have improved and where we still have more work to do. OurTransparency Centeris also a comprehensive destination for our integrity and transparency efforts. Also, see atimeline of our integrity efforts since 2016.', '', 'For more, visitabout.facebook.com/progress.']\n",
            "78 ['A lot has been said about Facebook this week. A series of articles published by theWall Street Journalhas focused on some of the most difficult issues we grapple with as a company — from content moderation and vaccine misinformation, to algorithmic distribution and the well-being of teens. These are serious and complex issues, and it is absolutely legitimate for us to be held to account for how we deal with them. But these stories have contained deliberate mischaracterizations of what we are trying to do, and conferred egregiously false motives to Facebook’s leadership and employees.', 'At the heart of this series is an allegation that is just plain false: that Facebook conducts research and then systematically and willfully ignores it if the findings are inconvenient for the company. This impugns the motives and hard work of thousands of researchers, policy experts and engineers at Facebook who strive to improve the quality of our products, and to understand their wider (positive and negative) impact. It’s a claim which could only be made by cherry-picking selective quotes from individual pieces of leaked material in a way that presents complex and nuanced issues as if there is only ever one right answer.', 'With any research, there will be ideas for improvement that are effective to pursue and ideas where the tradeoffs against other important considerations are worse than the proposed fix. The fact that not every idea that a researcher raises is acted upon doesn’t mean Facebook teams are not continually considering a range of different improvements. At the same time, none of these issues can be solved by technology companies alone, which is why we work in close partnership with researchers, regulators, policymakers and others.', 'But none of that collaborative work is helped by taking a deliberately lop-sided view of the wider facts. For example, to suggest that misinformation has somehow overwhelmed our COVID-19 vaccine response ignores the most important fact: that vaccine hesitancy among Facebook’s US users has declined by about 50% since January. TheJournalarticle goes on to discuss at length how pro-vaccine posts are undermined by negative comments, once again burying a crucial point: that health organizations continue posting because their own measurements show how their posts on our platforms effectively promote vaccines, despite negative comments.', 'Similarly, to suggest that the research community is settled in its view on the intersection between social media and well-being is simply not the case. The truth is that research into the impact social media has on people is still relatively nascent and evolving, and social media itself is changing rapidly.Some researchers arguethat we need more evidence to understand social media’s impact on people. Each study has limitations and caveats, so no single study is going to be conclusive. We need to rely on an ever-growing body of multi-method research and expert input.', 'What would be really worrisome is if Facebook didn’t do this sort of research in the first place. The reason we do it is to hold up a mirror to ourselves and ask the difficult questions about how people interact at scale with social media. These are often complex problems where there are no easy answers — notwithstanding the wish to reduce them to an attention-grabbing newspaper headline.', 'Facebook understands the significant responsibility that comes with operating a global platform. We take it seriously, and we don’t shy away from scrutiny and criticism. But we fundamentally reject this mischaracterization of our work and impugning of the company’s motives. I wish there were easy answers to these issues, and that choices we might make wouldn’t come with difficult trade-offs. That is not the world we live in. We will continue to invest in research into these serious and complex issues. We will continue to ask ourselves the hard questions. And we will continue to improve our products and services as a result.']\n",
            "79 ['We’ve beenclearthat we want to do more tocreate safer, more private experiencesfor young people. To do that we need to know how old everybody is on Instagram,so we’ve started asking people to share their birthday with us if they haven’t shared it previously.', 'This information allows us to create new safety features for young people, and helps ensure we provide the right experiences to the right age group. Recent examples include changes we made inMarchto prevent adults from sending messages to people under 18 who don’t follow them, andlast monthwe started to default new accounts belonging to people under the age of 16 into a private setting.', 'This information also allows us to personalize your experience. For example, we can applyrecent changes we madetorestrict advertiser targeting optionsfor audiences under the age of 18 to more people. It also helps us show you more relevant ads.', 'This work begana few years agowhen we started asking people for their birthday. While we have birthdays for most people on Instagram, to get a more complete picture we’re introducing two new changes.These changes only apply to people who haven’t already shared their birthday.', 'First, we’ll start to ask you for your birthday when you open Instagram. We’ll show you a notification a handful of times and if you haven’t provided us with your birthday by a certain point, you’ll need to share it to continue using Instagram. This information is necessary for new features we’re developing to protect young people.', '', 'Second, if you seewarningscreensplaced on posts, we’ll ask you for your birthday before you can see the post. These screens aren’t new, and we already show them on posts that may be sensitive or graphic, but we don’t currently ask for your birthday when viewing these posts. Now, we’ll start asking for your birthday on some of these screens if you haven’t shared it with us previously.', '', 'We recognize some people may give us the wrong birthday, and we’re developing new systems to address this. As we sharedrecently, we’re usingartificial intelligenceto estimate how old people are based on things like “Happy Birthday” posts. In the future, if someone tells us they’re above a certain age, and our technology tells us otherwise, we’ll show them a menu of options to verify their age. This work is still in the early stages, and we look forward to sharing more soon.', 'We hope this explains why we’re starting to ask some people for their birthday, and why it is so important for our efforts to provide safer, more private experiences for young people. For more information, head to ourHelp Center.']\n",
            "80 ['Today we’re publishing theCommunity Standards Enforcement Reportfor the second quarter of 2021. This report provides metrics on how we enforced our policies from April through June. This is our 10th report andsome of our long-term trends include:', 'In addition to our Community Standards Enforcement Report, this quarter we’re also sharing:', 'We’re committed to sharing meaningful data so we can be held accountable for our progress, even if the data shows areas where we need to do better.', 'Today, we’re also releasing thefirst in a series of reportsthat will give an overview of themost widely-viewed contentin Facebook’s News Feed, starting with the top 20 most viewed domains, links, Pages and posts in the US. These reports are public in theTransparency Centerand we will include them with each quarterly Community Standards Enforcement Report going forward.', 'COVID-19 is still a major public health issue, and we are committed to helping people get authoritative information, including vaccine information. We continue to remove harmful COVID-19 misinformation and prohibit ads that try to exploit the pandemic for financial gain. Since the start of the pandemic through June:', 'We’ve provided authoritative information to help improve vaccine acceptance, connecting 2 billion people to resources from health experts through our COVID-19 Information Center and educational pop-ups on Facebook and Instagram and helping 4 million people in the US alone access vaccines through our vaccine finder tool.', 'We know frompublic health researchthat people are more likely to get vaccinated if they see others in their community doing so. In countries where vaccines are available to most people, we ramped up our efforts to show when friends and neighbors share their support for vaccines through profile frames and stickers.', 'For people in the US on Facebook, vaccine hesitancy has declined by 50%. Globally, we have also seen vaccine acceptance rising. For example, ourCOVID-19 Trends and Impact Survey data which we conduct in partnership with Carnegie-Mellon and University of Maryland has since the beginning of the year shown vaccine acceptance rising by 35 percent in France, 25 percent in Indonesia, and 20 percent in Nigeria.', 'Prevalence of hate speech on Facebook continued to decrease for the third quarter in a row. In Q2, it was 0.05%, or 5 views per 10,000 views, down from 0.05-0.06%, or 5 to 6 views per 10,000 views in Q1.', '', 'We removed31.5 million pieces of hate speech content from Facebook, compared to 25.2 million in Q1, and 9.8 million from Instagram, up from 6.3 million in Q1. This is due to continued improvement in our proactive detection.Our investments in AI enable us to detect more kinds of hate speech violations on Facebook and Instagram. This technology helps us enforce our policies across billions of users and multiple languages. Steady, continuous AI improvements and advancements, such as theReinforcement Integrity Optimizer (RIO), enable our AI models to spot hate speech using real-world data and improve over time.', 'Keeping children safe on our apps is critical. Previously, we reported one metric, child nudity and sexual exploitation of children. In our latest report, we’ve added more data and created two new reporting categories under the broader topic of child endangerment: 1) nudity and physical abuse and 2) sexual exploitation.', '', 'We changed this to provide a more detailed, transparent overview of our efforts in this space to child safety experts, academics and the general public.', 'In Q2 2021, we improved our proactive detection technology on videos and expanded our media-matching technology on Facebook, allowing us to remove more old, violating content. Both enabled us to take action on more violating content.', 'In addition to new categories and ongoing improvements in reducing prevalence, we saw steady progress across many problem areas.', 'On Facebook in Q2 we took action on:', 'On Instagram in Q2 we took action on:']\n",
            "81 ['Today, we’re releasing the first in a series of reports that will give an overview of the most widely viewed content in News Feed, starting with domains, links, Pages and posts in the US.TheWidely Viewed Content Reportwill be updated quarterly in theTransparency Centerand will be released in conjunction with each quarterlyCommunity Standards Enforcement Report.', 'Ourinaugural reportcontains some noteworthy takeaways:', 'Our insights tool,CrowdTangle, was built to help people get an idea of content from Pages that gets the most likes, comments and reshares.We want this data to be broadly available to people, which is why we’re publishing it directly in our Transparency Center. We see this as a complement to insights that can be found through CrowdTangle, which is primarily a tool used by publishers.It’s important to note that there is so much content on Facebook that even the most-viewed content is still a small portion of what people see. Given thecustomized natureof News Feed,mostof what people see on Facebook is uniquely personalized to them.To paint a complete picture and provide more extensive detail of what people actually see on Facebook, we’ll release Widely Viewed Content Reports on a quarterly basis, starting in the US and eventually including more international data.', 'Transparency is part of everything we do, and releasing these reports is the latest step in our efforts to share data and hold ourselves accountable. Whether it’s sharing our content enforcement progress through theCommunity Standards Enforcement Report, submitting ourselves toexternal audit, working to release new data and tools (like the recently-announcedResearcher API) to researchers throughFacebook Open Research and Transparency(FORT), or expanding our Data for Good partnerships to help addressCOVID-19 or disaster relief, we’re committed to sharing useful and accurate information with the public.', 'See thefull reportandcompanion guidefor more information.']\n",
            "82 ['In recent weeks, there has been a debate about whether the global problem of COVID-19 vaccine misinformation can be solved simply by removing 12 people from social media platforms. People who have advanced this narrative contend that these 12 people are responsible for 73% of online vaccine misinformation on Facebook. There isn’t any evidence to support this claim. Moreover, focusing on such a small group of people distracts from the complex challenges we all face in addressing misinformation about COVID-19 vaccines.', 'That said, any amount of COVID-19 vaccine misinformation that violates our policies is too much by our standards — and we have removed over three dozen Pages, groups and Facebook or Instagram accounts linked to these 12 people, including at least one linked to each of the 12 people, for violating our policies. We have also imposed penalties on nearly two dozen additional Pages, groups or accounts linked to these 12 people, like moving their posts lower in News Feed so fewer people see them or not recommending them to others. We’ve applied penalties to some of their website domains as well so any posts including their website content are moved lower in News Feed. The remaining accounts associated with these individuals are not posting content that breaks our rules, have only posted a small amount of violating content, which we’ve removed, or are simply inactive. In fact, these 12 people are responsible for about just 0.05% of all views of vaccine-related content on Facebook. This includes all vaccine-related posts they’ve shared, whether true or false, as well as URLs associated with these people.', 'The reportupon which the faulty narrative is based analyzed only a narrow set of 483 pieces of content over six weeks from only 30 groups, some of which are as small as 2,500 users.They are in no way representative of the hundreds of millions of posts that people have shared about COVID-19 vaccines in the past months on Facebook. Further, there is no explanation for how the organization behind the report identified the content they describe as “anti-vax” or how they chose the 30 groups they included in their analysis. There is no justification for their claim that their data constitute a “representative sample” of the content shared across our apps.', 'Focusing on these 12 individuals misses the forest for the trees. We have worked closely with leading health organizations since January 2020 to identify and remove COVID-19 misinformation that could contribute to a risk of someone spreading or contracting the virus.Since the beginning of the pandemic across our entire platform, we have removed over 3,000 accounts, Pages and groups for repeatedly violating our rules against spreading COVID-19 and vaccine misinformation and removed more than 20 million pieces of content for breaking these rules.', 'None of this is to suggest that our work is done or that we are satisfied. Tracking and combating vaccine misinformation is a complex challenge, made more difficult by the lack of common definitions about what constitutes misinformation, and the reality that guidance from scientific and health experts has evolved and will continue to evolve throughout the pandemic. That’s why we’re continuing to work with external experts and governments to make sure that we are approaching these issues in the right way and making adjustments if necessary. In the meantime, we will continue doing our part to show people reliable information about COVID-19 vaccines from health experts and help people get vaccinated.']\n",
            "83 ['Today, we’re announcing new features to help protect people from abuse on Instagram:', 'We have a responsibility to make sure everyone feels safe when they’re on Instagram. We don’t allow hate speech or bullying on Instagram, and we remove it whenever we find it. We also want to protect people from having to experience this abuse in the first place, which is why we’re constantly listening to feedback from experts and our community, anddeveloping new featuresto give people more control over their experience on Instagram, and help protect them from abuse.', '', 'To help protect people when they experience or anticipate a rush of abusive comments and DMs, we’re introducingLimits: a feature that’s easy to turn on, and will automatically hide comments and DM requests from people who don’t follow you, or who only recently followed you.', 'We developed this feature because creators and public figures sometimes experience sudden spikes of comments and DM requests from people they don’t know. In many cases this is an outpouring of support — like if they go viral after winning an Olympic medal. But sometimes it can also mean an influx of unwanted comments or messages. Now, you can turn onLimitsandavoid it.', 'Our research shows that a lot of negativity towards public figures comes from people who don’t actually follow them, or who have only recently followed them, and who simply pile on in the moment.We saw this after the recent Euro 2020 final, which resulted in a significant and unacceptable spike in racist abuse towards players.Creators also tell us they don’t want to switch off comments and messages completely; they still want to hear from their community and build those relationships.Limitsallows you to hear from your long-standing followers, while limiting contact from people who might only be coming to your account to target you.', 'Limitswill be available to everyone on Instagram globally from today. Go to your privacy settings to turn it on or off, whenever you want. We’re also exploring ways to detect when you may be experiencing a spike in comments and DMs so that we can prompt you to turn onLimits.', '', 'We already show a warningwhen someone tries to post a potentially offensive comment. And if they try to post potentially offensive comments multiple times, we show an even stronger warning — reminding them of our Community Guidelines and warning them that we may remove or hide their comment if they proceed. Now, rather than waiting for the second or third comment, we’ll show this stronger message the first time.', 'To help protect people from abuse in their DM requests, we recentlyannouncedHidden Words, which allows you to automatically filter offensive words, phrases and emojis into a Hidden Folder, that you never have to open if you don’t want to. It also filters DM requests that are likely to be spammy or low-quality. We launched this feature in a handful of countries earlier this year, and it will be available for everyone globally by the end of this month. We’ll continue to encourage accounts with large followings to use it, with messages both in their DM inbox and at the front of their Stories tray.', 'We’ve expanded the list of potentially offensive words, hashtags and emojis that we automatically filter out of comments, and will continue updating it frequently. We recently added a new opt-in option to Hide More Comments that may be potentially harmful, even if they may not break our rules.', 'We hope these new features will better protect people from seeing abusive content, whether it’s racist, sexist, homophobic or any other type of abuse. We know there’s more to do, including improving our systems to find and remove abusive content more quickly, and holding those who post it accountable. We also know that, while we’re committed to doing everything we can to fight hate on our platform, these problems are bigger than us. We will continue to invest in organizations focused on racial justice and equity, and look forward to further partnership with industry, governments and NGOs to educate and help root out hate. This work remains unfinished, and we’ll continue to share updates on our progress.']\n",
            "84 ['Creating an experience on Instagram that’s safe and private for young people, but also fun, comes with competing challenges. We want them to easily make new friends and keep up with their interests, but we don’t want them to deal with unwanted DMs or comments from strangers. We think private accounts are the right choice for young people, but we recognize some young creators might want to have public accounts to build a following.', 'We want to strike the right balance of giving young people all the things they love about Instagram while also keeping them safe. That’s why we’re announcing changeswe’ll maketoday, including:', 'Wherever we can, we want to stop young people from hearing from adults they don’t know or don’t want to hear from. We believe private accounts are the best way to prevent this from happening. So starting this week, everyone who is under 16 years old (or under 18 in certain countries) will be defaulted into a private account when they join Instagram.', 'Private accounts let people control who sees or responds to their content. If you have a private account, people have to follow you to see your posts, Stories and Reels. People also can’t comment on your content in those places, and they won’t see your content at all in places like Explore or hashtags.', 'Historically, we asked young people to choose between a public account or a private account when they signed up for Instagram, but our recent research showed that they appreciate a more private experience. During testing, eight out of ten young people accepted the private default settings during sign-up.', 'For young people who already have a public account on Instagram, we’ll show them a notification highlighting the benefits of a private account and explaining how to change their privacy settings. We’ll still give young people the choice to switch to a public account or keep their current account public if they wish.', '“While most platforms have set their minimum age for participation at 13, there’s no on/off switch that makes someone ready to be a fully media-literate participant on that birthday. Defaulting accounts to private for under-16s encourages young people to develop comfort, confidence and capability as digital citizens during their younger years and help them develop habits to last a lifetime.”', '– David Kleeman, Senior Vice President, Global Trends, Dubit', '', 'We alsopublished an articletoday outlining the steps we’re taking as a company to understand people’s ages across our apps.', '“These new updates represent important progress towards creating a safer, more private experience for young people on Instagram. In particular, using machine learning to understand when it might not be appropriate for an adult to interact with a teen puts teens in the driver’s seat as far as who they interact with, and defaulting teens under 16 into private accounts helps young people keep their content less visible to adults.”', '– Larry Magid, CEO, ConnectSafely', 'Encouraging young people to have private accounts is a big step in the right direction when it comes to stopping unwanted contact from adults. But we’re going even further to make young people’s accounts difficult to find for certain adults.', 'We’ve developed new technology thatwill allowus to find accounts that have shown potentially suspicious behavior and stop those accounts from interacting with young people’s accounts. By “potentially suspicious behavior”, we mean accounts belonging to adults that may have recently been blocked or reported by a young person, for example.', 'Using this technology, now we won’t show young people’s accounts in Explore, Reels or Accounts Suggested For You to these adults. If they find young people’s accounts by searching for their usernames, they won’t be able to follow them. They also won’t be able to see comments from young people on other people’s posts, nor will they be able to leave comments on young people’s posts. We’ll continue to look for additional places where we can apply this technology.', 'We’re rolling out these changes in the US, Australia, France, the UK and Japan to start and will look to expand to more countries soon.', '“It is good to see Instagram utilizing technological solutions to minimize the opportunities for adults who behave suspiciously on the app to discover minors. This is a strong move to build on their work earlier this year to prevent all unconnected adults from being able to message minors. I appreciate the new policy to default new users who say they are under 16 years of age to a private account. We routinely recommend that teens have all of their social media profiles set to private so that they have better control over who can see what they post. Defaulting to private just makes sense as adolescents explore the boundaries of what they want to share with whom.”', '– Justin Patchin, Co-Director, Cyberbullying Research Center', 'We’re also making changes to how advertisers can reach young people with ads. Starting in a few weeks, we’ll only allow advertisers to target ads to people under 18 (or older in certain countries) based on their age, gender and location. This means that previously available targeting options, like those based on interests or on their activity on other apps and websites, will no longer be available to advertisers. These changes will be global and apply to Instagram, Facebook and Messenger.', 'We believe in showing people relevant ads so they can discover and purchase products that are interesting to them. In order to show people the most relevant ads, advertisers choose the types of people they want to see their ads. That could include choosing to show their ads to people with certain interests, like basketball, or based on information that they —or other partners— share with us about their activity on their website and apps. That’s information like whether someone put a certain pair of shoes in their shopping cart or browsed for a new summer grill.', 'We already give people ways to tell us that they would rather not see ads based on their interests or on their activities on other websites and apps, such asthrough controlswithin our ad settings. But we’ve heard from youth advocates that young people may not be well equipped to make these decisions. We agree with them, which is why we’re taking a more precautionary approach in how advertisers can reach young people with ads.', 'When young people turn 18, we’ll notify them about targeting options that advertisers can now use to reach them and the tools we provide to them to control their ad experience. If you’re a business looking for more information, please visit ourHelp Center.', 'We want young people to enjoy using Instagram while making sure we never compromise on their privacy and safety. We’ll continue listening to young people, parents, lawmakers and other experts to build an Instagram that works for young people and is trusted by parents.', '“Instagram’s strategy to proactively weed out potential predators is a welcome innovation; teens have a right to explore their social selves freely without having to worry about predators lurking in the shadows. Whilst teens are generally aware of the risks in sharing personal information, they are often less ‘street savvy’ when it comes to privacy settings. Defaulting young people into private accounts gives them time to adapt and learn to manage their privacy without restricting their freedom of choice in any way.”', '– Janice Richardson, International Advisor at Insight SA, Expert to the Council of Europe']\n",
            "85 ['As per our terms, we require people to be at least 13 years old to sign up for Facebook or Instagram. In some countries, our minimum age is higher. When people open our apps to sign up for an account, we ask them for their birthday. This is called an age screen. Those who are underage are not allowed to sign up, and we restrict people who repeatedly try to enter different birthdays into the age screen. But verifying someone’s age is not as simple as it might sound. While age screens are common in our industry, young people can — and often do — get around them by misrepresenting their age. So how are we addressing this problem?', 'Understanding people’s age on the internet is a complex challenge across our industry, and we already have various methods of finding and removing accounts used by people who misrepresent their age. For example, anyone canreportan underage account to us. Our content reviewers are also trained to flag reported accounts that appear to be used by people who are underage. If these people are unable to prove they meet our minimum age requirements, we delete their accounts.', 'Many argue that collecting ID is the answer to this industry problem, but there are significant limitations to this approach: many young people don’t have an ID, ID collection isn’t a fair or equitable solution, nor is it foolproof. Access to government IDs varies depending on where you live in the world, as does the information contained in an ID such as a birthday. Some have access to IDs but don’t get them unless they choose to travel, and some simply can’t afford one. Indeed, lack of ID access disproportionately impacts underserved communities around the world, particularly young women. Even if they did have an ID, some young people may be uncomfortable sharing it. For example, perhaps they’re a young member of the LGBTQ+ community and they worry about having their identity attached to a pseudonymous account.', 'While these are not new problems to solve, we will continue to invest in finding the right solutions. We need to keep people who are too young off of Facebook and Instagram, and we want to make sure that those whoareold enough receive the appropriate experience for their age. Today, we’re sharing how we’re tackling this issue from multiple angles. Here are a few examples.', 'Artificial intelligence is the cornerstone of the approach we’re taking. We’ve developed technology that allows us to estimate people’s ages, like if someone is below or above 18. We train the technology using multiple signals. We look at things like people wishing you a happy birthday and the age written in those messages, for example, “Happy 21st Bday!” or “Happy Quinceañera.” We also look at the age you shared with us on Facebook and apply it to our other apps where you have linked your accounts and vice versa — so if you share your birthday with us on Facebook, we’ll use the same for your linked account on Instagram.This technology isn’t perfect, and we’re always working to improve it, but that’s why it’s important we use it alongside many other signals to understand people’s ages.', 'This technology is also the basis of important changes we’re making to keep young people safe. We’re using it tostop adults from messaging young peoplethat don’t follow them on Instagram. Andwe announced todaythat we will no longer showing posts from young people’s accounts, or the accounts themselves, to adults that have shown potentially suspicious behavior. We plan to apply this technology across our apps to create more age-appropriate experiences and safety measures for young people. We’re also building similar technology to find and remove accounts belonging to people under the age of 13.', 'We’re focused on using existing data to inform our artificial intelligence technology. Where we do feel we need more information, we’re developing a menu of options for someone to prove their age. This is a work in progress and we’ll have more to share in time.', 'We’re also in discussions with the wider technology industry on how we can work together to share information in privacy-preserving ways that helps apps establish whether people are over a specific age. One area we believe has real promise is working with operating system (OS) providers, internet browsers and other providers so they can share information to help apps establish whether someone is of an appropriate age.', 'This has the dual benefit of helping developers keep underage people off their apps while removing the need to go through differing and potentially cumbersome age verification processes across multiple apps and services. While it’s ultimately up to individual apps and websites to enforce their age policies and comply with their legal obligations, collaboration with OS providers, internet browsers and others would be a helpful addition to those efforts.', 'We’re also looking at ways we can reduce the incentive for people under the age of 13 to lie about their age. The reality is that they’re already online, and with no foolproof way to stop people from misrepresenting their age, we want to build experiences designed specifically for them, managed by parents and guardians. This includes a new Instagram experience for tweens. We believe that encouraging them to use an experience that is age appropriate and managed by parents is the right path. It’s going to take a village to make this experience compelling enough so that this age groupwantsto use it, but we’re determined to get it right.', 'We believe this comprehensive plan is the right one for Facebook and Instagram, but the natural question for readers is how we’re going to do everything in a way that respects people’s privacy, and prioritizes safety at every turn. We’re fortunate to draw from multiple industry experts, organizations and bodies of research here.', 'First, to help us develop new products and features for young people,in 2017we convened a group of experts in the fields of online safety, child development and children’s media to share their expertise, research and guidance. This group, known as the Youth Advisors, helps shape our work by providing feedback on the development of new products and policies for young people. We meet regularly with the group, which includes the Family Online Safety Institute, Digital Wellness Lab, MediaSmarts, Project Rockit and the Cyberbullying Research Center.', 'We recently expanded this group to add new experts in privacy, youth development, psychology, parenting and youth media, and will continue expanding to include a diverse range of global perspectives. Our new members include: Jutta Croll at Stiftung Digitale Chancen, Pattie Gonsalves at Sangath – It’s Okay To Talk, Vicki Shotbolt at ParentZone UK, Dr. Alfiee M. Breland-Noble at AAKOMA Project, Rachel Rodgers at Northeastern University, Janis Whitlock at Cornell University and Amelia Vance at the Future of Privacy Forum.', 'Next, we continue to welcome productive collaboration with lawmakers and elected officials to guide us. Age verification is a focal point of multiple new and proposed regulatory frameworks on data protection, online harm and child safety. In particular, the ICO Age Appropriate Design Code, the UN Convention on the Rights of the Child, the Irish DPC’s Children’s Fundamentals and the EU Audiovisual Media Services Directive, among others, underpin the work we’re doing to create privacy and safety standards for building youth products at Facebook. We plan to share these standards publicly in the coming months.', 'Finally, we’ll continue to take part in dialogues about age verification, developing industry best practices and forming new technical standards. For example, we recently joined the Advisory Board for the euCONSENT Consortium to help develop EU-wide infrastructure for online age verification and parental consent.', 'This is complex territory, with competing interests and considerations. We’re committed to working with experts and the broader industry to give young people a compelling and safe experience on our services.']\n",
            "86 ['Today we’re launching Sensitive Content Control on Instagram, which allows you to decide how much sensitive content shows up in Explore. We believe people should be able to shape Instagram into the experience that they want. We’ve started to move in this direction with tools like the ability to turn off comments orRestrictsomeone from interacting with you on Instagram.', 'OurCommunity Guidelinesoutline what kind of content can be on Instagram, and the point of these guidelines isto keep people safe. We don’t allow hate speech, bullying or other content that might present a risk of harm to people. We also have rules about what kind of content we show you in places like Explore; we call these ourRecommendation Guidelines. These guidelines were designed to help ensure that we don’t show you sensitive content from accounts you don’t follow. You can think of sensitive content as posts that don’t necessarily break our rules, but could potentially be upsetting to some people — such as posts that may be sexually suggestive or violent.', 'This new feature gives you control over sensitive content. You can decide to leave things as they are or you can adjust the Sensitive Content Control to see more or less of some types of sensitive content. We recognize that everybody has different preferences for what they want to see in Explore, and this control will give people more choice over what they see.', '', 'To view your Sensitive Content Control, go to your profile, tap the Settings menu in the upper right corner, tap Account, then tap Sensitive Content Control. Here, you can decide whether to keep the setting at its default state, Limit, or to see more, Allow, or less of some types of sensitive content, Limit Even More. You can change your selection at any time. One exception to this: the Allow option will not be available to people under 18.', 'Our hope is that this gives you more choice, another way to make Instagram work better for you.', 'For more information about Instagram’s new Sensitive Content Control, you can visit theHelp Center.']\n",
            "87 ['When we launched the Oversight Board, wecommittedto consider and transparently respond to all of the board’s recommendations.', 'Today, we’re publishing our first quarterly update, covering Q1 2021, which provides 1) information about cases that Facebook has referred to the board and 2) an update on our progress implementing the board’s recommendations. These quarterly updates are designed to provide regular check-ins on the progress of this long-term work, while sharing more about how we approach these challenges. They are meant to hold us accountable to the board and the public.', 'In addition to providing users with direct access to appeal content decisions to the board, we regularly and proactively identify some of the most significant and difficult content decisions we’ve made on our platform and ask the board to review them. While the board notes when cases have been referred by Facebook, we haven’t previously disclosed details about the cases we referred to the board that werenotselected.', 'We refer cases involving issues that are severe, large-scale, and/or important for public discourse. Additionally, we look for content decisions that raise questions about current policies or their enforcement, with strong arguments on both sides for either removing or leaving up the content under review. We discussed how we prioritize content decisions for referral to the board in ourNewsroom.', 'Facebook teams with expertise on our content policies, our enforcement processes, and cultural context from regions around the world review the candidate cases and provide feedback on their significance and difficulty. We refer the most significant and difficult content decisions to the board, and the board has sole discretion to accept or decline those cases. As with appeals, the board’s decisions are binding. From November 2020 through March 31, 2021, we referred 26 content decisions to the board, and the board selected three: a case aboutsupposed COVID-19 cures; a case abouta veiled threat based on religious beliefs; and a case aboutthe decision to indefinitely suspend former US President Donald Trump’s account.', 'In the first quarter of 2021, the board issued 18 recommendations in six cases. We are implementing fully or in part 14 recommendations, still assessing the feasibility of implementing three, and taking no action on one.The size and scope of the board’s recommendations go beyond the policy guidance that we first anticipated when we set up the board, and several require multi-month or multi-year investments. The board’s recommendations touch on how we enforce our policies, how we inform users of actions we’ve taken and what they can do about it, and additional transparency reporting.We welcome these recommendations — the changes they have sparked make Facebook more transparent with users and the public, more consistent with our policy applications, and more proportional in our enforcement.', 'For example, last quarter, in response to the board’s recommendations, we launched and continue to test new user experiences that are more specific about why we remove content. We’ve made progress on the specificity of our hate speech notifications by using an additional classifier that is able to predict whatkindof hate speech is in the content: violence, dehumanization, mocking hate crimes, visual comparison, inferiority, contempt, cursing, exclusion, and/or slurs. People using Facebook in English now receive more specific messaging when they violate our hate speech policy. We’ll roll out more specific notifications for hate speech violations to other languages in the future. And, as a result of the board’s recommendations, we’re running tests to assess the impact of telling people about whether automation was involved in enforcement. Additionally, we’ve updated our Dangerous Organizations and Individual policy, creating three tiers of content enforcement for different designations of severity and adding definitions of key terms.', 'We hope our responses also add to the dialogue around the challenges of content moderation at scale by providing more insight into tradeoffs. Where we disagree in part or whole with a board recommendation — or where implementation will take a long time — we explain why.', 'The board’s impact comes not only from its binding decisions and recommendations on our policies and processes, but also from the public discourse surrounding the cases. We welcome the board’s feedback and review — along with feedback from the public — of our implementation of the recommendations, as well as how we can continue to improve.', 'See thefull updatefor more information.']\n",
            "88 ['The UN Women’s Generation Equality Forum is happening this week in Paris, which brings together governments, companies, youth and civil society to move the needle forward on gender equality. At Facebook, we have always believed that women should have equal access to all of the economic opportunities, education and social connection that the internet provides.', 'It’s why I joined Facebook as Head of Women’s Safety after over two decades working for nonprofits dedicated to keeping women safe — and today I’m excited to announce the launch of ourWomen’s Safety Huband the formation of ourGlobal Women’s Safety Expert Advisors, a group of 12 nonprofit leaders, activists and academic experts to help us develop new policies, products and programs that better support the women who use our apps.', 'These experts are distinguished in their fields and have contributed a tremendous amount to furthering the safety of women, on and offline. We’ve worked with them in the past, and are excited to put in place regular quarterly meetings dedicated specifically to advancing the safety of women online. Over time, we’ll include new experts from additional countries so we continue to hear from diverse voices.', 'With the help of our experts, we’ve developed our Women’s Safety Hub to centralize all the safety resources women need when navigating our platform. It includes specific resources for women leaders, journalists and survivors of abuse. Developed in consultation with nonprofit partners around the world and soon to be available in 55 languages, the hub containsvideo on demand safety trainingsand aplace to registerfor live safety training sessions that will be hosted in multiple languages.', '', 'Empowering our users through education is just one part of our work to keep women safer online. We’ve developed strongpoliciesto protect users from online abuse and usetools,such as proactive detection technology to help catch content that may violate our policies. For example, on Instagram we’ve announced a new feature called ‘Hidden Words’ that lets peoplefilter out potentially offensive messagesand on Facebook we’ve given you morecontrolover what you see. We havesophisticated technologyto combat the sharing of non-consensual intimate images, and we have developed a variety ofresourcesto help ensure all women feel safe using our platform. Thanks to user feedback and the experts we consult, we are constantly assessing the effectiveness of our tools and seeking out new options to empower women online.', 'We look forward to people using our Women’s Safety Hub and working with our Global Women’s Safety Expert Advisors in the months and years to come to help women feel safe on Facebook.', 'Facebook’s inaugural Global Women’s Safety Expert Advisors include:', 'Australia:Asher Flynnis Associate Professor of Criminology at Monash University and Vice President of the Australian and New Zealand Society of Criminology. Her work focuses on image-based abuse and technology-facilitated violence.', 'Brazil:Enrica Duncanis Project Director and Deputy Director of Nossas, a women-led laboratory for civic engagement and activism in Latin America that develops technology to equip citizens to impact policy making.', 'Global:Kalliopi Mingeirouis the Chief of the Ending Violence against Women and Girls Section at UN Women. Previously she workedfor UN agencies, as well as international NGOs in the areas of human rights, women’s rights and refugee protection in different countries.', 'Hong Kong:Lisa Mooreoversees Women’s Foundation’s research on gender issues and leads advocacy efforts that aim to transform existing attitudes that prevent women and girls from fully participating in society.', 'Indonesia:Tunggal Pawestriis an independent expert on gender equality, sexual rights and diversity issues and works to ensure more women are represented in public debates and leadership.', 'Ireland:Caitriona Gleesonspent two decades working to end gender-based violence and now leadsWomen for Election, a nonpartisan nonprofit which encourages and supports women in Ireland to run for politics.', 'Mexico:Margarita Guillé Tamayois a social activist, founder and executive coordinator of the Interamerican Network of Women Shelters. She is an international advisor on gender-based violence for governments and nonprofits/NGOs.', 'Morocco:Stephanie Willman Bordatis human rights lawyer, NGO activist and founding partner at MRA Mobilising for Rights Associates where she works throughout the Maghreb (Morocco, Algeria, Tunisia and Libya) to promote women’s human and legal rights.', 'Philippines:Mariane Dorothy Rosariois a Global Advocacy Champion for the World Association of Girl Guides and Girl Scouts (WAGGGS) and a Girls Get Equal advocate for Plan International. She advocates to end online abuse and harassment and violence against women and girls.', 'South Korea:Ji-Yeon Leeis Associate Professor, Counseling Psychology, Hankuk University of Foreign Studies. She specializes in cyber-sexual violence and counseling psychology.', 'Uganda:Neema Iyer,isthe founder and director of Pollicy, a civic technology organization. She works at the intersection of data, design and technology. Through feminist research, she tackles subjects such as digital inclusion and digital rights.', 'United States:Erica Olsenleads the TechSafety.org project at the National Network to End Domestic Violence and is an international expert on the intersection of technology and gender-based violence.']\n",
            "89 ['Today, we’re announcing several new tools to empower community builders based on feedback from group admins.', 'There are more than 70 million admins and moderators running active Facebook groups around the world, and what they do every day is at the heart of Facebook’s mission ofbuilding community and bringing the world closer together.', 'In fact, four years ago this month, we held our first Facebook Communities Summit in Chicago, where we announced this updated company mission with hundreds of group admins, and shared new features to nurture their communities on Facebook.', 'We’ve continued to support them in the years since and here are the new tools we’re rolling out.', 'Admin Homeis a simpler, more intuitive destination for all admin tools, settings and features that admins can tailor to their needs. With the new experience, admins can:', '', 'Keeping Facebook groups safe is a priority and admins play a key role in helping maintain a safe and healthy culture within their communities. We’re introducingcomment moderation to Admin Assist, allowing admins to set up criteria to automatically moderate both posts and comments. Now available across desktop and mobile, admins have the ability to:', 'We’re also testing a new type of Moderation Alert calledConflict Alerts. This uses AI to detect and\\xa0 notify admins when there may be contentious or unhealthy conversations in their group, so they can take action as needed.', 'In situations where it may be helpful toslow down a conversation, admins can temporarily limit how often specific group members can comment, and control how often comments can be made on certain posts that admins select.', 'This slideshow requires JavaScript.', 'It’s important for admins to be able to set, shape and reinforce a community’s culture. Understanding who their members are and setting clear rules and norms for the community to follow is at the center of that.', 'We’re introducing a newmember summaryfeature so that admins can see a consolidated summary of each group member’s activity in the group, such as the number of times they have posted and commented, or when they’ve had posts removed or been muted in the group.', 'Admins can nowappealviolations for content they or other admins posted, or that they approved from members, as well as content from members. These appeals will be reviewed by Facebook to make sure the right decision was made.', 'To help make it easier to share and enforce rules in Groups, admins and moderators can nowtag group rulesin comments and posts. Members can also tag specific group rules when they report posts and comments to admins, helping make community moderation simpler.', 'Over the last few months, we’ve also made several updates to our admin tools based on specific feedback we’ve heard from our admin community. This includes features likepinned comments,admin announcement notifications,and a range of other features you can read about in ourCommunity Blog.', 'This slideshow requires JavaScript.', '', 'Join us on Wednesday, June 16 at 10am PT for our FB Live, Community Connect: Announcing New Tools To Manage and Nurture Your Groups.']\n",
            "90 ['Today the Oversight Boardannouncedthat it has accepted its first policy advisory opinion referral from Facebook. You can read more about it in ourTransparency Center.', 'We can ask the board to provide us recommendations about how we can improve our policies, especially those that aresignificant and difficult, by requesting a policy advisory opinion. In this instance, we asked the board for recommendations about the right level of privacy for residential information. In this instance,\\xa0we asked the board for recommendations aboutour policy on Privacy Violations and Image Privacy Rights.', 'While not binding, the board’s guidance on our policies is a critical input into our policy development process. This process includes our Policy Forum where we convene subject experts from around the world to discuss potential changes to our Community Standards, ads policies, and major News Feed ranking changes. We publicly shareminutes for these meetingsto provide public insight into these discussions and iterations.', 'Once the board publishes its policy advisory opinion, as stipulated in thebylaws, we will take 30 days to review and publicly respond. The policy advisory opinion process differs from our normal case process because we are asking for the board’s input about a policy instead of a specific piece of content.', 'Through policy advisory opinions, the board will shape the development and enforcement of the policies that apply to more than 3 billion people across our apps. We thank the board for their continued thoughtful consideration of some of the most significant and difficult questions regarding our policies.']\n",
            "91 ['Last month, theOversight Board upheld Facebook’s suspensionof former US President Donald Trump’s Facebook and Instagram accounts following his praise for people engaged in violence at the Capitol on January 6. But in doing so, the board criticized the open-ended nature of the suspension, stating that “it was not appropriate for Facebook to impose the indeterminate and standardless penalty of indefinite suspension.” The board instructed us to review the decision and respond in a way that is clear and proportionate, and made a number of recommendations on how to improve our policies and processes.', 'We are today announcing new enforcement protocols to be applied in exceptional cases such as this, and we are confirming the time-bound penalty consistent with those protocols which we are applying to Mr. Trump’s accounts. Given the gravity of the circumstances that led to Mr. Trump’s suspension, we believe his actions constituted a severe violation of our rules which merit the highest penalty available under the new enforcement protocols. We are suspending his accounts for two years, effective from the date of the initial suspension on January 7 this year.', '', 'At the end of this period, we will look to experts to assess whether the risk to public safety has receded. We will evaluate external factors, including instances of violence, restrictions on peaceful assembly and other markers of civil unrest. If we determine that there is still a serious risk to public safety, we will extend the restriction for a set period of time and continue to re-evaluate until that risk has receded.', 'When the suspension is eventually lifted, there will be a strict set of rapidly escalating sanctions that will be triggered if Mr. Trump commits further violations in future, up to and including permanent removal of his pages and accounts.', 'In establishing the two year sanction for severe violations, we considered the need for it to be long enough to allow a safe period of time after the acts of incitement, to be significant enough to be a deterrent to Mr. Trump and others from committing such severe violations in future, and to be proportionate to the gravity of the violation itself.', 'We are grateful that the Oversight Board acknowledged that our original decision to suspend Mr. Trump was right and necessary, in the exceptional circumstances at the time. But we absolutely accept that we did not have enforcement protocols in place adequate to respond to such unusual events. Now that we have them, we hope and expect they will only be applicable in the rarest circumstances.', 'We know that any penalty we apply — or choose not to apply — will be controversial. There are many people who believe it was not appropriate for a private company like Facebook to suspend an outgoing President from its platform, and many others who believe Mr. Trump should have immediately been banned for life. We know today’s decision will be criticized by many people on opposing sides of the political divide — but our job is to make a decision in as proportionate, fair and transparent a way as possible, in keeping with the instruction given to us by the Oversight Board.', 'Of course, this penalty only applies to our services — Mr. Trump is and will remain free to express himself publicly via other means. Our approach reflects the way we try to balance the values of free expression and safety on our services, for all users, as enshrined in our Community Standards. Other social media companies have taken different approaches — either banning Mr. Trump from their services permanently or confirming that he will be free to resume use of their services when conditions allow.', 'The Oversight Board’s decision is accountability in action. It is a significant check on Facebook’s power, and an authoritative way of publicly holding the company to account for its decisions. It was established as an independent body to make binding judgments on some of the most difficult content decisions Facebook makes, and to offer recommendations on how we can improve our policies. As today’s announcements demonstrate, we take its recommendations seriously and they can have a significant impact on the composition and enforcement of Facebook’s policies.', 'Its response to this case confirms our view that Facebook shouldn’t be making so many decisions about content by ourselves. In the absence of frameworks agreed upon by democratically accountable lawmakers, the board’s model of independent and thoughtful deliberation is a strong one that ensures important decisions are made in as transparent and judicious a manner as possible. The Oversight Board is not a replacement for regulation, and we continue to call for thoughtful regulation in this space.', 'We are also committing to being more transparent about the decisions we make and how they impact our users. As well as our updated enforcement protocols, we are also publishing ourstrike system, so that people know what actions our systems will take if they violate our policies. And earlier this year, we launched a feature called ‘account status’, so people can see when content was removed, why, and what the penalty was.', 'In response to a recommendation by the Oversight Board, we are also providing more information in our Transparency Center about ournewsworthiness allowanceand how we apply it. We allow certain content that is newsworthy or important to the public interest to remain on our platform — even if it might otherwise violate our Community Standards. We may also limit other enforcement consequences, such as demotions, when it is in the public interest to do so. When making these determinations, however, we will remove content if the risk of harm outweighs the public interest.', 'We grant our newsworthiness allowance to a small number of posts on our platform. Moving forward, we will begin publishing the rare instances when we apply it. Finally, when we assess content for newsworthiness, we will not treat content posted by politicians any differently from content posted by anyone else. Instead, we will simply apply our newsworthiness balancing test in the same way to all content, measuring whether the public interest value of the content outweighs the potential risk of harm by leaving it up.', 'Along with these changes, we have also taken substantial steps to respond to the other policy recommendations the board included in their decision. Out of the board’s 19 recommendations, we are committed to fully implementing 15. We are implementing one recommendation in part, still assessing two recommendations, and taking no further action on one recommendation. Ourfull responses are available here.']\n",
            "92 ['Today we are pleased to announce the launch ofThe Resiliency Initiative website, a partnership between Facebook andThe Asia Foundationto combat hate and intolerance online.', 'The Resiliency Initiativeaims to promote tolerance, strengthen interfaith and inter-ethnic understanding, and counter violent extremism in Asia Pacific.', 'This community-centered initiative began withonline workshopsfor 60 organisations from Bangladesh, India, Indonesia, Malaysia, the Maldives, Myanmar, Nepal, Sri Lanka, Thailand, Pakistan and the Philippines. The website is the next step in strengthening the community of practice.', 'The Resiliency Initiative website provides civil society organizations with a suite of tools and resources to help them harness social media to build stronger communities — particularly in areas affected by violent conflict. It includes guidance ongetting started on social media,creating effective online content,managing their presence on social media,measuring impact, andcombating misinformation, as well ascase studieswith insights from communities across the region. The website is currently available in English and is launching in Bengali, Thai and Urdu in the coming weeks, with more languages to follow in the future.', 'In the second half of this year, The Resiliency Initiative will work with civil society organisations in Asia Pacific to build out their social resilience campaigns to combat hate online, and expand the reach of the program into new communities in the region. We’re also partnering with experts on a digital storytelling training program.', 'The Asia Foundation is a nonprofit international development organization committed to improving lives in Asia. Violence and conflict present enormous challenges for society and can significantly hinder growth and development in the region.The Foundation brings together diverse partners from governments and local communities — informed by realities on the ground — which is why The Resiliency Initiative is so important.', 'At Facebook, we aim to identify and remove harmful content from our platforms as quickly as possible — and we’vemade good progress in this area. But this is just one part of the solution. It’s equally important to enable constructive dialogue and encouragecounter speechin order to promote social cohesion and counter offline harm. We are pleased to have launched The Resiliency Initiative in partnership with The Asia Foundation as one of our flagship programs to address hate and violent extremism.']\n",
            "93 ['Today, we’re launching new ways to inform people if they’re interacting with content that’s been rated by a fact-checker as well as taking stronger action against people who repeatedly share misinformation on Facebook. Whether it’s false or misleading content about COVID-19 and vaccines, climate change, elections or other topics, we’re making sure fewer people see misinformation on our apps.', 'We want to give people more information before they like a Page that has repeatedly shared content that fact-checkers have rated, so you’ll see a pop up if you go to like one of these Pages. You can also click to learn more, including that fact-checkers said some posts shared by this Page include false information and a link to more information about our fact-checking program. This will help people make an informed decision about whether they want to follow the Page.', '', 'Since launching our fact-checking program in late 2016, our focus has been on reducing viral misinformation. We’ve taken stronger action against Pages, Groups, Instagram accounts and domains sharing misinformation and now, we’re expanding some of these efforts to include penalties for individual Facebook accounts too. Starting today, we will reduce the distribution of all posts in News Feed from an individual’s Facebook account if they repeatedly share content that has been rated by one of our fact-checking partners. We already reduce a single post’s reach in News Feed if it has been debunked.', 'We currently notify people when they share content that a fact-checker later rates, and now we’ve redesigned these notifications to make it easier to understand when this happens. The notification includes the fact-checker’s article debunking the claim as well as a prompt to share the article with their followers. It also includes a notice that people who repeatedly share false information may have their posts moved lower in News Feed so other people are less likely to see them.', '']\n",
            "94 ['Update on August 11, 2021 at 8:45AM PT:', 'Today, we announced new features to help protect people from abuse on Instagram. These include:', 'You can read more about these updateshere.', 'Update on July 22, 2021 at 6:10AM PT:', 'Racism, abuse and harassment have no place on our apps. Recently Black footballers at the UEFA European Championship faced racist abuse and harassment on Instagram. It’s our responsibility to protect athletes — and everyone — from abuse on our apps, which means moving faster to remove violating content and equipping them with tools to keep them safe.(Updated on July 23, 2021 at 6:25AM PT to clarify our approach to removing violating content.)', 'So, ahead of the Olympic Games we’re sharing some updates on how we’re working to improve. These efforts build on the products and policy updates we outlined in our initial post below. They address both racism that athletes may face, and also other forms of hate, including sexism, homophobia and more. We’ll continue to evolve our approach and will share more updates soon.', 'A big part of how we prevent people from seeing abuse is identifying offensive content using technology. Since context is often crucial to spotting abusive language, we’re constantly training and improving our technology to catch more of this sooner. Two updates:', '', 'We’ve been rolling out new Instagram notifications at the top of athletes’ feeds to help them set up safety features like Hidden Words. We’ll continue to show this notification to Olympians and Paralympians throughout the summer.', '', 'Originally published on May 26, 2021 at 3:00AM PT:', 'Athletes will take center stage this summer during the UEFA European Championship, and the Olympic and Paralympic Games. Millions of people across the world will use our platforms to celebrate the athletes, countries and moments that make these events so iconic.', 'However, platforms like Facebook and Instagram mirror society. Everything that is good, bad and ugly in our world will find expression on our apps. So while we expect to see tons of positive engagement, we also know there might be those who misuse our platforms to abuse, harass and attack athletes competing this summer.', 'We don’t want this behavior on Facebook and Instagram, which is why we’ve recently introduced new measures to protect athletes. Here’s how we’re helping them keep their focus on goals and glory, not hateful DMs and comments.', 'Hate speech is not allowed on our apps. Specifically,we don’t tolerate attacks on peoplebased on their protected characteristics, including race or religion, as well as more implicit forms of hate speech. When we become aware of hate speech, we remove it. We’re investing heavily in people and technology to find and remove this content faster. We have tripled — to more than 35,000 — the people working on safety and security at Facebook and we’re a pioneer in artificial intelligence technology to remove hateful content at scale.Between January and Marchof this year, we took action on 25.2 million pieces of hate speech on Facebook, including in DMs, 96% of which we found before anyone reported it. And on Instagram, during the same time, we took action on 6.3 million pieces of hate speech content, 93% of it before anyone reported it.', 'We’ve also introduced stricter penalties for people who send abusive DMs on Instagram. When someone sends DMs that break our rules, we prohibit that person from sending any more messages for a set period of time. If someone continues to send violating messages, we’ll disable their account. We’ll also disable new accounts created to get around our messaging restrictions, and will continue to disable accounts we find that are created purely to send abusive messages.', 'We have also introduced tools to help athletes protect themselves from abuse. These include:', 'We’re launching a dedicated Instagram account for athletes competing in Tokyo this summer. This private account will not only share Facebook and Instagram best practices, but also serve as a channel for athletes to send questions and flag issues to our team.', 'Because DMs are private conversations, we don’t proactively look for content like hate speech or bullying the same way we do elsewhere on Instagram. That’s why last year we rolled out reachability controls, which allow people to limit who can send them a DM — such as only people who follow them.', 'For those who still want to interact with fans, but don’t want to see abuse, we’ve announced a new feature called “Hidden Words.”When turned on, this tool will automatically filter DM requests containing offensive words, phrases and emojis, so athletes never have to see them. We’ve worked with leading anti-discrimination and anti-bullying organizations to develop a predefined list of offensive terms that will be filtered from DM requests when the feature is turned on. We know different words can be hurtful to different people, so athletes will also have the option to create their own custom list of words, phrases or emojis that they don’t want to see in their DM requests. All DM requests that contain these offensive words, phrases, or emojis — whether from a custom list or the predefined list — will be automatically filtered into a separate hidden requests folder.', 'Instagram and Facebook “Comment Controls” let athletes control who can comment on their posts. Athletes also have options in their privacy settings to automatically hide offensive comments on Facebook and Instagram. With that on, we use technology to proactively filter out words and phrases that are commonly reported for harassment. Athletes can also add their own list of words, phrases or emojis, so they never have to see them in comments again.', 'Athletes can block people on both Instagram or Facebook from seeing their posts or sending them messages.We’re also making it harder for someone already blocked on Instagram to contact them again through a new account. With this feature, whenever athletes decide to block someone on Instagram, they’ll have the option to both block their account and preemptively block new accounts that person may create.', 'We’ll remind athletes competing in these events this summer of these tools via an Instagram notification that will be sent to the top of their Feeds. This notification will make it easier for athletes to learn how to adopt and use a number of our safety features, liketwo-factor authentication and comment and messaging controls.', 'We’re committed to doing everything we can to fight hate and discrimination on our platforms, but we also know these problems are bigger than us. We look forward to working with other companies, sports organizations, NGOs, governments and educators to help keep athletes safe.']\n",
            "95 ['Today we launched a newTransparency Centerto provide a hub for all our integrity and transparency work. In addition to information on how we enforce our Community Standards, the Transparency Center will also become a central destination for all updates on how Facebook is responding to decisions, recommendations and most case updates from the Oversight Board. We’ll continue to use our Newsroom for significant moments related to the Oversight Board, including cases with a great deal of public interest and future expansions of the board’s scope.', 'Since the board started work last fall, they have selected 13 cases and issued over 40 recommendations. Facebook has responded to all of the board’s recommendations within 30 days and has committed to take action on a majority of those recommendations. With the launch of the Transparency Center, you’ll now be able to track a case from its selection through to our response to a decision’s accompanying recommendations, and be able to follow updates to those recommendations.', 'Facebook created and empowered the Oversight Board to exercise independent judgment over some of the most difficult and significant content decisions — and beyond the individual impact of case decisions, the board’s recommendations have already begun to play a central role in shaping how we approach content policies on our platform. We hope the Transparency Center will prove a helpful resource for those following our responses to the board’s decisions and recommendations, as the board continues to push us to improve our processes and policies.']\n",
            "96 ['In addition to our Community Standards Enforcement Report, this quarter we’re also sharing:', 'Today we’re publishing ourCommunity Standards Enforcement Reportfor the first quarter of 2021. This report provides metrics on how we enforced our policies from January through March, including metrics across 12 policies on Facebook and 10 on Instagram.', 'The newTransparency Centeris a single destination for our integrity and transparency efforts. It includes information on:', 'We’ll continue to add more information and build out the Transparency Center as our integrity efforts continue to evolve.', '', 'Last year we committed to undergoing anindependent auditto validate that our metrics are measured and reported correctly. We have selected EY to conduct this assessment, and we look forward to working with them.', 'Prevalence is one of the most useful metrics for understanding how often people see harmful content on our platform, so in this report, we’re expanding prevalence metrics on Instagram to include the prevalence of adult nudity and violent and graphic content.', 'In Q1 of 2021, the prevalence of adult nudity on both Facebook and Instagram was 0.03-0.04%. Violent and graphic content prevalence was 0.01-0.02% on Instagram. On Facebook, it was 0.03-0.04%, down from .05% last quarter. We’re working to share more data and match the metrics we share across both Facebook and Instagram. That’s why we’re releasing these prevalence numbers for the first time, and we’ll continue to share them each quarter to track our progress.', '', 'Prevalence of hate speech on Facebook continues to decrease. In Q1, it was 0.05-0.06%, or 5 to 6 views per 10,000 views.', '', 'We evaluate the effectiveness of our enforcement by trying to keep the prevalence of hate speech on our platform as low as possible, while minimizing mistakes in the content that we remove.This improvement in prevalence on Facebook is due tochanges we made to reduce problematic content in News Feed.', 'Advancements in AI technologieshaveallowed us toremove more hate speechfrom Facebook over time, and find more of it before users report it to us. When we first began reporting our metrics on hate speech in Q4 of 2017, our proactive detection rate was 23.6%. This means that of the hate speech we removed, 23.6% of it was found before a user reported it to us. The remaining majority of it was removed after a user reported it. Today we proactively detect about 97% of hate speech content we remove.', 'In addition to new metrics and ongoing improvements in prevalence, we saw steady numbers on the content we took action on across many problem areas.', 'On Facebook in Q1 we took action on:', 'On Instagram in Q1 we took action on:', 'COVID-19 continues to be a major public health issue, and we are committed to helping people get authoritative information, including vaccine information.From the start of the pandemic to April 2021, we removed more than 18 million pieces of content from Facebook and Instagram globally for violating our policies on COVID-19-related misinformation and harm. We’re also working to increase vaccine acceptance andcombat vaccine misinformation.']\n",
            "97 ['Note: For future Facebook updates about Oversight Board cases, please visit theTransparency Center.', 'Today, theOversight Board upheld Facebook’s suspensionof former US President Donald Trump’s Facebook and Instagram accounts. As we stated in January,we believe our decision was necessary and right, and we’re pleased the board has recognized that the unprecedented circumstances justified the exceptional measure we took.', 'However, while the board has not required Facebook to immediately restore Mr. Trump’s accounts, it has not specified the appropriate duration of the penalty. Instead, the board criticized the open-ended nature of the suspension, calling it an “indeterminate and standardless penalty,” and insisted we review our response. We will now consider the board’s decision and determine an action that is clear and proportionate. In the meantime, Mr. Trump’s accounts remain suspended.', 'The board also made a number of recommendations on how we should improve our policies. While these recommendations are not binding, we actively sought the board’s views on our policies around political figures and will carefully review its recommendations.', 'We thank the board for the care and attention it gave this case.']\n",
            "98 ['Over the past year, the use of private messaging apps like Messenger has surged. The global pandemic made staying connected with loved ones through private messaging, calling and video chats even more important. But the growth of private messaging predated the pandemic, which has brought important public policy considerations to the forefront.', 'In March Stan Chudnovsky,Head of Messenger, sharedthree trendsto expect in private messaging for 2021. We also hosted a virtual workshop with experts in privacy, safety, human rights and consumer protection for a discussion on the future of messaging. This was part of a new series of ‘Data Dialogues’ intended to bring together experts and practitioners from consumer advocacy organizations, academia, businesses, civil society and other companies to discuss challenging questions around how the industry approaches and protects people’s data. Below are some of the ways that we tackle these issues in relation to Messenger as well as the outcomes from our discussions.', 'Two years ago, Mark Zuckerberg announced aprivacy-focused visionfor social networking centered on messaging. It will be built on the principles of private interactions, encryption, reducing permanence, safety, interoperability, and secure data storage. Since then, we’ve built a team that’s focused on delivering this vision on Messenger. Our priorities are driven by talking with people about how they want to use Messenger and incorporating that feedback into usable private messaging features. We believe that listening to people is core to delivering a trusted and shared environment.', 'People tell us that they want reliable messaging with easy to find controls. For example, they say they want to know that their messages, whether text or voice, will be delivered wherever they are, especially in locations where connectivity isn’t reliable. They also want their communications to be protected and confidential. We’ve also heard people ask for more control over things like who can contact them, options to unsend a message or how long their messages stick around. In particular, we heard from the generation that’s grown up on the Internet that they’re cautious about their privacy and that they want ways to avoid others having a permanent record of their conversations. Based on this feedback, weintroduced vanish mode, a feature you can enable in Messenger and Instagram Direct that allows you to send messages that automatically disappear after both people see them.', 'People are also concerned about the security of their personal information online and the privacy of their messages. Seven out of 10 Americans said in 2019 that their personal information was less secure than five years earlier (source). And, over the last four years, more consumers around the world have usedmessaging apps that offer more privacy features (source).Over the past year, we introduced a number ofprivacy and safety tools, including more privacy settings, an app lock, safer message requests, message forwarding limits and more. We’re also working hard to bring default end-to-end encryption to all of our messaging services. This will protect people’s private messages and mean only the sender and recipient, not even us, can access their messages. While we expect to make more progress on default end-to-end encryption for Messenger and Instagram Direct this year, it’s a long-term project and we won’t be fully end-to-end encrypted until sometime in 2022 at the earliest. Moreover, the safety features we’ve already introduced are designed to work with end-to-end encryption, and we plan to continue building strong safety features into our services.', 'As we address these issues, we want to make sure they are guided by input from outside experts. Here are some of the key takeaways and points of feedback from our workshop:', 'The motivation behind all of this work is to build a trusted and secure private messaging service. Our journey in messaging will evolve as new challenges emerge. In addition to receiving feedback from consumers, we’ll continue to engage with this group from our workshop and other experts on these issues as we work collectively to find solutions.']\n",
            "99 ['In the year-plus that’s passed since the World Health Organization (WHO) first declared COVID-19 a global public health emergency, Facebook has supported the public health community by connecting people toaccurate information about COVID-19,removing harmful content,providing health researchers with data and toolsandhelping people get vaccinated.', 'Sometimes in emergency situations, “privacy” is framed as an all-or-nothing tradeoff, where people are forced to make the impossible choice between their privacy or public health interests. We believe that privacy and public health are complementary and there’s a way to do both well.', 'Today, we are publishing awhite paperon how we’re protecting privacy in our COVID-19 initiatives. This paper covers our decisions regarding data and how we sought to address the urgent needs of public health authorities and researchers while maintaining our commitment to privacy and other fundamental rights.', 'The paper also explores our work and lessons in the following areas:', 'We hope the white paper we’re releasing today will spark conversation about the best ways for companies like Facebook to contribute to public health initiatives like fighting COVID-19 while keeping data safe and secure.', 'In the coming months, we’ll host a series of broader discussions with global stakeholders to better understand how to improve our decision-making process, now and in the future, for similar projects in the public interest and should emergencies arise again.']\n",
            "100 ['Note: For future Facebook updates about Oversight Board cases, please visit theTransparency Center.', 'Update on April 23, 2021 at 2:30PM PT:', 'Facebook re-reviewed this content and determined we removed it in error, and we reinstated it. An existing policy was not properly applied to this content, and it does not violate our policy on Dangerous Individuals and Organizations. Debate over the conditions of confinement of anyone, including individuals associated with terrorist organizations, is often a legitimate topic for discussion. As with other cases where we’ve made an enforcement error, the board is still able to hear and issue a binding decision on the content along with any other recommendations.', 'Originally published on April 20, 2021 at 6:00AM PT:', 'Today, theOversight Board selected a caseappealed by an Instagram user regarding a post that featured a picture of Abdullah Ӧcalan, a founding member of the Kurdistan Workers’ Party (PKK). The post also included text urging readers to engage in conversation about Ӧcalan’s imprisonment.', 'We removed the post for violating Instagram’s Community Guidelines on Dangerous Individuals and Organizations, which state that Instagram is not a place to support or praise terrorism, organized crime, or hate groups. The PKK has been designated a terrorist organization by multiple countries, including the US and European Union. Instagram’s Community Guidelines also prohibit any praise, support or representation of founders or prominent members of terrorist organizations, such as Ӧcalan.', 'We will implement the board’s decision once it has finished deliberating, and we will update this post accordingly. Please see theboard’s websitefor the decision when they issue it.']\n",
            "101 ['As the trial of Derek Chauvin draws to a close, we are doing what we can to prepare for the verdict. This means preventing online content from being linked to offline harm and doing our part to keep our community safe.', 'Our teams are working around the clock to look for potential threats both on and off of Facebook and Instagram so we can protect peaceful protests and limit content that could lead to civil unrest or violence. This includes identifying and removing calls to bring arms to areas in Minneapolis, which we have temporarily deemed to be a high-risk location. We will continue to monitor events on the ground to determine if additional locations will be deemed as temporary, high-risk locations. We are also working to protect the memory of George Floyd and members of the Floyd family from harassment and abuse. Under our policies, we will remove content that praises, celebrates or mocks George Floyd’s death.', 'We know this trial has been painful for many people. We want to strike the right balance between allowing people to speak about the trial and what the verdict means, while still doing our part to protect everyone’s safety. We will allow people to discuss, critique and criticize the trial and the attorneys involved.', 'We will remove content that violates our Community Standards, including our policies against hate speech, bullying and harassment, graphic violence, and violence and incitement. As we have done in emergency situations in the past, we may also limit the spread of content that our systems predict is likely to violate our Community Standards in the areas of hate speech, graphic violence, and violence and incitement. We will remove Pages, groups, Events and Instagram accounts that violate our violence and incitement policy and we will remove events organized in temporary, high-risk locations that contain calls to bring arms.', 'Our policies against bullying and harassment distinguish between public figures and private individuals. This is because we want to allow discussion, which often includes critical commentary of people who are featured in the news or who have a large public audience. We consider Derek Chauvin a public figure, for voluntarily placing himself in the public eye, which means we will remove attacks that are severe, in line with our policies. For involuntary public figures and private individuals, our protections go further. We consider George Floyd an involuntary public figure which is why we apply a higher level of protection to content about his death.', 'As with all high-profile events, we are taking extra steps to limit misinformation. This includes using several tools to ensure that potential misinformation is flagged to our network of third-party fact-checking partners. For content that is graphic or may be difficult for some people to see, we will mark them as disturbing or sensitive.', 'And given the risk of violence following the announcement of the verdict, regardless of what it is, we remain in close contact with local, state and federal law enforcement. We will respond to valid legal requests and support any investigations that are in line with our policies.', 'We know this trial has been difficult for many people. But we also realize that being able to discuss what is happening and what it means with friends and loved ones is important. As the trial comes to a close, we will continue doing our part to help people safely connect and share what they are experiencing.']\n",
            "102 ['Note: For future Facebook updates about Oversight Board cases, please visit theTransparency Center.', 'Starting today, people who use Facebook and Instagram now have the ability to appeal other people’s content that has been left up to theOversight Board.Since October 2020, if content was removed from Facebook or Instagram and a user disagreed with Facebook’s re-reviewed decision to keep it down, that content was eligible for final appeal to theOversight Board. Today’s announcement represents an expansion of the board’s initial scope. As originally contemplated by theOversight Board’s bylaws,the board can now review Facebook’s decision to leave content on the platform — content eligible for appeal to the board still includes posts/statuses, photos, videos, comments, and shares.', '', 'As with all Facebook products, we will be rolling out the ability to appeal content left up to the Oversight Board to people across the world in waves to ensure stability of the product experience for users. We expect everyone on Facebook and Instagram to be able to appeal content left up over the coming weeks.', 'We will continue to work to expand the board’s scope over time and we will provide further updates as we do so.', 'If someone does not think that a piece of content should be on Facebook or Instagram, they first need to report the content to Facebook. OurHelp Center explains how to do this for various types of content.', 'If Facebook decides to keep the content up even after review, the reporting person will receive an Oversight Board Reference ID in theirSupport Inboxand from there canappeal Facebook’s decision to the Oversight Board.', '', 'While review of left-up content is an important piece of the oversight puzzle, there were a number of challenging technical and operational considerations we had to consider in the initial instance.', 'Foremost, we had to guarantee that everything would be done effectively and in a privacy-conscious manner. We had to consider, for example: how best to capture content at the time of appeal, in case the original poster edits the content later before review by the board? How should we group appeals by multiple users on a single piece of content even if there are different reasons identified to remove the content by those reporting it? Should we stop appeals of the same content to the board if the case is rejected, or allow additional appeals to reach the board? If the board selects a case, when should we stop allowing people to appeal that content — once selected, once a decision is being drafted, or after it is issued? How do we enable the board to sort through a larger volume of cases in an efficient way?', 'Content is often reported by multiple people, many of whom also want to appeal to the Oversight Board. We’ve structured the appeal process to accommodate these scenarios. In order to guarantee each reporting user’s voice is heard, multiple people will be able to report the same piece of content — and will be able to do so citing different reasons.', 'This means that, regardless of whether or not someone else has reported a piece of content, people may still appeal to the board and make the case for why this content should be removed.', 'In order for the Oversight Board to manage this, multiple reports will be compiled into a single case file for the board. This case file will exist for each piece of content that has been appealed to the board. Even if the board decides not to hear a case on a particular piece of content, other users may still appeal that same content, so their own voice can be heard on the matter.', 'Furthermore, if the board does take up a case, other users will be able to submit statements to the board, up until the board begins deliberations.', 'To protect the privacy of those appealing to the board, the board will only include details that could easily identify a reporter in the board’s written explanation if the reporter has given permission to do so. To learn more about the steps that are taken to remove details that can easily identify reporters and others, refer to thedata policy.', 'Finally, we want to make sure all relevant parties are informed on the latest status of a given piece of content.', 'Once the board decides to take a case regarding content that is left up, we will inform all users who have reported the case to the board by updating the case status in theOversight Board website portal.', 'We will also inform the original poster: when their content has been submitted to the board; if the board has decided to hear the case (at which point they will have the option to submit a statement to the board to provide further context around their content); and once the board has reached a decision.', 'The Oversight Board has already made a number of decisions and recommendations that have not onlydecided whether content stays down or is reinstated on Facebookbut is already having a broader and significantimpact on our content and enforcement policies and practices. We will continue to work to bring additional types of content into the board’s scope and will provide updates in the future.', 'We’re glad the Oversight Board is expanding their scope and impact, and look forward to their future decisions and recommendations.']\n",
            "103 ['Originally published inMorning Consult.', 'This week, the House Energy and Commerce Committee will examine how technology platforms like Facebook are tackling misinformation online. It is tempting to think about misinformation as a single challenge that can be solved with a single solution. But unfortunately, that’s not the case. Thinking of it that way also misses the opportunity to address it comprehensively. Tackling misinformation actually requires addressing several challenges including fake accounts, deceptive behavior, and misleading and harmful content. As the person responsible for the integrity of our products, I wanted to provide an update on how we approach each of them.', 'Let’s start with fake accounts. We take a hard line against this activity and block millions of fake accounts each day, most of them at the time of creation. Between October and December of 2020, we disabled more than 1.3 billion of them. We also investigate and take down covert foreign and domestic influence operations that rely on fake accounts. Over the past three years, we’ve removed over 100 networks ofcoordinated inauthentic behavior(CIB) from our platform and keep the public informed about our efforts through our monthly CIB reports.', 'We also crack down on deceptive behavior. We’ve found that one of the best ways to fight this behavior is by disrupting the economic incentives structure behind it. We’ve built teams and systems to detect and enforce against inauthentic behavior tactics behind a lot of clickbait. We also use artificial intelligence to help us detect fraud and enforce our policies against inauthentic spam accounts.', 'Misinformation can also be posted by people, even in good faith. To address this challenge, we’ve built a global network of more than 80 independent fact-checkers, who review content in more than 60 languages. When they rate something as false, we reduce its distribution so fewer people see it and add a warning label with more information for anyone who sees it. We know that when a warning screen is placed on a post, 95% of the time people don’t click to view it. We also notify the person who posted it and we reduce the distribution of Pages, Groups, and domains who repeatedly share misinformation. For the most serious kinds of misinformation, such as false claims about COVID-19 and vaccines and content that is intended to suppress voting, we will remove the content.', 'Over the past several years, we have invested in protecting our community and we now have over 35,000 people working on these challenges. We’re making progress thanks to these significant investments in both people and in technology such asArtificial Intelligence. Since the pandemic began,we’ve used our AI systems to take down COVID-19-related material that global health experts have flagged as misinformation and then detect copies when someone tries to share them. As a result, we’ve removed more than 12 million pieces of content about COVID-19 and vaccines.', 'But it’s not enough to just limit misinformation that people might see. We also connect people to reliable information from trusted experts. We do this through centralized hubs like ourCOVID-19 Information Center,Climate Science Information CenterorUS 2020 Voting Information Center, labels that we attach to certain posts with reliable information from experts, and notifications that we run in people’s feeds on both Facebook and Instagram.', 'Despite all of these efforts, there are some who believe that we have a financial interest in turning a blind eye to misinformation. The opposite is true. We have every motivation to keep misinformation off of our apps and we’ve taken many steps to do so at the expense of user growth and engagement.', 'For example, in 2018 wechanged our News Feed ranking systemto connect people to meaningful posts from their friends and family. We made this change knowing that it would reduce some of the most engaging forms of content, like short form video, and lead to people spending less time on Facebook — which is exactly what happened. The amount of time people spent on Facebookdecreased by roughly 5%in the quarter where we made this change.', 'As with every integrity challenge, our enforcement will never be perfect even though we are improving it all the time. While nobody can eliminate misinformation from the internet entirely, we continue using research, teams, and technologies to tackle it in the most comprehensive and effective way possible.']\n",
            "104 ['Since 2017, people on Facebook have been able to use physical security keys to log into their accounts on desktop to better protect their information from malicious hackers. Starting today, you can set up two-factor authentication and log into Facebook on iOS and Android mobile devices using a security key — available to anyone in the world.', 'Two-factor authentication is a security feature that helps safeguard your account every time you log into your Facebook account from an unknown device by requiring something youknow(your password) and something youhave(typically, an SMS code sent to your mobile phone or Authenticator app). It’s much harder for a bad actor to obtain both factors, which keep your password from being your last line of defense against phishing or other malicious attempts to compromise your information.', 'Physical security keys — which can be small enough to fit on your keychain — notify you each time someone tries accessing your Facebook account from a browser or mobile device we don’t recognize. We ask you to confirm it’s you with your key, which attackers don’t have.', '', 'Since 2017, we’ve encouraged people that are at high risk of being targeted by malicious hackers: politicians, public figures, journalists and human rights defenders. We strongly recommend that everyone considers using physical security keys to increase the security of their accounts, no matter what device they use.', 'You can purchase security keys directly from companies that make them (Facebook doesn’t manufacture hardware keys). The keys can either work through Bluetooth technology or by plugging it directly into your phone.', 'You can enroll your security key in two-factor authentication within theSecurity and Loginsection of your Settings.', '', 'For more information on how to enroll in two-factor authentication with a security key, please see ourHelp Center.']\n",
            "105 ['Update on October 20, 2021 at 9:00AM PT:', 'Today, we’re announcing new measures to keep Facebook Groups safe.', 'To continue limiting the reach of people who break our rules, we’ll start demoting all Groups content from members who have broken our Community Standards, anywhere on Facebook. These demotions will get more severe as they accrue more violations.', 'This measure will help reduce the ability of members who break our rules from reaching others in their communities, and builds on the existing restrictions placed upon members who violate Community Standards. These current penalties include restricting their ability to post, comment, add new members to a group or create new groups.', 'We also want to make sure that our enforcement is transparent and fair. That’s why we’re announcing Flagged by Facebook. This feature shows admins content that has been flagged for removal before it is shown to the broader community.', '', 'Admins can then either review and remove the content themselves, or ask for a review by Facebook and provide additional feedback on why they think that piece of content should remain on the platform. Flagged by Facebook involves admins in content review earlier in the process, before members receive a strike and content is removed.', 'Flagged by Facebook is in addition to the existing ability foradmins to appealwhen something is taken down for violating our Community Standards. This provides more fairness for communities and helps ensure that the right call is being made when it comes to enforcing our policies.', 'Originally published on March 17, 2021 at 8:00AM PT:', 'It’s important to us that people can discover and engage safely with Facebook groups so that they can connect with others around shared interests and life experiences. That’s why we’vetaken actionto curb the spread of harmful content, like hate speech and misinformation, and made it harder for certain groups to operate or be discovered, whether they’re Public or Private. When a group repeatedly breaks our rules, we take it down entirely.', 'Today we’re sharing the latest in ourongoing work to keep Groups safe, which includes our thinking on how to keep recommendations safe as well as reducing privileges for those who break our rules. These changes will roll out globally over the coming months.', 'We know we have a greater responsibility when we are amplifying or recommending content. As we work to make sure that potentially harmful groups aren’t recommended to people, we try to be careful not to penalize high-quality groups on similar topics. The tension we navigate isn’t between our business interests and removing low-quality groups — it’s about taking action on potentially harmful groups while still ensuring that community leaders can grow their groups that follow the rules and bring people value. We try to balance this carefully in our recommendations guidelines, which can be foundhere.', 'As behaviors evolve on our platform, though, we recognize we need to do more. This is why we recently removed civic and political groups, as well as newly created groups, from recommendations in the US.', 'While people can still invite friends to these groups or search for them, we have now started to expand these restrictions globally. This builds on restrictions we’ve made to recommendations, like removing health groups from these surfaces, as well as groups that repeatedly share misinformation.', 'We are also adding more nuance to our enforcement. When a group starts to violate our rules, we will now start showing them lower in recommendations, which means it’s less likely that people will discover them. This is similar to our approach in News Feed, where we show lower quality posts further down, so fewer people see them.', 'We believe that groups and members that violate our rules should have reduced privileges and reach, with restrictions getting more severe as they accrue more violations, until we remove them completely. And when necessary in cases ofsevere harm, we will outright remove groups and people without these steps in between.', 'We’ll start to let people know when they’re about to join a group that has Community Standards violations, so they can make a more informed decision before joining. We’ll limit invite notifications for these groups, so people are less likely to join. For existing members, we’ll reduce the distribution of that group’s content so that it’s shown lower in News Feed. We think these measures as a whole, along with demoting groups in recommendations, will make it harder to discover and engage with groups that break our rules.', '', 'We will also start requiring admins and moderators to temporarily approve all posts when that group has a substantial number of members who have violated our policies or were part of other groups that were removed for breaking our rules. This means that content won’t be shown to the wider group until an admin or moderator reviews and approves it. If an admin or moderator repeatedly approves content that breaks our rules, we’ll take the entire group down.', 'When someone has repeated violations in groups, we will block them from being able to post or comment for a period of time inanygroup. They also won’t be able to invite others to any groups, and won’t be able to create new groups. These measures are intended to help slow down the reach of those looking to use our platform for harmful purposes and build onexisting restrictionswe’ve put in place over the last year.', 'There is always more to do to keep Facebook Groups safe, and we will continue to build and invest to make sure people can rely on these places for connection and support.']\n",
            "106 ['More and more, human rights are exercised — and violated — online. Billions of people enjoy freedom of expression, access to information and the right to education in the digital space. But they can also experience hate speech, bullying and harassment and have their privacy violated in that same space. At Facebook, we’re committed to respecting human rights in our business operations, product development, policies and programming. To further that commitment, today we’re launching acorporate human rights policy, covering all of Facebook Inc, and a fund to support human rights defenders.', 'This new policy sets out the human rights standards we will strive to respect as defined in international law including theUnited Nations Guiding Principles on Business and Human Rights(UNGPs). And it sets out how we will apply these standards to our apps and products, policies, programming, and overall approach to our business. We will report our most critical human rights issues, like risks to freedom of expression, to our Board of Directors. And we will release a public report annually on how we’re addressing human rights concerns stemming from our products, policies or business practices — something very few other companies do. This yearly report will build on our existing practice ofdisclosinghuman rights impact assessments and detailed responses to recommendations.', 'We’ve worked over the years to support human rights defenders who use our platform. Now we’re creating a fund that will give offline assistance to human rights defenders facing critical threats and support new digital security efforts, beginning in Asia later this year. We’ll also build on our existing work to protect defenders’ accounts — efforts that includecombating malicious actorswho are targeting them, protecting them from incorrect content removals usingCross Check, offering advancedsecurity options, taking steps to thwart unauthorized access to the accounts of defenders who are arrested or detained, and partnering with human rights organizations on outreach and training.', 'We’re launching this policy to build on our commitments as part of theGlobal Network Initiative, and our recent human rights work. That work includes:', 'Our goal is for Facebook, as a business and a platform, to be a place forequality, safety, dignity and free speech — the core principles of human rights — and to build systems that respect human rights and guidance of the UNGPs. The struggle for human rights online will continue to face new challenges as authoritarian governments are increasingly seeking to exert control over the internet and use it as a means of repression. No one company will be perfect, but we will do all we can to live up to the commitments we are making today. And we know that we will be judged based on our actions, not our words.']\n",
            "107 ['Protecting young people on Instagram is important to us. Today, we’re sharing updates on new features and resources as part of our ongoing efforts to keep our youngest community members safe. We’re also providing an update on our work to understand age in a way that helps keep people — especially young people — safe. We have dedicated teams focused on youth safety, and we work closely with experts to inform the features we develop.', 'We want parents to have the information to help their teens have a safe and positive experience on Instagram. In the US, we’ve collaborated with The Child Mind Institute and ConnectSafely to publish a new Parents Guide. It includes the latest safety tools and privacy settings and a list of tips and conversation starters to help parents navigate discussions with their teens about their online presence. This updated Guide has launched with expert partners in other countries includingArgentina,Brazil,India,Indonesia,Japan,MexicoandSingaporeand will be rolled out in more countries soon. This also complements ourexisting Parents’ Guideswhich provide support for parents in theUK,France,Italy,GermanyandSpain, which were developed in partnership with local safety experts.', '“Instagram can provide young people the opportunity to strengthen connections, practice social skills and find supportive communities. It’s important that teens and parents are equipped with information on how to manage their time on the platform so that it’s thoughtful, safe and intentional. The new Parents Guide we’ve worked on does a great job of distilling what parents should know about how to support their teens as they navigate social media.”', '– Dr. Dave Anderson, Clinical Psychologist, Child Mind Institute', 'We require everyone to be at least 13 to use Instagram and we ask new users to provide their age when they sign up for an account. While many people are honest about their age, we know that young people can lie about their date of birth. We want to do more to stop this from happening, but verifying people’s age online is complex and something many in our industry are grappling with. To address this challenge — we’re developing new artificial intelligence and machine learning technology to help us keep teens safer as well as apply new age-appropriate features, like those described below.', 'To protect teens from unwanted contact from adults, we’re introducing a new feature that prevents adults from sending messages to people under 18 who don’t follow them. For example, when an adult tries to message a teen who doesn’t follow them, they receive a notification that DM’ing them isn’t an option. This feature relies on our work to predict peoples’ ages using machine learning technology, and the age people give us when they sign up. As we move to end-to-end encryption, we’re investing in features that protect privacy and keep people safe without accessing the content of DMs.', '“Around the world, it’s widely understood that most social media platforms require a 13-year minimum age requirement, but the complexity of age verification remains a long-standing, industry-wide challenge. That’s why it’s positive to see Instagram investing in innovative technologies that can and will create a safer online environment for younger users. By using machine learning to flag potentially inappropriate interactions, improving teen privacy features, and DM-ing younger users with real-time safety info, Instagram is equipping young people with tools to be the architects of their own online experience.”', '– Lucy Thomas, Co-Founder / Co-CEO, PROJECT ROCKIT', '', 'In addition to preventing conversations between adults and teens who don’t follow one another, we’ll start using prompts — or safety notices — to encourage teens to be cautious in conversations with adults they’re already connected to. Safety notices in DMs will notify young people when an adult who has been exhibiting potentially suspicious behavior is interacting with them in DMs. For example, if an adult is sending a large amount of friend or message requests to people under 18, we’ll use this tool to alert the recipients within their DMs and give them an option to end the conversation, or block, report, or restrict the adult.People will start seeing these in some countries this month, and we hope to have them available everywhere soon.', '“There are cases where it is appropriate for \\u200badults and teens to interact on Instagram but it’s important that teens be protected against unwanted contact from adults. Requiring that \\u200bthe teen – not the adult – establish the connection empowers teens to protect themselves. It puts them in the driver’s seat and gives them more control over their experiences on Instagram.”', '– Larry Magid, CEO, ConnectSafely.org', '', 'In the coming weeks, we’ll start exploring ways to make it more difficult for adults who have been exhibiting potentially suspicious behavior to interact with teens. This may include things like restricting these adults from seeing teen accounts in ‘Suggested Users’, preventing them from discovering teen content in Reels or Explore, and automatically hiding their comments on public posts by teens.', 'Having a private account offers more protections for teens as they can better control who can see and interact with their content. We’ve recently added a new step when someone under 18 signs up for an Instagram account that gives them the option to choose between a public or private account. We aim is to encourage young people to opt for a private account by equipping them with information on what the different settings mean.', 'We know young people, like aspiring creators or athletes, find value in public accounts. So teens can still opt for a public account if they choose to do so after learning more about the options. If a person doesn’t choose ‘private’ when signing up, we send them a notification later on highlighting the benefits of a private account and reminding them to check their settings. This is just a first step. We’re assessing additional measures we can take to protect young people on Instagram, including additional privacy settings. We’ll have more to share in the coming months.', '“The introduction of Instagram’s teenage privacy settings is a welcome change to the platform. We know that some young people make the conscious choice to have public profiles, and this new update allows young people to enter a more controlled environment and requires there to be a conscious decision before entering a more public environment, which in itself provides an important educational moment to help prepare for this step. This change is for new users, and we need to work to address this question of user awareness of privacy choices on existing accounts.”', '– Will Gardner, CEO, Childnet International', '', 'We believe that everyone should have a safe and supportive experience on Instagram. These updates are a part of our ongoing efforts to protect young people — and our specialist teams continue to invest in new interventions that further limit inappropriate interactions between adults and teens.']\n",
            "108 ['Every day, the free flow of data across borders keeps billions of people connected, allows millions of small businesses to trade internationally, and enables countless people to work in lockdown together. This free flow of data supports many of the services that are fundamental to our daily lives. It also underpins the global economy. It means a small tech start-up in Germany can use a US-based cloud provider. A Spanish product development company can run an operation across multiple time zones. A French retailer can maintain a call centre in Morocco. Millions of people can keep in touch with friends and family who live in different countries using video conferencing software. It also supports critical public services such as health and education.', 'Our global services are built to connect you to the people, places and things you enjoy, regardless of where in the world they may be. The content you see on our services is not static like a normal webpage, but is always being updated. For example, when you load Facebook on your phone, your News Feed might show you recent posts from friends in New York and Dublin, enable you to read the comments on the page of a small business from Italy, or participate in a discussion in a group with people from around the world. This content is a dynamic selection of information that changes over time without regard to international boundaries. All of this requires a constant global flow of information to make the connections that make your experience using Facebook unique and personalized.', 'Because this information is interconnected, we couldn’t simply split it up into regional silos. Our services are designed to be global and are supported by a cutting-edge global infrastructure that’s taken us over a decade to build. Seamless global data transfers are therefore a necessary ingredient for our services to work.', 'Cross-border data transfers between the European Union and the United States have been the subject of recent litigation and regulatory action, includinga ruling in July last yearby the Court of Justice of the European Union (CJEU). The CJEU invalidated the EU-US Privacy Shield, a legal mechanism for transatlantic data transfers, in light of concerns over whether US surveillance laws provided EU users with the protections required by EU law. Like many other businesses — large and small — Facebook relies onStandard Contractual Clauses(SCCs) to transfer data to countries outside the EU, including to the United States. Since the ruling, Facebook has been working to follow the steps set out by the CJEU to ensure that we can continue to transfer data safely and securely in accordance with GDPR.', 'We want to explain in more detail the commitments we make to our EU users to keep their information safe and secure when it is transferred to the US, and the policies we have in place to evaluate and respond to government requests. We’re also providing answers toFrequently Asked Questionswhere you can learn more.', 'To keep your data safe when it is transferred from the EU/EEA to the US we rely onSCCs, a tool approved by the European Commission which provides several important legal safeguards and whose validity was confirmed by the CJEU.', 'We also use a number of supplementary measures to protect your data. These include:', 'You can also learn more aboutstandard contractual clauses. For more information on the safeguards and measures we have in place to protect your data when it is transferred to the US, please seeour FAQs.', 'FISA is the authority governing US government requests related to US National Security. In responding to FISA requests, Facebook follows the same process as for all government requests for user information — we comply only where we have a good-faith belief that the law requires us to do so. In addition, we scrutinize every government request we receive to make sure it is legally valid, no matter which government makes the request. When we do comply, we produce only information that is narrowly tailored to respond to that request. If we determine that a government request is not consistent with applicable law or our policies, we push back and engage governments to address any apparent deficiencies. If the request is unlawful we will challenge or reject the request.', 'Bypublishing guidelines for government requests, we encourage governmental entities to submit only requests that are necessary, proportionate, specific and strictly compliant with applicable laws.', 'In addition, we engage with governments to encourage practices that protect peoples’ rights. We belong to advocacy groups like theGlobal Network Initiative, whose mission is to advance the freedom of expression and privacy rights of Internet users worldwide, andReform Government Surveillance, which advocates for government data requests to be rule-bound, narrowly tailored, transparent, subject to strong oversight and protective of end-to-end encryption.', 'For more information about how we respond to government requests including those under US intelligence laws like FISA, please see ourFAQs.']\n",
            "109 ['Note: For future Facebook updates about Oversight Board cases, please visit theTransparency Center.', 'Today, theOversight Board selected a caseappealed by a Facebook user regarding a comment with a meme depicting Turkey having to choose between “The Armenian Genocide is a lie” and “The Armenians were terrorists who deserved it.”', 'Facebook took down this content for violating ourpolicy on hate speech, as laid out in our Community Standards. We do not allow hate speech on Facebook, even in the context of satire, because it creates an environment of intimidation and exclusion, and in some cases, may promote real-world violence.', 'We will implement the board’s decision once it has finished deliberating, and we will update this post accordingly. Please see theboard’s websitefor the decision when they issue it.']\n",
            "110 ['Note: For future Facebook updates about Oversight Board cases, please visit theTransparency Center.', 'Today, theOversight Board selected a caseappealed by a Facebook user regarding a comment they made on a post containing pictures, a video and text about the January 2021 protests in support of Alexei Navalny held in Saint Petersburg, Russia. The commenter called another user a “common and cowardly bot” (as translated from Russian) over comments the other user had made against the ongoing protests.', 'Facebook took down this content for violating ourpolicy on bullying and harassment, as laid out in our Community Standards. For private individuals we “remove content that’s meant to degrade or shame” and in some instances we require self-reporting, as was done in this case, so we can better understand if the individual is feeling bullied or harassed.', 'We will implement the board’s decision once it has finished deliberating, and we will update this post accordingly. Please see theboard’s websitefor the decision when they issue it.']\n",
            "111 ['Note: For future Facebook updates about Oversight Board cases, please visit theTransparency Center.', 'In January, the Oversight Board publisheddecisions on their first set of cases, which weimmediately implemented. The board also published recommendations covering 17 areas where Facebook could improve its content moderation.', 'In addition to the Oversight Board’s binding rulings on content, we are committed to consider its recommendations and communicate transparently about actions taken. Today, we are committing to action to address 11 of the board’s recent recommendations. In several of these instances, we have already acted on the board’s recommendations, while in others, we are committing to what was recommended by the board, or going further. We also are assessing the feasibility of five more of the recommendations and will provide updates in the future.', 'There is one remaining recommendation that wedisagreewith and will not be taking action on since it relates to softening our enforcement of COVID-19 misinformation. In consultation with global health authorities, we continue to believe our approach of removing COVID-19 misinformation that might lead to imminent harm is the correct one during a global pandemic.', '', 'For each recommendation, we have provideddetailed responsesand will continue to update as we make progress on our commitments. Some of the actions we are taking include:', 'We’ve also started theprocess of reinstatingidentical content with parallel contextin the following cases:Uyghur Muslims,Hydroxychloroquine, Azithromycin and COVID-19, and aNazi Quote. These actions will affect not only content previously posted on Facebook and Instagram but also future content.', 'For cases where the board upholds our final judgment, we will continue to ensure identical content with parallel context remains either up or down in line with the board’s decision.', 'When we created the Oversight Board, we hoped its impact would come not just from its decisions on individual cases, but also from broader recommendations on how we can improve our policies and practices. This is the start of that process.', 'The board deals with some of the trickiest content moderation issues Facebook faces, where there are often no easy decisions. We want this process to be as open and transparent as possible, which is why we are responding to every one of their recommendations in detailhere.', 'A summary of our response to the recommendations made in theBreast Cancer Symptoms and Nuditycase is below. Please see the overall detailed responsehereor the case Newsroom post for additional details.', '', 'A summary of our response to the recommendations made in theHydroxychloroquine, Azithromycin and COVID-19case is below. Please see the overall detailed responsehereor the case Newsroom post for additional details.', '', 'A summary of our response to the recommendations made in theArmenians in Azerbaijancase is below. Please see the overall detailed responsehereor the case Newsroom post for additional details.', '', 'A summary of our response to the recommendations made in theNazi Quotecase is below. Please see the overall detailed responsehereor the case Newsroom post for additional details.', '']\n",
            "112 ['Using our apps to harm children is abhorrent and unacceptable. Our industry-leading efforts to combat child exploitation focus on preventing abuse, detecting and reporting content that violates our policies, and working with experts and authorities to keep children safe.', 'Today, we’re announcing new tools we’re testing to keep people from sharing content that victimizes children and recent improvements we’ve made to our detection and reporting tools.', 'To understand how and why people share child exploitative content on Facebook and Instagram, we conducted an in-depth analysis of the illegal child exploitative content we reported to the National Center for Missing and Exploited Children (NCMEC) in October and November of 2020. We found that more than 90% of this content was the same as or visually similar to previously reported content. And copies of just six videos were responsible for more than half of the child exploitative content we reported in that time period. While this data indicates that the number of pieces of content does not equal the number of victims, and that the same content, potentially slightly altered, is being shared repeatedly, one victim of this horrible crime is one too many.', 'The fact that only a few pieces of content were responsible for many reports suggests that a greater understanding of intent could help us prevent this revictimization. We worked with leading experts on child exploitation, including NCMEC, to develop aresearch-backed taxonomyto categorize a person’s apparent intent in sharing this content. Based on this taxonomy, we evaluated 150 accounts that we reported to NCMEC for uploading child exploitative content in July and August of 2020 and January 2021, and we estimate that more than 75% of these people did not exhibit malicious intent (i.e. did not intend to harm a child). Instead, they appeared to share for other reasons, such as outrage or in poor humor (i.e. a child’s genitals being bitten by an animal). While this study represents our best understanding, these findings should not be considered a precise measure of the child safety ecosystem. Our work to understand intent is ongoing.', 'Based on our findings, we are developing targeted solutions, including new tools and policies to reduce the sharing of this type of content. We’ve started by testing two new tools — one aimed at the potentially malicious searching for this content and another aimed at the non-malicious sharing of this content. The first is a pop-up that is shown to people who search for terms on our apps associated with child exploitation. The pop-up offers ways to get help from offender diversion organizations and shares information about the consequences of viewing illegal content.', '', 'The second is a safety alert that informs people who have shared viral, meme child exploitative content about the harm it can cause and warns that it is against our policies and there are legal consequences for sharing this material. We share this safety alert in addition to removing the content, banking it and reporting it to NCMEC. Accounts that promote this content will be removed. We are using insights from this safety alert to help us identify behavioral signals of those who might be at risk of sharing this material, so we can also educate them on why it is harmful and encourage them not to share it on any surface — public or private.', '', 'For years, we’ve used technology to find child exploitative content and detect possible inappropriate interactions with children or child grooming.Butwe’ve expanded our work to detect and remove networks that violate our child exploitation policies, similar to our efforts against coordinated inauthentic behavior and dangerous organizations.', 'In addition, we’ve updated ourchild safety policiesto clarify that we will remove Facebook profiles, Pages, groups and Instagram accounts that are dedicated to sharing otherwise innocent images of children with captions, hashtags or comments containing inappropriate signs of affection or commentary about the children depicted in the image. We’ve always removed content that explicitly sexualizes children, but content that isn’t explicit and doesn’t depict child nudity is harder to define. Under this new policy, while the images alone may not break our rules, the accompanying text can help us better determine whether the content is sexualizing children and if the associated profile, Page, group or account should be removed.', 'After consultations with child safety experts and organizations,we’ve made it easier to report content for violating our child exploitation policies. To do this, we added the option to choose “involves a child” under the “Nudity & Sexual Activity” category of reporting in more places on Facebook and Instagram. These reports will be prioritized for review.We also started usingGoogle’s Content Safety APIto help us better prioritize content that may contain child exploitation for our content reviewers to assess.', '', 'To learn more about our ongoing efforts to protect children in both public and private spaces on our apps, visitfacebook.com/safety/onlinechildprotection.']\n",
            "113 ['Today, we’re introducing new ways to support people on Instagram who may be affected by negative body image or an eating disorder, including surfacing more expert-backed resources when people search for eating disorder-related content, expanding our work with experts to help inform our policies, and collaborating with community leaders to help them create and share positive, inspiring body image content.', 'While we don’t allow content that promotes or encourages self-harm and eating disorders, we do allow people toshare their own experiences and journeysaround self-image and body acceptance. We know that these stories can prompt important conversations and provide community support, but can also be triggering for some. To address this, when someone tries to search for or share self-harm related content, we currently blur potentially triggering images and point people to helpful resources. However, we’ve heard from experts that we would support people more if we made available dedicated resources to cope with eating disorders or body dissatisfaction, which is why we are introducing new resources specific to body image issues.', 'These new resources will include contacts for local eating disorders hotlines in certain countries, such asBeatin the UK,National Eating Disorder Information Centrein Canada andButterfly Foundationin Australia, as well as new advice on how to build body confidence that we built in partnership with the National Eating Disorders Association (NEDA) in the US. As experts tell us that intervening early can be helpful, if someone tries searching for terms related to disordered eating, we’ll share these resources first before showing the search results. These resources will also be surfaced if someone tries sharing this content, or if a friend is concerned about something they see posted and wants to offer support. In the coming weeks, we’ll also make it easier to connect with friends in the moment by adding the ability to message on Instagram directly from the resources.', '', 'We don’t want anyone on Instagram to feel marginalized, particularly people with eating disorders or body image issues. While we already work in partnership with experts to understand how to support those affected by eating disorders, there’s always more we can learn. That’s why we’re hosting feedback sessions with community leaders and experts globally to learn more about emerging issues in the eating disorders space, and new approaches for offering support.', 'We’re also working with NEDA to share programming during National Eating Disorders Awareness Week in the US for the third year in a row. Throughout the week, community leaders like@mikzazon,@jamesissmilingand@kendramorouswill be sharing Reels to encourage positive body image, push back against weight stigma and harmful stereotypes, and show that all bodies are worthy and deserve to be celebrated.', 'To learn more about supporting a friend who may be struggling, you can view resourceshere.']\n",
            "114 ['Update on December 7, 2021 at 11:00PM PT:', 'We are expanding our ban of the Myanmar military (“Tatmadaw”) and will now also remove Pages, Groups and accounts representing military-controlled businesses. This builds on our existing ban on these entities advertising on Facebook, which was announced in February, and the various enforcement actions we’ve taken since then which are outlined below.', 'We’re taking this latest action based on extensive documentation by the international community of these businesses’ direct role in funding the Tatmadaw’s ongoing violence and human rights abuses in Myanmar. This has formed the basis for escalating sanctions imposed by the US, EU, and other governments, and has been chronicled in painstaking reporting by civil society and human rights organizations. The Myanmar military has far-reaching commercial interests which are not always possible to definitively determine. So we are using the UN Fact-Finding Mission on Myanmar’s 2019 report on the economic interests of the Tatmadaw, as the basis to guide these efforts, in line with the UN Guiding Principles on Business and Human Rights.', 'Our team continues to monitor the situation on the ground in Myanmar and we will continue to take any action necessary to keep our community safe.', 'Update on April 14, 2021 at 4:00PM PT:', 'We are implementing a specific policy for Myanmar to remove praise, support and advocacy of violence by Myanmar security forces and protestors from our platform.', 'This falls under our existingcoordinating harm and publicizing crime policyand includes:', 'For example, we’ll remove:', 'We continue to closely monitor the situation in Myanmar and take the necessary steps to keep our platform safe.', 'Update on March 31, 2021 at 6:00PM PT:', 'Today, we launched a new safety feature in Myanmar that allows you to lock your profile. We are constantly looking for additional ways to keep people safe and we’re committed to providing a secure platform for people to express themselves.', 'Given the evolving situation on the ground in Myanmar and the conversations we’ve had in recent weeks about security concerns, including with activists, journalists and civil society groups, we understood that there was a need for additional safety features.', 'This new feature allows you to lock your profile and is designed for people who want more control over their Facebook experience. It enables you to apply multiple existing privacy settings plus several new features to your Facebook profile in one easy step. When you lock your profile, non-friends cannot:', 'An indicator is added to your profile page to remind you your profile is locked. To turn on this feature, from your profile:', 'Update on February 24, 2021 at 8:00PM PT:', 'Today, we are banning the remaining Myanmar military (“Tatmadaw”) and military-controlled state and media entities from Facebook and Instagram, as well as ads from military-linked commercial entities.', 'We’re continuing to treat the situation in Myanmar as an emergency and we remain focused on the safety of our community, and the people of Myanmar more broadly.', 'Events since the February 1 coup, including deadly violence, have precipitated a need for this ban. We believe the risks of allowing the Tatmadaw on Facebook and Instagram are too great.', 'We’re also prohibiting Tatmadaw-linked commercial entities from advertising on the platform. We are using the UN Fact-Finding Mission on Myanmar’s 2019 report, on the economic interests of the Tatmadaw, as the basis to guide these efforts, along with the UN Guiding Principles on Business and Human Rights. These bans will remain in effect indefinitely.', 'We’ve held the Tatmadaw to the same Community Standards as all of our users around the world and have removed content from military Pages and accounts that violated these policies. But we’ve reached this decision to ban them based on four guiding factors:', 'This action builds on the steps we have taken in recent years to prevent the Tatmadaw from abusing our platform. Among these are: banning 20 military-linked individuals and organisations in 2018, including Commander-in-Chief Min Aung Hlaing, for their role in severe human rights violations; and removing at least six Coordinated Inauthentic Behavior networks run by the Tatmadaw from 2018 to 2020.', 'Since the coup, we have disabled the Tatmadaw True News Information Team Page, and MRTV and MRTV Live Pages for continuing to violate our policies which prohibit coordinating harm and incitement to violence. We have also reduced the distribution of content on at least 23 pages and profiles controlled and/or operated by the Tatmadaw so fewer people see them.', 'This ban does not cover government ministries and agencies engaged in the provision of essential public services. This includes the Ministry of Health and Sport, and the Ministry of Education.', 'We are continuing to monitor the situation and will take additional measures if necessary to keep people safe.', 'Originally published February 11, 2021 at 6:00PM PT:', 'Following the military coup in Myanmar on February 1, the situation on the ground remains volatile and Facebook is adapting to meet these events.', 'Our focus is three-fold: First, do everything we can to prevent online content from being linked to offline harm and keep our community safe. Second, protect freedom of expression for the tens of millions of Myanmar citizens who rely on Facebook now more than ever. Third, ensure that Facebook, Messenger and our family of apps stay online as a source of information and means of communication.', 'Facebook is treating the situation in Myanmar as an emergency. Our Integrity Operations Center has been running around the clock since the coup began. It brings together subject matter experts from across the company, including Myanmar nationals with native language skills, so we can monitor and respond to any threats in real time.', 'Beyond that, we’ve put several measures in place to support our community in Myanmar during this time.', 'Key among these is the decision to significantly reduce the distribution of all content on Facebook Pages and profiles run by the Myanmar Military (“Tatmadaw”) that have continued to spread misinformation. In line with our global policies on repeat offenders of misinformation, we will also no longer be recommending them to people. Among other military-run accounts,\\xa0these measures apply to theTatmadaw Information Team’sFacebook Page and to Tatmadaw spokespersonBrigadier-General Zaw Min Tun’sFacebook account.\\xa0This same action will be applied to any additional pages that the military controls that repeatedly violate our misinformation policies.', 'We have also indefinitely suspended the ability for Myanmar government agencies to send content removal requests to Facebook through our normal channels reserved for authorities around the world.', 'Simultaneously, we are protecting content, including political speech, that allows the people of Myanmar to express themselves and to show the world what is transpiring inside their country.', 'We’re also taking the following additional steps:', 'These efforts build on our work since 2018 to keep people safe and reduce the risk of political violence in Myanmar. Last year, we worked toprotect Myanmar’s 2020 election. We’ve also worked toreduce hate speech, ban certain individuals and organisations and partner with civil societyto address challenges on the ground in Myanmar. While this work is never complete, we’ve made important progress. Between October and December last year, we took action on 350,000 pieces of content containing hate speech in Myanmar, of which 99% were detected before anyone reported it to us.(Updated on May 20, 2022 at 4:10PM PT to clarify the proactive rate definition.)', 'We are closely monitoring the rapidly evolving situation in Myanmar, and are in close communication with governments, institutions and non-governmental organizations that care deeply about Myanmar’s future. We are also monitoring the impact of sanctions that are likely to be imposed in the coming days, and exploring additional measures that we will share soon.', 'We join with governments, the UN, and civil society around the world in calling for internet services in Myanmar to be restored immediately so that the people there can communicate with loved ones, express their political views, access important information, and run their businesses.', 'We remain vigilant to emerging trends and will not hesitate to take additional measures as appropriate.']\n",
            "115 ['Today we’re publishing ourCommunity Standards Enforcement Reportfor the fourth quarter of 2020. This report provides metrics on how we enforced our policies from October through December, including metrics across 12 policies on Facebook and 10 on Instagram.', 'Last quarter, we shared theprevalence of hate speechon Facebook for the first time to show the percentage of times people see this type of content on our platform. This quarter, hate speech prevalence dropped from 0.10-0.11% to 0.07-0.08%, or 7 to 8 views of hate speech for every 10,000 views of content. The prevalence of violent and graphic content also dropped from 0.07% to 0.05% and adult nudity content dropped from 0.05-0.06% to 0.03-0.04%.', '', 'Our improvements in prevalence are mainly due to changes we made to reduce problematic content in News Feed. Each post is ranked by processes that take into account a combination of integrity signals, such as how likely a piece of content is to violate our policies, as well as signals we receive from people, such as from surveys or actions they take on our platform like hiding or reporting posts. Improving how we use these signals helps tailor News Feed to each individual’s preferences, and also reduces the number of times we display posts that later may be determined to violate our policies.', 'Our proactive rate, the percentageof content we took action on that we found before a user reported it to us, improved in certain problem areas, most notably bullying and harassment.Our proactive rate for bullying and harassment went from 26% in Q3 to 49% in Q4 on Facebook, and 55% to 80% on Instagram.Improvements to our AIin areas where nuance and context are essential, such as hate speech or bullying and harassment, helped us better scale our efforts to keep people safe.', '', 'We’re slowly continuing to regain our content review workforce globally, though we anticipate our ability to review content will be impacted by COVID-19 until a vaccine is widely available. With limited capacity, we prioritize the most harmful content for our teams to review, such as suicide and self-injury content.', 'On Facebook in Q4 we took action on:', 'On Instagram in Q4 we took action on:', 'This year, we plan to share additional metrics on Instagram and add new policy categories on Facebook. We’re also working to make our enforcement data easier for people to understand by making these reports more interactive. Our goal is to lead the technology industry in transparency, and we’ll continue to share more enforcement metrics as part of this effort. We also believe that no company should grade its own homework. Last year, we committed toundertakinganindependent, third-party audit of our content moderation systems to validate the numbers we publish, and we’llbegin this process this year.', 'We will continue building on this progress and improving our technology and enforcement efforts to keep harmful content off of our apps.']\n",
            "116 ['Note: For future Facebook updates about Oversight Board cases, please visit theTransparency Center.', 'Update on April 29, 2021 at 7:00AM PT:', 'We welcome theOversight Board’s decision todayon this case. Facebook previously reinstated this content as it did not violate our policies and was removed in error so no further action will be taken on this content.', 'After conducting a review of the recommendation provided by the board in addition to their decision, we will update this post.', 'Originally published on February 9, 2021 at 5:01AM PT:', 'Today, theOversight Board selected a caseappealed by someone on Facebook regarding a post with a video from Global Punjab TV and accompanying text claiming the Rashtriya Swayamsevak Sangh (RSS) and members of the Indian Government are threatening Sikhs with violence.', 'Upon initial review, Facebook took down this content for violating ourpolicy on dangerous individuals and organizations, as laid out in our Community Standards. However, upon further review, we determined we removed this content in error and reinstated it. We continue to welcome the board’s review of this case — any decision they make on the content will be binding, and we welcome any policy guidance related to it.', 'We will implement the board’s decision once it has finished deliberating, and we will update this post accordingly. Please see theboard’s websitefor the decision when they issue it.']\n",
            "117 ['Note: For future Facebook updates about Oversight Board cases, please visit theTransparency Center.', 'Update on June 24, 2021 at 1:00PM PT:', 'Following up on one of the Oversight Board’s non-binding recommendations in this case, today we are adding the following language to our Community Standards Hate Speech Policy Rationale:', '“We define hate speech as a direct attack against people — rather than concepts or institutions — on the basis of what we call protected characteristics: race, ethnicity, national origin, disability, religious affiliation, caste, sexual orientation, sex, gender identity and serious disease. We define attacks as violent or dehumanizing speech, statements of inferiority, expressions of contempt, disgust or dismissal, cursing, and calls for exclusion or segregation. We also prohibit the use of harmful stereotypes, which we define as dehumanizing comparisons that have historically been used to attack, intimidate, or exclude specific groups, and that are often linked with offline violence.”', 'Blackface was popular in the United States at the end of the Civil War and the beginning of the 1900s. Its purpose was to dehumanize Black people.Specifically, this included non-Black people darkening their skin and exaggerating facial features while demeaning Black people as “lazy, ignorant, superstitious, hypersexual, prone to thievery and cowardice.”', 'Unfortunately, this tactic has persisted throughout history and continues today, not just in America but in other parts of the world as well. This can lead to exclusionary practices in our societies and can also lead to offline harm such as hate crimes and excessive force. Facebook works to ensure that hateful and demeaning words and imagery are not on its platform and to educate people when they attempt to put it there.', 'Update on May 13, 2021 at 11:00AM PT:', 'The board issued their binding decision for this case last month upholding our initial decision in this case. At that time the board also issued two non-binding recommendations, which we are responding to in the table below.', '', 'Update on April 13, 2021 at 6:00AM PT:', 'We welcome the Oversight Board’sdecision today on this case. The board decided to uphold Facebook’s decision so we have taken no further action related to this case or the content.', 'After conducting a review of the recommendations provided by the board in addition to their decision, we will update this post.', 'Originally published on January 29, 2021 at 7:00AM PT:', 'Today, theOversight Board selected a caseappealed by a Facebook user regarding a video of a child interacting with three adults — one of whom is dressed to portray Sinterklaas and two of whom are dressed to portray Zwarte Piet. The child shakes hands and a hat is placed on his head by one of the adults portraying Zwarte Piet. Festive music is playing and accompanying text in the post, written in Dutch, states the child is happy.', 'Facebook has taken down this content for violating ourpolicy on hate speech, as laid out in our Community Standards. We do not allow hate speech on Facebook that makes “designated dehumanizing comparisons, generalizations, or behavioral statements (in written or visual form) that includes… caricatures of Black people in the form of blackface.”', 'We will implement the board’s decision once it has finished deliberating, and we will update this post accordingly. Please see theboard’s websitefor the decision when they issue it.']\n",
            "118 ['Note: For future Facebook updates about Oversight Board cases, please visit theTransparency Center.', 'Today, theOversight Boardpublished theirdecisions on the first set of casesthey chose to review. We will implement these binding decisions in accordance with thebylawsand have already restored the content in three of the cases as mandated by the Oversight Board. We restored thebreast cancer awareness postlast year, as it did not violate our policies and was removed in error.', 'Given that we are in the midst of a global pandemic, we feel it’s important to briefly comment on the decision in theCOVID-19 case. The board rightfully raises concerns that we can be more transparent about our COVID-19 misinformation policies.We agree that these policies could be clearer and intend to publish updated COVID-19 misinformation policies soon. We do believe, however, that it is critical for everyone to have access to accurate information, and our current approach in removing misinformation is based on extensive consultation with leading scientists, including from the CDC and WHO. During a global pandemic this approach will not change.', 'Included with the board’s decisions are numerous policy advisory statements. According to the bylaws we will have up to 30 days to fully consider and respond to these recommendations. We believe that the board included some important suggestions that we will take to heart. Their recommendations will have a lasting impact on how we structure our policies.', 'We look forward to continuing to receive the board’s decisions in the years to come. For more information about what happens next in the process now that we have received these first decisions from the Oversight Board, please seethe FAQbelow.', 'Now that we have the Oversight Board’s decisions, what are the next steps for Facebook?', 'Since we just received the board’s decisions a short time ago, we will need time to understand the full impact of their decisions. We will update theNewsroom postsabout each case within 30 days to explain how we have considered the policy recommendations, including whether we will put them through ourpolicy development process.', 'Some of today’s recommendations include suggestions for major operational and product changes to our content moderation — for example allowing users to appeal content decisions made by AI to a human reviewer. We expect it to take longer than 30 days to fully analyze and scope these recommendations.', 'Are the Oversight Board’s decisions binding?', 'Yes. Today’s decisions (and future board decisions) are binding on Facebook, and we will restore or remove content based on their determination. The board’s policy recommendations are advisory, and we will look to them for guidance in modifying and developing our policies.', 'What will you do about content which is the same or similar to content which the board ruled on?', 'When it is feasible to do so, we will implement the board’s decision across content that is identical and made with similar sentiment and context. See below for more detail.', 'How many pieces of content are you taking action on as a result of the board’s decisions today?', 'We cannot provide a number right now since we are still reviewing the decisions. We’ve taken action on the individual pieces of content the board has decided on. Our teams are also reviewing the board’s decisions to determine where else they should apply to content that’s identical or similar.', '', 'How will a decision by the Oversight Board be implemented?', 'There are several phases to fully implement a decision by the Oversight Board. The board’s decision will impact content on the platform in two ways — through the binding aspects of the decision itself, and through any additional guidance or recommendation the board includes.', 'Case Content:As illustrated in the graphic above, we begin implementing the decision by taking action on the case content. Per the bylaws, we will do so within seven days of the board’s decision.', 'Identical Content with Parallel Context:Facebook will implement the Oversight Board’s decision across identical content with parallel context if it exists. First, Facebook will use the board’s decision to define parallel context. For example, if we see another post using the same image that the board decided should be removed, we may also remove that post if it is shared with the same sentiment. If the post has the same image but a different context (for example the post condemns the image rather than supports it) this would not be considered parallel context and we would leave it on the platform.', 'In order to take action on identical context with parallel context, Facebook’s policy team will first analyze the board’s decision to determine what constitutes identical content in each case. It will then determine the context in which the board’s decision should also apply to the identical content. One key element of the analysis involves reassessing the case content’s scope and severity based on the board’s decision.', 'Next, Facebook’s operations team, who enforce our policies, will investigate how the decision can be scaled. There are some limitations for removing seemingly identical content including when it is similar, but not similar enough for our systems to always identify it. The operations team will ensure that new posts using the content are either allowed to remain on the platform, or are taken down, depending on the board’s decision.', 'After this step is completed, we will update the case specific Newsroom Post with our follow up actions on this content.', 'Similar Content:Similar content means content that is not immediately impacted by the Oversight Board’s decision (the content is not identical or the context is not the parallel), but that raises the same questions around Facebook policies. If the Oversight Board issues apolicy advisory statementwith its decision, or makes a decision in response to a Facebook request for a policy advisory opinion, Facebook will\\xa0 review policy recommendations oradvisory statements,and publicly respond within 30 days to explain how it will approach the recommendation. First Facebook’s policy team will review the recommendation from the board, and will decide if the recommendation\\xa0 should go to thePolicy Forumfor further review and to potentially changeFacebook’s Community StandardsorInstagram’s Community Guidelines.', 'After these steps are completed, Facebook will update the case specific Newsroom post and, in instances where the recommendation is considered at the Policy Forum, document the process in the Policy Forumminutes. Facebook has committed to considering the board’s recommendation through its policy development process. The policy development process is a large part of how we envision that the board’s decisions will have lasting influence over our policies, procedures and practices.']\n",
            "119 ['Today, on International Holocaust Remembrance Day, we remember the lives of the six million Jews who were systematically persecuted and killed, alongside members of other minority groups, by the Nazis and their collaborators during the Holocaust.', 'We honor the memories of the victims and recognize the role we can play to help fulfill the promise ‘Never Again.’ Starting today, we will begin to connect people with authoritative information about the Holocaust. Anyone who searches on Facebook for terms associated with either the Holocaust or Holocaust denial, will see a message from Facebook encouraging them to connect with credible information about the Holocaust off Facebook.', 'We’re taking these steps given the well-documented rise in anti-Semitism globally and the alarming level of ignorance about the Holocaust, especially among young people. We want to help our community learn about the events that led to the Holocaust and the genocide of one-third of the Jewish people.', 'This builds on our recent efforts to keep Holocaust denial content off of our platform. In October, weannounced an update to our hate speech policythat prohibits any content that denies or distorts the events of the Holocaust. This followed a number of other steps to help combat hate including banning anti-Semitic stereotypes about the collective power of Jews that often depict them running the world or its major institutions.', '', 'The tool that we’re announcing today will first be available in English speaking countries including Australia, New Zealand, Canada, United Kingdom, Ireland and the United States. We will then expand this to more languages and countries over the coming months.', 'The siteaboutholocaust.orgwas created by the World Jewish Congress with the support of the United Nations Educational, Scientific and Cultural Organization (UNESCO) with the goal of providing young people with essential information about the history of the Holocaust and its legacy. This site includes easy to read facts about the Holocaust and survivor testimonies, reviewed by leading experts in the field of Holocaust studies.', 'Audrey Azoulay, UNESCO Director-General said:', '“Transmitting the history of the Holocaust is key to combatting denial and conspiracy theories today — it is key to equipping people with the skills they need to refuse the hateful logic of antisemitism, racism and hatred, and to challenging those who seek to exploit ignorance. We must join forces to share factual and reliable information on social media platforms, and this partnership is a clear step in the right direction.”', 'Ronald S. Lauder, President of the World Jewish Congress said:', '“Holocaust denial, Holocaust distortion, and the spreading of conspiracy myths about the Holocaust generally have become cornerstones in the vicious incitement of antisemitic hatred on the part of white supremacists, neo-Nazis, and other extremist forces. The World Jewish Congress is deeply gratified to work with UNESCO and Facebook to ensure that Facebook’s 2.7 billion users are provided with accurate, comprehensive information about the Holocaust.Connecting Facebook users toAboutHolocaust.orgwill contribute greatly to promoting tolerance and empathy as the antidote to resurgent antisemitism, xenophobia, bigotry, and hate.”', 'We are grateful to the many partners who helped inform today’s launch including the Simon Wiesenthal Center, the American Jewish Committee, Hope not Hate, CEJI — A Jewish Contribution to an Inclusive Europe, Community Security Trust, the European Union of Jewish Students, B’nai B’rith International, and the Amadeu Antonio Foundation. We will continue to partner with organizations around the world to fight hatred and prejudice and encourage understanding and respect for all people.']\n",
            "120 ['Note: For future Facebook updates about Oversight Board cases, please visit theTransparency Center.', 'Today, Facebook is referring itsdecision to indefinitely suspendformer US President Donald Trump’s access to his Facebook and Instagram accounts to the independentOversight Board. The board was established last year to make the final call on some of the most difficult content decisions Facebook makes. It is an independent body and its decisions are binding — they can’t be overruled by CEO Mark Zuckerberg or anyone else at Facebook. The board itself is made up of experts and civic leaders from around the world with a wide range of backgrounds and perspectives.', 'We believe our decision was necessary and right. Given its significance, we think it is important for the board to review it and reach an independent judgment on whether it should be upheld. While we await the board’s decision, Mr. Trump’s access will remain suspended indefinitely. We look forward to receiving the board’s decision — and we hope, given the clear justification for our actions on January 7, that it will uphold the choices we made. In addition to the board’s determination on whether to uphold or overturn the indefinite suspension, Facebook welcomes any observations or recommendations from the board around suspensions when the user is a political leader.', 'Our decision to suspend then-President Trump’s access was taken in extraordinary circumstances: a US president actively fomenting a violent insurrection designed to thwart the peaceful transition of power; five people killed; legislators fleeing the seat of democracy. This has never happened before — and we hope it will never happen again. It was an unprecedented set of events which called for unprecedented action.', 'In making our decision, our first priority was to assist in the peaceful transfer of power. This is why, when announcing the suspension on January 7, we said it would be indefinite and for at least two weeks. We are referring it to the Oversight Board now that the inauguration has taken place.', 'The reaction to our decision shows the delicate balance private companies are being asked to strike. Some said that Facebook should have banned President Trump long ago, and that the violence on the Capitol was itself a product of social media; others that it was an unacceptable display of unaccountable corporate power over political speech.', 'We have taken the view that in open democracies people have a right to hear what their politicians are saying — the good, the bad and the ugly — so that they can be held to account. But it has never meant that politicians can say whatever they like. They remain subject to our policies banning the use of our platform to incite violence. It is these policies that were enforced when we took the decision to suspend President Trump’s access.', 'Whether you believe the decision was justified or not, many people are understandably uncomfortable with the idea that tech companies have the power to ban elected leaders.', 'Many argue private companies like Facebook shouldn’t be making these big decisions on their own. We agree.', 'Every day, Facebook makes decisions about whether content is harmful, and these decisions are made according to Community Standards we have developed over many years. It would be better if these decisions were made according to frameworks agreed by democratically accountable lawmakers. But in the absence of such laws, there are decisions that we cannot duck.', 'This is why we established the Oversight Board. It is the first body of its kind in the world: an expert-led independent organization with the power to impose binding decisions on a private social media company. Its decision will be available at theboard’s websitewhen it is issued.']\n",
            "121 ['We believe freedom of expression is a fundamental human right, and we work hard to protect and defend these values around the world. More than half of the people in Turkey rely on Facebook to stay in touch with their friends and family, to expresstheir opinions and grow their businesses.', 'We have been closely following developments on Turkey’s recently amended Internet Law No. 5651 which stipulates new requirements for social media platforms. Like other companies, we have decided to begin the process of appointing a legal entityas a local representative in compliance with the law, while also recognizing how important it is for our platform to be a place where users can exercise their freedom of expression.', 'This decision does not change Facebook’s Community Standards, nor the global process for reviewing government requests, and we will withdraw the representative if we face pressure on either. We will continue to review and evaluate government requests in accordance with our policies, including our commitments as a Global Network Initiative member, and under the UN Guiding Principles on Business and Human Rights. We will continue to report details of the content we restrict, in line with our existing transparency processes.', 'We remain committed to the Turkish community and maintaining free expression and other human rights in Turkey.']\n",
            "122 ['Update on Saturday, January 16, 2021 at 11:00AM PT:', 'We are banning ads that promote weapon accessories and protective equipment in the US at least through January 22, out of an abundance of caution. We already prohibit ads for weapons, ammunition and weapon enhancements like silencers. But we will now also prohibit ads for accessories such as gun safes, vests and gun holsters in the US.', 'Update on January 15, 2021 at 1:57PM PT:', 'We’re monitoring for signals of violence or other threats both in Washington, D.C. and across all 50 states. In the lead up to Inauguration Day, we have implemented a series of additional measures to continue preventing attempts to use our services for violence. This includes our ongoing pause on all political advertising. And, as we did in the weeks after the presidential election, we are promoting accurate information about the election and the violence at the Capitol instead of content that our systems predict may be less accurate, delegitimizes the election or portrays the rioters as victims. We have also implemented specific measures to reduce opportunities for abuse in Groups.', 'Building on these steps, we have added two additional measures to further prevent people from trying to use our services to incite violence.', 'We will continue to monitor and add additional measures as needed.', 'Originally published on January 11, 2021 at 1:05PM PT:', 'We began preparing for Inauguration Day last year. But our planning took on new urgency after last week’sviolence in Washington, D.C., and we are treating the next two weeks as a major civic event. We’re taking additional steps and using the same teams and technologies we used during the general election to stop misinformation and content that could incite further violence during these next few weeks.', 'We are now removing content containing the phrase “stop the steal” under our Coordinating Harm policy from Facebook and Instagram. We removed the original Stop the Steal group in November and have continued to remove Pages, groups and events that violate any of our policies, including calls for violence. We’ve been allowing robust conversations related to the election outcome and that will continue. But with continued attempts to organize events against the outcome of the US presidential election that can lead to violence, and use of the term by those involved in Wednesday’s violence in DC, we’re taking this additional step in the lead up to the inauguration. It may take some time to scale up our enforcement of this new step but we have already removed a significant number of posts.', 'Our teams are working 24/7 to enforce our policies around the inauguration. We will keep our Integrity Operations Center operating at least through January 22 to monitor and respond to threats in real time. We already had it active ahead of Georgia’s runoff elections and Congress’s counting of the Electoral College votes in the US presidential election. We extended it due to the violence at the Capitol last week.', 'As was the case through the 2020 elections, we’ve continued to proactively reach out to federal and local law enforcement and we are providing information in response to valid legal requests. As always, we will continue to remove content, disable accounts and work with law enforcement when there is a risk of physical harm or direct threats to public safety.', 'In addition to the indefinite suspension of President Trump’s account that we announced on January 7, we’re keeping our pause in place on all ads in the US about politics or elections. This means that we aren’t allowing any ads from politicians, including President Trump.', 'We are also connecting people with reliable information and high-quality news about the inauguration and the transition process. After the inauguration, our label on posts that attempt to delegitimize the election results will reflect that Joe Biden is the sitting president. Our Voting Information Center will stay active on Facebook and Instagram through the inauguration so it can continue to help people find reliable information and updates about the electoral process.', 'During inauguration week, we will add a news digest to Facebook News as a curated place for people to find reliable news about the inauguration. This will include live video of the inauguration at the US Capitol on January 20. Facebook News often includes news digests dedicated to events of national or global significance, such as “COVID-19” or “Unrest in America” with stories selected by the curation team. There will also be curated live video of the inauguration and other major moments on Facebook Watch.', 'We’ve had emergency measures in place since before the US elections such as not recommending civic groups for people to join. Last week, we implemented several additional ones, including increasing the requirement of Group admins to review and approve posts before they can go up, automatically disabling comments on posts in Groups that start to have a high rate of hate speech or content that incites violence, and using AI to further demote content that likely violates our policies. We’re keeping these measures in place.', 'We will stay vigilant to additional threats and take further action if necessary to keep people safe and informed.']\n",
            "123 ['Update on January 7, 2021 at 8:05AM PT:', 'We believe the risks of allowing President Trump to continue to use our service during this period are simply too great, so we are extending the block we have placed on his Facebook and Instagram accounts indefinitely and for at least the next two weeks.', 'Update on January 6, 2021 at 6:28PM PT:', \"We've assessed two policy violations against President Trump's Page which will result in a 24-hour feature block, meaning he will lose the ability to post on the platform during that time.\", '— Meta Newsroom (@MetaNewsroom)January 7, 2021', '', 'Originally published on January 6, 2021 at 4:00PM PT:', 'Let us speak for the leadership team in saying what so many of us are feeling. We are appalled by the violence at the Capitol today. We are treating these events as an emergency. Our Elections Operations Center has already been active in anticipation of the Georgia elections and the vote by Congress to certify the election, and we are monitoring activity on our platform in real time. For those of you who are wondering, here are the actions we’re taking:', 'First, we have been searching for and removing the following content:', 'As a part of this, we removed from Facebook and Instagram the recent video of President Trump speaking about the protests and his subsequent post about the election results. We made the decision that on balance these posts contribute to, rather than diminish, the risk of ongoing violence.', 'Next, we’re updating our label on posts across our platforms that attempt to delegitimize the election results. The new text reads:“Joe Biden has been elected President with results that were certified by all 50 states. The US has laws, procedures, and established institutions to ensure the peaceful transfer of power after an election.”', 'In recent days and weeks, we have also taken enforcement action consistent with our policy banning militarized social movements like the Oathkeepers and the violence-inducing conspiracy theory QAnon. We’ve also continued to enforce our ban on hate groups including the Proud Boys and many others. We’ve already removed over 600 militarized social movements from our platform.', 'We’ve had emergency measures in place since before the US elections like not recommending civic groups for people to join. We’re keeping them in place. Today we’re implementing several additional ones as well, including:', 'We’re continuing to monitor the situation and will take additional measures if necessary to keep people safe.']\n",
            "124 ['Jump to latest news', 'Facebook is supporting the global public health community’s work to keep people safe and informed during the coronavirus public health crisis. We’re also working to address the long-term impacts by supporting industries in need and making it easier for people to find and offer help in their communities.', 'Here’s an overview of how we’re providing access to accurate information, supporting relief efforts and keeping people connected. We’ll continue to add to this post as we announce updates.', '1. Ensuring everyone has access to accurate information and removing harmful content', '2. Supporting health and economic relief efforts', '3. Keeping people connected', 'Updating Our Ad Policy for COVID-19 Vaccines', 'Given the recent approval of COVID-19 vaccines, we want people to be able to safely promote information about these vaccines on Facebook. We will now allow ads that highlight the ability of a COVID-19 vaccine to prevent someone from contracting the virus, as well as ads promoting ways to safely access a COVID-19 vaccine. We’ll continue to prohibit content that tries to exploit the pandemic for commercial gain. And ads or organic posts that promote the sale of a COVID-19 vaccine, such as attempts to sell COVID-19 vaccine kits or expedited access to the vaccine, will be rejected. We will also reject ads that claim the vaccine is a cure for the virus.', 'It will take some time to train our systems and teams on these policies, and we expect enforcement to ramp up over the coming weeks and months.', 'Providing Aid to Diverse Suppliers through Receivables Financing', 'In response to the ongoing impact of the COVID-19 pandemic – particularly the challenges facing minority and women-owned businesses – we recently launchedThe Facebook Receivables Financing Programto support US-based suppliers. This one-year financing program allowsminority, women, veteran, LGBTQ and disability-owned companies that are headquartered in the US and have been paid directly by Facebook in 2019 or 2020 to have their invoices paid now instead of in the 60 to 120 day period it normally takes to get paid for work they’ve already done. Our goal with this program is to help level the playing field by providing businesses with access to more working capital.', 'We’ll do this by providing immediate cash for work suppliers have done and pay they’re owed by other, non-Facebook, companies. Suppliers can upload eligible invoices to the Receivables Financing platform and get funded in a few days. We partnered with Supplier Success, a minority-owned business with extensive experience providing receivables financing, to administer our Receivable Financing platform and collaborated with Crowdz.io to operate a seamless and secure platform to safely buy receivables. Together, Supplier Success and Crowdz.io will collect the suppliers’ invoices from their customers, and Facebook will reinvest the collected receivables to purchase additional invoices. Facebook is not making any return on these funds.', 'Removing False Claims About COVID-19 Vaccines', 'Given the recent news that COVID-19 vaccines will soon be rolling out around the world, over the coming weeks we will start removing false claims about these vaccines that have been debunked by public health experts on Facebook and Instagram. This is another way that we are applying our policy to remove misinformation about the virus that could lead to imminent physical harm. This could include false claims about the safety, efficacy, ingredients or side effects of the vaccines. For example, we will remove false claims that COVID-19 vaccines contain microchips, or anything else that isn’t on the official vaccine ingredient list. We will also remove conspiracy theories about COVID-19 vaccines that we know today are false: like specific populations are being used without their consent to test the vaccine’s safety. We will not be able to start enforcing these policies overnight. Since it’s early and facts about COVID-19 vaccines will continue to evolve, we will regularly update the claims we remove based on guidance from public health authorities as they learn more.', 'We will also continue to help people stay informed about these vaccines by promoting authoritative sources of information through ourCOVID-19 Information Center.', 'Mark Zuckerberg is live with Dr. Anthony Fauci, America’s top infectious disease expert, to discuss progress toward a COVID-19 vaccine and how we can slow the spread of the virus this holiday season.', 'Connecting People to Mental Health Resources', 'Experts agree that COVID-19 has exacerbated mental health challenges around the world, and the repercussions will be felt for years to come. We’ve been working with leading authorities around the world — like NAMI, Kids Help Phone and It’s OK to Talk — to invest in the critical areas of mental health support, including handling financial stress, parenting support, coping with loss and grief, managing substance use and taking care of overall emotional health. Today we’re introducing Emotional Health, acentralized resource centeron the Facebook app with tips and information from leading experts. The resource will be available globally, with locally relevant information from mental health officials.', 'Learn moreabout how we’remaking it easier for people to get the support they need for themselves and others who might be struggling.', '', 'Allowing the Promotion and Sale of Hand Sanitizer and Surface Disinfecting Wipes', 'In March, we temporarily banned ads and commerce listings forhand sanitizer and surface disinfecting wipesto help protect against scams, inflated prices and hoarding. Since then, we’ve continued to monitor trends and activity around COVID-19 to better understand how people are using our platform and advertising tools during the pandemic. Today we’re scaling back this temporary ban to allow people to promote and trade hand sanitizer and surface disinfecting wipes on our apps.', 'Supporting Teachers, Parents and Students This Back-To-School Season', 'Back-to-school looks different this year due to COVID-19, and parents, teachers and students around the world are facing a myriad of challenges, from remote teaching and learning, balancing work and home responsibilities, and most importantly, maintaining the safety and well-being of everyone involved. To help, we’re launching anEducator Hubto support teachers and providing resources across our apps to help people stay connected and take care of each other. The Educator Hub will help teachers find or build their online communities and discover guides and other resources for the classroom and beyond.Learn more.', 'Mark Zuckerberg is live with Dr. Anthony Fauci, America’s top infectious disease expert. They’ll discuss the US’ response to COVID-19, progress on a vaccine, and what we need to do next to stop the spread of the virus.', 'We continue working to keep people safe and informed about COVID-19. We have connected over 2 billion people to resources from health authorities through ourCOVID-19 Information Centerand pop-ups on Facebook and Instagram with over 600 million people clicking through to learn more. Since January, people have raised over $100 million for COVID-19 related fundraisers on Facebook and Instagram. Over half of those donations were under $25.', 'FactsAboutCOVID-19', 'To further limit the spread of misinformation, this week we are launching a dedicated section of theCOVID-19 Information Centercalled Facts about COVID-19.It will debunk common myths that have been identified by the World Health Organization such as drinking bleach will prevent the coronavirus or that taking hydroxychloroquine can prevent COVID-19. This is the latest step in our ongoing work to fight misinformation about the pandemic.', '', 'Global Reminders to Wear Face Coverings', 'With the rise in COVID-19 cases in the US and in many other parts of the world, we are expanding our alerts reminding people to wear face coverings internationally as recommended by health authorities. These alerts have been running at the top of Facebook and Instagram in the US since early July. Starting this week, we will expand them to more countries globally.', 'With the rise in COVID-19 cases in the US, we’re putting an alert at the top of Facebook and Instagram to remind everyone to wear face coverings and find more prevention tips from the CDC in our COVID-19 Information Center.', 'Launching Summer of Support', 'Over the past few months, many businesses have changed the way they operate, and many more are looking for ways to pivot and move forward. Today we’re kicking off our Boost with FacebookSummer of Supportprogram to help millions of people get training in the digital skills they need to succeed. Over the next six weeks, we’ll offer free online training, live sessions and conversations on topics such as reimagining customer support, transitioning from brick and mortar to digital, and more. You can learn more about Summer of Support and other ways we’re supporting businesseshere.', 'Expanding Our Blood Donations Feature', 'COVID-19 has led to blood shortages around the world due to shelter in place orders limiting the ability for people to donate. To help, we’re expanding our FacebookBlood Donations featureto connect more people to their local blood banks, so they know when there is a shortage and where it is safe to donate. The Blood Donations feature is now available in South Africa, Senegal, Kenya, Burkina Faso, Côte d’Ivoire and Egypt as well as the US, India, Brazil, Pakistan and Bangladesh.We’re also working with partners in India and Brazil to connect people with more local blood banks and hospitals through the Blood Donations feature. And in the US, we’re excited to announce a new partnership withAABBto connect people to hospital blood banks.', '', 'Allowing the Promotion of Non-Medical Masks on Facebook and Instagram', 'Since the World Health Organization declared COVID-19 a global pandemic, governments and authorities around the world have evolved their guidance on the need to wear masks. In March, wetemporarily banned ads and commerce listings for maskson our apps to help protect against scams, misleading medical claims, medical supply shortages, inflated prices and hoarding. Since then, we’ve continued to monitor trends and activity around COVID-19 to better understand how people are using our platform and advertising tools during the pandemic.', 'Many health authorities now advise wearing non-medical masks – and in some places masks are required for activities like taking public transportation or visiting a store – and we’ve seen people and businesses of all sizes working to fill this need. So we’re scaling back this temporary ban to allow people to promote and trade non-medical masks, including those that are homemade or handmade, in organic posts, ads and commerce listings on Facebook and Instagram. We will still maintain a temporary ban on selling medical masks, such as surgical or N95 masks, to prevent people from exploiting the pandemic for financial gain.You can learn more about how we define non-medical masks and advertiser restrictions for these adshere.', 'Releasing New Data for Good Tools', 'Today we’re releasing new visualizations and datasets publicly to help researchers, NGOs and others combat the COVID-19 pandemic. You can learn more about these and our other Data for Good toolshere.', 'Tomorrow on#GivingTuesdayNowwe’re expandingCommunity Helpto make it easier for people to support local businesses and nonprofits. Starting tomorrow, people will be able to find gift cards and vouchers to support local businesses, donate to local nonprofit fundraisers, sign up to become a blood donor and find local job opportunities — all inCommunity Help.', '', 'Partnering with ITDRC and NetHope to Address the Digital Divide', 'The coronavirus pandemic has underscored the importance of internet connectivity. While many people have shifted their lives online, there are still more than 3.5 billion people, including more than18 million Americans, who lack reliable internet access. To help, we’re partnering with the Information Technology Disaster Resource Center (ITDRC) and NetHope to provide internet connectivity to communities most impacted by COVID-19. The goal of these partnerships is to better understand the unique barriers these communities face in getting online and create the programs and infrastructure needed to increase the availability and affordability of high-quality internet access.', 'Update on Content Review Work', 'Throughout the COVID-19 crisis, we’ve worked to keep both our workforce and the people who use our platforms safe. Last monthwe announcedthat we would temporarily send our content reviewers home. Since then we’ve shared updates on changes we’ve made to keep our platform safe during this time, including increasing the use of automation, carefully prioritizing user reports, and temporarily altering our appeals process.', 'We’ve also asked some of our full-time employees to review content related to real-world harm like child safety and suicide and self-injury. It’s become clear in recent weeks that our offices are unlikely to return to business as usual in the near future. Some of our full-time employees will continue to review sensitive content, butas Mark referenced last weekwe will begin working with our partners to bring a small number of content reviewers back to offices to support these efforts in the coming weeks.', 'Returning to the office will be voluntary. We’ll also work with our partners to put protections in place to keep content reviewers safe. These will include: greatly reducing building capacity in these offices to ensure government guidelines on physical distancing can be observed, implementing strict cleaning protocols and providing personal protective equipment like masks and gloves as well as temperature checks at the beginning of every shift.', 'As the situation evolves, we’ll continue to share changes we make to keep both our community and the people who review content on our platforms safe.', 'Facebook Joins Open COVID Patent Pledge', 'Today Facebook joined Amazon, Hewlett Packard, IBM, and Microsoft in signing theOpen COVID Patent Pledgeto help make patents freely available in the fight against COVID-19. The pledge allows people to useour patentsto advance innovation that may help in ending the COVID-19 pandemic and minimizing the impact of the disease —\\xa0without any uncertainty around intellectual property rights or fear of litigation.', 'Sharing COVID-19 Symptom Maps and Expanding Survey Globally to Help Predict Disease Spread', 'Today Carnegie Mellon University (CMU) Delphi Research Center made public theinitial resultsof their US symptom survey wepromoted on Facebook. Using aggregate data from Carnegie Mellon, Facebook produced its first report andnew interactive maps, which we plan to update daily through this outbreak. Mark Zuckerberg wrote in theWashington Postabout how surveys like this can be an important tool in fighting COVID-19 and announced that we’re working with faculty from the University of Maryland to expand the program globally.', '', 'Limiting the Spread of COVID-19 Misinformation', 'Today we shared someadditional stepswe’re taking to combat COVID-19 related misinformation and make sure people have the accurate information they need to stay safe.', 'Making It Easier to Support Businesses on Instagram', 'We’re making it easier for people to support the businesses they love through gift cards, online food orders and fundraisers all on Instagram.Learn more.', '', 'Getting Expert Insights on How We Can Safely Re-Open Society', 'Mark Zuckerberg and Priscilla Chan are live with Dr. Tom Frieden, the former director of the CDC and founder of Resolve to Save Lives. They’ll discuss how we can contain the spread of COVID-19 and how we should approach reopening society.', 'Helping the WHO Share Timely Information on Messenger', 'Today the World Health Organization (WHO) launched an interactive experience on Messenger to provide accurate and timely information about the coronavirus outbreak. People will now be able tomessage the WHOwith questions about COVID-19 and get quick answers for free. The WHO created this Messenger experience with support fromSprinklras part of theprogramwe recently announced to pair developer partners with health organizations to help them connect with people and deliver critical information during the COVID-19 outbreak.Learn more.', 'Connecting People to Well-Being Tips and Resources', 'The COVID-19 pandemic has forced people around the world to adjust to new routines, cope with loneliness, job loss, grief and more. And it’s tough for all of us in different ways, not just physically but mentally. To help, we’re sharing tips from experts to stay well, supporting the work of mental health organizations, and giving you tools to manage your time on Facebook.', '', 'Helping People Get Reliable Information In Groups and Local Alerts', 'As people are turning to Groups to connect with communities they care about and get support during this time, we want to make it easy to find and share reliable information in groups. Here are a few things we’re doing:', '', 'In addition, we more than doubled the number of state and local governments and health agencies onboarded toFacebook local alerts, so we now have more than 2,000 partners using the tool to communicate timely information to their communities.', 'New Tools to Help Health Researchers Track and Combat COVID-19', 'Today we’reannouncingnew Data for Good tools to support health researchers and nonprofits:', '', 'Helping Small Businesses', 'Today we’re sharing an update on our efforts to help small businesses get through this challenging time. These include:', 'Making It Easier for People to Request or Offer Help in Their Communities', 'Today we’re announcing Community Help, a place for people to request or offer help to neighbors, such as volunteering to deliver groceries or donating to a local food pantry or fundraiser. You can access Community Help in the COVID-19 Information Center on Facebook or by visitingfacebook.com/covidsupport. We’re starting to roll it out in the US, the UK, France, Australia and Canada in the next few days, and we’re working to bring it to more countries in the coming weeks.', '', '', 'Donating $25 Million to Support Healthcare Workers', 'Mark Zuckerberg and Priscilla Chan are live with Governor Gavin Newsom to talk about California’s response to the COVID-19 outbreak. They’ll discuss the urgent need for more healthcare workers and Facebook’s $25 million donation to help support healthcare workers on the front line.', 'Investing $100 Million in the News Industry', 'The news industry is working under extraordinary conditions to keep people informed during the COVID-19 pandemic. Today we’reannouncingan additional $100-million investment to support journalists — including $25 million in emergency grant funding for local news through the Facebook Journalism Project, and an extra $75 million in marketing to get money to publishers around the world at a time when their advertising revenue is declining.', 'This investment is in addition to the support we’ve already pledged to the news industry in response to COVID-19:$1 million in grantsfor local news,$1 million in grantsfor fact-checking organizations, and a$1-million donationto the International Fact-Checking Network.', 'Launching the Messenger Coronavirus Community Hub', 'Today, we’re launching theMessenger Coronavirus Community Hubwith tips and resources to keep people connected to their friends, family, colleagues and community, and prevent the spread of misinformation. It also includes advice on how to recognize and avoid scams and misinformation online.Read moreabout how you can use Messenger to stay connected and informed during this time.', 'Helping Young People Safely Navigate the Internet', 'Today we’re launching our digital literacy program,Get Digital, to provide lessons and resources to help young people develop the competencies and skills they need to more safely navigate the internet. These resources are designed to be used by educators and families both in the classroom and at home, but they’ve become even more important as young people spend more time on their devices while at home during the COVID-19 outbreak.', 'Get Digital will help young people learn how to:', 'It will also help them discover how technology can be used for civic and political engagement. And it can help them develop digital skills, such as understanding algorithms, and explore programming and more to help prepare them for future careers in technology.', 'We’re partnering with UNESCO, the International Society for Technology in Education (ISTE), National PTA, and EVERFI to distribute our new digital literacy tools to parents and educators around the world. Lessons are drawn from the Youth and Media team at the Berkman Klein Center for Internet & Society at Harvard University, which has made them freely available worldwide under a Creative Commons license, and the Greater Good Science Center.', 'Sharing Tips for People Working Remotely', 'Remote work can be challenging whether you’re balancing caregiving and work, trying to lead a dispersed team, or adjusting to a new routine and responsibilities. That’s why we created an online resource with tips to help our global team stay connected, be productive and do their best work, wherever they’re working. We’re sharing it publicly today in case it’s helpful to others as many adjust to working remotely during this challenging time. Check out ourremote work resources.', 'Combating COVID-19 Misinformation Across Our Apps', 'Today we shared anoverviewof how we’re connecting people to reliable information and taking aggressive steps to combat COVID-19 misinformation across our apps.', 'Keeping Our Apps Stable and Reliable', 'As more people around the world are physically distancing themselves from others, we’ve seen people using our apps more than ever. Today, we shared some data to give context onthe load we’re managing. Our apps were built to withstand spikes, but the usage growth from COVID-19 is unprecedented across the industry. We’re monitoring usage patterns carefully, making our systems more efficient and adding capacity when needed, and we’re doing everything we can to keep our apps stable and reliable during this time.', 'Helping People Stay Informed and Connected on Instagram', 'Today we announcedupdatesto help people stay informed, safe and connected on Instagram during this challenging time. These include:', 'Helping Government Health Organizations Use Messenger', 'Today we’re announcing two initiatives to help government health organizations in their response to the coronavirus outbreak using Messenger.', 'Read moreabout how we’re leveraging Messenger’s reach, tools and technology to help people stay connected and informed during this time.', 'Launching the WHO Health Alert on WhatsApp', 'Today we launched theWorld Health Organization’s Health Alert on WhatsApp. TheWHO Health Alertis free to use and will answer common questions about COVID-19. It provides timely, reliable information about how to prevent the spread of the coronavirus as well as travel advice, coronavirus myth debunking and more. Tocontact the WHO Health Alert, save the number +41 79 893 1892 in your phone contacts and then text the word ‘Hi’ in a WhatsApp message to get started. The service is initially launching in English but will be available in all six United Nations languages (English, Arabic, Chinese, French, Russian and Spanish) within the coming weeks.', 'It’s an honor to work with@WHOto provide this simple service to get the latest information directly from the experts right on WhatsApp. Tap the link below to get started. Share these tips and de-bunked rumors with your friends and family 🙏https://t.co/WWhbKccdABpic.twitter.com/EYCuAliCk2', '— WhatsApp (@WhatsApp)March 20, 2020', '', 'Keeping Our Platform Safe With Remote and Reduced Content Review', 'We recently announced that we’re temporarilysending content reviewers home. We want to make sure our platform remains a safe place for people to connect during this time, but with a reduced and remote workforce, below are some ways our content review processes will be impacted.', 'Policy Enforcement:We will continue to enforce our policies and prioritize preventing and disrupting harm across our platform. We are conducting human rights due diligence, looking at potential risks, and putting in place contingency plans that both prioritize the safety of our content reviewers and support the integrity of our platform. As Mark Zuckerberg discussed ona press call, for example, we have shifted certain content review work to full time employeesand are focusingon areas including child safety, terrorism, suicide and self-injury, and harmful content related to COVID-19.', 'Some contract reviewers will work from home, but with a reduced and remote workforce, we will now rely more on our automated systems to detect and remove violating content and disable accounts.As a result, we expect to make more mistakes, and reviews will take longer than normal, but we will continue to monitor how our systems are performing and make adjustments. In addition, reviewing content can be challenging, and working from home presents new obstacles in providing support to our teams, but we’re working to ensure our content reviewers have the resources and help they need during this time.', 'User Reports:When people report content to us that they believe violates our policies, they will see a new message letting them knowthat we have fewer content reviewers available and will prioritize reported content that has the greatest potential \\u200bto harm our community. This means some reports will not be reviewed as quickly as they used to be and we will not get to some reports at all.', 'Appeals:Normally when we remove content, we offer the person who posted it the option to request that we review the content again if they think we made a mistake. Now, given our reduced workforce, we’ll give people the option to tell us that they disagree with our decision and we’ll monitor that feedback to improve our accuracy, but we likely won’t review content a second time.', 'We’re working hard to minimize any impact on people as they use Facebook, Instagram and Messenger during this time, but we know some may feel this impact either when reporting content to us or appealing content we remove.', 'We’re doing everything we can to keep our global teams and the community that uses our apps safe while continuing to provide the services people and businesses rely on.', 'Getting Expert Health Tips and Information From Dr. Fauci', 'Mark Zuckerberg is live with Dr. Anthony Fauci, America’s top infectious disease expert involved in leading our government’s response to COVID-19. They’ll discuss how we can all help fight the spread of the coronavirus and what governments are doing to respond to the pandemic.', 'Banning Ads for Hand Sanitizer, Disinfecting Wipes and COVID-19 Testing Kits', 'In addition to masks, we’re now also banning ads and commerce listings for hand sanitizer, surface disinfecting wipes and COVID-19 testing kits. And if we see people selling these products in organic posts on Facebook or Instagram, we’ll remove them.', \"We’ll be ramping up our automated enforcement for ads and commerce next week.  If we see abuse around these products in organic posts, we'll remove those, too (2/2)\", '— Rob Leathern (@robleathern)March 19, 2020', '', 'Minimizing Disruptions for Businesses and Partners on OurPlatform', 'As we announcedon Monday,we’re working with our partners to send home all contract workers who perform content review, until further notice. Since this includes people who review ads and monetized content, we wanted to share more about what this means for advertisers, publishers and creators that use our tools.', 'For Advertisers', 'We use a combination of people and technology to review ads on Facebook and Instagram, and our automated systems already play a big role in that process. Nowwith a reduced and remote workforce, we’re relying on automated technology even more.This may mean:', 'For Content Creators and Publishers', 'All monetized content goes through brand safety reviews. This includes Instant Articles and videos with in-stream ads. Since our ability to review new content is now limited, we won’t be able to approve all content for monetization. We’re working on how to support partners at this time.', 'As this situation continues to evolve, we may need to make further changes to our systems. While we’re working to minimize disruptions for businesses and partners, we will inevitably make mistakes. We will do our best to address any issues as quickly as we can and continue to provide updates.', 'Press Call Recap', 'This morning on a press call, Mark Zuckerberg shared how we’re supporting people and businesses affected by the coronavirus outbreak and how we’re working with health authorities to make sure everyone can access accurate information. He also announced a newCoronavirus Information Centeron Facebook to help people find information and tips, and he shared how we’re giving governments and emergency services around the world free access to Workplace. Read the fulltranscript from his press call.', 'Offering Workplace to Government and Emergency Organizations for Free', 'Starting today, we’re offering Workplace Advanced to government agencies and emergency services free of charge for 12 months. These organizations play a vital role during the coronavirus outbreak, whether it’s acting as first responders or coordinating public information. Workplace can help inform and connect their employees, allowing them to share critical information in real-time and enabling leadership to reach employees via live videos, posts and more.Read moreabout how we’re supporting emergency services and government organizations during this time.', '', 'Launching the Coronavirus Information Center on Facebook', 'Today we’re announcing the Coronavirus (COVID-19) Information Center, featured at the top of News Feed, to provide a central place for people to get the latest news and information as well as resources and tips to stay healthy and support their family and community.', 'It includes real-time updates from national health authorities and global organizations such as the World Health Organization, as well as helpful articles, videos and posts about social distancing and preventing the spread of COVID-19.', 'People can also follow the Coronavirus Information Center to receive updates from health authorities directly in their News Feed. And starting in the US, people will see features to help them connect with local groups and ask for or offer help within their community.', 'We’re rolling out the information center in Italy, France, Germany, Spain, the UK and the US within the next 24 hours, and we’ll expand it to more countries in the coming days.', '', 'Helping People Stay Connected Using WhatsApp', 'In these uncertain times, reliable communication is critical. That’s why we’ve nearly doubled server capacity for WhatsApp and continue to see strong reliability as people place more voice and video calls around the world. In addition, today we launched aninformation hubwith tips on how healthcare workers, educators and local businesses can stay connected using WhatsApp. We also donated $1 million to the International Fact-Checking Network (IFCN) to expand the presence of local fact-checkers on WhatsApp.', 'We’re grateful to@who@undp@uniceffor coordinating the response to this crisis including using@WhatsAppto do so. Already several ministries of health are providing updates to citizens on WhatsApp and we will expand these services together.', '— Will Cathcart (@wcathcart)March 18, 2020', '', 'Supporting Fact-Checkers and Local News Organizations', 'To support fact-checkers in their work around COVID-19, we’re partnering with The International Fact-Checking Network (IFCN) to launch a$1 million grant programto increase their capacity during this time.', 'We’re also supporting local news organizations as they deal with unexpected costs of covering COVID-19 and provide increased coverage during this time. To help, the Facebook Journalism Project is partnering with the Lenfest Institute for Journalism and the Local Media Association to offer a total of$1 million in grants to local news organizationscovering COVID-19 in the US and Canada.', 'Investing $100 Million in Small Businesses', 'We’re creating a $100 million grant program to help small businesses around the world impacted by the coronavirus.', 'Keeping Our People and Our Platforms Safe', 'To keep our people safe, we recently requested that anyone who can work from home do so in all of our offices around the world. We are also continuing to take the necessary steps to keep our platform safe.', 'Over the past couple of years we’ve substantially scaled up our investments in safety and security, including by rapidly growing content review teams and expanding our machine learning capabilities.For both our full-time employees and contract workforce there is some work that cannot be done from home due to safety, privacy and legal reasons.We have taken precautions to protect our workers by cutting down the number of people in any given office, implementing recommended work from home globally, physically spreading people out at any given office and doing additional cleaning. Given the rapidly evolving public health concerns, we are taking additional steps to protect our teams andwill be working with our partners over the course of this week to sendall contract workers who perform content review home, until further notice. We’ll ensure that all workers are paid during this time.', 'We believe the investments we’ve made over the past three years have prepared us for this situation. With fewer people available for human review we’ll continue to prioritize imminent harm and increase our reliance on proactive detection in other areas to remove violating content. We don’t expect this to impact people using our platform in any noticeable way. That said, there may be some limitations to this approach and we may see some longer response times and make more mistakes as a result.', 'These are unprecedented times, but the safety and security of our platform will continue.\\xa0 We are grateful to all of our teams working hard to continue doing the essential work to keep our community safe.', 'Working With Industry Partners', 'Joint industry statement from Facebook, Google, LinkedIn, Microsoft, Reddit, Twitter and YouTube', '“We are working closely together on COVID-19 response efforts. We’re helping millions of people stay connected while also jointly combating fraud and misinformation about the virus, elevating authoritative content on our platforms, and sharing critical updates in coordination with government healthcare agencies around the world. We invite other companies to join us as we work to keep our communities healthy and safe.”', '', 'Matching $20 Million in Donations to Support COVID-19 Relief Efforts', 'We’rematching $20 million in donationsto support COVID-19 relief efforts.', 'Connecting People With Credible Health Information on Instagram', 'We shared updates on our efforts to support the Instagram community during this time.', 'To help people get relevant and up-to-date resources, we will start showing more information from@WHOand local health ministries at the top of Instagram’s Feed in some countries.pic.twitter.com/czAHYItlEx', '— Instagram Comms (@InstagramComms)March 13, 2020', '', 'To thank the health workers who have been working tirelessly to keep their communities safe, we developed a sticker for people to show their gratitude on Instagram. This will be available in the stickers gallery.pic.twitter.com/BS5IKAWBuL', '— Instagram Comms (@InstagramComms)March 13, 2020', '', 'Supporting Businesses and Community Leaders', 'To help people stay safe and informed during the COVID-19 outbreak, we’re providing additional resources to our community. We shared a blog post on ourCommunity Hubto provide accurate information on disease prevention and connect community leaders with tools to help them manage their community. We also created aBusiness Resource Hubthat includes tips and trainings to help businesses navigate challenges during the COVID-19 outbreak and support their customers during this time.', 'Expanding Access to Facebook Local Alerts', 'In addition, we’re helping local governments and emergency response organizations more easily communicate with their communities. As COVID-19 has spread in the US, local governments have used Facebook to share critical information with their communities about this fast evolving situation. Because of the increasing need to get timely and accurate information to local communities, we’re expanding access to Facebook local alerts to even more municipal governments, state and local emergency response organizations and law enforcement agencies. State and local public health agencies will now also have the ability to push out timely, accurate information to their local communities. And we’ll provide additionaltraining to partnersas they start using local alerts to share best practices for using the tool most effectively.', 'Eligible organizations and government agencies canrequest access to the local alerts tool here.', 'Banning Ads and Commerce Listings for Medical Face Masks', 'We are temporarily banning advertisements and commerce listings, like those on Marketplace, that sell medical face masks. We’ll begin to enforce this change over the next few days. We already prohibit people from making health or medical claims related to the coronavirus in product listings on commerce surfaces, including those listings that guarantee a product will prevent someone from contracting it. We also have a dedicated channel for local governments to share listings they believe violate local laws. Our teams are monitoring the COVID-19 situation closely and will make necessary updates to our policies if we see people trying to exploit this public health emergency.', 'Update: We’re banning ads and commerce listings selling medical face masks. We’re monitoring COVID19 closely and will make necessary updates to our policies if we see people trying to exploit this public health emergency. We’ll start rolling out this change in the days ahead.', '— Rob Leathern (@robleathern)March 7, 2020', '', 'Removing COVID-19 Misinformation on Instagram', 'Today we shared updates about the changes we’ve made to keep the Instagram community safe and informed on COVID-19.', 'We’re removing known harmful misinformation related to COVID-19, and when someone taps on a hashtag related to COVID-19, we show resources from@WHO,@CDCand local health authorities.pic.twitter.com/Dw2Y8ZwfaI', '— Instagram Comms (@InstagramComms)March 6, 2020', '', 'Finally, we’re thinking through a longer term solution to help connect people searching COVID-19 related terms with credible information. In the meantime, we’re showing the accounts of leading health organizations in these searches to better connect people to credible resources.pic.twitter.com/RUNwJh94Cf', '— Instagram Comms (@InstagramComms)March 6, 2020', '', 'Supporting Global Health Organizations With Free Ads and More', 'CEO Mark Zuckerberg posted about the latest steps Facebook is taking.', 'As world health officials issue new guidance and warnings about coronavirus (COVID-19), we’re continuing our work to connect people to information from regional and local health organizations and limit the spread of misinformation and harmful content about the virus.', 'Connecting People to Accurate Information and Helpful Resources', 'Anyone who searches for information related to the virus on Facebook is shown educational pop-ups on top of search results connecting them to expert health organizations including the World Health Organization (WHO). We’ve launched these globallyover the last few weeksin all languages on Facebook, directing people to the WHO. In several countries we are directing people to their local ministry of health. For example, in the US we are directing people to information from the Centers for Disease Control and Prevention (CDC) and in Singapore, we’re directing people to the Singapore Ministry of Health. Moreover, in countries where the WHO has reported person-to-person transmission and deaths, we’ve shown additional messages to people toward the top of News Feed with more information.', '', 'Exploitative Tactics in Ads', 'Yesterday we put a new policy into effect to protect people from those trying to exploit this emergency for financial gain. This means we are now prohibiting ads for products that refer to the coronavirus in ways intended to create a panic or imply that their products guarantee a cure or prevent people from contracting it. For example, ads for face masks that imply they are the only ones still available or claim that they are guaranteed to prevent the virus from spreading will not be allowed to run on our platforms.', 'Today, the World Health Organization (WHO) declared the coronavirus a public health emergency of international concern. As the global public health community works to keep people safe, Facebook is supporting their work in several ways, most especially by working to limit the spread of misinformation and harmful content about the virus and connecting people to helpful information. Here are some specific steps we are taking.', 'Our global network of third-party fact-checkers are continuing their work reviewing content and debunking false claims that are spreading related to the coronavirus. When they rate information as false, we limit its spread on Facebook and Instagram and show people accurate information from these partners. We also send notifications to people who already shared or are trying to share this content to alert them that it’s been fact-checked.', 'We will also start to remove content with false claims or conspiracy theories that have been flagged by leading global health organizations and local health authorities that could cause harm to people who believe them. We are doing this as an extension of our existing policies to remove content that could cause physical harm. We’re focusing on claims that are designed to discourage treatment or taking appropriate precautions. This includes claims related to false cures or prevention methods — like drinking bleach cures the coronavirus — or claims that create confusion about health resources that are available. We will also block or restrict hashtags used to spread misinformation on Instagram, and are conducting proactive sweeps to find and remove as much of this content as we can.', 'Our platforms are already being used to help people connect with accurate information about the situation, including from global and regional health organizations. We’ve been closely coordinating with leading health organizations to make this easier and more accessible for people using Facebook and Instagram.', 'For example, we will help people get relevant and up-to-date information from partners through messages on top of News Feed on Facebook; these will be deployed based on guidance from the WHO. When people search for information related to the virus on Facebook or tap a related hashtag on Instagram, we willsurface an educational pop-up with credible information. We have also provided free advertising credits to enable organizations to run coronavirus education campaigns on Facebook and Instagram in affected regions and are discussing ways to provide additional assistance and support to health authorities.', 'We are empowering leading researchers at Harvard University’s School of Public Health and National Tsing Hua University in Taiwan by sharing aggregated and anonymized mobility data and high resolution population density maps to help inform their forecasting models for the spread of the virus as part of our broader Data for Good program. We may expand these efforts to a broader set of partners in the coming weeks. We are also helping partners understand how people are talking about the issue online through tools like CrowdTangle to better inform their efforts.', 'Not all of these steps are fully in place. It will take some time to roll them out across our platforms and step up our enforcement methods.', 'We will provide updates on additional steps we are taking in coordination with global and regional partners as the situation continues to evolve.']\n",
            "125 ['Note: For future Facebook updates about Oversight Board cases, please visit theTransparency Center.', 'Update on March 11, 2021 at 10:05AM PT:', 'When the Oversight Board issued its binding decision for this case last month, we implemented the decision and reinstated the case content. At that time the board also issued a non-binding recommendation, which we are responding to in the table below. Simultaneously we’ve started the process of reinstatingidentical content with parallel contextin line with the board’s decision. This action will affect content previously posted on Facebook and in the future, when we review identical content with parallel context, we will action it in line with this decision.', '', 'Update on February 18, 2021 at 12:00PM PT:', 'In accordance with the Oversight Board’s decision on February 12, 2021, Facebook has reinstated the case content.', 'Update on February 12, 2021 at 8:00AM PT:', 'We welcome the Oversight Board’sdecision today on this case. Facebook will review the board’s decision and reinstate the content within seven days, as outlined in the bylaws. We will update this post once the content has been restored.', 'In accordance with thebylaws, we will also initiate a review of identical content with parallel context. If we determine that we have the technical and operational capacity to take action on that content as well, we will do so promptly. For more information, please see our Newsroom post abouthow we will implement the board’s decisions. We will update this post again once any further action is taken on other identical content with parallel context.', 'After conducting a review of the policy advisory statement provided by the board in addition to their decision, we will update this post.', 'Originally published on December 3, 2020 at 5:00PM PT:', 'Today, theOversight Board selected a casereferred by Facebook regarding a post in a Group that appears to exist for Muslims in India. The post contains a statement about a sword being taken from its scabbard if people speak against the prophet. The post also references President Emmanuel Macron of France.', 'Facebook deemed this post a veiled threat, and we took it down for violating ourpolicy on Violence and Incitementas laid out in our Community Standards.', 'Facebook referred this case to the Oversight Board as an example of a challenging decision about statements that may incite violence even when not explicit. It also highlights an important tension we face when addressing religious speech that could be interpreted as a threat of violence.', 'We will implement the board’s decision once it has finished deliberating, and we will update this post accordingly. Please see theboard’s websitefor the decision when they issue it.']\n",
            "126 ['Note: For future Facebook updates about Oversight Board cases, please visit theTransparency Center.', 'Update on February 25, 2021 at 10:00AM PT:', 'When the board issued their binding decision for this case last month, we immediately implemented it and reinstated the case content. At that time they did not issue any non-binding recommendations for this case. We’ve started the process of reinstatingidentical content with parallel contextin line with the board’s decision. This action will affect not only content previously posted on Facebook but also future content.', 'Update on January 28, 2021 at 7:00AM PT:', 'We welcome the Oversight Board’sdecision today on this case. Facebook has acted to comply with the board’s decision immediately, and this content has been reinstated.', 'In accordance with thebylaws, we will also initiate a review of identical content with parallel context. If we determine that we have the technical and operational capacity to take action on that content as well, we will do so promptly. For more information, please see our post abouthow we will implement the board’s decisions. We will update this post again once any further action is taken on other identical content with parallel context.', 'Originally published on December 1, 2020 at 5:45AM PT:', 'Today, theOversight Board selected a caseappealed by someone on Facebook regarding a photo of a deceased child in connection with commentary on China’s treatment of Uyghur Muslims.', 'Facebook has taken down this content for violating ourpolicy on hate speech, as laid out in our Community Standards. We do not allow hate speech on Facebook because it creates an environment of intimidation and exclusion, and in some cases, may promote real-world violence.', 'We will implement the board’s decision once it has finished deliberating, and we will update this post accordingly. Please see theboard’s websitefor the decision when they issue it.']\n",
            "127 ['Note: For future Facebook updates about Oversight Board cases, please visit theTransparency Center.', 'Update on February 25, 2021 at 10:00AM PT:', 'When the board issued their binding decision for this case last month, we immediately implemented their decision and reinstated the case content. At that time they also issued a series of non-binding recommendations which we are responding to in the table below. Simultaneously we’ve started the process of reinstatingidentical content with parallel contextin line with the board’s decision. This action will affect not only content previously posted on Facebook but also future content.', '', 'Update on January 28, 2021 at 7:00AM PT:', 'We welcome the Oversight Board’sdecision today on this case. Facebook has acted to comply with the board’s decision immediately, and this content has been reinstated.', 'In accordance with thebylaws, we will also initiate a review of identical content with parallel context. If we determine that we have the technical and operational capacity to take action on that content as well, we will do so promptly. For more information, please see our post abouthow we will implement the board’s decisions. We will update this post again once any further action is taken on other identical content with parallel context.', 'After conducting a review of the policy advisory statement provided by the board in addition to their decision, we will update this post.', 'Originally published on December 1, 2020 at 5:45AM PT:', 'Today, theOversight Board selected a caseappealed by someone on Facebook regarding a post which contained an alleged quote from Joseph Goebbels, the Reich Minister of Propaganda in Nazi Germany.', 'Facebook has taken down this content for violating ourpolicy on dangerous individuals and organizations,as laid out in our Community Standards.', 'We will implement the board’s decision once it has finished deliberating, and we will update this post accordingly. Please see theboard’s websitefor the decision when they issue it.']\n",
            "128 ['Note: For future Facebook updates about Oversight Board cases, please visit theTransparency Center.', 'Update onDecember 3, 2020 at 5:00 PM PT:', 'The boardannouncedanupdate to this casetoday. As a result of a user deleting content on Facebook, this case has been deleted from our platform and from the board’s systems, which means the board will no longer be able to view or issue a decision on this case. Users are ultimately in control of their content on Facebook and have the right to permanently delete data associated with it. Since users can delete content on Facebook we expect there to be future instances when this happens before the board issues a decision, resulting in the case being removed from consideration. There will be no further updates to this case.', 'Originally published on December 1, 2020 at 5:45 AM PT:', 'Today, theOversight Board selected a caseappealed by someone on Facebook regarding comments made by a public figure about violence by the global Muslim community toward French people.', 'Facebook has taken down this content for violating ourpolicy on hate speech, as laid out in our Community Standards. We do not allow hate speech on Facebook because it creates an environment of intimidation and exclusion, and in some cases, may promote real-world violence.', 'We will implement the board’s decision once it has finished deliberating, and we will update this post accordingly. Please see theboard’s websitefor the decision when they issue it.']\n",
            "129 ['Note: For future Facebook updates about Oversight Board cases, please visit theTransparency Center.', 'Update on February 25, 2021 at 10:00AM PT:', 'When the board issued their binding decision for this case last month, we immediately implemented their decision and reinstated the case content. At that time they also issued a series of non-binding recommendations which we are responding to in the table below. Simultaneously we’ve started the process of reinstatingidentical content with parallel contextin line with the board’s decision. This action will affect not only content previously posted on Facebook but also future content.', '', 'Update on January 28, 2021 at 7:00AM PT:', 'We welcome the Oversight Board’sdecision today on this case. Facebook has acted to comply with the board’s decision immediately, this content has been reinstated.', 'In accordance with thebylaws, we will also initiate a review of identical content with parallel context. If we determine that we have the technical and operational capacity to take action on that content as well, we will do so promptly. For more information, please see our post abouthow we will implement the board’s decisions. We will update this post again once any further action is taken on other identical content with parallel context.', 'After conducting a review of the policy advisory statement provided by the board in addition to their decision, we will update this post.', 'Originally published on December 1, 2020 at 5:45AM PT:', 'Today, theOversight Board selected a casereferred by Facebook regarding a post in a Group claiming hydroxychloroquine and azithromycin is a cure for COVID-19 and criticizing the French government’s response to COVID-19.', 'Facebook took down this content for violatingour policy on Violence and Incitementas laid out in our Community Standards.', 'Facebook referred this case to the board because we found itsignificant and difficultas it creates tension betweenour values of voice and safety. While we are committed to preserving people’s ability to discuss and share information about the COVID-19 pandemic, and to debate the efficacy of potential treatments and mitigation strategies, we also want to limit the spread of false information that could lead to harm.', 'We will implement the board’s decision once it has finished deliberating, and we will update this post accordingly. Please see theboard’s websitefor the decision when they issue it.']\n",
            "130 ['Note: For future Facebook updates about Oversight Board cases, please visit theTransparency Center.', 'Update on February 25, 2021 at 10:00AM PT:', 'The board issued their binding decision for this case last month upholding our initial decision in this case. At that time they also issued a non-binding recommendation which we are responding to in the table below.', '', 'Update on January 28, 2021 at 7:00AM PT:', 'We welcome the Oversight Board’sdecision today on this case. The board decided to uphold Facebook’s decision so we have taken no further action related to this case or the content.', 'After conducting a review of the policy advisory statement provided by the board in addition to their decision, we will update this post.', 'Originally published on December 1, 2020 at 5:45AM PT:', 'Today, theOversight Board selected a caseappealed by someone on Facebook regarding historical photos purportedly showing churches in Baku and a caption indicating disdain for Azerbaijani people and support for Armenia in the Nagorno-Karabakh dispute.', 'Facebook has taken down this content for violating ourpolicy on hate speech, as laid out in our Community Standards. We do not allow hate speech on Facebook because it creates an environment of intimidation and exclusion, and in some cases, may promote real-world violence.', 'We will implement the board’s decision once it has finished deliberating, and we will update this post accordingly. Please see theboard’s websitefor the decision when they issue it.']\n",
            "131 ['Note: For future Facebook updates about Oversight Board cases, please visit theTransparency Center.', 'Update on February 25, 2021 at 10:00AM PT:', 'As noted below, Facebook previously reinstated this content as it did not violate our policies. The board issued their binding decision for this case last month confirming that this content should remain up. At that time they also issued a series of non-binding recommendations which we are responding to in the table below. Simultaneously we’ve started the process of ensuringidentical content with parallel contextremains up in line with the board’s decision.', '', 'Update on January 28, 2021 at 7:00AM PT:', 'We welcome the Oversight Board’sdecision today on this case. Facebook previously reinstated this content as it did not violate our policies and was removed in error so no further action will be taken on this content.', 'In accordance with thebylaws, we will also initiate a review of identical content with parallel context. If we determine that we have the technical and operational capacity to take action on that content as well, we will do so promptly. For more information, please see our post abouthow we will implement the board’s decisions. We will update this post again once any further action is taken on other identical content with parallel context.', 'After conducting a review of the policy advisory statement provided by the board in addition to their decision, we will update this post.', 'Originally published on December 1, 2020 at 5:45AM PT:', 'Today, theOversight Board selected a caseappealed by someone on Instagram regarding photos with nudity related to breast cancer symptoms.', 'Facebooktook downthis content for violating ourpolicy on Adult Nudity and Sexual Activity, as laid out in our Community Standards.However upon further review we determined we removed this content in error and have reinstated it. We continue to welcome the board’s review of this case – any decision they make on the content will be binding, and we welcome any policy guidance related to it.', 'We will implement the board’s decision once it has finished deliberating, and we will update this post accordingly. Please see theboard’s websitefor the decision when they issue it.']\n",
            "132 ['Today, for the first time, we are including the prevalence of hate speech on Facebook as part of our quarterlyCommunity Standards Enforcement Report.', 'Prevalenceestimates the percentage of times people see violating content on our platform. We calculate hate speech prevalence by selecting a sample of content seen on Facebook and then labeling how much of it violates our hate speech policies. Because hate speech depends on language and cultural context, we send these representative samples to reviewers across different languages and regions. Based on this methodology, we estimated the prevalence of hate speech from July 2020 to September 2020 was 0.10% to 0.11%. In other words, out of every 10,000 views of content on Facebook, 10 to 11 of them included hate speech.', 'We specificallymeasure how much harmful content may be seen on Facebook and Instagrambecausethe amount of times content is seen is not evenly distributed. One piece of content could go viral and be seen by lots of people in a very short amount of time, whereas other content could be on the internet for a long time and only be seen by a handful of people.', 'We evaluate the effectiveness of our enforcement by trying to keep the prevalence of hate speech on our platform as low as possible, while minimizing mistakes in the content that we remove.', 'Defining hate speech isn’t simple, as there are many differing opinions on what constitutes hate speech. Nuance, history, language, religion and changing cultural norms are all important factors to consider as we defineour policies.', 'Based on input from a wide array of globalexpertsand stakeholders, we define hate speech as anything that directly attacks people based on protected characteristics, including race, ethnicity, national origin, religious affiliation, sexual orientation, sex, gender, gender identity or serious disability or disease.', 'Over the last few years, we’ve expanded our policies to provide greater protections to people from different types of abuse. We’ve taken steps to combat white nationalism and white separatism; introduced new rules on content calling for violence against migrants; banned holocaust denial; and updated our policies to account for certain kinds of implicit hate speech, such as content depicting blackface, or stereotypes about Jewish people controlling the world.', 'Our goal is to remove hate speech any time we become aware of it, but we know we still have progress to make. Language continues to evolve, and a word that was not a slur yesterday may become one tomorrow. This means content enforcement is a delicate balance between making sure we don’t miss hate speech while not removing other forms of permissible speech. That’s why we prioritize themost critical contentfor people to reviewbased on factors such as virality, severity of harm and likelihood of violation.', 'When it comes to enforcement, we use a combination of user reports and technology to find hate speech on Facebook and Instagram. Every week, people across the world report millions of pieces of content to us that they believe violate our policies. These reports are reviewed in over 50 languages and give us insight into what’s happening on our platform so we can continue to refine our policies. We also strive to improve our reporting tools to make it easier for people to report content they think may violate our policies, but there are limitations with this. For example, in areas with lower digital literacy, people may be less aware of the option to file a user report. People also often report content they may dislike or disagree with, but that does not violate our policies. For example, users may report content from rival sports teams or spoilers for TV shows they haven’t watched yet. In addition, some content may be seen by a lot of people before it is reported, so we can’t rely on user reports alone.', 'We use AI to help prioritize content for review, so our reviewers can focus on content that poses the most harm, and spend more timetraining and measuring the quality of our automated systems.', 'We’ve developed AI tools and systems to proactively find and remove hate speech at scale. Because hate speech is so contextual, AI detection requires an ability to review posts holistically, with context, and across multiple languages.', 'Advancements in AI technologieshave allowed us to remove more hate speech from Facebook over time, and find more of it before users report it to us. When we first began reporting our metrics for hate speech, in Q4 of 2017, our proactive detection rate was 23.6%. This means that of the hate speech we removed, 23.6% of it was found before a user reported it to us. The remaining majority of it was removed after a user reported it. Today we proactively detect about 95% of hate speech content we remove. Whether content is proactively detected or reported by users, we often use AI to take action on the straightforward cases and prioritize the more nuanced cases, where context needs to be considered, for our reviewers.', '', 'We’ve invested billions of dollars in people and technology to enforce these rules, and we have more than 35,000 people working on safety and security at Facebook. As speech continues to evolve over time, we continue to revise our policies to reflect changing societal trends. But we believe decisions about free expression and safety shouldn’t be made by Facebook alone, so we continue to consultthird-party experts in shaping our policies and enforcement tactics. Andfor difficult and significant content decisions, we can now refer cases to theOversight Boardfor their independent review and binding decisions.', 'With the use of prevalence, user reports and AI, we’re working to keep Facebook and Instagram inclusive and safe places for everyone who uses them.']\n",
            "133 ['Today we’re publishing ourCommunity Standards Enforcement Reportfor the third quarter of 2020.This reportprovides metrics on how we enforced our policies from July through September and includes metrics across 12 policies on Facebook and 10 policies on Instagram.', 'For the first time, we’re including the prevalence of hate speech on Facebook globally. In Q3 2020, hate speech prevalence was 0.10% – 0.11% or 10 to 11 views of hate speech for every 10,000 views of content. Due to our investments in AI, we have been able to remove more hate speech and find more of it proactively before users report it to us. Our enforcement metrics this quarter, including how much hate speech content we found proactively and how much content we took action on, indicate that we’re making progress catching harmful content. Prevalence, on the other hand,estimates the percentage of times people see violating content on our platform.Read more aboutour work onhate speech.', 'While the COVID-19 pandemic continues to disrupt our content review workforce, we are seeing some enforcement metrics return to pre-pandemic levels. Our proactive detection rates for violating content are up from Q2 across most policies, due to improvements in AI and expanding our detection technologies to more languages. Even with a reduced review capacity, we still prioritize the most sensitive content for people to review, which includes areas like suicide and self-injury and child nudity.', 'On Facebook in Q3, we took action on:', 'On Instagram in Q3, we took action on:', 'The increase in our proactive detection rate for hate speech on Instagram was driven in part by improving our proactive detection technology for English, Arabic and Spanish languages, and expanding automation technology. We expect fluctuations in these numbers as we continue to adapt to COVID-related workforce challenges.', 'Today we are updating ourCommunity Standards websiteto include additionalpolicies that require more context and can’t always be applied at scale. These policies often require specialized teams to gather more information on a given issue in order to make decisions. For example, we require additional information, typically from a family member, before removing a deceased person’s account. We may also use additional information from trusted partners with local expertise or public news sources to help us make enforcement decisions for these nuanced policies.', 'Several of these policies have been announced before. For example, our policy that prohibits posting misinformation and unverifiable rumors that contribute to the risk of imminent violence or physical harm, and our policy to add a warning label to sensitive content such as imagery posted by a news agency that depicts child nudity in the context of famine, genocide, war crimes or crimes against humanity.While these policies are not new, we are sharing more details today to be even more transparent about our enforcement practices.Moving forward, just as we do with our scaled policies, we will continue to publicly update the Community Standards monthly as new policies are developed that require additional context.', 'We’ll continue improving our technology and enforcement efforts to remove harmful content from our platform and keep people safe while using our apps.', 'The Community Standards Enforcement Report is published in conjunction with our biannualTransparency Reportthat shares numbers on government requests for user data, content restrictions based on local law, intellectual property takedowns and internet disruptions.']\n",
            "134 ['We want to do everything we can to keep people safe on Instagram.We’ve worked withexperts to better understand the deeply complex issues of mental health, suicide and self-harm, and how best to support those who are vulnerable. No one at Instagram takes these issues lightly, including me.We’ve made progressover the past few years, and today we’re rolling out more technology in Europe to help with our efforts. But our work here is never done and we need to constantly look for ways to do more.', 'We recognize that these are deeply personal issues for the people who are affected. They are also complicated and always evolving, which is why we continue to update our policies and products so we can best support our community. We’ve never allowed anyone to promote or encourage suicide or self-harm on Instagram, andlast year we updated our policies to remove all graphic suicide and self-harm content. We also extended our policies to disallow fictional depictions like drawings, memes or other imagery that shows materials or methods associated with suicide or self-harm.', 'It’s not enough to address these difficult issues through policies and products alone. We also believe it’s important to provide help and support to the people who are struggling. Weoffersupport to people who search for accounts or hashtags related to suicide and self-harm and direct them to local organizations that can help. We’ve also collaborated with Samaritans, the suicide prevention charity, on theirindustry guidelines, which are designed to help platforms like ours strike the important balance between tackling harmful content and providing sources of support to those who need it.', 'We use technologyto help us proactively find and remove more harmful suicide and self-harm content. Our technology finds posts that may contain suicide or self-harm content and sends them to human reviewers to make the final decision and take the right action. Those actions include removing the content; connecting the poster to local organizations who can help; or, in the most severe cases, calling emergency services. Between April and June this year, over 90% of the suicide and self-harm content we took action on was found by our own technology before anyone reported it to us. But our goal is to get that number as close as we possibly can to 100%.', 'Until now,we’ve only been able to use this technologyto find suicide and self-harm contentoutsidethe European Union, which made it harder for us to proactively find content and send people help. I’m pleased to share that, today in the EU, we’re rolling out some of this technology, which will work across both Facebook and Instagram. We can now look for posts that likely break our rules around suicide and self-harm and make them less visible by automatically removing them from places like Explore. And when our technology is really confident that a post breaks our rules, we can now automatically remove it altogether.', 'This is an important step that will protect more people in the EU. But we want to do a lot more. The next step is using our technology not just to find the content and make it less visible, but to send it to our human reviewers and get people help, like we do everywhere else in the world. Not having this piece in place in the EU makes it harder for us to remove more harmful content, and connect people to local organizations and emergency services.We’re in current discussions with regulators and governments about how best to bring this technology to the EU, while recognizing their privacy considerations. We think and hope we can find the right balance so that we can do more. These issues are too important not to push for more.', 'We believe our community should be able to hold us accountable for how well we enforce our policies and take action on harmful content. That’s why we publish regular Community Standards Enforcement Reports to share global data on how much violating content we’re taking action on, and what percentage of that content we’re finding ourselves, before it’s reported. This timeline outlines the progress we’ve made on tackling suicide and self-harm content on Instagram, as shown through these reports.']\n",
            "135 ['Today we are updating our hate speech policy to prohibit any content that denies or distorts the Holocaust.', 'Organizations that study trends in hate speech are reporting increases in online attacks against many groups worldwide, and we continue our efforts to remove it. We have banned more than 250 white supremacist organizations and updated our policies to address militia groups and QAnon. We also routinely ban other individuals and organizations globally, and we took down 22.5 million pieces of hate speech from our platform in the second quarter of this year. Following a year of consultation with external experts, we recently banned anti-Semitic stereotypes about the collective power of Jews that often depicts them running the world or its major institutions.', 'Today’s announcement marks another step in our effort to fight hate on our services. Our decision is supported by the well-documented rise in anti-Semitism globally and the alarming level of ignorance about the Holocaust, especially among young people. According to a recent survey of adults in the US aged 18-39, almost a quarter said they believed the Holocaust was a myth, that it had been exaggerated or they weren’t sure.', 'Institutions focused on Holocaust research and remembrance, such as Yad Vashem, have noted that Holocaust education is also a key component in combatting anti-Semitism. Beginning later this year, we will direct anyone to credible information off Facebook if they search for terms associated with the Holocaust or its denial on our platform.', 'For many years, we have worked with communities around the world to help us understand how hatred, including anti-Semitism, is expressed online. These efforts have included regular discussions with groups that have a global reach, like the World Jewish Congress and the American Jewish Committee, as well as organizations focused on protecting local Jewish communities such as Community Security Trust in the UK. We’ve also worked with institutions and groups that combat hate and anti-Semitism such as the Simon Wiesenthal Center.', 'Enforcement of these policies cannot happen overnight. There is a range of content that can violate these policies, and it will take some time to train our reviewers and systems on enforcement. We are grateful to many partners for their input and candor as we work to keep our platform safe.']\n",
            "136 ['Last week, Vice President of Global Affairs and Communications Nick Clegg spoke with Richard Waters of the Financial Times, as part of The Next Web conference, about how to balance regulation and innovation.', 'As part of this discussion, Nick explained the new measures Facebook has put in place to protect the 2020 US presidential election, its efforts to protect elections around the world since 2016, progress in removing harmful content, and the need for a solution to EU-US data flows to avoid economic damage.', 'The full discussion can be watched above. The following paragraphs are an edited transcript of Nick’s remarks on select topics to provide a snapshot of the points he raised during the conversation.', 'Since this discussion, we have rolled out severalnew measures in the run up to the US elections, including prohibit ads that seek to undermine the ultimate outcome of the election and planning to temporarily stop running all social issue, electoral, and political ads in the US after the polls close on November 3, to reduce opportunities for confusion or abuse.', 'This is a polarized and aggressive election at a difficult time for the world and for the country, in the midst of this pandemic and its damaging socioeconomic effects.', 'One of the things we’re focused on is what happens after the election. We have specific and concrete measures for if a candidate were to declare prematurely victory before the official results are in.', 'First, we will label the post so that people will see that the results have not yet been certified and that the declaration of victory is premature.', 'Second, we’re working with Reuters and others to make sure that once the election results are definitively certified, we can convey that at great volume to tens of millions of Americans by prominently displaying them in their newsfeeds.', 'We are also en route to our target of having 4 million Americans registered to vote and we have a new tool to help us: the Voting Information Center. This will be displayed at the top of people’s News Feeds from now until November 3rd and provides information about how to vote, when to vote, and how to fill in a mail-in ballot according to the local rules.', 'Facebook has moved with enormous ambition and speed since the mistakes of the 2016 election, which clearly shook the company down to its roots.', 'What we’ve put in place recently is a final iteration of additional guardrails. These come on top of four years of work to make sure that 2020 is, at least as far as Facebook is concerned, an election which is conducted on our platform better than it was in 2016.', 'Since then, there have been more than 200 elections around the world, where we have constantly iterated to improve our election defense mechanisms. We’ve employed 35,000 people and we work with 70 fact checkers in over 50 languages. We have an Ads Library to provide transparency on who’s paying for ads, who’s running them, which voters they’re trying to address, and how much money they’re spending. This is far more transparent than anything that exists in the radio, television or print media.', 'Over the last year, we’ve spent more money — billions of dollars — on the integrity of our platforms than the total revenues of the company when it was floated back in 2012.', 'You are never going to eliminate everything you don’t want online. So the question is, are we able to hold ourselves to account for making significant progress in meeting people’s expectations at scale? Now, on that, we’ve done some very bold new things.', 'Two years ago we were only able to identify 23% of hate speech before it’s reported to us, but we now do so in over 90% of cases. This shows that our machine learning tools, and in particular AI systems, are able to operate at scale. Last year we removed 6.5 billion fake accounts, which is significant progress.', 'The European Union and the US need to flesh out a solution that enables data to be transferred out of Europe to other jurisdictions. The European Court of Justice first struck down Safe Harbour, then struck down Privacy Shield, and now the Irish Data Protection Commissioner appears to be raising questions about the use of Standard Contract Clauses, which are used by the vast majority of companies in Europe.', 'At the heart of this is the court’s view that the data protections which are afforded to EU citizens cannot be guaranteed in view of the US surveillance patterns. This is even though those EU data protection provisions explicitly carve out for EU member states surveillance powers which in many ways are just as intrusive as the American surveillance powers.', 'Like many other companies, we are caught in the middle of this. We’re all looking for legal certainty, which can only be provided by the EU and the US negotiating a successor regime for Privacy Shield. In the meantime, I hope that the ability for companies to transfer data is not suddenly turned off, because that would deliver a dramatic shock to the data economy, in Europe and elsewhere.', 'We have data centers in Europe and all around the world. The issue is not about where data is located but about who has access to it. The idea that you can divide up global data into perfectly segmented cake slices is not something which anyone who knows anything about the data economy thinks is realistic. But even if you did it, it doesn’t actually answer the underlying issue of access to that data, which is in dispute between the European Union and the US. In the end, the European Union and the US have to resolve this through political negotiation.']\n",
            "137 ['On World Suicide Prevention Day, we want to raise awareness of a vital public health issue that profoundly affects individuals, their loved ones and the communities around them – as we sadly have seen, yet again, in recent weeks.', 'During COVID-19, suicide has become an even greater risk. A Junestudyfrom the US Centers for Disease Control and Prevention found that the pandemic is having a serious impact on the mental health ofyoung adults, caregivers, essential workers and minoritiesin particular. One in four young adults aged 18-24 said they considered suicide in the 30 days prior to the study. They specifically cited the pandemic as a factor.', 'Since the pandemic began, we have taken a number of additional steps to keep people safe, including providing people with tips we developed with global experts, localized resources and easy access to over 100 local crisis helplines through ourCOVID-19 Information Center.Expertshave made clear that making these tips and resources easier to find is key to those seeking help. We will be expanding them soon.', 'We’re taking more steps to help those who might need it, including by:', 'We are committed to doing all we can to help those who use our platforms to stay safe. Visit ourSuicide Prevention Resource pageto learn more.']\n",
            "138 ['Thousands of European and US businesses rely on the safe and legal transfer of data between jurisdictions. International data transfers underpin the global economy and support many of the services that are fundamental to our daily lives.', 'In July, the Court of Justice of the European Union (CJEU)invalidatedPrivacy Shield, a legal framework regulating transfers of personal data from the EU to the US. At the same time, the CJEU stated that Standard Contractual Clauses, (SCCs), an alternative legal mechanism for transferring data from the EU to a third country, continue to be valid. But the rationale in invalidating Privacy Shield has nonetheless created significant uncertainty – not just for US tech companies, or even for all the European businesses who rely on online services to reach new customers, but for all European businesses with transatlantic data flows.', 'With theestablishmentof a European Data Protection Board taskforce to consider how to apply the CJEU ruling, as well as ajoint statementfrom the EU Commission and US Department of Commerce that they have initiated discussions for an “enhanced” EU-US Privacy Shield, we are setting out our position on how to secure the long term stability of international data transfers. We supportglobal rules that can ensure consistent treatment of data around the world.', 'In its recent decision, the CJEU invalidated the Privacy Shield mechanism for transferring data between the EU and US, due to concerns over US national security laws. Before the ruling,more than 5,000companies relied on Privacy Shield.', 'Although the court also ruled that Standard Contractual Clauses (SCCs) remain valid (providing the data exporter puts in place appropriate safeguards to ensure a high level of protection for data subjects), its rationale in invalidating Privacy Shield has prompted a discussion around businesses’ reliance on SCCs.', 'Like many other businesses, Facebook relies on SCCs to transfer data to countries outside the EU, including to the United States. Since the CJEU’s ruling in July, Facebook has been working hard to follow the steps set out by the Court to ensure that we can continue to transfer data in a safe and secure way. This includes ensuring that we have robust safeguards in place, such as industry standard encryption and security measures, and comprehensive policies governing how we respond to legal requests for data.', 'The Irish Data Protection Commission (IDPC) has commenced an inquiry into Facebook controlled EU-US data transfers, and has suggested that SCCs cannot in practice be used for EU-US data transfers. While this approach is subject to further process, if followed, it could have a far reaching effect on businesses that rely on SCCs and on the online services many people and businesses rely on.', 'A lack of safe, secure and legal international data transfers would damage the economy and hamper the growth of data-driven businesses in the EU, just as we seek a recovery from COVID-19. The impact would be felt by businesses large and small, across multiple sectors. In the worst case scenario, this could mean that a small tech start up in Germany would no longer be able to use a US-based cloud provider. A Spanish product development company could no longer be able to run an operation across multiple time zones. A French retailer may find they can no longer maintain a call centre in Morocco.', 'The effects would reach beyond the business world, and could impact critical public services such as health and education. Ireland’s Covid Tracking App states, in its terms, that it relies on SCCs as one of a number of mechanisms to transfer data to one of its processors in the US. International cloud providers and email platforms provide services to schools, Universities and hospitals across Europe. Millions of people use video conferencing software every day, to keep in touch with friends and family who live in different countries.', 'Businesses need clear, global rules, underpinned by the strong rule of law, to protect transatlantic data flows over the long term.', 'The EU has led the way in establishing a framework for data protection that protects and empowers users. Privacy rules will continue to evolve, and global rules can ensure the consistent treatment of data wherever it is stored. Facebook therefore welcomes the efforts already underway between EU and US lawmakers toevaluate the potential for an “enhanced” EU-US framework – a Privacy Shield Plus. These efforts will need to recognise that EU Member States and the US are both democracies that share common values and the rule of law, are deeply culturally, socially and commercially interconnected, and have very similar data surveillance powers and practices', 'Werecognize that building a sustainable framework that supports frictionless data flows to other countries and legal systems, while at the same time ensuring that the fundamental rights of EU users are respected, is not an easy task and will take time. Whilepolicymakers are working towards a sustainable, long-term solution, we urge regulators to adopt a proportionate and pragmatic approach to minimise disruption to the many thousands of businesses who, like Facebook, have been relying on these mechanisms in good faith to transfer data in a safe and secure way.', 'Our priority is to ensure that our users, advertisers, customers and partners can continue to enjoy Facebook services while keeping their data safe and secure. We will continue to transfer data in compliance with the recent CJEU ruling and until we receive further guidance.']\n",
            "139 ['In the midst of a global pandemic, upcoming elections and increasing racial tensions, we’re seeing a shift in the way people are using Instagram. More than ever, people are turning to the platform to raise awareness for the racial, civic and social causes they care about. It’s a big part of why wecommitted in Juneto review the ways Instagram could be underserving certain groups of people. We have a responsibility to look at what we build and how we build, so that people’s experiences with our products better mirror the actions and aspirations of our community.', 'Below is an update on areas where we’ve made progress this summer. This is by no means comprehensive, and we have a lot more to do, but I’m going to share regular updates so our community knows that this work is important and ongoing.', 'To ensure this work is fully supported, we’ve created a dedicated product group – the Instagram Equity team – that will focus on better understanding and addressing bias in our product development and people’s experiences on Instagram. The Equity team will focus on creating fair and equitable products. This includes working with our Responsible AI team to ensure algorithmic fairness. In addition, they’ll create new features that respond to the needs of underserved communities. Separate from this new product group, we’re alsohiring a new Director of Diversity and Inclusionfor Instagram who will help advance Instagram’s goal of finding, keeping and growing more diverse talent.', 'We’ve developed and updated a number of our company policies to support communities worldwide. Weupdated our policiesto more specifically account for certain kinds of implicit hate speech, such as content depicting blackface, or stereotypes about Jewish people. We also strengthened enforcements against people who make serious rape threats, and we’ll now disable any account that makes these threats as soon as we become aware of them, rather than just removing the content.In addition, we’ll ensure involuntary public figures – people who may not have sought attention and who we’ve seen are often members of marginalized communities – are protected from harassment and bullying just as they were before finding themselves in the public eye.', 'We’ve continued to prioritize the removal of content that violates ourpolicy against hate groups. This includesremoving 23 different banned organizations, over half of which supported white supremacy. In addition, we recently announced updates totake action on organizations tied to violence,such as QAnon.', 'We’ve also made some changes for creators and businesses. For example, people with Business and Creator accounts can now manage who can send them direct messages.And we’ve begun expanding comment warnings to include comments in Live,so people will be asked to reconsider comments that might be offensive before they’re posted.', 'We spent the past two months reviewing Instagram’s verification practices and have started making changes to ensure a fairer process. An account must meet certain criteria before we verify it, including a degree of notability. We measure notability through press articles about the person applying for verification. We’ve now expanded our list of press sources we consider in the process to include more Black, LGBTQ+, and Latinx media.', 'While follower count was never a requirement to get verified through the in-app form (which anyone can apply for), we did have certain systems in place that prioritized accounts with high followings to help get through the tens of thousands of requests received every day. We’ve since removed this from the automated part of the process.', 'In response to ongoing concerns around perceived censorship on Instagram,we recently publishedthe guidelines we use to determine the types of content that can appear in places like Explore. Our hope is that people will better understand why some types of content aren’t included in recommendations across Instagram and Facebook, and therefore may not be distributed as widely. We consulted over 50 leading experts specializing in recommendation systems, social computing, freedom of expression, safety, civil and digital rights in developing these guidelines.']\n",
            "140 ['As a part of our ongoing efforts to provide people with a safer, more private messaging experience, today we’re introducing a forwarding limit on Messenger, so messages can only be forwarded to five people or groups at a time. Limiting forwarding is an effective way to slow the spread of viral misinformation and harmful content that has the potential to cause real world harm.', 'We believe controlling the spread of misinformation is critical as the global COVID-19 pandemic continues and we head toward major elections in the US, New Zealand and other countries. We’ve taken steps to provide people with greater transparency and accurate information. OurCoronavirus (COVID-19) Community Hubgives people access to up-to-date information and resources designed to help them stay safe. And ourVoting Information Centerand voter registration notifications ensure people know how to register to vote and encourage them to make their voices heard. We are introducing a forwarding limit on Messenger to help curb the efforts of those looking to cause chaos, sow uncertainty or inadvertently undermine accurate information.', 'We want Messenger to be a safe and trustworthy platform to connect with friends and family.Earlier this year weintroducedfeatureslike safety notifications, two-factor authentication, and easier ways to block and report unwanted messages. This new feature provides yet another layer of protection by limiting the spread of viral misinformation or harmful content, and we believe it will help keep people safer online.']\n",
            "141 ['Update on October 17, 2022 at 5:00 AM PT:', 'As part of our work to continue enforcing this policy, as of August 15, 2022, we have identified over 1,151 militarized social movements to date and in total, removed about 4,200 Pages, 20,800 groups, 200 events, 59,800 Facebook profiles and 8,900 Instagram accounts. We’ve also removed about 4,200 Pages, 12,000 groups, 840 events, 67,200 Facebook profiles and 38,800 Instagram accounts for violating our policy against QAnon.', 'We continue to strengthen our enforcement by identifying additional militarized social movements and new terms associated with QAnon. We’ll continue consulting experts to inform our strategy and will identify and remove content accordingly.', 'Update on November 9, 2021 at 10:00 AM PT:', 'As part of our work to continue enforcing this policy, as of September 14, 2021, we have identified over 1,013 militarized social movements to date and in total, removed about 4,000 Pages, 20,600 groups, 190 events, 54,900 Facebook profiles and 8,300 Instagram accounts. We’ve also removed about 3,900 Pages, 11,300 groups, 640 events, 50,300 Facebook profiles and 32,500 Instagram accounts for violating our policy against QAnon.', 'We continue to strengthen our enforcement by identifying additional militarized social movements and new terms associated with QAnon. Improvements in our ability to detect text within images has helped us to remove profiles and accounts focused on sharing a high volume of QAnon content. We’ll continue consulting experts to inform our strategy and will identify and remove content accordingly.', 'Update on January 19, 2021 at 8:12 PM PT:', 'We remain vigilant in enforcing our expanded Dangerous Individuals and Organizations policy against militarized social movements and violence-inducing conspiracy networks, such as QAnon. This effort was front and center during our work around the US presidential election last year. From August to November 30, 2020, we removed about 3,200 Pages, 18,800 groups, 100 events, 23,300 Facebook profiles and 7400 Instagram accounts for violating our policy against militarized social movements. At the same time, we also removed about 3,000 Pages, 9,800 groups, 420 events, 16,200 Facebook profiles, and 25,000 Instagram accounts for violating our policy against QAnon.', 'Since then, we’ve continued to enforce this policy. As of January 12, 2021, we have identified over 890 militarized social movements to date and in total, removed about 3,400 Pages, 19,500 groups, 120 events, 25,300 Facebook profiles and 7500 Instagram accounts. We’ve also removed about 3,300 Pages, 10,500 groups, 510 events, 18,300 Facebook profiles and 27,300 Instagram accounts for violating our policy against QAnon.', 'We continue to strengthen our enforcement by identifying additional militarized social movements, new terms associated with QAnon and how people attempt to skirt our detection, including focusing more on Facebook profiles used to organize and promote these movements and groups on our platform. We’ll continue consulting experts to inform our strategy and will identify and remove content accordingly.These groups are constantly working to avoid our enforcement and we’ll continue to study how they evolve in order to keep people safe.', 'Update on October 27, 2020 at 6:19PM PT:', 'In August, we expanded our Dangerous Individuals and Organizations policy to address militarized social movements and violence-inducing conspiracy networks, such as QAnon. Since then, we’ve identified over 600 militarized social movements, removing about 2,400 Pages, 14,200 Groups and about 1,300 Instagram accounts they maintained, and in addition, we’ve removed about 1,700 Pages, 5,600 Groups and about 18,700 Instagram accounts representing QAnon.', 'The number of identified militarized social movements reflects a range of offline groups including long-standing organizations, recently rebranded groups, and smaller, newly established organizations. And the numbers of removals reflect differences in how Facebook and Instagram are used. For example, there were fewer Facebook Groups tied to QAnon than Instagram accounts, but these groups often had more members compared to the Instagram accounts which had fewer followers.', 'We are continuing to strengthen our enforcement by identifying additional militarized social movements, and removing more Groups, Pages and Instagram accounts tied to QAnon. We’ll continue consulting experts to inform our enforcement strategy and identifying and removing content accordingly.', 'Update on October 21, 2020 at 10:00AM PT:', 'An Update on Our Enforcement Against QAnon', 'Starting today, when someone searches for terms related to QAnon on Facebook and Instagram, we will redirect them to credible resources fromthe Global Network on Extremism and Technology (GNET), the academic research network of the Global Internet Forum to Counter Terrorism. This is the latest expansion of ourRedirect Initiativeto help combat violent extremism and will direct people to resources that can help inform them of the realities of QAnon and its ties to violence and real world harm.', 'As we continue to study the impact of our enforcement against QAnon, we’ll partner with GNET to assess the impact of this Redirect Initiative, and we’ll continue to reassess the list of terms that, when searched for on our platform, should direct people to these resources.', 'Update on October 6, 2020 at 2:00PM PT:', 'On August 19, we announced a set of measures designed to disrupt the ability of QAnon and Militarized Social Movements to operate and organize on our platform. In the first month, we removed over 1,500 Pages and Groups for QAnon containing discussions of potential violence and over 6,500 Pages and Groups tied to more than 300 Militarized Social Movements. But we believe these efforts need to be strengthened when addressing QAnon.', 'Starting today, we will remove any Facebook Pages, Groups and Instagram accounts representing QAnon, even if they contain no violent content. This is an update from the initial policy in August that removed Pages, Groups and Instagram accounts associated with QAnon when they discussed potential violence while imposing a series of restrictions to limit the reach of other Pages, Groups and Instagram accounts associated with the movement. Pages, Groups and Instagram accounts that represent an identified Militarized Social Movement are already prohibited. And we will continue to disable the profiles of admins who manage Pages and Groups removed for violating this policy, as we began doing in August.', 'We are starting to enforce this updated policy today and are removing content accordingly, but this work will take time and need to continue in the coming days and weeks. Our Dangerous Organizations Operations team will continue to enforce this policy and proactively detect content for removal instead of relying on user reports. These are specialists who study and respond to new evolutions in violating content from this movement and their internal detection has provided better leads in identifying new evolutions in violating contentthan sifting through user reports.', 'We’ve been vigilant in enforcing our policy and studying its impact on the platform but we’ve seen several issues that led to today’s update. For example, while we’ve removed QAnon content that celebrates and supports violence, we’ve seen other QAnon content tied to different forms of real world harm, including recent claims that the west coast wildfires were started by certain groups, which diverted attention of local officials from fighting the fires and protecting the public. Additionally, QAnon messaging changes very quickly and we see networks of supporters build an audience with one message and then quickly pivot to another. We aim to combat this more effectively with this update that strengthens and expands our enforcement against the conspiracy theory movement.', 'This is not the first update to this policy – we began directing people to credible child safety resources when they search for certain child safety hashtags last week – and we continue to work with external experts to address QAnon supporters using the issue of child safety to recruit and organize. We expect renewed attempts to evade our detection, both in behavior and content shared on our platform, so we will continue to study the impact of our efforts and be ready to update our policy and enforcement as necessary.', 'Update on September 30, 2020 at 4:10PM PT:', 'Today we’re sharing a few updates on our enforcement against militarized social movements and QAnon:', 'On September 16, we started down-ranking content in the Pages and Groups that have been restricted but not removed. Now, people who are members of Groups that have been restricted and follow Pages that have been restricted, will see content from these Groups and Pages further down in their News Feed.', 'As of yesterday, we are also prohibiting anyone on our platform from running ads that praise, support or represent militarized social movements and QAnon.', 'We are taking steps to address evidence that QAnon adherents are increasingly using the issue of child safety and hashtags like #savethechildren to recruit and organize. Starting today, we will direct people to credible child safety resources when they search for certain child safety hashtags. In addition, content about QAnon and child safety is eligible for fact checking through our third-party fact-checking program. Content that is debunked will be reduced in News Feed and filtered from Explore and hashtags on Instagram, will receive a label (so that people who see it, try to share it or already have, will see more context), and it will be rejected as an ad.', 'Originally published on August 19, 2020 at 12:00PM PT:', 'Today we are taking action against Facebook Pages, Groups and Instagram accounts tied to offline anarchist groups that support violent acts amidst protests, US-based militia organizations and QAnon. We already remove content calling for or advocating violence and we ban organizations and individuals that proclaim a violent mission. However, we have seen growing movements that, while not directly organizing violence, have celebrated violent acts, shown that they have weapons and suggest they will use them, or have individual followers with patterns of violent behavior. So today we are expanding our Dangerous Individuals and Organizations policy to address organizations and movements that have demonstrated significant risks to public safety but do not meet the rigorous criteria to be designated as a dangerous organization and banned from having any presence on our platform. While we will allow people to post content that supports these movements and groups, so long as they do not otherwise violate our content policies, we will restrict their ability to organize on our platform.', 'Under this policy expansion, we will impose restrictions to limit the spread of content from Facebook Pages, Groups and Instagram accounts. We will also remove Pages, Groups and Instagram accounts where we identify discussions of potential violence, including when they use veiled language and symbols particular to the movement to do so.', 'We will take the following actions – some effective immediately, and others coming soon:', 'As a result of some of the actions we’ve already taken, we’ve removed over 790 groups, 100 Pages and 1,500 ads tied to QAnon from Facebook, blocked over 300 hashtags across Facebook and Instagram, and additionally imposed restrictions on over 1,950 Groups and 440 Pages on Facebook and over 10,000 accounts on Instagram. These numbers reflect differences in how Facebook and Instagram are used, with fewer Groups on Facebook with higher membership rates and a greater number of Instagram accounts with fewer followers comparably. Those Pages, Groups and Instagram accounts that have been restricted are still subject to removal as our team continues to review their content against our updated policy, as will others we identify subsequently. For militia organizations and those encouraging riots, including some who may identify as Antifa, we’ve initially removed over 980 groups, 520 Pages and 160 ads from Facebook. We’ve also restricted over 1,400 hashtags related to these groups and organizations on Instagram.', 'Today’s update focuses on our Dangerous Individuals and Organizations policy but we will continue to review content and accounts against all of our content policies in an effort to keep people safe. We will remove content from these movements that violate any of our policies, including those against fake accounts, harassment, hate speech and/or inciting violence. Misinformation that does not put people at risk of imminent violence or physical harm but is rated false by third-party fact-checkers will be reduced in News Feed so fewer people see it. And any non-state actor or group that qualifies as a dangerous individual or organization will be banned from our platform. Our teams will also study trends in attempts to skirt our enforcement so we can adapt. These movements and groups evolve quickly, and our teams will follow them closely and consult with outside experts so we can continue to enforce our policies against them.']\n",
            "142 ['Today we’re publishing the sixth edition of ourCommunity Standards Enforcement Report, our first quarterly update, providing metrics on how we enforced our policies from April 2020 through June 2020. This report includes metrics across 12 policies on Facebook and 10 policies on Instagram.', 'Due to the COVID-19 pandemic, we sent our content reviewers home in March to protect their health and safety and relied more heavily on our technology to help us review content. We’ve since brought many reviewers back online from home and, where it is safe, a smaller number into the office. We’ll continue usingtechnology to prioritizethe review ofcontent that has the potential to cause the most harm.Today’s report shows the impact of COVID-19 on our content moderation and demonstrates that, while our technology for identifying and removing violating content is improving, there will continue to be areas where we rely on people to both review content and train our technology.', 'For example, we rely heavily on people to review suicide and self-injury and child exploitative content, and help improve the technology that proactively finds and removes identical or near-identical content that violates these policies. With fewer content reviewers, we took action on fewer pieces of content on both Facebook and Instagram for suicide and self-injury, and child nudity and sexual exploitation on Instagram. Despite these decreases, we prioritized and took action on the most harmful content within these categories. Our focus remains on finding and removing this content while increasing reviewer capacity as quickly and as safely as possible.', 'The number of appeals is also much lower in this report because we couldn’t always offer them. We let people know about this and if they felt we made a mistake, we still gave people the option to tell us they disagreed with our decision. We reviewed many of these instances, and restored content when appropriate. Lastly, because we’ve prioritized removing harmful content over measuring certain efforts during this time, we were unable to calculate the prevalence of violent and graphic content, and adult nudity and sexual activity. We anticipate we’ll be able to share these metrics for Q3 in our next report.', 'Despite the impact of COVID-19, improvements to our technology enabled us to take action on more content in some areas, and increase our proactive detection rate in others. Our proactive detection rate for hate speech on Facebook increased 6 points from 89% to 95%. In turn, the amount of content we took action on increased from 9.6 million in Q1 to 22.5 million in Q2. This is because we expanded some of our automation technology in Spanish, Arabic and Indonesian and made improvements to our English detection technology in Q1. In Q2, improvements to our automation capabilities helped us take action on more content in English, Spanish and Burmese. On Instagram, our proactive detection rate for hate speech increased 39 points from 45% to 84% and the amount of content we took action on increased from 808,900 in Q1 2020 to 3.3 million in Q2. These increases were driven by expanding our proactive detection technologies in English and Spanish.', 'Another area where we saw improvements due to our technology was terrorism content. On Facebook, the amount of content we took action on increased from 6.3 million in Q1 to 8.7 million in Q2. And thanks to both improvements in our technology and the return of some content reviewers, we saw increases in the amount of content we took action on connected to organized hate on Instagram and bullying and harassment on both Facebook and Instagram.', 'We’ve made progress combating hate on our apps, but we know we have more to do to ensure everyone feels comfortable using our services. That’s why we’ve established new inclusive teams and task forces, including the Instagram Equity Team and the Facebook Inclusive Product Council, to help us build products that are deliberately fair and inclusive, and we’re launching a Diversity Advisory Council that will provide input based on lived experience on a variety of topics and issues. We’re alsoupdating our policiesto more specifically account for certain kinds of implicit hate speech, such as content depicting blackface, or stereotypes about Jewish people controlling the world. We also continued to prioritize the removal of content that violates ourpolicy against hate groups. Since October 2019, we’ve conducted 14strategic network disruptionsto remove 23 different banned organizations, over half of which supported white supremacy.', 'We want people to be confident that the numbers we report around harmful content are accurate, so we will undergo anindependent, third-party audit, starting in 2021, to validate the numbers we publish in our Community Standards Enforcement Report.', 'As the COVID-19 pandemic evolves, we’ll continue adapting our content review process and working to improve our technology and bring more reviewers back online.']\n",
            "143 ['Today, Facebook’s third civil rights audit report is being published — bringing to a close an independent two-year review of our policies and practices by noted civil liberties and civil rights expert Laura W. Murphy and Megan Cacace, partner in the civil rights law firm Relman Colfax, PLLC. This two-year journey has had a profound effect on the way we think about our impact on the world.', 'When we agreed to become the first social media company to undertake an audit of this kind, at the encouragement of the civil rights community, no one knew that the final report would be published at a time when racial injustice and police brutality is bringing millions of people to the streets — both at home and abroad — to campaign for change. We also had no idea that it would be published at a time when Facebook itself has faced heavy criticism from many in the civil rights community about hateful content on our platform and is subject to a boycott by a number of advertisers. While the audit was planned, and most of it carried out, long before recent events, its release couldn’t come at a more important time.', 'Facebook stands firmly against hate. Being a platform where everyone can make their voice heard is core to our mission, but that doesn’t mean it’s acceptable for people to spread hate. It’s not. We have clear policies against hate — and we strive constantly to get better and faster at enforcing them. We have made real progress over the years, but this work is never finished and we know what a big responsibility Facebook has to get better at finding and removing hateful content.', 'The audit looked at a wide range of civil rights issues, including our policies against hate. There are no quick fixes to these issues — nor should there be. This audit has been a deep analysis of how we can strengthen and advance civil rights at every level of our company — but it is the beginning of the journey, not the end. What has become increasingly clear is that we have a long way to go. As hard as it has been to have our shortcomings exposed by experts, it has undoubtedly been a really important process for our company. We would urge companies in our industry and beyond to do the same.', 'Thanks to Laura and Megan’s leadership, and the continued advocacy of civil rights groups and leaders, we believe we are in a better place today than we were two years ago. Over the course of the audit process, we have made significant progress in a number of critical areas. But the auditors have been extremely candid with their feedback, urging us to go further in a range of areas. While we won’t make every change they call for, we will put more of their proposals into practice. We have started to do that — and we are making new commitments today. But first it is important to acknowledge where the auditors believe we are still falling short. Specifically, the audit report finds:', 'We have a long way to go — but we are making progress. In her introduction to the report, Laura W. Murphy says the audit has been meaningful and “has led to some significant improvements in the platform.” The progress we have made includes:', 'The report also acknowledges that the audit process has deepened our relationships with civil rights groups and leaders. Even if these relationships still generate serious criticism, what was previously ad-hoc and informal engagement has, over the course of two years, become consistent, meaningful and more rigorous.', 'I want to thank Laura W. Murphy, Megan Cacace and the team at Relman Colfax, and the wider civil rights community. In often difficult circumstances, they continued to show up to help us advance the civil rights of everyone who uses Facebook. You can read the full audithere.']\n",
            "144 ['This piece originally ran inAdAge.', 'When society is divided and tensions run high, those divisions play out on social media. Platforms like Facebook hold up a mirror to society — with more than 3 billion people using Facebook’s apps every month, everything that is good, bad and ugly in our societies will find expression on our platform. That puts a big responsibility on Facebook and other social media companies to decide where to draw the line over what content is acceptable.', 'Facebook has come in for much criticism in recent weeks following its decision to allow controversial posts by President Trump to stay up, and misgivings on the part of many people, including companies that advertise on our platform, about our approach to tackling hate speech. I want to be unambiguous: Facebook does not profit from hate. Billions of people use Facebook and Instagram because they have good experiences — they don’t want to see hateful content, our advertisers don’t want to see it, and we don’t want to see it. There is no incentive for us to do anything but remove it.', 'More than 100 billion messages are sent on our services every day. That’s all of us, talking to each other, sharing our lives, our opinions, our hopes and our experiences. In all of those billions of interactions a tiny fraction are hateful. When we find hateful posts on Facebook and Instagram, we take a zero tolerance approach and remove them. When content falls short of being classified as hate speech — or of our other policies aimed at preventing harm or voter suppression — we err on the side of free expression because, ultimately, the best way to counter hurtful, divisive, offensive speech, is more speech. Exposing it to sunlight is better than hiding it in the shadows.', 'Unfortunately, zero tolerance doesn’t mean zero incidences. With so much content posted every day, rooting out the hate is like looking for a needle in a haystack. We invest billions of dollars each year in people and technology to keep our platform safe. We have tripled — to more than 35,000 — the people working on safety and security. We’re a pioneer in artificial intelligence technology to remove hateful content at scale.', 'And we’re making real progress. A recent European Commission report found that Facebook assessed 95.7% of hate speech reports in less than 24 hours, faster than YouTube and Twitter. Last month, we reported that we find nearly 90% of the hate speech we remove before someone reports it — up from 24% little over two years ago. We took action against 9.6 million pieces of content in the first quarter of 2020 — up from 5.7 million in the previous quarter. And 99% of the ISIS and Al Qaeda content we remove is taken down before anyone reports it to us.', 'We are getting better — but we’re not complacent. That’s why we recently announced new policies and products to make sure everyone can stay safe, stay informed, and ultimately use their voice where it matters most — voting. We understand that many of our critics are angry about the inflammatory rhetoric President Trump has posted on our platform and others, and want us to be more aggressive in removing his speech. As a former politician myself, I know that the only way to hold the powerful to account is ultimately through the ballot box. That is why we want to use our platform to empower voters to make the ultimate decision themselves, on election day. This Friday every Facebook user of voting age in the US will be given information, prominently displayed on the top of their News Feed, on how to register to vote. This will be one step in the largest voter information campaign in US history, with a goal of registering 4 million voters. We have also been updating our policies to crack down on voter suppression. Many of these changes are a direct result of feedback from the civil rights community — we’ll keep working with them and other experts as we adjust our policies to address new risks as they emerge.', 'Of course, focusing on hate speech and other types of harmful content on social media is necessary and understandable, but it is worth remembering that the vast majority of those billions of conversations are positive.', 'Look at what happened when the coronavirus pandemic took hold. Billions of people used Facebook to stay connected when they were physically apart. Grandparents and grandchildren, brothers and sisters, friends and neighbors. And more than that, people came together to help each other. Thousands and thousands of local groups formed — millions of people came together — in order to organize to help the most vulnerable in their communities. Others, to celebrate and support our healthcare workers. And when businesses had to close their doors to the public, for many Facebook was their lifeline. More than 160 million businesses use Facebook’s free tools to reach customers, and many used these tools to help them keep their businesses afloat when their doors were closed to the public — saving people’s jobs and livelihoods.', 'Importantly, Facebook helped people to get accurate, authoritative health information. We directed more than 2 billion people on Facebook and Instagram to information from the World Health Organization and other public health authorities, with more than 350 million people clicking through.', 'And it is worth remembering that when the darkest things are happening in our society, social media gives people a means to shine a light. To show the world what is happening, to organize against hate and come together, and for millions of people around the world to show their solidarity. We’ve seen that all over the world on countless occasions — and we are seeing it right now with the Black Lives Matter movement.', 'We may never be able to prevent hate from appearing on Facebook entirely, but we are getting better at stopping it all the time.']\n",
            "145 ['SummaryToday we are designating a violent US-based anti-government network as a dangerous organization and banning it from our platform. This network uses the term boogaloo but is distinct from the broader and loosely-affiliated boogaloo movement because it actively seeks to commit violence. For months, we have removed boogaloo content when there is a clear connection to violence or a credible threat to public safety, and today’s designation will mean we remove more content going forward, including Facebook Groups and Pages. This is the latest step in our commitment to ban people who proclaim a violent mission from using our platform.', 'As part of today’s action, we are designating a violent US-based anti-government network under ourDangerous Individuals and Organizations policyand disrupting it on our services. As a result, this violent network is banned from having a presence on our platform and we will remove content praising, supporting or representing it. This network appears to be based across various locations in the US, and the people within it engage with one another on our platform. It is actively promoting violence against civilians, law enforcement and government officials and institutions. Members of this network seek to recruit others within the broader boogaloo movement, sharing the same content online and adopting the same offline appearance as others in the movement to do so.', 'Facebook designates non-state actors under our Dangerous Individuals and Organizations policy after a rigorous process that takes into account both online and offline behavior. During this process, we work to identify an actor’s goals and whether they have a track record of offline violence. We know the initial elements of the boogaloo movement began as far back as 2012, and we have been closely following its developments since 2019. We understand that the term has been adopted by a range of anti-government activists who generally believe civil conflict in the US is inevitable. But activists are divided over numerous issues, including the goal of a civil conflict, racism and anti-Semitism, and whether to instigate violent conflict or be prepared to react when it occurs. We noted that some people who participated at the Gun Rights Rally that took place in Richmond, VA on January 20, 2020, wore the outfit now typical for boogaloo adherents and we have since tracked the movement’s expansion as participants engage at various protests and rallies across the country. More recently, officials have identified violent adherents to the movement as those responsible for several attacks over the past few months. These acts of real-world violence and our investigations into them are what led us to identify and designate this distinct network.', 'In order to make Facebook as inhospitable to this violent US-based anti-government network as possible, we conducted astrategic network disruptionof their presence today removing 220 Facebook accounts, 95 Instagram accounts, 28 Pages and 106 groups that currently comprise the network. We have also removed over 400 additional groups and over 100 other Pages for violating our Dangerous Individuals and Organizations policy as they hosted similar content as the violent network we disrupted but were maintained by accounts outside of it. As part of our designation process, we will now identify where we can strengthen how we enforce our policy against this banned network and spot attempts by the violent US anti-government network to return to our platform.', 'Today’s designation is not the first time we’ve taken action against violence within the boogaloo movement. We have always removed boogaloo content when we identify a clear call for violence. As a result, we removed over 800 posts for violating ourViolence and Incitement policyover the last two months and limited the distribution of Pages and groups referencing the movement by removing them from the recommendations we show people on Facebook.', 'So long as violent movements operate in the physical world, they will seek to exploit digital platforms. We are stepping up our efforts against this network and know there is still more to do. As we’ve seen following other designations, we expect to see adversarial behavior from this network including people trying to return to using our platform and adopting new terminology. We are committed to reviewing accounts, Groups, and Pages, including ones currently on Facebook, against our Dangerous Individuals and Organizations policy. We are grateful to researchers, investigators and reporters who identify the fault lines that help us focus on elements of the broad boogaloo movement that pose the greatest risk of real harm.', 'We will continue to study new trends, including the language and symbols this network shares online so we can take the necessary steps to keep those who proclaim a violent mission off our platform. We know that our efforts will never completely eliminate the risk from this network, or other dangerous organizations, but we will continue to remove content and accounts that break our rules so we can keep people safe.']\n",
            "146 ['Today Mark Zuckerberg shared an update on the work we’re doing to prepare for the 2020 US elections and fight against racial injustice, much of which is a direct result of our civil rights audit.', '']\n",
            "147 ['We don’t allow hate speech on Facebook. Over the past few years, we’ve invested in new technologies and improved our processes to find and remove hate speech from our platform.And we produce atransparency reportevery six months to share our progress. Not every company does this, but we think it’s important to be transparent about how we’re doing and allow people to hold us accountable.', 'We also signed the European Commission’s code of conduct on countering illegal hate speech online. As part of this code of conduct, the European Commission runs regular independent tests on each company that signed on to make sure they are removing this content quickly and effectively. The fifthreportwas published this week, and it showed that we are reviewing reports of hate speech quicker than before, deleting more of it and doing it transparently.', 'According to this independent report,Facebook assessed 95.7% and Instagram assessed 91.8% of hate speech notifications in less than 24 hours, compared to 81.5% for YouTube and 76.6% for Twitter. The European Commission alsostatesthat “only Facebook informs users systematically; all the other platforms have to make improvements.”While we recognize we have more to do, these results suggest we are moving in the right direction and have systems in place which continue to lead our industry.', 'Moving fast to find and remove hate speech takes significant investment in both people and technology.We have tripled the size of our teams working in safety and security since 2016 to over 35,000 people – including teams that review reports of hate speech 24 hours a day, seven days a week.Over the last two years, we’ve also invested heavily inAI technologyto proactively detect hate speechin more languages, so that we can find and remove this harmful content before people report it to us, and sometimes before anyone even sees it. While these technologies are not perfect,our most recent transparency reportshowed that we proactively find and take down almost 90% of the hate speech we remove from Facebook before anyone reports it to us – up from 38% over the same period two years ago.', 'European Commission Vice President Vera Jourova and Commissioner Didier Reyndersrecognizedour progress in fighting hate speech on our platform, and we will continue to develop new tools and invest in technology to detect and remove it.']\n",
            "148 ['Child exploitation is a problem across the internet, and it’s our collective responsibility – from social media and messaging services to cloud services and gaming platforms, as well as device makers and internet service providers – to fight this abuse and protect kids online. At Facebook, we use sophisticated technology and behavioral signals not only to prevent, detect and remove images and videos that exploit children, but also to detect and prevent grooming, or potentially inappropriate interactions between a minor and an adult. And we use this technology across Facebook, Instagram, Messenger and WhatsApp. But any industry-wide problem requires solutions broader than just one company – we need a robust international effort to combat this problem.', 'That’s why today, Facebook joined Google, Microsoft and 15 other tech companies to announce the formation ofProject Protect: A plan to combat online child sexual abuse– a renewed commitment and\\xa0 investment from theTechnology Coalitionexpanding its scope and impact to protect kids online and guide its work for the next 15 years.', 'Project Protect will focus on five key areas:', '“Project Protect brings together the brightest minds from across the tech industry to tackle a grave issue that no one company can solve on its own – child exploitation and abuse. Facebook is proud to help lead this initiative that we hope will lead to real changes that keep children safe.”', '– Sheryl Sandberg, Facebook COO', 'Our cross-industry work to protect kids online extends beyond today’s announcement. For example, we made our photo and video-matching technologiesopen source, which allows industry partners, developers and non-profits to more easily identify abusive content, share hashes — or digital fingerprints — of different types of harmful content and allow hash-sharing systems to communicate with each other, making the systems that much more powerful. We also recently hosted our fifth child safety hackathon, where we brought together engineers, data scientists and designers from across the industry as well as non-profit partners NCMEC, Thorn, SaferNet Brazil, INHOPE, Cybertip.ca, and IWF, to code and prototype more than a dozen projects focused on making the internet a safer place for children. Following the event, we committed to help fund the Internet Watch Foundation’sinitiativefor young people to confidentially report self-generated sexual images of minors. And we recently committed to help fund a project led byTech Mattersthat will develop new technology to support child helplines and make them more accessible to children in crisis.', 'We have also taken steps across our apps to make the broader internet safer for children. This includes running PhotoDNA on links shared on all our apps from other internet sites and their associated content to detect known child exploitation housed elsewhere on the internet. Not only does this help keep our platforms safer, but it also helps keep the broader internet safer as all violating content is shared with the National Center for Missing and Exploited Children (NCMEC) who work with local law enforcement around the world.', 'Lastly, we continue to innovate and use best-in-class technology to prevent abuse as we expand the privacy and security of our messaging services. For example, last month weannounceda new safety feature in Messenger that provides tips for spotting suspicious activity, encourages people under the age of 18 to be cautious when interacting with an adult they may not know, and empowers them to block or ignore someone when something doesn’t seem right.']\n",
            "149 ['Freedom of expression is a foundational human right that allows for the free flow of information. We’re reminded how vital this is, in particular, as the world grapples with COVID-19 and accurate and authoritative information is more important than ever. Human rights defenders know this and fight for these freedoms every day. For Facebook, which stands for giving people voice, these rights are core to why we exist.', 'Today, we’re releasing the findings of three independent human rights impact assessments we commissioned in 2018 to evaluate the role of our services in Sri Lanka, Indonesia and Cambodia, along with details on how we’ve responded to the recommendations in each assessment. The assessments build on the work we’ve done over the last two years, beginning with creation of a human rights team to inform our policies, products, programs and partnerships around the world.', 'Since then, we’ve formalized an approach to determine which countries require more investment, including increased staffing, product changes and research. We have committed toexpanding end-to-end encryption, a security function that is already core to WhatsApp, to all of our messaging products to protect people’s private messages, including journalists and human rights defenders. In October of last year, weupdated the values that underpin our Community Standardsto specifically reference human rights principles. And earlier this year, the Global Network Initiative (GNI), completedits biennial assessment of Facebook, which determined the company is making good-faith efforts to implement the GNI Principles with improvement over time. The assessor reported Facebook had “strengthened its systematic review of both privacy and freedom of expression.”', 'The assessments we’re releasing today underscore the role our services play in providing voice to people, promoting civic and political engagement, and shining a light on human rights issues and abuse, especially in places where activists, human rights defenders and vulnerable communities don’t otherwise have a platform.', 'They also highlight the threats to people’s rightsand encourage us to respond more resolutely. We accept this responsibility, and acknowledge the human rights impacts outlined in these reports. We will continue to strive to keep people safe and their information secure.', 'Why and How We Do Human Rights Impact Assessments', 'We’re committed to understanding the role our platforms play offline and how Facebook’s products and policies can evolve to create better outcomes. Engaging independent experts and evaluating our work through the lens of global human rights principles is key to achieving this goal.', 'The three assessments we commissioned were conducted in accordance with theUN Guiding Principles on Business and Human Rights. The assessment of Facebook’s role in Cambodia was completed by BSR, and the assessments of Sri Lanka and Indonesia by Article One.', 'While the three assessments focus on Cambodia, Indonesia and Sri Lanka, the recommendations in each report have implications for other contexts, countries and regions in which Facebook is used.This reflects the universal nature of human rights, the global reach of our products, and the intersectionality of the impacts identified.', 'HRIA Recommendations and Our Progress', 'The reports each made similar recommendations to help us better protect human rights, including:', 'We welcome the recommendations and have taken steps towards filling these gaps, as our responses demonstrate.', 'Over the last two years, we have formalized an approach for prioritizing countries at risk of conflict and tailoring policy and product solutions to account for the unique needs of each. In Sri Lanka, for example, we are reducing the distribution of frequently reshared messages, which are often associated with clickbait and misinformation. These demotions seek to respect the guidance on permissible limits to freedom of expression under Article 19 of the ICCPR.', 'We have also taken lessons from Cambodia, where government surveillance of internet and social media use is pervasive. We expanded the ways that users can keep their accounts secure and started encouraging people to use authenticator apps rather than SMS for more secure two-factor authentication.', 'We also madekey updates to our Community Standards. For example, in 2018, we adopted a policy to remove verified misinformation that contributes to the risk of imminent physical harm, which we later expanded to apply to unverifiable rumors. The policy, which is global in scope, is especially applicable to conflict-affected areas, and has been used to remove content in Sri Lanka and Indonesia. We further updated our policies to protect vulnerable groups, including veiled women, LGBTQ+ individuals and human rights activists whose “outing” might increase risks of offline harm. We began using proactive detection technology to identify potentially violating hate speech, developing machine learning capabilities in Sinhala and Bahasa Indonesia. And we expanded our policies against voter interference, which proved critical ahead of elections in Sri Lanka and Indonesia in 2019, and will be equally important ahead of Cambodian elections in 2022 and 2023.', 'We increased staffing significantly, hiring policy leads and program managers in Sri Lanka, Indonesia and Cambodia, and expanding the number of content reviewers who speak Sinhala, Tamil, Bahasa Indonesia, Javanese and Khmer. With bigger and more specialized teams, we’ve formalized engagement with civil society organizations, many of whom serve asa regular and invaluable source of inputas we make updates to our Community Standards to account for new types of abuse. Our investment in civil society has further extended to digital and media literacy programs and economic initiatives like#SheMeansBusiness. We also strengthened our local fact-checking partnerships in Sri Lanka and Indonesia, and we’re always looking to expand the program with organizations certified by the International Fact-Checking Network.', 'As we work to protect human rights and mitigate the adverse impacts of our platform, we have sought to communicate more transparently and build trust with rights holders. We also aim to use our presence in places like Sri Lanka, Indonesia and Cambodia to advance human rights, as outlined in the UN Guiding Principles on Business and Human Rights and in Article One and BSR’s assessments. In particular, we are deeply troubled by the arrests of people who have used Facebook to engage in peaceful political expression, and will continue to advocate for freedom of expression and stronger protections of user data.', 'Final Note', 'The progress we’ve laid out here represents the beginning of our work in Sri Lanka, Indonesia and Cambodia, not the end. Facebook learns from every human rights impact assessment we undertake, and these reports are critical to changing how we operate to better support communities around the world. We have a long road ahead, but sharing some of the progress we’ve made is part of our commitment to demonstrating action and accountability.', 'Article One undertook its Human Rights Impact Assessments in Indonesia and Sri Lanka during 2018, using a methodology informed by guidance from the UN Guiding Principles on Business and Human Rights as well as Article One’s award-winning process for and experience in conducting human rights impact assessments around the world. The Indonesia HRIA involved interviews with 35 organizations, and the HRIA for Sri Lanka reflects interviews with 29 organizations, as well as focus groups of 150 participants. Both assessments encompassed interviews with relevant Facebook employees, and were funded by Facebook. Article One retained editorial control of its contents.', 'BSR undertook its Human Rights Impact Assessment (HRIA) of Cambodia in late 2018 and early 2019, using a methodology based on the UN Guiding Principles on Business and Human Rights (UNGPs). It involved interviews with 35 affected rights holders and stakeholders in Cambodia, as well as in-country research and interviews with relevant Facebook employees. The HRIA was funded by Facebook, though BSR retained editorial control of its contents.', 'Human Rights Impact Assessments', 'Facebook’s Responses']\n",
            "150 ['Update on October 17, 2022 5:00 AM PT:', 'As we draw closer to the US 2022 midterm elections, we wanted to share a bit more about our ongoing work to keep our platforms safe.As a part of this continued work, in 2022 we have disrupted and taken down six distinct US-based neo-nazi and white supremacist networks trying to use our platforms. Some were known groups like the KKK and the Proud Boys. But about 25% of these disruptions targeted new groups and new adversarial behavior.', 'One of the reasons we’ve been able to make this progress is because of a tactic we’ve been using called Strategic Network Disruptions (SND). Since 2020, when our team began leveraging this strategy to target a banned group’s presence across our apps, we’ve continued to grow and evolve this tactic. Though the majority of our actions againstDangerous Organizations and Individualscomes fromroutine contentenforcement there are times when, as we face an especially determined or adversarial group, content enforcement alone is not enough. That’s why we leverage this targeted, precision SND approach to do three things in particular:', 'This is a rapidly changing and highly adversarial space, with networks that are often aggressive in their attempts to find new ways of sneaking back onto our platforms. SNDs allow us to be nimble and respond to new threats that automation or content moderation alone might miss. We are committed to this important work, and look forward to sharing more information as our approaches develop.', 'Update on May 14, 2020 at 3:00PM PT:', 'We’re sharing a statement to mark the one-year anniversary of the Christchurch Call to Action.', '“One year ago we committed to the Christchurch Call to Action in response to the March 15, 2019 attack in Christchurch, New Zealand. Since then, our companies have continued our shared work to prevent terrorists and violent extremists from abusing digital platforms. Through the Global Internet Forum to Counter Terrorism, we created a protocol to jointly combat the spread of terrorist content following an attack, established a growing advisory committee of government and international organizations to help inform our work, launched working groups to take new proactive steps to address terrorist and violent extremist content online, and continued to support academic research on how terrorists use digital platforms. This work is only the beginning, and we are committed to making meaningful progress in the years to come working closely with governments, international organizations, and the multiple stakeholders who support the Christchurch Call.”– Amazon, Facebook, Google, Microsoft, and Twitter', 'Originally published on May 12, 2020 at 9:00AM PT:', 'Last year,we committed to being more transparentabout how we combat hate and dangerous organizations on our apps. Today, we’re sharing an update on these efforts, includingnew enforcement metricsand details on the tactics we’ve developed to disrupt this behavior. This month also marks the one-year anniversary of theChristchurch Call to Action, which brought government and industry leaders together, led by New Zealand Prime Minister Jacinda Ardern and French President Emmanuel Macron, to curb the spread of terrorism and extremism online. We continue delivering on our commitments to the nine-point action plan for digital platforms, including publishing regular reports on detection and removal of terrorist or violent extremist content on our apps.', 'Removing Organized Hate and Dangerous Organizations', 'We ban groups that proclaim a hateful and violent mission from having a presence on our apps and we remove content that represents, praises or supports them. To date, we’ve identified a range of groups across the globe as hate organizations because they engage in coordinated violence against others based on characteristics such as religion, race, ethnicity or national origin and we routinely evaluate groups and individuals to determine if they violate our policy.', 'Three years ago, we started to develop a playbook and aseries of automated techniquesto detect content related to terrorist organizations such as ISIS, al Qaeda and their affiliates. We’ve since expanded these techniques to detect and remove content related to other terrorist groups and organized hate. We’re now able to detect text embedded in images and videos in order to understand its full context, and we’ve built media matching technology to find content that’s identical or near-identical to photos, videos, text and even audio that we’ve already removed. When we started detecting hate organizations we focused on groups that posed the greatest threat of violence at that time, and we’ve now expanded to detect more groups tied to different hate-based and violent extremist ideologies and using different languages. In addition to building new tools, we’ve also adapted strategies from our counterterrorism work, such as leveraging off-platform signals to identify dangerous content on Facebook, and implementing procedures to audit the accuracy of our AI’s decisions over time.', 'Sharing Metrics', 'In the first three months of 2020, we removed about 4.7 million pieces of content on Facebook connected to organized hate, an increase of over 3 million pieces of content from the previous quarter. Additionally, we increased our proactive detection rate for organized hate, the percentage of content we remove that we detect before someone reports it to us, from 89.6% in Q4 2019 to 96.7% in Q1 2020. We saw similar progress on Instagram where our proactive detection rate increased from 57.6% to 68.9%, and we removed 175,000 pieces of content in Q1 2020, up from 139,800 the previous quarter. In addition, since we built this system for detecting organized hate content based on what we learned from detecting terrorist content, we’ve been able to identify where content related to one problem is distinct from the other. For example, we’ve seen that violations for organized hate are more likely to involve memes while terrorist propaganda is often dispersed from a central media arm of the organization and includes formalized branding. Identifying these patterns helps us continue to fine tune the systems for detecting organized hate and terrorist content.', 'Evolving Our Enforcement Tactics', 'We remain vigilant in learning and combating new ways people may try to abuse our apps. We work with external partners to get the latest intelligence about adversarial behavior across the internet, and we commission independent research from academics and experts. We also learn from different teams at Facebook about successful methods in combating other forms of abuse that can be applied to this work.', 'Over the last six months, we worked with colleagues on our Threat Intelligence team to leverage their strategy for combating coordinated inauthentic behavior in order to develop a new tactic that targets a banned group’s presence across our apps. We do this by identifying signals that indicate a banned organization has a presence, and then proactively investigating associated accounts, Pages and Groups before removing them all at once. Once we remove their presence, we work to identify attempts by the group to come back on our platform. We’re also studying how dangerous organizations initially bypassed our detection, as well as how they attempt to return to Facebook after we remove their accounts, in order to strengthen our enforcement and create new barriers to keep them off our apps.', 'We’ll continue working to disrupt and remove dangerous organizations from our platform and we’ll share how we’re doing at enforcing our policies and combating new ways people may try to abuse our apps.']\n",
            "151 ['Today we’re publishing the fifth edition of ourCommunity Standards Enforcement Report, providingmetricson how well we enforced our policies from October 2019 through March 2020. We’ve spent the last few years building tools, teams and technologies to help protect elections from interference, prevent misinformation from spreading on our apps and keep people safe from harmful content. So when the COVID-19 crisis emerged, we had the tools and processes in place to move quickly and we were able to continue finding and removing content that violates our policies. When we temporarily sent our content reviewers home due to the COVID-19 pandemic, we increased our reliance on these automated systems and prioritized high-severity content for our teams to review in order to continue to keep our apps safe during this time.', 'This report includes data only through March 2020 so it does not reflect the full impact of the changes we made during the pandemic. We anticipate we’ll see the impact of those changes in our next report, and possibly beyond, and we will be transparent about them. For example, for the past seven weeks we couldn’t always offer the option to appeal content decisions and account removals, so we expect the number of appeals to be much lower in our next report. We also prioritized removing harmful content over measuring our efforts, so we may not be able to calculate the prevalence of violating content during this time. Today’s report shows the impact of advancements we’ve made in the technology we use to proactively find and remove violating content.', 'What’s New in This Report?', 'We are now including metrics across 12 policies on Facebook and metrics across 10 policies on Instagram. The report introduces Instagram data in four issue areas: Hate Speech, Adult Nudity and Sexual Activity, Violent and Graphic Content, and Bullying and Harassment. For the first time, we are also sharing data on the number of appeals people make on content we’ve taken action against on Instagram, and the number of decisions we overturn either based on those appeals or when we identify the issue ourselves. We’ve also added data on our efforts to combat organized hate on Facebook and Instagram. You can learn more about these efforts and the progress we’ve madehere.', 'Progress in Finding and Removing Violating Content', 'We improved our technology that proactively finds violating content, which helped us remove more violating content so fewer people saw it.', '', 'Over the last six months, we’ve started to use technology more to prioritize content for our teams to review based on factors like virality and severity among others. Going forward, we plan to leverage technology to also take action on content, including removing more posts automatically. This will enable our content reviewers to focus their time on other types of content where more nuance and context are needed to make a decision.', 'The Community Standards Enforcement Report is published in conjunction with our bi-annualTransparency Reportthat shares numbers on government requests for user data, content restrictions based on local law, intellectual property take-downs and internet disruptions.', 'In the future we’ll share Community Standards Enforcement Reports quarterly, so our next report will be released in August.']\n",
            "152 ['Note: For future Facebook updates about Oversight Board cases, please visit theTransparency Center.', 'Today,Facebook’s new Oversight Boardannounces its first members, marking a fundamental change in the way some of the most difficult and significant decisions around content on our platforms will be made.', 'As Mark Zuckerberg put it when he firstoutlinedhis blueprint for a new system for content governance and enforcement, “Facebook should not make so many important decisions about free expression and safety on our own.”With our size comes a great deal of responsibility and while we have always taken advice from experts on how to best keep our platforms safe, until now, we have made the final decisions about what should be allowed on our platforms and what should be removed. And these decisions often are not easy to make – most judgments do not have obvious, or uncontroversial, outcomes and yet many of them have significant implications for free expression.', 'That’s why we have created and empowered a new group to exercise independent judgment oversome of the most difficult and significant content decisions. In doing so, we’ve sought input from bothcritics and supporters of Facebook, hosting a global consultation process of workshops and roundtables with more than 650 people in 88 different countries, that resulted in:', 'Oversight Board Members', 'The members announced today reflect a wide range of views and experiences. They have lived in over 27 countries, speak at least 29 languages and are all committed to the mission of the Oversight Board. Weexpect them to make some decisions that we, at Facebook, will not always agree with – but that’s the point: they are truly autonomous in their exercise of independent judgment. We also expect that the board’s membership itself will face criticism. But its long-term success depends on it having members who bring different perspectives and expertise to bear.', '', 'The Selection Process', 'Facebook helped kick off themember selection processby choosing four co-chairs, who have since been working with us to select the additional 16 members announced today. Membership selection will continue in this way until the board has selected up to 40 members, at which point it alone will take responsibility for selection of members in future.Therecommendation portalremains open for additional suggestions.', 'The members contract directly with the Oversight Board, are not Facebook employees, and cannot be removed by Facebook.', 'Our Commitment', 'For our part, Facebook will implement the board’s decisions unless doing so could violate the law, and will respond constructively and in good faith to policy guidance put forth by the board.', 'The board won’t be able to hear every case we or the public might want it to hear, but we look forward to working with the board to ensure that its scope grows over time. As it does, we know the board will play an increasingly important role in setting precedent and direction for content policy at Facebook. And in the long term, we hope its impact extends well beyond Facebook, and serves as a springboard for similar approaches to content governance in the online sphere.', 'As always, we remain hugely grateful to everyone who has lent their time, energy, and expertise to this first-of-its-kind project.']\n",
            "153 ['We’re constantly working to find and stop coordinated campaigns that seek to manipulate public debate across our apps. In 2019 alone, we took down over 50 networks worldwide for engaging in coordinated inauthentic behavior (CIB), including ahead of major democratic elections.', 'These efforts are led by a cross-disciplinary team focused on finding and disrupting both the most sophisticated influence operations aimed to manipulate public debate as well as high volume inauthentic behaviors like spam and fake engagement. Over the past several years, our team has grown to over 200 people with expertise ranging from open source research, to threat investigations, cyber security, law enforcement and national security, investigative journalism, engineering, product development, data science and academic studies in disinformation.', 'You can find more information about our previous enforcement actionshere.', 'Purpose of This Report', 'Over the past three years, we’ve shared our findings about coordinated inauthentic behavior we detect and remove from our platforms. As part of regular CIB reports, we’re sharing information about all networks we take down over the course of a month to make it easier for people to see progress we’re making in one place.', 'What is CIB?', 'While we investigate and enforce against any type of inauthentic behavior — including fake engagement, spam and artificial amplification — we approach enforcement against these mostly financially-motivated activities differently from how we counter foreign interference or domestic influence operations. We routinely take down less sophisticated, high-volume inauthentic behaviors like spam and we do not announce these enforcement actions when we take them.', 'We view influence operations as coordinated efforts to manipulate public debate for a strategic goal where fake accounts are central to the operation. There are two tiers of these activities that we work to stop: 1) coordinated inauthentic behavior in the context of domestic, non-state campaigns (CIB) and 2) coordinated inauthentic behavior on behalf of a foreign or government actor (FGI).', 'Coordinated Inauthentic Behavior (CIB)When we find domestic, non-government campaigns that include groups of accounts and Pages seeking to mislead people about who they are and what they are doing while relying on fake accounts, we remove both inauthentic and authentic accounts, Pages and Groups directly involved in this activity.', 'Foreign or Government Interference (FGI)If we find any instances of CIB conducted on behalf of a government entity or by a foreign actor, we apply the broadest enforcement measures including the removal of every on-platform property connected to the operation itself and the people and organizations behind it.', 'Continuous EnforcementWe monitor for efforts to re-establish a presence on Facebook by networks we previously removed for CIB. Using both automated and manual detection, we continuously remove accounts and Pages connected to networks we took down in the past.', 'This month, we removed eight networks of accounts, Pages and Groups. Two of them — from Russia and Iran — focused internationally (FGI), and the remaining six — in the US, Georgia, Myanmar and Mauritania — targeted domestic audiences in their respective countries (CIB). We have shared information about our findings with law enforcement, policymakers and industry partners.', 'We know that people looking to mislead others — whether through phishing, scams, or influence operations — try to leverage crises to advance their goals, and the coronavirus pandemic is no different. All of the networks we took down for CIB in April were created before the COVID-19 pandemic began, however, we’ve seen people behind these campaigns opportunistically use coronavirus-related posts among many other topics to build an audience and drive people to their Pages or off-platform sites. The majority of the networks we took down this month were still trying to grow their audience or had a large portion of engagement on their Pages generated by their own accounts.', 'Networks Removed in April, 2020:', 'We are making progress rooting out this abuse, but as we’ve said before, it’s an ongoing effort. We’re committed to continually improving to stay ahead. That means building better technology, hiring more people and working more closely with law enforcement, security experts and other companies.', 'See thedetailed reportfor more information.']\n",
            "154 ['With billions of people unable to see their friends and family in person due to COVID-19, people are relying on WhatsApp more than ever to communicate. People are talking to doctors, teachers, and isolated loved ones via WhatsApp during this crisis. That’s why all your messages and calls on WhatsApp are end-to-end encrypted by default to give you a secure place for your most personal conversations.', 'Last year we introduced users to the concept of messages that have been forwarded many times. These messages are labeled withdouble arrowsto indicate they did not originate from a close contact. In effect, these messages are less personal compared to typical messages sent on WhatsApp. We are now introducing a limit so that these messages can only be forwarded to one chat at a time.', 'As a private messaging service, we’ve taken several steps over the years to help keep conversations intimate. For example, we previously setlimits on forwarded messagesto constrain virality. At the time, we saw a 25% decrease in total message forwards globally.', 'Is all forwarding bad? Certainly not. We know many users forward helpful information, as well as funny videos, memes, and reflections or prayers they find meaningful. In recent weeks, people have also used WhatsApp to organizepublic momentsof support for frontline health workers. However, we’ve seen a significant increase in the amount of forwarding which users have told us can feel overwhelming and can contribute to the spread of misinformation. We believe it’s important to slow the spread of these messages down to keep WhatsApp a place for personal conversation.', 'In addition to this change, we are working directly with NGOs and governments, including the World Health Organization and over 20 national health ministries, to help connect people with accurate information. Together these trusted authorities have sent hundreds of millions of messages directly to people requesting information and advice. You can learn more about these efforts, as well as how to submit potential myths, hoaxes and rumors tofact-checking organizationson ourWhatsApp Coronavirus Information Hub.', 'We believe that now more than ever people need to be able to connect privately. Our teams are hard at work to keep WhatsApp running reliably during this unprecedented global crisis. We’ll continue to listen to your feedback and improve ways for people to share with each other on WhatsApp.']\n",
            "155 ['On Sunday, February 16, theFinancial Timespublished the following op-ed by Mark Zuckerberg.', 'Every day, platforms like Facebook have to make trade-offs on important social values — between free expression and safety, privacy and law enforcement, and between creating open systems and locking down data.', 'There is rarely a clear “right” answer. Often it is as important that decisions are made in a way that people feel is legitimate.', 'I don’t think private companies should make so many decisions alone when they touch on fundamental democratic values. That is why last yearI called for regulationin four areas: elections, harmful content, privacy and data portability.', 'On Monday Facebook is publishing oursecond white papersetting out some questions regulation might address. We’ve also been working with governments — including in France and New Zealand — on what regulation could look like. A few themes kept coming up.', 'One is transparency. Governments often tell us it’s hard to design content regulation because they don’t have insight into how our systems work. Facebook already publishes moredetailed reportsabout harmful content thanany othermajor internet service, and we’ve shown regulators how our systems operate. We’re also looking at opening up our content moderation systems for external audit.', 'Then there are political ads. We believe advertising is more transparent on Facebook than television, print or other online services. We publish details about political and issue ads — including who paid for them, how much was spent, and how many people were reached — in ourads library.', 'But who decides what counts as political advertising in a democracy? If a non-profit runs an ad about immigration during an election, is it political? Who should decide — private companies, or governments?', 'Another theme is openness. I’m glad the EU is looking at makingdata sharingeasier, because it enables people to build things that are valuable for society. International agencies use Facebook’sData for Goodprogramme to figure out which communities need help after natural disasters, and governments use our publicly available population density maps for vaccination campaigns.', 'Of course, you should always be able to transfer your data between services. But how do we define what counts as your data? If I share something with you, like my birthday, should you be able to take that data to other services, like your calendar app? Is that my data or yours?', 'We have to balance promoting innovation and research against protecting people’s privacy and security.', 'Without clear rules on portability, strict privacy laws encourage companies to lock down data, refusing to share with others, to minimise regulatory risks.', 'Lastly, we need more oversight and accountability. People need to feel that global technology platforms answer to someone, so regulation should hold companies accountable when they make mistakes.', 'Companies like mine also need better oversight when we make decisions, which is why we’re creating an independentOversight Boardso people can appeal Facebook’s content decisions.', 'Tech companies should serve society. That includes at the corporate level, so we support the OECD’s efforts to createfair global tax rulesfor the internet.', 'I believe good regulation may hurt Facebook’s business in the near term but it will be better for everyone, including us, over the long term.', 'These are problems that need to be fixed and that affect our industry as a whole. If we don’t create standards that people feel are legitimate, they won’t trust institutions or technology.', 'Of course, we won’t agree with every proposal. Regulation can have unintended consequences, especially for small businesses that can’t do sophisticated data analysis and marketing on their own. Millions of small businesses rely on companies like ours to do this for them.', 'If regulation makes it harder for them to share data and use these tools, that could disproportionately hurt them and inadvertently advantage larger companies that can.', 'Still, rather than relying on individual companies to set their own standards, we’d benefit from a more democratic process. This is why we’re pushing for new legislation, and it’s why we support existing US proposals to prevent election interference like theHonest Ads Actand theDeter Act.', 'To be clear, this isn’t about passing off responsibility. Facebook is not waiting for regulation; we’re continuing to make progress on these issues ourselves.', 'But I believe clearer rules would be better for everyone. The internet is a powerful force for social and economic empowerment. Regulation that protects people and supports innovation can ensure it stays that way.']\n",
            "156 ['Over the past decadethe internet has improved economies, reunited families, raised money for charity and helped bring about political change. However, the internet has also made it easier to share harmful content like hate speech and terrorist propaganda.', 'Governments, academics and others are debating how to hold internet platforms accountable, particularly in their efforts to keep people safe and protect fundamental rights like freedom of expression.', 'Last year, Facebook CEO Mark Zuckerberg called for governments to work with online platforms to create and adopt new regulation for online content, noting, “It’s impossible to remove all harmful content from the Internet, but when people use dozens of different sharing services — all with their own policies and processes — we need a more standardized approach.”', 'Today, we’re publishing a white paper setting out some questions that regulation of online content might address.', '“Charting a Way Forward: Online Content Regulation“builds on recent developments on this topic, including legislative efforts and scholarship.', 'Moving the Conversation Forward', 'The paper poses four questions which go to the heart of the debate about regulating content online:', 'Guidelines for Future Regulation', 'The development of regulatory solutions should involve not just lawmakers, private companies and civil society, but also those who use online platforms. The following principles are based on lessons we’ve learned from our work in combating harmful content and our discussions with others.', 'If designed well, new frameworks for regulating harmful content can contribute to the internet’s continued success by articulating clear ways for government, companies, and civil society to share responsibilities and work together. Designed poorly, these efforts risk unintended consequences that might make people less safe online, stifle expression and slow innovation.', 'We hope today’s white paper helps to stimulate further conversation around the regulation of content online. It builds on a paper we published last September ondata portability, and we plan on publishing similar papers on elections and privacy in the coming months.']\n",
            "157 ['Today, on Safer Internet Day, we wanted to highlight some of the tools and features we offer to help keep people safe across our apps and give them more control over their experience online.', 'Keeping Your Account Safe', 'There are some easy things you can do to help keep yourFacebookand Instagram accounts secure, including making sure you have astrong passwordand enablingtwo-factor authentication. When enabling two-factor authentication, we recommend using anauthentication appas your primary security method. You can also use Facebook’sSecurity Checkuptool to review apps and browsers where you’re logged in to Facebook and get alerts when your account is logged in to from an unrecognized device.', 'And to help keep Facebook Groups and Pages secure, we now require some admins of popular and active Groups and Pages to enable two-factor authentication to help protect against account takeovers. Facebook Page admins have also told us they are sometimes confused about why certain changes are happening to their Page and which of their fellow admins or business partners are responsible for the change. This is particularly problematic in cases of malicious account takeovers or “rogue” admins. That’s why earlier this year we rolled out thePage Management Historytab which lets Page admins see actions taken by other Page admins.', 'We know phishing is an increasingly prevalent issue, so to make it easier for people to determine if an email is legitimate, we createdEmails from Instagramin Instagram settings so you can see all recent emails Instagram sent to you. This will help you distinguish legitimate emails sent by Instagram from phishing emails which may appear to come from an official Instagram account. Similarly, people can confirm whether an email is from Facebook by checking if it came fromfacebookmail.com and by reviewing recent emails we’ve sent in theSecurity and Login Settings. We will never ask you for your password in an email or Facebook message.', 'Preventing Bullying and Harassment', 'Bullying and harassment are not allowed on Facebook or Instagram. But since we know we can’t prevent or catch everything, we offer tools to help you control your experience. For example, you can choose to ignore all messages from a bully or block them entirely without that person being notified and you can also moderate comments on your posts.', 'We work proactively to create new tools to stop bullying before it even happens. For example, on Instagram, if someone writes a comment or caption for a feed post that our AI detects as potentially offensive, they will receive a warning that the language used is similar to language that has been reported for bullying. They then have an opportunity to edit the caption or comment before it’s posted. We’ve found that these types of nudges can encourage people to reconsider posting potentially offensive or harmful language.', 'We know young people are reluctant to report or block peers who bully them, so last year we created a new feature on Instagram calledRestrict. Once you Restrict an account, you won’t receive any notifications from them. Comments from a restricted account will only be visible to you and the person you restricted, and messages from a restricted account will automatically be moved to Message Request. The restricted account will not be able to see when you’ve read their direct messages or when you are active on Instagram.', '', 'If you or someone you know has experienced online bullying, visit ourBullying Prevention Hubfor useful resources, tools and strategies toeffectively address bullying behavior and its consequences.', 'Controlling Who You Interact With', 'We believe you should be able to control who you interact with online. The FacebookHelp Centerexplains how you can control who reaches your inbox or your message requests folder on Messenger. You can also use tools likeblocking and reportingto stop unwanted interactions or report an issue in Messenger. Parents control who their child is connected to inMessenger Kidsand can remove people from their child’s contact list at any time. We alsoupdated the waykids block contactsin Messenger Kids to give them a simpler way to manage who they interact with.And on Instagram, we recently launched anew settingto help you control who can send you direct messages. This new feature allows only people you follow to message you and add you to group threads.', 'For more information about the features we have in place to keep you safe, visitfacebook.com/safety,wellbeing.instagram.comandmessenger.com/privacy.']\n",
            "158 ['We know creators come to Facebook to build positive and supportive communities around the games they love, so today we’re introducing new tools to help gaming creators foster inclusive environments.', 'While ourCommunity Standardsprotect against the most egregious harms like hate speech and terrorism, sometimes all it takes is one person being rude, mean or simply disruptive to ruin a conversation for everyone. And what may be considered competitive banter in one streaming community, might be considered toxic in another. Gaming creators are tone setters, so that’s why we’re releasing a toolkit to help them set guidelines for positive conversations in their community.', 'We worked with theFair Play Alliance, a coalition of game companies encouraging healthy communities in online gaming, and partnered directly with their Executive Steering Committee, to establishrulescreators and moderators can use to set guidelines and help avoid disruptive comments. People form communities over a shared love of gaming, but we know some groups of people, like women, can be targets of negative, hurtful stereotypes — so, rules like “Be Accepting” and “Respect Boundaries” can help maintain a positive environment for everyone, regardless of race, ethnicity, sexual orientation, gender identity or ability. Similarly, “Don’t Criticize” can help newer players feel welcome. The rules will promote inclusion and respect to help people feel safe sharing their voice.', 'Creators will be able to access the toolkit rules through a Chat Rules button in the streamer dashboard. While creators often list chat rules in their Page description or at the bottom of a stream, the new toolkit makes rules more visible and gives creators a baseline of eight preset rules to start with. We’ll expand and update the rules based on feedback from creators and the way gaming community conversations evolve. We’re testing these rules now with a small group of creators and we’ll roll them out globally in the coming months.', 'The toolkit will offer four new features:', 'Clear Standards: Creators can select from a list of gaming-specific rules for their community before they go live. They can also add a custom description about their stream to help set expectations about type of conversation they want to foster. Once a creator selects rules from the Chat Rules section of the streamer dashboard, fans will be asked to accept the rules before they’re allowed to leave a comment.', '', 'Content Removals: We’ve made comment removals happen in real time, so when a comment is removed or someone is banned, their comments will disappear from the stream immediately.', 'Transparency in Moderation: Moderators will also now be able to select which rules were violated so the fan can receive feedback about why their content was removed. This level of transparency will help creators educate their audience and inform well-intentioned fans who may have inadvertently broken a rule.', '', 'Moderation Dashboard: In addition to these rules, moderators will now have access to a new moderation dashboard with resources to prevent harassment, protect their privacy and help ensure creators feel safe.', 'With the new toolkit, creators and moderators will still be able to remove comments, mute viewers for a short period of time or ban people from their Page or stream. Once someone is banned they will still be able to watch the stream but won’t be able to comment or react to the stream or other people, and their previous comments will be removed.', 'We know gaming has changed over time, and so have the people who play, so it’s important for us to support creators and their moderators by helping set guidelines for positive conversations. Our work doesn’t end here — we’re excited to continue partnering with the Fair Play Alliance to develop additional features and ensure creators and fans alike can find safe and inclusive communities on Facebook.']\n",
            "159 ['Note: For future Facebook updates about Oversight Board cases, please visit theTransparency Center.', 'Since Mark Zuckerberg first laid outhis visionfor oversight of content decisions at Facebook, we’ve been laying the groundwork for a new independent organization to review cases and make binding content decisions. At theend of last year, we shared an update on the establishment of the Oversight Board Trust and LLC, which will manage Facebook’s funding for the board, oversee its operations and hold contracts with members. Today, we areproposing aset of bylawsand asummary chart, providing more details on Facebook’s process for implementing a board decision, and announcing the Director of Oversight Board Administration.', 'The bylaws set the rules for the board’s operations and procedures, andwhile we’ve taken inspiration from traditional corporate and non-profit bylaws,this document reflects the unique arrangement between the Oversight Board, Facebook and the Oversight Board Trust. They spell out the authorities and responsibilities of each entity, as well as the role of the people who use Facebook’s services. Once approved by the board, the bylaws will governthe board’sday-to-day operations and a final version of this document will be published on the board’s website.(Update on March 2, 2021 at 05:00AM PT: Article 1, Section 3 (Oversight Board Case Review and Decisions) and Article 2, Section 2 (Facebook Case Submissions, Information for Board Review and Implementation) of the bylaws have been amended. To learn more about these changes please see theboard’s announcementor the complete, updatedOversight Board bylaws.)(Update on November 2, 2021 at 6:00AM PT: Article 1, Section 3 (Case Review and Decisions) of the bylaws have been amended. To learn more about these changes please see theboard’s announcementor the complete updatedOversight Board bylaws.) (Update on February 1, 2022 at 08:00AM PT:Article 2, Section 2 (Facebook Case Submissions, Information for Board Review and Implementation) of the bylaws have been amended. To learn more about these changes please see the updatedOversight Board bylaws.)', 'Case Timeline', 'We are also building a case management toolthat will ensure user privacy and provide secure access for board members to review case information.', 'Cases will initially only involve individual pieces of content that we have taken down, and will be referred to the board through two avenues. First, anyone who disagrees with the outcome of Facebook’s decision to take down their content on Instagram or Facebook, and has exhausted appeals, will have 15 days to submit an appeal to the board. Second, Facebook itself will be able to directly refersignificant and difficultcases.', 'As we continue to improve and expand the technology that makes appeals to the board possible, we want to also make it possible forpeople to refer cases where Facebook decided not to remove a piece of content. Similarly, the types of content that the board can review will grow over time, such as Groups and Pages, as described in the bylaws. The Oversight Board is meant to be dynamic. It will need to remain responsive to shifts in how people use Facebook’s services.', 'Given the large number of content decisions Facebook makes, as well as the time it will take to hear cases, we expect the board will choose cases that have the greatest potential to guide Facebook’s future decisions and policies. We expect the board to come to a case decision, and for Facebook to have acted on that decision, in approximately 90 days.', '', 'In order to ensure the board can weigh in on the most significant decisions facing Facebook, including those with real-world implications, we have included a mechanism for expedited review. In these situations, Facebook can refer urgent cases straight to the board for immediate consideration. This process was created in response to feedback from external stakeholders, who stressed that the board will need to review some cases much more quickly than others.', 'Once the initial group of board membersisin place and begins operationswithin the next few months,the boardwilldeterminethe type of casesit prioritizesand the cadence at whichit reviews them.', 'Implementing Board Decisions', 'Facebook is committed to implementing the board’s decision on individual pieces of content within seven days, as outlined in the bylaws. Facebook will also assess the technical and operational feasibility of applying the decision to identical content with parallel context, as explained in the bylaws.', 'When the board provides an additional policy recommendation, Facebook will review that guidance. Some recommendations may involve only minor modifications to current policies or practices, while others may involve more substantial or complex changes. The latter will go through our fullpolicy development processor other appropriate channels. This will allow for a thorough and considered analysis of the proposed policy recommendation, as well as additionalstakeholder engagement.', 'As stated in the bylaws, Facebook will provide a public response regarding any policy recommendations and follow-on action within 30 days. This is a crucial aspect of our commitment to the board, as well as to public transparency.', '', 'Staffing and the Director of the Oversight Board Administration', 'An important piece of feedback that we incorporated from our global consultation was that the board should have a dedicated staff. Staff members won’t be deciding cases, but their duties might involvesupporting case selection, facilitating board meetings and ensuring the board has the support necessary to make considered and thoughtful decisions. The staff will also support the trustees regarding their fiduciary and other responsibilities.', 'Today, we’re announcing that the first Director of Oversight Board Administration will be Thomas Hughes, former Executive Director for Article 19, an international non-governmental organization with a focus on freedom of expression and digital rights. Hugheswill lead the board’s administrative staff.', 'In the coming months, we will announce board members and trustees as the LLC and Hughes continue to hire staff to support the board as it prepares to hear its first cases.']\n",
            "160 ['People share millions of photos and videos on Facebook every day, creating some of the most compelling and creative visuals on our platform. Some of that content is manipulated, often for benign reasons, like making a video sharper or audio more clear. But there are people who engage in media manipulation in order to mislead.', 'Manipulations can be made through simple technology like Photoshop or through sophisticated tools that use artificial intelligence or “deep learning” techniques to create videos that distort reality – usually called “deepfakes.” While these videos are still rare on the internet, they present a significant challenge for our industry and society as their use increases.', 'Today we want to describe how we are addressing both deepfakes and all types of manipulated media. Our approach has several components, from investigatingAI-generated content and deceptive behaviors like fake accounts, to partnering with academia, government and industry to exposing people behind these efforts.', 'Collaboration is key. Across the world, we’ve been driving conversations with more than 50 global experts with technical, policy, media, legal, civic and academic backgrounds to inform our policy development and improve the science of detecting manipulated media.', 'As a result of these partnerships and discussions, we are strengthening our policy toward misleading manipulated videos that have been identified as deepfakes. Going forward, we will remove misleading manipulated media if it meets thefollowing criteria:', 'This policy does not extend to content that is parody or satire, or video that has been edited solely to omit or change the order of words.', 'Consistent with our existing policies, audio, photos or videos, whether a deepfake or not, will be removed fromFacebookif they violate any of our otherCommunity Standardsincluding those governing nudity, graphic violence, voter suppression and hate speech.', 'Videos that don’t meet these standards for removal are stilleligible for review by one ofour independent third-party fact-checkers,which include over 50 partners worldwide fact-checking in over 40 languages. If a photo or video is rated false or partly false by a fact-checker, we significantly reduce its distribution in News Feed and reject it if it’s being run as an ad.And critically, people who see it, try to share it, or have already shared it, will see warnings alerting them that it’s false.', 'This approach is critical to our strategy and one we heard specifically from our conversations with experts. If we simply removed all manipulated videos flagged by fact-checkers as false, the videos would still be available elsewhere on the internet or social media ecosystem. By leaving them up and labelling them as false, we’re providing people with important information and context.', 'Our enforcement strategy against misleading manipulated media also benefits from our efforts to root out the people behind these efforts. Just last month, we identified and removed a network using AI-generated photos to conceal their fake accounts. Our teams continue to proactively hunt for fake accounts and other coordinated inauthentic behavior.', 'We are also engaged in the identification of manipulated content, of which deepfakes are the most challenging to detect. That’s why last September we launched theDeep Fake Detection Challenge, which has spurred people from all over the world to produce more research and open source tools to detect deepfakes. This project, supported by $10 million in grants, includes a cross-sector coalition of organizations including the Partnership on AI, Cornell Tech, the University of California Berkeley, MIT, WITNESS, Microsoft, the BBC and AWS, among several others in civil society and the technology, media and academic communities.', 'In a separate effort, we’ve partnered with Reuters, the world’s largest multimedia news provider, to help newsrooms worldwide to identify deepfakes and manipulated media through afree online training course. News organizations increasingly rely on third parties for large volumes of images and video, and identifying manipulated visuals is a significant challenge. This program aims to support newsrooms trying to do this work.', 'As these partnerships and our own insights evolve, so too will our policies toward manipulated media. In the meantime, we’re committedto investing within Facebook and working with other stakeholders in this area to find solutions with real impact.']\n",
            "161 ['In the summer of 2017, Facebook, Microsoft, Twitter and YouTube came together to form theGlobal Internet Forum to Counter Terrorism(GIFCT). Since then, the organization has grown, withnine technology companiesworking together to disrupt terrorists’ and violent extremists’ abilities to promote themselves, share propaganda and exploit digital platforms to glorify real-world acts of violence. This year, we made significant progress in our work, but we also faced new challenges. New threats emerged in how terrorists and violent extremists seek to exploit and abuse digital platforms, and we adapted our efforts to combat and prevent them.', 'Focusing on CollaborationWe’ve made progress in large part by working together as a collective of technology companies, but we’ve also partnered with experts in government, civil society and academia who share our goal. For example, by working with the UN CTED mandated NGO, Tech Against Terrorism, GIFCT has brought over 140 tech companies, 40 NGOs and 15 government bodies together in workshops across the world to date. This year, we held four workshops – in the US, Jordan, India and the UK – to discuss and study the latest trends in terrorist and violent extremist activity online.', 'These collaborations are vital to GIFCT’s mission. That’s why we announced at the United Nations General Assembly in September that GIFCT would becomean independent organizationin order to put collaborations across tech, civil society, government and academia at the center of GIFCT’s work. GIFCT is now established as an independent 501c3 based in the US, and we are officiallyseeking an experienced Executive Directorto build on the consortium’s early achievements and lead the independent GIFCT into the next decade.', 'Responding to Terrorist and Violent Extremist EventsIt’s been an important year for GIFCT and efforts to combat abuse of our platforms. The abuse of social media to glorify the horrific terrorist attack in Christchurch, New Zealand demonstrated the need for greater collaboration to respond to mass violence in order to curb the spread of violent extremist content. Since theChristchurch Call to Actionwas signed in May 2019, GIFCT has worked to implement thenine-point planto prevent terrorist exploitation of the internet while respecting human rights and freedom of speech.', 'As part of this plan, GIFCT developed the Content Incident Protocol to respond to emerging and active terrorist or violent extremist events and assess for any potential online content produced and disseminated by those responsible for or aiding in the attack. Since the attack in Christchurch, GIFCT member companies have developed, refined and tested the protocol through workshops with Europol and the New Zealand Government. To date, we’ve initiated the CIP assessment process more than 35 times in response to terrorist and violent extremist events across the world. Thefirst CIP wasactivatedon October 9, following the shooting in Halle, Germany when the perpetrator filmed his attack and copies of the original livestream circulated on non-GIFCT member platforms. Ultimately, GIFCT shared hashes, or digital fingerprints, related to 36 visually-distinct videos from the attack so that member companies could quickly detect and remove any instances of the content on their respective platforms.', 'Developing Resources to Further Our WorkAt GIFCT’s Annual Summit in July we released our first evertransparency reportand launched a cross-platformCampaign Toolkitfor activists and practitioners. We alsoreached our 2019 goalto contribute over 200,000 hashes, or digital fingerprints, of known terrorist images and video propaganda to our shared industry database allowing us to safely share this content so member companies can quickly identify and take action on potential terrorist content on their respective platforms.', 'Supporting Research and Knowledge SharingConducting and funding research to study counterterrorism and terrorism is a critical part of our work and was a key focus this year. In 2019, we supported the first phase of theGIFCT Academic Research Network, the Global Research Network on Terrorism and Technology. This phase was led by theRoyal United Services Instituteand produced13 original independent research paperslooking at different aspects of terrorism. We also announced that phase 2 of the Academic Research Network, the Global Network on Extremism and Technology, will begin in January 2020 and will be led by theInternational Centre for the Study of Radicalisation.', 'What’s NextFacebook’s chair of GIFCT this year brought important milestones for the organization and we remain dedicated to supporting this work as GIFCT is established as a standalone organization with an independent Executive Director and staff. In 2020, Microsoft will assume the chair of the independent GIFCT’s Operating Board, within the new governance framework of the institution. In addition to the Executive Director and staff, GIFCT’s structure will include an Independent Advisory Council composed of government representatives and civil society members, including advocacy groups, human rights specialists, researchers and technical experts, and a series of Working Groups designed to allow a wide range of stakeholders to deep-dive on key issues.', 'As GIFCT enters a new phase, we are proud of what has been accomplished and excited about next steps. We thank all of our partners for their work to date, and we’ll continue to collaborate with a range of experts to improve our collective ability to prevent terrorists and violent extremists from exploiting digital platforms.']\n",
            "162 ['Starting today, we are rolling out a new feature on Instagram that notifies people when their captions on a photo or video may be considered offensive, and gives them a chance to pause and reconsider their words before posting.', 'As part of our long-term commitment to lead the fight against online bullying, we’ve developed and tested AI that can recognize different forms of bullying on Instagram.Earlier this year, we launched a featurethat notifies people when their comments may be considered offensive before they’re posted. Results have been promising, and we’ve found that these types of nudges can encourage people to reconsider their words when given a chance.', '', 'Today, when someone writes a caption for a feed post and our AI detects the caption as potentially offensive, they will receive a prompt informing them that their caption is similar to those reported for bullying. They will have the opportunity to edit their caption before it’s posted.', 'In addition to limiting the reach of bullying, this warning helps educate people on what we don’t allow on Instagram, and when anaccount may be at risk ofbreaking our rules. To start, this feature will be rolling out in select countries, and we’ll begin expanding globally in the coming months.']\n",
            "163 ['Today we’re publishing the fourth edition of ourCommunity Standards Enforcement Report, detailing our work for Q2 and Q3 2019. We are now including metrics across ten policies on Facebook and metrics across four policies on Instagram.', 'These metrics include:', 'We also launched anew pagetoday so people can view examples of how our Community Standards apply to different types of content and see where we draw the line.', 'For the first time, we are sharing data on how we are doing at enforcing our policies on Instagram. In this first report for Instagram, we are providing data on four policy areas: child nudity and child sexual exploitation; regulated goods — specifically, illicit firearm and drug sales; suicide and self-injury; and terrorist propaganda. The report does not include appeals and restores metrics for Instagram, as appeals on Instagram were only launched in Q2 of this year, but these will be included in future reports.', 'While we use the same proactive detection systems to find and remove harmful content across both Instagram and Facebook, the metrics may be different across the two services. There are many reasons for this, including: the differences in the apps’ functionalities and how they’re used – for example, Instagram doesn’t have links, re-shares in feed, Pages or Groups; the differing sizes of our communities; where people in the world use one app more than another; and where we’ve had greater ability to use our proactive detection technology to date. When comparing metrics in order to see where progress has been made and where more improvements are needed, we encourage people to see how metrics change, quarter-over-quarter, for individual policy areas within an app.', 'Across the most harmful types of content we work to combat, we’ve continued to strengthen our efforts to enforce our policies and bring greater transparency to our work. In addition to suicide and self-injury content and terrorist propaganda, the metrics for child nudity and sexual exploitation of children, as well as regulated goods, demonstrate this progress. The investments we’ve made in AI over the last five years continue to be a key factor in tackling these issues. In fact,recent advancements in this technologyhave helped with rate of detection and removal of violating content.', 'Forchild nudity and sexual exploitation of children, we made improvements to our processes for adding violations to our internal database in order to detect and remove additional instances of the same content shared on both Facebook and Instagram, enabling us to identify and remove more violating content.', 'On Facebook:', 'While we are including data for Instagram for the first time, we have made progress increasing content actioned and the proactive rate in this area within the last two quarters:', 'Forour regulated goods policyprohibiting illicit firearm and drug sales, continued investments in our proactive detection systems and advancements in our enforcement techniques have allowed us to build on the progress from the last report.', 'On Facebook:', 'On Instagram:', 'Over the last two years, we’ve invested in proactive detection of hate speech so that we can detect this harmful content before people report it to us and sometimes before anyone sees it. Our detection techniques include text and image matching, which means we’re identifying images and identical strings of text that have already been removed as hate speech, and machine-learning classifiers that look at things like language, as well as the reactions and comments to a post, to assess how closely it matches common phrases, patterns and attacks that we’ve seen previously in content that violates our policies against hate.', 'Initially, we’ve used these systems to proactively detect potential hate speech violations and send them to our content review teams since people can better assess context where AI cannot. Starting in Q2 2019, thanks to continued progress in our systems’ abilities to correctly detect violations, we began removing some posts automatically, but only when content is either identical or near-identical to text or images previously removed by our content review team as violating our policy, or where content very closely matches common attacks that violate our policy. We only do this in select instances, and it has only been possible because our automated systems have been trained on hundreds of thousands, if not millions, of different examples of violating content and common attacks. In all other cases when our systems proactively detect potential hate speech, the content is still sent to our review teams to make a final determination. With these evolutions in our detection systems, our proactive rate has climbed to 80%, from 68% in our last report, and we’ve increased the volume of content we find and remove for violating our hate speech policy.', 'While we are pleased with this progress, these technologies are not perfect and we know that mistakes can still happen. That’s why we continue to invest in systems that enable us to improve our accuracy in removing content that violates our policies while safeguarding content that discusses or condemns hate speech. Similar to how we review decisions made by our content review team in order to monitor the accuracy of our decisions, our teams routinely review removals by our automated systems to make sure we are enforcing our policies correctly. We also continue to review content again when people appeal and tell us we made a mistake in removing their post.', 'Since our last report, we have improved the ways we measure how much content we take action on after identifying an issue in our accounting this summer. In this report, we are updating metrics we previously shared for content actioned, proactive rate, content appealed and content restored for the periods Q3 2018 through Q1 2019.', 'During those quarters, the issue with our accounting processes did not impact how we enforced our policies or how we informed people about those actions; it only impacted how we counted the actions we took. For example, if we find that a post containing one photo violates our policies, we want our metric to reflect that we took action on one piece of content — not two separate actions for removing the photo and the post. However, in July 2019, we found that the systems logging and counting these actions did not correctly log the actions taken. This was largely due to needing to count multiple actions that take place within a few milliseconds and not miss, or overstate, any of the individual actions taken.', 'We’ll continue to refine the processes we use to measure our actions and build a robust system to ensure the metrics we provide are accurate. We share more details about these processeshere.']\n",
            "164 ['At Facebook, we believe that women should have equal access to all of the economic opportunity, education and social connection the internet provides.', '“It’s a civil liberties and civil rights issue to be able to access loved ones any time, access information, access job searches,” says Cindy Southworth. “The world is out there, and you need access to technology to access that world.”', 'Southworth is the Executive Vice President of the US-based National Network to End Domestic Violence. As a member of theFacebook Safety Advisory Board, her organization works with us to make our platform a safer, more welcoming place for women. Southworth has spent almost 30years working with domestic violence victims and is keenly aware of how social media can be both an abuser’s tool and a victim’s lifeline — which is why at Facebook, we work to reduce the abuse and harassment that can keep women offline while building tools and resources to empower them online.', 'We take a comprehensive approach to making our platform a safer place for women, including writing clear policies and developing cutting-edge technology to help prevent abuse from happening in the first place.', 'TheFacebook Community Standardsand theInstagram Community Guidelinesoutline the rules for what is and isn’t allowed on Facebook and Instagram. They’re developed by our policy teams and include rules against behaviors that disproportionately impact women, such as the sharing ofnon-consensual intimate imagery, which is illegal in many places around the world. They also include rules against harassment, like sending multiple unwanted messages to a person who’s made it clear that they don’t want to receive them.', 'As weupdate and refine our policiesto keep pace with changes happening online and offline around the world, we regularly engage with outside experts. In July, for example, our policy teamexpanded our hate speech policyon targeted cursing, profanity used to attack a private individual, to include female-gendered terms.In crafting our recommendation, wespoke to expertsaround the world, including anthropological and cognitive linguists, women’s rights organizations and safety organizations.', 'These rules apply to everyone who uses Facebook and Instagram. And because cultural norms around things like sexuality, friendships and women’s roles in society can differ so widely, these conversations with global experts help us understand how abuse and harassment manifest differently in different places.', '“The general themes when it comes to women’s safety tend to be the same around the world,” says Monika Bickert, Facebook’s Vice President of Global Policy Management. “But we find that when we look at specific countries or regions, the actual types of behavior are very localized.”', 'For example, harassers will commonly try to humiliate a woman by sharing images of her that would be considered shameful in her community. In the US, a harasser might select a nude photo or a video of the woman engaging in a sexual activity. We’d remove the image according to our standards on thesexual exploitation of adults. In some countries, a woman could be shamed or put at risk if someone shared a photo of her ankle, or a photo of her walking with a man who isn’t a family member. If someone shares this in a way that makes clear they’re trying to humiliate her, that would fall under our standards onbullying and harassment.', 'To account for this wide spectrum of harassment types, our rules need to be thoughtful and similarly comprehensive.', 'In addition to policies, we develop technology to fight behavior that threatens to keep women offline. We offera number of toolsto help people control their experience on Facebook, such as ignoring unwanted messages and blocking other people without them being notified. Victims and their allies can also report violating behavior, and we will remove anything that doesn’t follow our policies.', 'Global research helps us better serve people around the world in this area as well. In India, both people who use our services and safety advocates told us that some women in the country choose not to share profile pictures that include their faces because they’re concerned that someone might try to take those photos and impersonate them in ways that would shame or dishonor them or their families. So we developed an optionalprofile picture guardthat gives women more control over who can download or share their pictures. This is available in India, Pakistan, Egypt and other countries where women have similar concerns.', 'Blocking, reporting and other user-facing tools are only part of the solution and their success relies on people knowing to seek them out and understanding how to use them — plus feeling comfortable enough to use them. A victim who’s already feeling anxious or threatened may not want to trigger a harasser for fear of retribution. Sometimes, the behavior isn’t visible to the woman it affects: an ex might share non-consensual intimate images in a private group, for example. Or a bully might set up a fake account in a woman’s name and operate it without her knowledge, adding members of her community as friends. That’s why Facebook is not only investing in digital literacy programs andimproved safety resourcesbut we’re also investing in technology that can find violating content proactively — and in some cases, prevent it from being shared in the first place.', 'Facebook’s work to prevent the non-consensual sharing of intimate images, or NCII, serves as a clear example of this comprehensive approach to deploying technology. In 2017, we launcheda pilot programto help potential victims prevent their intimate images from appearing on Facebook and Instagram without their consent. As part of this program, people who fear their images are in danger of being shared can reach out to a victim advocate organization, where someone will help them securely submit those photos to Facebook. On our end, we create digital fingerprints of the images before destroying them. The images are never seen by anyone at Facebook before they are deleted. Then, using photo-matching technology, we block the images from being posted to Facebook and Instagram.', 'Of course, the pilot program only works if the potential victim is aware that their images are at risk of being shared. In cases where an intimate image is shared to Facebook and Instagram and then reported to us after the fact, we can minimize the damage by using the same combination of digital fingerprinting and photo-matching technology so they don’t get shared again.', 'But we wanted to do even more. That’s why we developed machine-learning and artificial-intelligence techniques toproactively detectnude or near-nude images and videos shared without permission — without anyone having to report them.', 'Comprehensive approaches to complicated problems, like the one we’ve developed for NCII, require a lot of input and a lot of expertise, and we know we can’t do this alone.That’s why we host roundtable discussions around the world with women’s safety experts, women who have experienced some of these issues and women’s advocates to ensure we’re including their feedback, perspectives and expertise in our work.', 'One example of this kind of collaborative work is theannual Global Safety and Well-Being Summit, which brought together over 100 organizations from 40 countries this year to discuss women’s safety as well as other topics such as suicide prevention and raising children in the digital era.', 'Nighat Dad, Executive Director of the Digital Rights Foundation in Pakistan, attended the 2019 summit in New York, and has worked with Facebook on issues related to harassment, including the sharing of non-consensual intimate images.', '“Online gender-based violence — it’s not a technology problem, it’s a societal problem,” said Dad. “The people who are working on the ground, they need to work together on this and also keep telling social media platforms how they can improve their products, how they can improve their reporting mechanisms. It’s not just one person who can address the issue, or one organization or one institution, we all need to work together.”', 'Resources', 'Learn More']\n",
            "165 ['By Freddy Abnousi, MD, Head of Healthcare Research', 'Many of today’s leading health threats aren’t ones that science or medicine can solve alone. Changing trends in communication and unequal access to care mean we need new solutions and partnerships to overcome these global challenges.', 'Take the issue of blood shortages. Every few seconds, someone in the world needs blood. But people often aren’t aware of shortages and don’t know where to donate. To address this, we launched a feature in the US, India, Brazil, Bangladesh and Pakistan that makes it easy to sign up as a donor on Facebook and get notified when nearby blood banks are in need. So far,more than 50 million peoplehave signed up to donate.', 'Another area we’re exploring is preventive health. Tens of millions of people in the US are missing out on recommended preventive care, according to the Centers for Disease Control and Prevention. Preventive measures have the potential to detect disease early when it’s most treatable and, in some cases, prevent it from developing. Yet factors such as awareness, access and cost create barriers to testing for many people.', 'To help, we’re working with US health organizations to offer a new Preventive Health tool that connects people to health resources and checkup reminders. Our initial focus is on the top two leading causes of death in the US: heart disease and cancer, (according toCDC) as well as the flu, a seasonal illness that affects millions each year. The resources available in the tool are provided by the American Cancer Society, the American College of Cardiology, the American Heart Association and the Centers for Disease Control and Prevention — organizations recognized for their education and expertise in these areas.', '“Heart disease is the number one killer of men and women around the world and in many cases it is 100% preventable. By incorporating prevention reminders into platforms people are accessing every day, we’re giving people the tools they need to be proactive about their heart health.”– Richard Kovacs, MD, President of the American College of Cardiology', 'How Preventive Health Works', 'In the US, people can search for Preventive Health in the Facebook mobile app and find out which checkups, such as cholesterol tests or mammograms, are recommended by these health organizations based on the age and sex they provide. Reminders for flu shots will also appear at the appropriate time of year.', 'The tool allows people to mark when tests are completed, set reminders to schedule future tests and tell loved ones about the tool to increase awareness of preventive care. People can also learn more about each checkup and find affordable places to receive care.', '“We’ve contributed our content and resources to the Facebook Preventive Health tool to empower Americans to take the first step to know about and take action to lower blood pressure, blood sugar and cholesterol, each of which has been shown to increase the chance of a longer, healthier life and reduce the likelihood of a heart attack or stroke.”– Eduardo Sanchez, MD, Chief Medical Officer for Prevention at the American Heart Association', '', '“One of the main reasons people don’t get screened for cancer is that they don’t realize their own risk. We hope this program will help by building awareness about important recommendations from expert organizations.”– Richard Wender, MD, Chief Cancer Control Officer at the American Cancer Society', 'Most of the preventive measures recommended by the health organizations we’re working with, such as blood pressure tests, are free of charge with insurance coverage, but we know many people do not have insurance. To help people get affordable care, Preventive Health offers a way to find Federally Qualified Health Centers near them. These centers are located in underserved areas and provide care to everyone, regardless of their ability to pay.', '', 'People can also use Preventive Health to find convenient locations that offer flu shots, such as grocery stores, pharmacies and urgent care clinics.', '“Flu vaccines can have wide-ranging benefits beyond just preventing the disease, such as reducing the risk of hospitalization, preventing serious medical events for some people with chronic diseases, and protecting women during and after pregnancy. New tools like this will empower users with instant access to information and resources they need to become a flu fighter in their own communities.”– Nancy Messonnier, MD, Director, National Center for Immunization and Respiratory Diseases, CDC', 'Over time, we’ll work with additional organizations to include more resources and expand to other countries.', 'Privacy Matters', 'Health is particularly personal, so we took privacy and safety into account from the beginning. For example, Preventive Health allows you to set reminders for your future checkups and mark them as done, but it doesn’t provide us, or the health organizations we’re working with, access to your actual test results.Personal information about your activity in Preventive Health is not shared with third parties, such as health organizations or insurance companies, so it can’t be used for purposes like insurance eligibility.', 'We don’t show ads based on the information you provide in Preventive Health — that includes things like setting a reminder for a test, marking it as done or searching for a healthcare location. As always, other actions that you take on Facebook could inform the ads you see, for example, liking the Facebook page of a health organization or visiting an external website linked to from Preventive Health.', 'To learn more about Preventive Health and privacy, see thispost.', 'Our Efforts Across Health', 'Preventive Health and Blood Donations are just two of the ways we can help people advocate for their own health and help others:', 'We know there’s more we can do to help people, and we’ll continue to partner with organizations to provide access to resources and reach people in diverse communities.', 'More on Preventive Health:https://preventivehealth.facebook.com/', 'American Cancer Society:https://www.cancer.org/', 'American College of Cardiology:https://www.acc.org/', 'American Heart Association:https://www.heart.org/', 'Centers for Disease Control and Prevention:https://www.cdc.gov/']\n",
            "166 ['By Erin Egan, VP and Chief Privacy Officer, Public Policy', 'We created Facebook’sPreventive Health toolto connect you to health resources and checkup reminders, making it easier to take control of your health. Because we know health data is particularly personal, we took extra steps to protect your privacy and collect a limited amount of information necessary to make the tool function and improve it over time.', 'Who sees my information and activity?', 'Your activity within Preventive Health will not be posted publicly or shared with others. Information you provide is securely stored and access is restricted to a group of people at Facebook who work on the product or maintain our systems. We don’t share personal information about your activity in Preventive Health with third parties, such as health organizations or insurance companies, so it can’t be used for purposes like insurance eligibility.', 'What choices and controls do I have?', 'You can decide whether you want to use the Preventive Health tool. The tool will give you options to set reminders for your future checkups and mark them as done, but it will not give us access to your actual test results. If you choose, you can share the tool with your friends or family through Messenger or News Feed to encourage them to try it, but doing so will not share your activity within the tool.', 'If you have Location Services turned on, we can use that information to show you Federally Qualified Health Centers (FQHCs) in your area. If not, we default to showing a location based on your current city. You can control whether your device shares precise location information with Facebook Products via Location Services, a setting on your mobile device.', 'How does this impact data collection and the ads I see?', 'Preventive Health uses your age and sex to suggest checkups recommended by health organizations. Your age and sex is based on your Facebook profile by default, but you can change these in the Preventive Health tool.', 'To help you keep track of your checkups, we collect information you provide, such as when you set reminders or mark a screening as done. We also log more general activity, like frequency of clicks for a specific button, which allows us to understand how the tool is being used, in order to improve it over time.', 'We don’t show ads based on the information you provide in Preventive Health — that includes things like setting a reminder for a test, marking it as done or searching for a healthcare location. As always, other actions that you take on Facebook could inform the ads you see, for example, liking the Facebook page of a health organization or visiting an external website linked to from Preventive Health.']\n",
            "167 ['Learn more about how we’reprotecting the US 2020 elections.', 'Update on January 27, 2020 at 1:30PM PT:In order to continue running issue, electoral or political ads in the US, advertisers must assign a Page Owner. To help ensure all advertisers have time to complete this, we are extending our deadline to become compliant to February 8, 2020.', 'Original post on October 21, 2019:', 'We have a responsibility to stop abuse and election interference on our platform. That’s why we’ve made significant investments since 2016 to better identify new threats, close vulnerabilities and reduce the spread of viral misinformation and fake accounts.', 'Today, almost a year out from the 2020 elections in the US, we’re announcing several new measures to help protect the democratic process and providing an update on initiatives already underway:', 'Fighting foreign interference', 'Increasing transparency', 'Reducing misinformation', 'Combating Inauthentic Behavior', 'Over the last three years, we’ve worked to identify new and emerging threats and removecoordinated inauthentic behavioracross our apps. In the past year alone, we’ve taken down over 50 networks worldwide, many ahead of major democratic elections. As part of our effort to counter foreign influence campaigns, this morning we removed four separate networks of accounts, Pages and Groups on Facebook and Instagram for engaging in coordinated inauthentic behavior. Three of them originated in Iran and one in Russia. They targeted the US, North Africa and Latin America.We have identified these manipulation campaignsas part of our internal investigations into suspected Iran-linked inauthentic behavior, as well as ongoing proactive work ahead of the US elections.', 'We took down these networks based on their behavior, not the content they posted. In each case, the people behind this activity coordinated with one another and used fake accounts to misrepresent themselves, and that was the basis for our action. We have shared our findings with law enforcement and industry partners. More details can be foundhere.', 'As we’ve improved our ability to disrupt these operations, we’ve also built a deeper understanding of different threats and how best to counter them. We investigate and enforce against any type of inauthentic behavior. However, the most appropriate way to respond to someone boosting the popularity of their posts in their own country may not be the best way to counter foreign interference. That’s why we’re updating ourinauthentic behavior policyto clarifyhow we deal with the range of deceptive practices we see on our platforms, whether foreign or domestic, state or non-state.', 'Protecting the Accounts of Candidates, Elected Officials and Their Teams', 'Today, we’re launchingFacebook Protectto further secure the accounts of elected officials, candidates, their staff and others who may be particularly vulnerable to targeting by hackers and foreign adversaries. As we’ve seen in past elections, they can be targets of malicious activity. However, because campaigns are generally run for a short period of time, we don’t always know who these campaign-affiliated people are, making it harder to help protect them.', 'Beginning today, Page admins can enroll their organization’s Facebook and Instagram accounts in Facebook Protect and invite members of their organization to participate in the program as well. Participants will be required to turn on two-factor authentication, and their accounts will be monitored for hacking, such as login attempts from unusual locations or unverified devices. And, if we discover an attack against one account, we can review and protect other accounts affiliated with that same organization that are enrolled in our program. Read more about Facebook Protect and enrollhere.', '', 'Making Pages More TransparentWe want to make sure people are using Facebook authentically, and that they understand who is speaking to them. Over the past year, we’ve taken steps to ensure Pages are authentic and more transparent by showing people the Page’s primary country location and whether the Page has merged with other Pages. This gives people more context on the Page and makes it easier to understand who’s behind it.', 'Increasingly, we’ve seen people failing to disclose the organization behind their Page as a way to make people think that a Page is run independently. To address this, we’re adding more information about who is behind a Page, including a new “Organizations That Manage This Page” tab that will feature the Page’s “Confirmed Page Owner,” including the organization’s legal name and verified city, phone number or website.', 'Initially, this information will only appear on Pages with large US audiences that have gone through Facebook’sbusiness verification. In addition, Pages that have gone through the new authorization process to run ads about social issues, elections or politics in the US will also have this tab. And starting in January, these advertisers will be required to show their Confirmed Page Owner.', 'If we find a Page is concealing its ownership in order to mislead people, we will require it to successfully complete the verification process and show more information in order for the Page to stay up.', '', 'Labeling State-Controlled Media', 'We want to help people better understand the sources of news content they see on Facebook so they can make informed decisions about what they’re reading. Next month, we’ll begin labeling media outlets that are wholly or partially under the editorial control of their government as state-controlled media. This label will be on both their Page and in our Ad Library.', 'We will hold these Pages to a higher standard of transparency because they combine the opinion-making influence of a media organization with the strategic backing of a state.', 'We developed our own definition and standards for state-controlled media organizations with input from more than 40 experts around the world specializing in media, governance, human rights and development. Those consulted represent leading academic institutions, nonprofits and international organizations in this field, including Reporters Without Borders, Center for International Media Assistance, European Journalism Center, Oxford Internet Institute, Center for Media, Data and Society (CMDS) at the Central European University, the Council of Europe, UNESCO and others.', 'It’s important to note that our policy draws an intentional distinction between state-controlled media and public media, which we define as any entity that is publicly financed, retains a public service mission and can demonstrate its independent editorial control. At this time, we’re focusing our labeling efforts only on state-controlled media.', 'We will update the list of state-controlled media on a rolling basis beginning in November. And, in early 2020, we plan to expand our labeling to specific posts and apply these labels on Instagram as well. For any organization that believes we have applied the label in error, there will be an appeals process.', 'Making it Easier to Understand Political Ads', 'In addition to making Pages more transparent, we’re updating the Ad Library, Ad Library Report and Ad Library API to help journalists, lawmakers, researchers and others learn more about the ads they see. This includes:', 'In addition to updates to the Ad Library API, in November, we will begin testing a new database with researchers that will enable them to quickly download the entire Ad Library, pull daily snapshots and track day-to-day changes.', 'Visit our Help Center to learn more about the changesto Pagesandthe Ad Library.', 'Preventing the Spread of Viral MisinformationOn Facebook and Instagram, we work to keep confirmed misinformation from spreading. For example, we reduce its distribution so fewer people see it—on Instagram, we remove it from Explore and hashtags, and on Facebook, we reduce its distribution in News Feed.On Instagram, we also make content from accounts that repeatedly post misinformation harder to find by filtering content from that account from Explore and hashtag pages for example. And on Facebook,if Pages, domains or Groups repeatedly share misinformation, we’ll continue to reduce their overall distribution and we’ll place restrictions on the Page’s ability to advertise and monetize.', 'Over the next month, content across Facebook and Instagram that has been rated false or partly false by a third-party fact-checker will start to be more prominently labeled so that people can better decide for themselves what to read, trust and share. The labels below will be shown on top of false and partly false photos and videos, including on top of Stories content on Instagram, and will link out to the assessment from the fact-checker.', '', 'Much like we do on Facebook when people try to share known misinformation, we’re also introducing a new pop-up that will appear when people attempt to share posts on Instagram that include content that has been debunked by third-party fact-checkers.', '', 'In addition to clearer labels, we’re also working to take faster action to prevent misinformation from going viral, especially given that quality reporting and fact-checking takes time. In many countries, including in the US, if we have signals that a piece of content is false, we temporarily reduce its distribution pending review by a third-party fact-checker.', 'Fighting Voter Suppression and IntimidationAttempts to interfere with or suppress voting undermine our core values as a company, and we work proactively to remove this type of harmful content. Ahead of the 2018 midterm elections, we extended our voter suppression and intimidation policies to prohibit:', 'We remove this type of content regardless of who it’s coming from, andahead of the midterm elections, our Elections Operations Center removed more than 45,000 pieces of content that violated these policies—more than 90% of which our systems detected before anyone reported the content to us.', 'We also recognize that there are certain types of content, such as hate speech, that are equally likely to suppress voting. That’s why ourhate speech policiesban efforts to exclude people from political participation on the basis of things like race, ethnicity or religion (e.g., telling people not to vote for a candidate because of the candidate’s race, or indicating that people of a certain religion should not be allowed to hold office).', 'In advance of the US 2020 elections, we’re implementing additional policies and expanding our technical capabilities on Facebook and Instagram to protect the integrity of the election. Following up on a commitment we made in thecivil rights audit reportreleased in June, we have now implemented our policy banning paid advertising that suggests voting is useless or meaningless, or advises people not to vote.', 'In addition, our systems are now more effective at proactively detecting and removing this harmful content. We use machine learning to help us quickly identify potentially incorrect voting information and remove it.', 'We are also continuing to expand and develop our partnerships to provide expertise on trends in voter suppression and intimidation, as well as early detection of violating content. This includes working directly with secretaries of state and election directors to address localized voter suppression that may only be occurring in a single state or district. This work will be supported by our Elections Operations Center during both the primary and general elections.', 'Helping People Better Understand What They See Online', 'Part of our work to stop the spread of misinformation is helping people spot it for themselves. That’s why we partner with organizations and experts in media literacy.', 'Today, we’re announcing an initial investment of $2 million to support projects that empower people to determine what to read and share — both on Facebook and elsewhere.', 'These projects range from training programs to help ensure the largest Instagram accounts have the resources they need to reduce the spread of misinformation, to expanding a pilot program that brings together senior citizens and high school students to learn about online safety and media literacy, to public events in local venues like bookstores, community centers and libraries in cities across the country. We’re also supporting a series of training events focused on critical thinking among first-time voters.', 'In addition, we’re including a new series of media literacy lessons in our Digital Literacy Library. These lessons are drawn from the Youth and Media team at the Berkman Klein Center for Internet & Society at Harvard University, which has made them available for free worldwide under a Creative Commons license. The lessons, created for middle and high school educators, are designed to be interactive and cover topics ranging from assessing the quality of the information online to more technical skills like reverse image search.', 'We’ll continue to develop our media literacy efforts in the US and we’ll have more to share soon.']\n",
            "168 ['Today, Mark Zuckerberg spoke at Georgetown University about the importance of protecting free expression. He underscored his belief that giving everyone a voice empowers the powerless and pushes society to be better over time — a belief that’s at the core of Facebook.', 'In front of hundreds of students at the school’s Gaston Hall, Mark warned that we’re increasingly seeing laws and regulations around the world that undermine free expression and human rights. He argued that in order to make sure people can continue to have a voice, we should: 1) write policy that helps the values of voice and expression triumph around the world, 2)fend off the urge to define speech we don’t like as dangerous, and 3) build new institutions so companies like Facebook aren’t making so many important decisions about speech on our own.', 'Read Mark’s full speech below.', 'Hey everyone. It’s great to be here at Georgetown with all of you today.', 'Before we get started, I want to acknowledge that today we lost an icon, Elijah Cummings. He was a powerful voice for equality, social progress and bringing people together.', 'When I was in college, our country had just gone to war in Iraq. The mood on campus was disbelief. It felt like we were acting without hearing a lot of important perspectives. The toll on soldiers, families and our national psyche was severe, and most of us felt powerless to stop it. I remember feeling that if more people had a voice to share their experiences, maybe things would have gone differently. Those early years shaped my belief that giving everyone a voice empowers the powerless and pushes society to be better over time.', 'Back then, I was building an early version of Facebook for my community, and I got to see my beliefs play out at smaller scale. When students got to express who they were and what mattered to them, they organized more social events, started more businesses, and even challenged some established ways of doing things on campus. It taught me that while the world’s attention focuses on major events and institutions, the bigger story is that most progress in our lives comes from regular people having more of a voice.', 'Since then, I’ve focused on building services to do two things: give people voice, and bring people together. These two simple ideas — voice and inclusion — go hand in hand. We’ve seen this throughout history, even if it doesn’t feel that way today. More people being able to share their perspectives has always been necessary to build a more inclusive society. And our mutual commitment to each other — that we hold each others’ right to express our views and be heard above our own desire to always get the outcomes we want — is how we make progress together.', 'But this view is increasingly being challenged. Some people believe giving more people a voice is driving division rather than bringing us together. More people across the spectrum believe that achieving the political outcomes they think matter is more important than every person having a voice. I think that’s dangerous. Today I want to talk about why, and some important choices we face around free expression.', 'Throughout history, we’ve seen how being able to use your voice helps people come together. We’ve seen this in the civil rights movement. Frederick Douglass once called free expression “the great moral renovator of society”. He said “slavery cannot tolerate free speech”. Civil rights leaders argued time and again that their protests were protected free expression, and one noted: “nearly all the cases involving the civil rights movement were decided on First Amendment grounds”.', 'We’ve seen this globally too, where the ability to speak freely has been central in the fight for democracy worldwide. The most repressive societies have always restricted speech the most — and when people are finally able to speak, they often call for change. This year alone, people have used their voices to end multiple long-running dictatorships in Northern Africa. And we’re already hearing from voices in those countries that had been excluded just because they were women, or they believed in democracy.', 'Our idea of free expression has become much broader over even the last 100 years. Many Americans know about the Enlightenment history and how we enshrined the First Amendment in our constitution, but fewer know how dramatically our cultural norms and legal protections have expanded, even in recent history.', 'The first Supreme Court case to seriously consider free speech and the First Amendment was in 1919, Schenk vs the United States. Back then, the First Amendment only applied to the federal government, and states could and often did restrict your right to speak. Our ability to call out things we felt were wrong also used to be much more restricted. Libel laws used to impose damages if you wrote something negative about someone, even if it was true. The standard later shifted so it became okay as long as you could prove your critique was true. We didn’t get the broad free speech protections we have now until the 1960s, when the Supreme Court ruled in opinions like New York Times vs Sullivan that you can criticize public figures as long as you’re not doing so with actual malice, even if what you’re saying is false.', 'We now have significantly broader power to call out things we feel are unjust and share our own personal experiences. Movements like #BlackLivesMatter and #MeToo went viral on Facebook — the hashtag #BlackLivesMatter was actually first used on Facebook — and this just wouldn’t have been possible in the same way before. 100 years back, many of the stories people have shared would have been against the law to even write down. And without the internet giving people the power to share them directly, they certainly wouldn’t have reached as many people. With Facebook, more than 2 billion people now have a greater opportunity to express themselves and help others.', 'While it’s easy to focus on major social movements, it’s important to remember that most progress happens in our everyday lives. It’s the Air Force moms who started a Facebook group so their children and other service members who can’t get home for the holidays have a place to go. It’s the church group that came together during a hurricane to provide food and volunteer to help with recovery. It’s the small business on the corner that now has access to the same sophisticated tools only the big guys used to, and now they can get their voice out and reach more customers, create jobs and become a hub in their local community. Progress and social cohesion come from billions of stories like this around the world.', 'People having the power to express themselves at scale is a new kind of force in the world — a Fifth Estate alongside the other power structures of society. People no longer have to rely on traditional gatekeepers in politics or media to make their voices heard, and that has important consequences. I understand the concerns about how tech platforms have centralized power, but I actually believe the much bigger story is how much these platforms have decentralized power by putting it directly into people’s hands. It’s part of this amazing expansion of voice through law, culture and technology.', 'So giving people a voice and broader inclusion go hand in hand, and the trend has been towards greater voice over time. But there’s also a counter-trend. In times of social turmoil, our impulse is often to pull back on free expression. We want the progress that comes from free expression, but not the tension.', 'We saw this when Martin Luther King Jr. wrote his famous letter from Birmingham Jail, where he was unconstitutionally jailed for protesting peacefully. We saw this in the efforts to shut down campus protests against the Vietnam War. We saw this way back when America was deeply polarized about its role in World War I, and the Supreme Court ruled that socialist leader Eugene Debs could be imprisoned for making an anti-war speech.', 'In the end, all of these decisions were wrong. Pulling back on free expression wasn’t the answer and, in fact, it often ended up hurting the minority views we seek to protect. From where we are now, it seems obvious that, of course, protests for civil rights or against wars should be allowed. Yet the desire to suppress this expression was felt deeply by much of society at the time.', 'Today, we are in another time of social tension. We face real issues that will take a long time to work through — massive economic transitions from globalization and technology, fallout from the 2008 financial crisis, and polarized reactions to greater migration. Many of our issues flow from these changes.', 'In the face of these tensions, once again a popular impulse is to pull back from free expression. We’re at another cross-roads. We can continue to stand for free expression, understanding its messiness, but believing that the long journey towards greater progress requires confronting ideas that challenge us. Or we can decide the cost is simply too great. I’m here today because I believe we must continue to stand for free expression.', 'At the same time, I know that free expression has never been absolute. Some people argue internet platforms should allow all expression protected by the First Amendment, even though the First Amendment explicitly doesn’t apply to companies. I’m proud that our values at Facebook are inspired by the American tradition, which is more supportive of free expression than anywhere else. But even American tradition recognizes that some speech infringes on others’ rights. And still, a strict First Amendment standard might require us to allow terrorist propaganda, bullying young people and more that almost everyone agrees we should stop — and I certainly do — as well as content like pornography that would make people uncomfortable using our platforms.', 'So once we’re taking this content down, the question is: where do you draw the line? Most people agree with the principles that you should be able to say things other people don’t like, but you shouldn’t be able to say things that put people in danger. The shift over the past several years is that many people would now argue that more speech is dangerous than would have before. This raises the question of exactly what counts as dangerous speech online. It’s worth examining this in detail.', 'Many arguments about online speech are related to new properties of the internet itself. If you believe the internet is completely different from everything before it, then it doesn’t make sense to focus on historical precedent. But we should be careful of overly broad arguments since they’ve been made about almost every new technology, from the printing press to radio to TV. Instead, let’s consider the specific ways the internet is different and how internet services like ours might address those risks while protecting free expression.', 'One clear difference is that a lot more people now have a voice — almost half the world. That’s dramatically empowering for all the reasons I’ve mentioned. But inevitably some people will use their voice to organize violence, undermine elections or hurt others, and we have a responsibility to address these risks. When you’re serving billions of people, even if a very small percent cause harm, that can still be a lot of harm.', 'We build specific systems to address each type of harmful content — from incitement of violence to child exploitation to other harms like intellectual property violations — about 20 categories in total. We judge ourselves by the prevalence of harmful content and what percent we find proactively before anyone reports it to us. For example, our AI systems identify 99% of the terrorist content we take down before anyone even sees it. This is a massive investment. We now have over 35,000 people working on security, and our security budget today is greater than the entire revenue of our company at the time of our IPO earlier this decade.', 'All of this work is about enforcing our existing policies, not broadening our definition of what is dangerous. If we do this well, we should be able to stop a lot of harm while fighting back against putting additional restrictions on speech.', 'Another important difference is how quickly ideas can spread online. Most people can now get much more reach than they ever could before. This is at the heart of a lot of the positive uses of the internet. It’s empowering that anyone can start a fundraiser, share an idea, build a business, or create a movement that can grow quickly. But we’ve seen this go the other way too — most notably when Russia’s IRA tried to interfere in the 2016 elections, but also when misinformation has gone viral. Some people argue that virality itself is dangerous, and we need tighter filters on what content can spread quickly.', 'For misinformation, we focus on making sure complete hoaxes don’t go viral. We especially focus on misinformation that could lead to imminent physical harm, like misleading health advice saying if you’re having a stroke, no need to go to the hospital.', 'More broadly though, we’ve found a different strategy works best: focusing on the authenticity of the speaker rather than the content itself. Much of the content the Russian accounts shared was distasteful but would have been considered permissible political discourse if it were shared by Americans — the real issue was that it was posted by fake accounts coordinating together and pretending to be someone else. We’ve seen a similar issue with these groups that pump out misinformation like spam just to make money.', 'The solution is to verify the identities of accounts getting wide distribution and get better at removing fake accounts. We now require you to provide a government ID and prove your location if you want to run political ads or a large page. You can still say controversial things, but you have to stand behind them with your real identity and face accountability. Our AI systems have also gotten more advanced at detecting clusters of fake accounts that aren’t behaving like humans. We now remove billions of fake accounts a year — most within minutes of registering and before they do much. Focusing on authenticity and verifying accounts is a much better solution than an ever-expanding definition of what speech is harmful.', 'Another qualitative difference is the internet lets people form communities that wouldn’t have been possible before. This is good because it helps people find groups where they belong and share interests. But the flip side is this has the potential to lead to polarization. I care a lot about this — after all, our goal is to bring people together.', 'Much of the research I’ve seen is mixed and suggests the internet could actually decrease aspects of polarization. The most polarized voters in the last presidential election were the people least likely to use the internet. Research from the Reuters Institute also shows people who get their news online actually have a much more diverse media diet than people who don’t, and they’re exposed to a broader range of viewpoints. This is because most people watch only a couple of cable news stations or read only a couple of newspapers, but even if most of your friends online have similar views, you usually have some that are different, and you get exposed to different perspectives through them. Still, we have an important role in designing our systems to show a diversity of ideas and not encourage polarizing content.', 'One last difference with the internet is it lets people share things that would have been impossible before. Take live-streaming, for example. This allows families to be together for moments like birthdays and even weddings, schoolteachers to read bedtime stories to kids who might not be read to, and people to witness some very important events. But we’ve also seen people broadcast self-harm, suicide, and terrible violence. These are new challenges and our responsibility is to build systems that can respond quickly.', 'We’re particularly focused on well-being, especially for young people. We built a team of thousands of people and AI systems that can detect risks of self-harm within minutes so we can reach out when people need help most. In the last year, we’ve helped first responders reach people who needed help thousands of times.', 'For each of these issues, I believe we have two responsibilities: to remove content when it could cause real danger as effectively as we can, and to fight to uphold as wide a definition of freedom of expression as possible — and not allow the definition of what is considered dangerous to expand beyond what is absolutely necessary. That’s what I’m committed to.', 'But beyond these new properties of the internet, there are also shifting cultural sensitivities and diverging views on what people consider dangerous content.', 'Take misinformation. No one tells us they want to see misinformation. That’s why we work with independent fact checkers to stop hoaxes that are going viral from spreading. But misinformation is a pretty broad category. A lot of people like satire, which isn’t necessarily true. A lot of people talk about their experiences through stories that may be exaggerated or have inaccuracies, but speak to a deeper truth in their lived experience. We need to be careful about restricting that. Even when there is a common set of facts, different media outlets tell very different stories emphasizing different angles. There’s a lot of nuance here. And while I worry about an erosion of truth, I don’t think most people want to live in a world where you can only post things that tech companies judge to be 100% true.', 'We recently clarified our policies to ensure people can see primary source speech from political figures that shapes civic discourse. Political advertising is more transparent on Facebook than anywhere else — we keep all political and issue ads in an archive so everyone can scrutinize them, and no TV or print does that. We don’t fact-check political ads. We don’t do this to help politicians, but because we think people should be able to see for themselves what politicians are saying. And if content is newsworthy, we also won’t take it down even if it would otherwise conflict with many of our standards.', '', 'I know many people disagree, but, in general, I don’t think it’s right for a private company to censor politicians or the news in a democracy. And we’re not an outlier here. The other major internet platforms and the vast majority of media also run these same ads.', '', 'American tradition also has some precedent here. The Supreme Court case I mentioned earlier that gave us our current broad speech rights, New York Times vs Sullivan, was actually about an ad with misinformation, supporting Martin Luther King Jr. and criticizing an Alabama police department. The police commissioner sued the Times for running the ad, the jury in Alabama found against the Times, and the Supreme Court unanimously reversed the decision, creating today’s speech standard.', 'As a principle, in a democracy, I believe people should decide what is credible, not tech companies. Of course there are exceptions, and even for politicians we don’t allow content that incites violence or risks imminent harm — and of course we don’t allow voter suppression. Voting is voice. Fighting voter suppression may be as important for the civil rights movement as free expression has been. Just as we’re inspired by the First Amendment, we’re inspired by the 15th Amendment too.', '', 'Given the sensitivity around political ads, I’ve considered whether we should stop allowing them altogether. From a business perspective, the controversy certainly isn’t worth the small part of our business they make up. But political ads are an important part of voice — especially for local candidates, up-and-coming challengers, and advocacy groups that may not get much media attention otherwise. Banning political ads favors incumbents and whoever the media covers.', 'Even if we wanted to ban political ads, it’s not clear where we’d draw the line. There are many more ads about issues than there are directly about elections. Would we ban all ads about healthcare or immigration or women’s empowerment? If we banned candidates’ ads but not these, would that really make sense to give everyone else a voice in political debates except the candidates themselves? There are issues any way you cut this, and when it’s not absolutely clear what to do, I believe we should err on the side of greater expression.', 'Or take hate speech, which we define as someone directly attacking a person or group based on a characteristic like race, gender or religion. We take down content that could lead to real world violence. In countries at risk of conflict, that includes anything that could lead to imminent violence or genocide. And we know from history that dehumanizing people is the first step towards inciting violence. If you say immigrants are vermin, or all Muslims are terrorists — that makes others feel they can escalate and attack that group without consequences. So we don’t allow that. I take this incredibly seriously, and we work hard to get this off our platform.', 'American free speech tradition recognizes that some speech can have the effect of restricting others’ right to speak. While American law doesn’t recognize “hate speech” as a category, it does prohibit racial harassment and sexual harassment. We still have a strong culture of free expression even while our laws prohibit discrimination.', 'But still, people have broad disagreements over what qualifies as hate and shouldn’t be allowed. Some people think our policies don’t prohibit content they think qualifies as hate, while others think what we take down should be a protected form of expression. This area is one of the hardest to get right.', 'I believe people should be able to use our services to discuss issues they feel strongly about — from religion and immigration to foreign policy and crime. You should even be able to be critical of groups without dehumanizing them. But even this isn’t always straightforward to judge at scale, and it often leads to enforcement mistakes. Is someone re-posting a video of a racist attack because they’re condemning it, or glorifying and encouraging people to copy it? Are they using normal slang, or using an innocent word in a new way to incite violence? Now multiply those linguistic challenges by more than 100 languages around the world.', 'Rules about what you can and can’t say often have unintended consequences. When speech restrictions were implemented in the UK in the last century, parliament noted they were applied more heavily to citizens from poorer backgrounds because the way they expressed things didn’t match the elite Oxbridge style. In everything we do, we need to make sure we’re empowering people, not simply reinforcing existing institutions and power structures.', 'That brings us back to the cross-roads we all find ourselves at today. Will we continue fighting to give more people a voice to be heard, or will we pull back from free expression?', 'I see three major threats ahead:', 'The first is legal. We’re increasingly seeing laws and regulations around the world that undermine free expression and people’s human rights. These local laws are each individually troubling, especially when they shut down speech in places where there isn’t democracy or freedom of the press. But it’s even worse when countries try to impose their speech restrictions on the rest of the world.', 'This raises a larger question about the future of the global internet. China is building its own internet focused on very different values, and is now exporting their vision of the internet to other countries. Until recently, the internet in almost every country outside China has been defined by American platforms with strong free expression values. There’s no guarantee these values will win out. A decade ago, almost all of the major internet platforms were American. Today, six of the top ten are Chinese.', '', 'We’re beginning to see this in social media. While our services, like WhatsApp, are used by protesters and activists everywhere due to strong encryption and privacy protections, on TikTok, the Chinese app growing quickly around the world, mentions of these protests are censored, even in the US.', 'Is that the internet we want?', 'It’s one of the reasons we don’t operate Facebook, Instagram or our other services in China. I wanted our services in China because I believe in connecting the whole world and I thought we might help create a more open society. I worked hard to make this happen. But we could never come to agreement on what it would take for us to operate there, and they never let us in. And now we have more freedom to speak out and stand up for the values we believe in and fight for free expression around the world.', 'This question of which nation’s values will determine what speech is allowed for decades to come really puts into perspective our debates about the content issues of the day. While we may disagree on exactly where to draw the line on specific issues, we at least can disagree. That’s what free expression is. And the fact that we can even have this conversation means that we’re at least debating from some common values. If another nation’s platforms set the rules, our discourse will be defined by a completely different set of values.', '', 'To push back against this, as we all work to define internet policy and regulation to address public safety, we should also be proactive and write policy that helps the values of voice and expression triumph around the world.', 'The second challenge to expression is the platforms themselves — including us. Because the reality is we make a lot of decisions that affect people’s ability to speak.', 'I’m committed to the values we’re discussing today, but we won’t always get it right. I understand people are concerned that we have so much control over how they communicate on our services. And I understand people are concerned about bias and making sure their ideas are treated fairly. Frankly, I don’t think we should be making so many important decisions about speech on our own either. We’d benefit from a more democratic process, clearer rules for the internet, and new institutions.', 'That’s why we’re establishing an independent Oversight Board for people to appeal our content decisions. The board will have the power to make final binding decisions about whether content stays up or comes down on our services — decisions that our team and I can’t overturn. We’re going to appoint members to this board who have a diversity of views and backgrounds, but who each hold free expression as their paramount value.', 'Building this institution is important to me personally because I’m not always going to be here, and I want to ensure the values of voice and free expression are enshrined deeply into how this company is governed.', 'The third challenge to expression is the hardest because it comes from our culture. We’re at a moment of particular tension here and around the world — and we’re seeing the impulse to restrict speech and enforce new norms around what people can say.', 'Increasingly, we’re seeing people try to define more speech as dangerous because it may lead to political outcomes they see as unacceptable. Some hold the view that since the stakes are so high, they can no longer trust their fellow citizens with the power to communicate and decide what to believe for themselves.', 'I personally believe this is more dangerous for democracy over the long term than almost any speech. Democracy depends on the idea that we hold each others’ right to express ourselves and be heard above our own desire to always get the outcomes we want. You can’t impose tolerance top-down. It has to come from people opening up, sharing experiences, and developing a shared story for society that we all feel we’re a part of. That’s how we make progress together.', '', 'So how do we turn the tide? Someone once told me our founding fathers thought free expression was like air. You don’t miss it until it’s gone. When people don’t feel they can express themselves, they lose faith in democracy and they’re more likely to support populist parties that prioritize specific policy goals over the health of our democratic norms.', 'I’m a little more optimistic. I don’t think we need to lose our freedom of expression to realize how important it is. I think people understand and appreciate the voice they have now. At some fundamental level, I think most people believe in their fellow people too.', 'As long as our governments respect people’s right to express themselves, as long as our platforms live up to their responsibilities to support expression and prevent harm, and as long as we all commit to being open and making space for more perspectives, I think we’ll make progress. It’ll take time, but we’ll work through this moment. We overcame deep polarization after World War I, and intense political violence in the 1960s. Progress isn’t linear. Sometimes we take two steps forward and one step back. But if we can’t agree to let each other talk about the issues, we can’t take the first step. Even when it’s hard, this is how we build a shared understanding.', 'So yes, we have big disagreements. Maybe more now than at any time in recent history. But part of that is because we’re getting our issues out on the table — issues that for a long time weren’t talked about. More people from more parts of our society have a voice than ever before, and it will take time to hear these voices and knit them together into a coherent narrative. Sometimes we hope for a singular event to resolve these conflicts, but that’s never been how it works. We focus on the major institutions — from governments to large companies — but the bigger story has always been regular people using their voice to take billions of individual steps forward to make our lives and our communities better.', 'The future depends on all of us. Whether you like Facebook or not, we need to recognize what is at stake and come together to stand for free expression at this critical moment.', 'I believe in giving people a voice because, at the end of the day, I believe in people. And as long as enough of us keep fighting for this, I believe that more people’s voices will eventually help us work through these issues together and write a new chapter in our history — where from all of our individual voices and perspectives, we can bring the world closer together.', '']\n",
            "169 ['By Antigone Davis, Global Head of Safety', 'Social media is where people can turn to celebrate life’s most joyful moments and seek support in some of the hardest. While an online community can provide invaluable support, we know that many find it uncomfortable to share personal feelings in a broad public setting.', 'Private messaging, on the other hand, can make it easier to talk about emotional or serious subjects, according to a survey Facebook conducted in the UK, US and Australia. Respondents said they could communicate more clearly and be more open when messaging versus in person. In fact, 80% of people surveyed said they felt they could be completely honest when messaging.', 'In honor ofWorld Mental Health Day, and to help people have important conversations around mental health, we’re releasing a “Let’s Talk” Stories filter on Facebook and Messenger. Developed with input from the World Health Organization (WHO), the filter acts as an invitation for friends who might be struggling to reach out for support through Messenger.', '', 'We’re also releasing a“Let’s Talk” sticker packon Messenger with 16 stickers that can help when words are hard to find. Each time a sticker is sent, Facebook will donate $1 to a group of mental health organizations, up to $1 million USD. It’s our hope that these tools will make it easier for people to begin conversations that can lead to support.', '', 'It takes less than a minute to show someone you care. This year for World Mental Health Day, the World Health Organization is encouraging people to take40 seconds of actionto let people who are struggling know they’re not alone. Sharing your “Let’s Talk” selfie is an easy way to do that. To use the World Mental Health Day “Let’s Talk” camera filter, open the camera in Facebook or Messenger and tap on the filter on the bottom of your screen. You can also download the sticker pack by clicking on the smiley face in the text box of any Messenger conversation.', 'Showing you’re available to help a friend is the first step, but what should you do next? According to mental health experts, it’s important to show that you care and are really listening. Express your concern, allow them to open up and help them find resources. Facebook offers some resources through oursafety and well-being center. You can also findsupport there for yourselfif you are struggling. Facebook Groups can be another place to go to find supportive connections. More than 2.5 million people in the US, UK and Australia are members of at least one of the 7,000 groups dedicated to supporting people with mental health.', 'We encourage people to look for more resources from local, state,federalorinternationalorganizations. A list of organizations Facebook is donating to can be found below.']\n",
            "170 ['By Nick Clegg, VP of Global Affairs and Communications', 'Speaking at the Atlantic Festival in Washington DC today, I set out the measures that Facebook is taking to prevent outside interference in elections and Facebook’s attitude towards political speech on the platform. This is grounded in Facebook’s fundamental belief in free expression and respect for the democratic process, as well as the fact that, in mature democracies with a free press, political speech is already arguably the most scrutinized speech there is.', 'You can read the full text of my speech below, but as I know there are often lots of questions about our policies and the way we enforce them I thought I’d share the key details.', 'Fact-Checking Political Speech', 'We rely on third-party fact-checkers to help reduce the spread of false news and other types of viral misinformation, like memes or manipulated photos and videos. We don’t believe, however, that it’s an appropriate role for us to referee political debates and prevent a politician’s speech from reaching its audience and being subject to public debate and scrutiny. That’s why Facebook exempts politicians from our third-party fact-checking program. We have had this policy on the books for over a year now, posted publicly on our site under our eligibility guidelines. This means that we will not send organic content or ads from politicians to our third-party fact-checking partners for review. However, when a politician shares previously debunked content including links, videos and photos, we plan to demote that content, display related information from fact-checkers, and reject its inclusion in advertisements. You can find more about the third-party fact-checking program and content eligibilityhere.', 'Newsworthiness Exemption', 'Facebook has had a newsworthiness exemption since2016. This means that if someone makes a statement or shares a post which breaks our community standards we will still allow it on our platform if we believe the public interest in seeing it outweighs the risk of harm. Today, I announced that from now on we will treat speech from politicians as newsworthy content that should, as a general rule, be seen and heard. However, in keeping with the principle that we apply different standards to content for which we receive payment, this will not apply to ads – if someone chooses to post an ad on Facebook, they must still fall within our Community Standards and our advertising policies.', 'When we make a determination as to newsworthiness, we evaluate the public interest value of the piece of speech against the risk of harm. When balancing these interests, we take a number of factors into consideration, including country-specific circumstances, like whether there is an election underway or the country is at war; the nature of the speech, including whether it relates to governance or politics; and the political structure of the country, including whether the country has a free press. In evaluating the risk of harm, we will consider the severity of the harm. Content that has the potential to incite violence, for example, may pose a safety risk that outweighs the public interest value. Each of these evaluations will be holistic and comprehensive in nature, and will account for international human rights standards.', 'Read the full speech below.', '', 'Facebook', 'For those of you who don’t know me, which I suspect is most of you, I used to be a politician – I spent two decades in European politics, including as Deputy Prime Minister in the UK for five years.', 'And perhaps because I acquired a taste for controversy in my time in politics, a year ago I came to work for Facebook.', 'I don’t have long with you, so I just want to touch on three things:I want to say a little about Facebook;about how we are getting ourselves ready for the 2020 election;and about our basic attitude towards political speech.', 'So…Facebook.', 'As a European, I’m struck by the tone of the debate in the US around Facebook.Here you have this global success story, invented in America, based on American values, that is used by a third of the world’s population.', 'A company that has created 40,000 US jobs in the last two years, is set to create 40,000 more in the coming years, and contributes tens of billions of dollars to the economy. And with plans to spend more than $250 billion in the US in the next four years.', 'And while Facebook is subject to a lot of criticism in Europe, in India where I was earlier this month, and in many other places, the only place where it is being proposed that Facebook and other big Silicon Valley companies should be dismembered is here.', 'And whilst it might surprise you to hear me say this, I understand the underlying motive which leads people to call for that remedy – even if I don’t agree with the remedy itself.', 'Because what people want is that there should be proper competition, diversity, and accountability in how big tech companies operate – with success comes responsibility, and with power comes accountability.', 'But chopping up successful American businesses is not the best way to instill responsibility and accountability. For a start, Facebook and other US tech companies not only face fierce competition from each other for every service they provide – for photo and video sharing and messaging there are rival apps with millions or billions of users – but they also face increasingly fierce competition from their Chinese rivals. Giants like Alibaba, TikTok and WeChat.', 'More importantly, pulling apart globally successful American businesses won’t actually do anything to solve the big issues we are all grappling with – privacy, the use of data, harmful content and the integrity of our elections.', 'Those things can and will only be addressed by creating new rules for the internet, new regulations to make sure companies like Facebook are accountable for the role they play and the decisions they take.', 'That is why we argue in favor of better regulation of big tech, not the break-up of successful American companies.', 'Elections', 'Now, elections.It is no secret that Facebook made mistakes in 2016, and that Russia tried to use Facebook to interfere with the election by spreading division and misinformation.But we’ve learned the lessons of 2016. Facebook has spent the three years since building its defenses to stop that happening again.', 'And we are seeing results. Last year, a Stanford report found that interactions with fake news on Facebook was down by two-thirds since 2016.', 'I know there’s also a lot of concern about so-called deepfake videos.We’ve recently launched an initiative called the Deepfake Detection Challenge, working with the Partnership on AI,companies like Microsoft and universities like MIT, Berkeley and Oxford,to find ways to detect this new form of manipulated content so that we can identify them and take action.', 'But even when the videos aren’t as sophisticated – such as the now infamous Speaker Pelosi video – we know that we need to do more.', 'As Mark Zuckerberg has acknowledged publicly, we didn’t get to that video quickly enough and too many people saw it before we took action. We must and we will get better at identifying lightly manipulated content before it goes viral and provide users with much more forceful information when they do see it.', 'We will be making further announcements in this area in the near future.', 'Crucially, we have also tightened our rules on political ads.Political advertising on Facebook is now far more transparent than anywhere else – including TV, radio and print advertising.', 'People who want to run these ads now need to submit ID and information about their organization. We label the ads and let you know who’s paid for them. And we put these ads in a library for seven years so that anyone can see them.', 'Political speech', 'Of course, stopping election interference is only part of the story when it comes to Facebook’s role in elections.Which brings me to political speech.', 'Freedom of expression is an absolute founding principle for Facebook. Since day one, giving people a voice to express themselves has been at the heart of everything we do.We are champions of free speech and defend it in the face of attempts to restrict it. Censoring or stifling political discourse would be at odds with what we are about.', 'In a mature democracy with a free press, political speech is a crucial part of how democracy functions.And it is arguably the most scrutinized form of speech that exists.', 'In newspapers, on network and cable TV, and on social media, journalists, pundits, satirists, talk show hosts and cartoonists – not to mention rival campaigns – analyze, ridicule, rebut and amplify the statements made by politicians.', 'At Facebook, our role is to make sure there is a level playing field, not to be a political participant ourselves.', 'To use tennis as an analogy, our job is to make sure the court is ready – the surface is flat, the lines painted, the net at the correct height.But we don’t pick up a racket and start playing. How the players play the game is up to them, not us.', 'We have a responsibility to protect the platform from outside interference, and to make sure that when people pay us for political ads we make it as transparent as possible.But it is not our role to intervene when politicians speak.', 'That’s why I want to be really clear today – we do not submit speech by politicians to our independent fact-checkers, and we generally allow it on the platform even when it would otherwise breach our normal content rules.', 'Of course, there are exceptions. Broadly speaking they are two-fold: where speech endangers people; and where we take money, which is why we have more stringent rules on advertising than we do for ordinary speech and rhetoric.', 'I was an elected politician for many years. I’ve had both words and objects thrown at me, I’ve been on the receiving end of all manner of accusations and insults.', 'It’s not new that politicians say nasty things about each other – that wasn’t invented by Facebook. What is new is that now they can reach people with far greater speed and at a far greater scale. That’s why we draw the line at any speech which can lead to real world violence and harm.', 'I know some people will say we should go further. That we are wrong to allow politicians to use our platform to say nasty things or make false claims.But imagine the reverse.', 'Would it be acceptable to society at large to have a private company in effect become a self-appointed referee for everything that politicians say? I don’t believe it would be. In open democracies, voters rightly believe that, as a general rule, they should be able to judge what politicians say themselves.', 'Conclusion', 'So, in conclusion, I understand the debate about big tech companies and how to tackle the real concerns that exist about data, privacy, content and election integrity. But I firmly believe that simply breaking them up will not make the problems go away. The real solutions will only come through new, smart regulation instead.', 'And I hope I have given you some reassurance about our approach to preventing election interference, and some clarity over how we will treat political speech in the run up to 2020 and beyond.', 'Thank you.']\n",
            "171 ['Note: For future Facebook updates about Oversight Board cases, please visit theTransparency Center.', '“The content policies we write and the decisions we make every day matter to people. That’s why we always have to strive to keep getting better. The Oversight Board will make Facebook more accountable and improve our decision-making. This charter is a critical step towards what we hope will become a model for our industry.”', '– Nick Clegg, VP Global Affairs and Communications, Facebook', 'Since November, whenMark Zuckerberg first wroteabout his vision for how content should be governed on Facebook, a team within our company has been working to design and implement this idea, with the help ofinput and feedbackfrom people all around the world.', 'Today, we’re announcing more details on the structure of the Oversight Board and its relationship to Facebook in the form ofa charter. This central governing document defines the board’s mandate and describes its relationship to Facebook. It establishes its membership, governance and decision-making authority, and it sets out parameters for things like the size, scope and power of the board. In the coming months this charter will be available in multiple languages on a new board website.', 'Accompanying the charter isa letter from Mark Zuckerbergexplaining the board’s purpose and goals.', 'Governing Documents', 'This charter is only one of many documents that will govern the Oversight Board. We are also crafting bylaws which will provide greater operational detail on the board’s institutional independence and rules of procedure. These bylaws will include accountability mechanisms, such as a code of conduct and board member disqualifications. They will also elaborate on the processes for assembling panels, developing case materials and implementing board decisions. While we are preparing these bylaws on the board’s behalf, ultimately the board alone will have the ability to change them.', 'Governance Structure', 'We often received a key piece of feedback: make sure the board is independent from Facebook. One way we’re addressing this is by establishing an independent trust. The Oversight Board, the trust and Facebook will have separate roles and responsibilities, all of which will work to ensure that the board is set up for success.', 'As part of our overall transparency efforts, trust documents will be publicly released, and these will establish the formal relationship between the board, the trust and Facebook.', '', 'Design Decisions for the Board', 'Along with the charter, we areproviding a summarywhich breaks down the elements from thedraft charter, the feedback we’ve received, and the rationale behind our decisions in relation to both. Many issues have spurred healthy and constructive debate. Four areas in particular were:', 'ProcessBoth Facebook and its users will be able to refer cases to the board for review. For now, the board will begin its operations by hearing Facebook-initiated cases. The system for users to initiate appeals to the board will be made available over the first half of 2020.', 'At a high level, the following graphic outlines the basic process by which the board will select, review and decide upon cases and how Facebook will implement and respond to those decisions:', '', 'As a first step, we’ve identified guidelines for how we will prioritize our most significant and difficult cases for Facebook’s referrals to the board. Our current thinking focuses on indicators that demonstrate cases are both significant and difficult:', 'While today is an important milestone, there is much more work we still need to do.', 'Over the next few months, we will continue testing our assumptions and ensuring the board’s operational readiness. In addition, we will focus on sourcing and selecting of board members, finalizing the bylaws that will complement the charter, and working toward having the board deliberate on its first cases early in 2020.', 'We are committed to consulting outside experts at every step, and we look forward to providing more updates on our progress.']\n",
            "172 ['Note: For future Facebook updates about Oversight Board cases, please visit theTransparency Center.', 'We are continuing to build the Oversight Board.', 'We spent the summer taking action on the feedback we received during our globalconsultationprocessand today, we’re answering the questions originally laid out in thedraft charterby publishing anupdated charter.', 'Meanwhile, the initial group of board members are being sourced, the criteria for vetting and interviewing those members are being finalized, and the tools and training that will empower them to fulfill their roles are being built.', 'For the board to be successful, all potential members should embody certain principles, such as a commitment to the board as an institution. In addition, we are seeking candidates who are experienced at deliberating thoughtfully and collegially as open-minded contributors on a team, skilled at making and explaining decisions based on a set of policies, and familiar with matters relating to digital content and governance, including free expression, civic discourse, equality, safety, privacy and technology.', 'After gathering feedback from our consultation process, holding conversations with subject matter experts and consulting industry best practices, we’ve established a six-step process for sourcing and selecting board members.', '', 'Sourcing', 'Getting membership right starts with identifying the widest possible set of diverse candidates from outside of our normal channels. To do so, we’ve taken recommendations from participants from our global consultation and engaged consultants and executive search firms to assist with this process.', 'In addition, we are partnering with the firm Baker McKenzie, which assisted with ourpublic consultation process, to open arecommendations portalthat will allow anyone interested to put forward candidates for future selection.', 'Vetting', 'In order for the board to exercise independent judgment, members must not have actual or perceived conflicts of interest that could compromise their decision-making. We will work with the international law firm Jenner & Block to screen for any such conflicts, including but not limited to:anyone who is a current or former employee of Facebook, or a spouse or domestic partner of an employee; a current government official or lobbyist working on behalf of any government; a high-ranking official within a political party; or a significant shareholder of Facebook.', 'Interviews', 'Following vetting, we will hold interviews with candidates. Working with the global executive search firm Heidrick & Struggles, we will use these interviews to evaluate a candidate’s competency and experience based on a set of strict criteria set out in our Candidate Review Guide.We will continue to refine this guide with the advice of experts.', '', 'Diversity Review', 'In order for the board to be effective in its service to Facebook’s large and diverse community, we think it’s important for members to reflect and represent a broad range of knowledge, competencies, backgrounds, perspectives, experience and expertise. In addition to sourcing members from a mix of professional backgrounds and experience, the board will strive for a broad diversity of geographic, gender, political, social and religious representation and perspectives. Other considerations include: members who possess a range of familiarity with technology and digital platforms, as well as constructive critics of Facebook and its policies.', 'Since every aspect of diversity cannot be represented among the board’s limited membership, it is important for members to be able to call upon additional expertise to provide guidance on local context and cultural norms, and we’re building that capability into the board’s procedures.', 'Selection', 'Facebook will extend a limited number of offers to candidates to serve on the Oversight Board as co-chairs.', 'If and when those members accept the role, they will then work together with us to select, interview and make offers to candidates to fill the remaining board positions, over time. All members, including the co-chairs, will be formally appointed by the trustees.', 'Orientation and Learning', 'To ensure that all members are able to effectively carry out their work on the Oversight Board, we will invite them for an Orientation and Learning session.', 'This session will focus on educating board members on Facebook’s policies, policy development and moderation processes and other relevant topics to prepare them for their work, help them understand their roles and forge working relationships with each other.', 'Ongoing Process', 'Our goal is to select and publish the initial board member names this year. We will repeat this process for every new board member until we reach 40 members.', 'In the future, the board itself will lead the membership selection process, including identifying, screening and selecting future candidates who will continue to be formally appointed by the trustees.', 'We remain grateful for everyone’s input, insight and recommendations as we build the board.']\n",
            "173 ['Today, we’re sharing a series of updates and shifts that improve how we combat terrorists, violent extremist groups and hate organizations on Facebook and Instagram. These changes primarily impact ourDangerous Individuals and Organizations policy, which is designed to keep people safe and prevent real-world harm from manifesting on our services. Some of the updates we’re sharing today were implemented in the last few months, while others went into effect last year but haven’t been widely discussed.', 'Some of these changes predate the tragic terrorist attack in Christchurch, New Zealand, but that attack, and the global response to it in the form of the Christchurch Call to Action, has strongly influenced the recent updates to our policies and their enforcement. First, the attack demonstrated the misuse of technology to spread radical expressions of hate, and highlighted where we needed to improve detection and enforcement against violent extremist content. In May, we announced restrictions on who can use Facebook Live and met with world leaders in Paris to sign the New Zealand Government’sChristchurch Call to Action. We also co-developed anine-point industry planin partnership with Microsoft, Twitter, Google and Amazon, which outlines the steps we’re taking to address the abuse of technology to spread terrorist content.', 'Improving Our Detection and Enforcement', 'Two years ago, wedescribed some of the automated techniqueswe use to identify and remove terrorist content. Our detection techniques include content matching, which allows us to identify copies of known bad material, and machine-learning classifiers that identify and examine a wide range of factors on a post and assess whether it’s likely to violate our policies. To date, we have identified a wide range of groups as terrorist organizations based on their behavior, not their ideologies, and we do not allow them to have a presence on our services. While our intent was always to use these techniques across different dangerous organizations, we initially focused on global terrorist groups like ISIS and al-Qaeda. This has led to the removal of more than 26 million pieces of content related global terrorist groups like ISIS and al-Qaeda in the last two years, 99% of which we proactively identified and removed before anyone reported it to us.', 'We’ve since expanded the use of these techniques to a wider range of dangerous organizations, including both terrorist groups and hate organizations. We’ve banned more than 200 white supremacist organizations from our platform, based on our definitions of terrorist organizations and hate organizations, and we use a combination of AI and human expertise to remove content praising or supporting these organizations. The process to expand the use of these techniques started in mid-2018 and we’ll continue to improve the technology and processes over time.', 'We’ll need to continue to iterate on our tactics because we know bad actors will continue to change theirs, but we think these are important steps in improving our detection abilities. For example, the video of the attack in Christchurch did not prompt our automatic detection systems because we did not have enough content depicting first-person footage of violent events to effectively train our machine learning technology. That’s why we’re working with government and law enforcement officials in the US and UK to obtain camera footage from their firearms training programs – providing a valuable source of data to train our systems. With this initiative, we aim to improve our detection of real-world, first-person footage of violent events and avoid incorrectly detecting other types of footage such as fictional content from movies or video games.', 'Updating Our Policy', 'While terrorism is a global issue, there is currently no globally recognized and accepted definition of terrorist organizations. So we’ve developed adefinitionto guide our decision-making on enforcing against these organizations. We are always looking to see where we can improve and refine our approach and we recently updated how we define terrorist organizations in consultation with counterterrorism, international humanitarian law, freedom of speech, human rights and law enforcement experts. The updated definition still focuses on the behavior, not ideology, of groups. But while our previous definition focused on acts of violence intended to achieve a political or ideological aim, our new definition more clearly delineates that attempts at violence, particularly when directed toward civilians with the the intent to coerce and intimidate, also qualify.', 'Giving People Resources to Leave Behind Hate', 'Our efforts to combat terrorism and hate don’t end with our policies. In March, we started connecting people who search for terms associated with white supremacy on Facebook Search to resources focused on helping people leave behind hate groups. When people search for these terms in the US, they are directed toLife After Hate, an organization founded by former violent extremists that provides crisis intervention, education, support groups and outreach. And now, we’re expanding this initiative to more communities.', 'We’re expanding this initiative to Australia and Indonesia and partnering withMoonshot CVEto measure the impact of these efforts to combat hate and extremism. Being able to measure our impact will allow us to hone best practices and identify areas where we need to improve. In Australia and Indonesia, when people search for terms associated with hate and extremism, they will be directed toEXIT Australiaandruangobrol.idrespectively. These are local organizations focused on helping individuals leave the direction of violent extremism and terrorism. We plan to continue expanding this initiative and we’re consulting partners to further build this program in Australia and explore potential collaborations in New Zealand. And by using Moonshot CVE’s data-driven approach to disrupting violent extremism, we’ll be able to develop and refine how we track the progress of these efforts across the world to connect people with information and services to help them leave hate and extremism behind. We’ll continue to seek out partners in countries around the world where local experts are working to disengage vulnerable audiences from hate-based organizations.', 'Expanding Our Team', 'All of this work has been led by a multi-disciplinary group of safety and counterterrorism experts developing policies, building product innovations and reviewing content with linguistic and regional expertise to help us define, identify and remove terrorist content from Facebook and Instagram. Previously, the team was solely focused on counterterrorism — identifying a wide range of organizations including white supremacists, separatists and Islamist extremist jihadists as terrorists. Now, the team leads our efforts against all people and organizations that proclaim or are engaged in violence leading to real-world harm. And the team now consists of 350 people with expertise ranging from law enforcement and national security, to counterterrorism intelligence and academic studies in radicalization.', 'This new structure was informed by a range of factors, but we were particularly driven by the rise in white supremacist violence and the fact that terrorists increasingly may not be clearly tied to specific terrorist organizations before an attack occurs, as was seen in Sri Lanka and New Zealand. This team of experts is now dedicated to taking the initial progress we made in combating content related to ISIS, al-Qaeda and their affiliates, and further building out techniques to identify and combat the full breadth of violence and extremism covered under our Dangerous Organizations policy.', 'Remaining Committed to Transparency', 'We are committed to being transparent about our efforts to combat hate, which is why when we share the fourth edition of the Community Standards Enforcement Report in November, our metrics on how we’re doing at enforcing our policies against terrorist organizations will include our efforts against all terrorist organizations for the first time. To date, the data we’ve provided about our efforts to combat terrorism has addressed our efforts against Al Qaeda, ISIS and their affiliates. These updated metrics will better reflect our comprehensive efforts to combat terrorism worldwide.', 'We know that bad actors will continue to attempt to skirt our detection with more sophisticated efforts and we are committed to advancing our work and sharing our progress.']\n",
            "174 ['By Monika Bickert, Vice President, Global Policy Management', 'Today, we’re expanding the values that serve as the basis for ourCommunity Standards— the guidepost for what is and isn’t allowed on Facebook. For more than a decade, we’ve focused on giving people voice, making Facebook a safe place and applying our policies consistently and fairly around the world. Those values remain important to us. However, as we’ve grown and introduced new products, features and services, our Community Standards have become more expansive and nuanced. The values we’re publishing today reflect the policies we’ve developed over time and what we stand for as a company.', 'Our commitment to giving people voice remains paramount. We also focus on authenticity, safety, privacy and dignity in writing and enforcing our Community Standards. We’ve updated the preamble to our Community Standards to reflect these values and included it below to help people understand the environment we want to foster on Facebook.', 'Voice', 'The goal of our Community Standards is to create a place forexpression and give people voice. Building community and bringing the world closer together depends on people’s ability to share diverse views, experiences, ideas and information. We want people to be able to talk openly about the issues that matter to them, even if some may disagree or find them objectionable. In some cases, we allow content which would otherwise go against our Community Standards – if it is newsworthy and in the public interest. We do this only after weighing the public interest value against the risk of harm, and we look to international human rights standards to make these judgments.', 'A commitment to expression is paramount, but we recognize the internet creates new and increased opportunities for abuse. For these reasons, when we limit expression we do it in service of one or more of the following values:', 'Our Community Standards apply to everyone around the world, and to all types of content. They’re designed to be comprehensive – for example, content that might not be considered hateful may still be removed for violating a different policy.', 'We recognize that words mean different things or affect people differently depending on their local community, language or background. We work hard to account for these nuances while also applying our policies consistently and fairly to people and their expression.']\n",
            "175 ['By Antigone Davis, Global Head of Safety', 'As a global online community, keeping people safe on our apps is incredibly important to us. Since 2006, we’ve worked with experts from around the world to inform our policies, practices and products supporting those at risk of suicide or self-injury.', 'Today, on World Suicide Prevention Day, we’re sharing an update on what we’ve learned and some of the steps we’ve taken in the past year, as well as additional actions we’re going to take, to keep people safe on our apps, especially those who are most vulnerable.', 'Improving How We Handle Suicide and Self-injury Related Content', 'Earlier this year, we began hosting regularconsultationswith experts from around the world to discuss some of the more difficult topics associated with suicide and self-injury. These include how we deal with suicide notes, the risks of sad content online and newsworthy depictions of suicide. Further details of these meetings are available on Facebook’s newSuicide Prevention pagein ourSafety Center.', 'As a result of these consultations, we’ve made several changes to improve how we handle this content. We tightened our policy aroundself-harmto no longer allow graphic cutting images to avoid unintentionally promoting or triggering self-harm, even when someone is seeking support or expressing themselves to aid their recovery. OnInstagram, we’ve also made it harder to search for this type of content and kept it from being recommended in Explore. We’ve also taken steps to address the complex issue ofeating disorder contenton our apps by tightening our policy to prohibit additional content that may promote eating disorders. And with these stricter policies, we’ll continue to send resources to people who post content promoting eating disorders or self-harm, even if we take the content down. Lastly, we chose to display a sensitivity screen over healed self-harm cuts to help avoid unintentionally promoting self-harm.', 'Our engagement with experts has proven so valuable that we’re alsohiring a health and well-being expertto join our safety policy team. This person will focus exclusively on the health and well-being impacts of our apps and policies, and will explore new ways to improve support for our community, including on topics related to suicide and self-injury.', 'And for the first time, we’re also exploring ways to share public data from our platform on how people talk about suicide, beginning with providing academic researchers with access to the social media monitoring tool, CrowdTangle. To date, CrowdTangle has been available primarily to help newsrooms and media publishers understand what is happening on Facebook. But we are eager to make it available to two select researchers who focus on suicide prevention to explore how information shared on Facebook and Instagram can be used to further advancements in suicide prevention and support.', 'In addition to all we are doing to find more opportunities and places to surface resources, we’re continuing to build new technology to help us find and take action on potentially harmful content, including removing it or adding sensitivity screens. From April to June of 2019, we took action on more than 1.5 million pieces of suicide and self-injury content on Facebook and found more than 95% of it before it was reported by a user. During that same time period, we took action on more than 800 thousand pieces of this content on Instagram and found more than 77% of it before it was reported by a user.(Updated on September 10, 2019 at 11:30 AM PT to share more information on how we handle potentially harmful content.)', 'Becoming a Safer Forum for Difficult Conversations', 'Experts have told us that one of the most effective ways to prevent suicide is for people to hear from friends and family who care about them. Facebook has a unique role in facilitating those kinds of connections and we’re taking additional steps to support those who are discussing these sensitive topics, especially young people.', 'To help young people safely discuss topics like suicide, we’re enhancing our online resources by including Orygen’s#chatsafe guidelinesin Facebook’s Safety Center and in resources on Instagram when someone searches for suicide or self-injury content.', 'The #chatsafe guidelines were developed together with young people to provide support to those who might be responding to suicide-related content posted by others or for those who might want to share their own feelings and experiences with suicidal thoughts, feelings or behaviors.', 'We’ll continue to invest in people, technology and resources so that we can do more to protect people on our apps. Visit ourSuicide Prevention Resource pageto learn more about what’s available.']\n",
            "176 ['By Tom Alison, VP of Engineering', 'Private groups can be important places for people to come together and share around a range of personal topics, like identifying as LGBTQ or discussing challenges around a rare health condition.', 'But being in a private group doesn’t mean that your actions should go unchecked. We have a responsibility to keep Facebook safe, which is why our Community Standards apply across Facebook, including in private groups. To enforce these policies, we use a combination of people and technology — content reviewers and proactive detection. Over the last few years, we’ve invested heavily in both, including hiring more than 30,000 people across our safety and security teams.', 'Within this, a specialized team has been working on theSafe Communities Initiative: an effort that started two years ago with the goal of protecting people using Facebook Groups from harm. Made up of product managers, engineers, machine learning experts and content reviewers, this team works to anticipate the potential ways people can do harm in groups and develops solutions to minimize and prevent it. As the head of Facebook Groups, I want to explain how we’re making private groups safer by focusing on three key areas: proactive detection, tools for admins, and transparency and control for members.', 'One of the main ways we keep people safe is proactively identifying and removing posts and groups that break our rules. This is a main area of focus for the Safe Communities Initiative, and it runs across private and public groups.', 'Increasingly, we can use AI and machine learning to proactively detect bad content before anyone reports it, and sometimes before people even see it. As content is flagged by our systems or reported by people, trained reviewers consider context and determine whether the content violates our Community Standards. We then use these examples to train our technology to get better at finding and removing similar content. Just as we used proactive detection in public, closed and secret groups before, this process will continue to apply to all public and private groups underour new simplified privacy model.', 'Deciding whether an entire group should stay up or come down is nuanced. If an individual post breaks our Community Standards, it comes down, but with dozens, hundreds, or sometimes thousands of different members and posts, at what point should a whole group be deemed unacceptable for Facebook?', 'One big factor we look at is subject matter: Does the name or description of the group include hate speech or other content that we don’t allow? Another important factor is the action of admins and moderators, since they set the tone for the group. In April, we updated our policy to look more closely at admin and moderator behavior. If group leaders often break our rules, or if they commonly approve posts from other members who break our rules, those are clear strikes against the overall group. And if a group member repeatedly violates our standards, we’ll start requiring admins to review their posts before anyone else can see them. Then if an admin approves a post that breaks our rules, it will count against the whole group. These, combined with a number of other factors, help us determine whether the group should be taken down. If the group doesn’t cross this line, it will stay up, but we’ll continue to remove individual posts that go against our Community Standards.', 'Admins know their communities best, and we want to empower them to run meaningful groups. That’s why we built Group Quality, which gives admins an overview of content Facebook has removed and flagged to them for most Community Standards violations. We also added a section about false news found in the group. These tools give admins more clarity about how and when we enforce our policies in their groups and gives them greater visibility into what is happening in their communities. This also means that they’re more accountable for what happens under their watch.', 'We help admins to establish positive group norms by adding a section for rules so they can be clear about what is and isn’t allowed. Admins and moderators also have the option to share which rule a member broke when declining a pending post, removing a comment or muting a member.', 'We’re also committed to giving group members more transparency and control. When someone joins a group, they should know what type of community they will be a part of. That’s why before joining a group, we let people see relevant details about it, like who the admins and moderators are, and whether the group has gone by any other names in the past. You can also preview a group you were invited to and have the option to accept or decline the invitation.', 'Through the Safe Communities Initiative, we’ll continue to ensure that Facebook Groups can be places of support and connection, not hate or harm. There’s always more to do, and we’ll keep improving our technology, tools and policies to help keep people safe.']\n",
            "177 ['ByAntigone Davis, Global Head of Safety, andGuy Rosen, VP of Integrity', 'At Facebook, we rely on a combination of technology and people to help keep our platforms safe. When we identify a harmful piece of content, such as child exploitation, terrorist propaganda, or graphic violence, technology can help us find duplicates and prevent them from being shared.', 'Today, we are open-sourcing two technologies that detect identical and nearly identical photos and videos — sharing some of the tech we use to fight abuse on our platform with others who are working to keep the internet safe. These algorithms will be open-sourced onGitHubso our industry partners, smaller developers and non-profits can use them to more easily identify abusive content and share hashes — or digital fingerprints — of different types of harmful content. For those who already use their own or other content matching technology, these technologies are another layer of defense and allow hash-sharing systems to talk to each other, making the systems that much more powerful.', '“In just one year, we witnessed a 541% increase in the number of child sexual abuse videos reported by the tech industry to the CyberTipline. We’re confident that Facebook’s generous contribution of this open-source technology will ultimately lead to the identification and rescue of more child sexual abuse victims,” said John Clark, President and CEO of theNational Center for Missing and Exploited Children (NCMEC).', 'Over the years, Facebook has contributed hundreds of open-source projects to share our technology with the wider community, but this is the first time we’ve shared any photo- or video-matching technology. Building on Microsoft’s generous contribution of PhotoDNA to fight child exploitation 10 years years ago and the more recent launch of Google Content Safety API, today’s announcement also is part of an industry-wide commitment to building a safer internet.', 'Known as PDQ and TMK+PDQF, these technologies are part of a suite of tools we use at Facebook to detect harmful content, and there are other algorithms and implementations available to industry such as pHash, Microsoft’s PhotoDNA, aHash, and dHash. Our photo-matching algorithm, PDQ, owes much inspiration to pHash although was built from the ground up as a distinct algorithm with independent software implementation. The video-matching technology, TMK+PDQF, was developed together byFacebook’s Artificial Intelligence Research teamand academics from the University of Modena and Reggio Emilia in Italy.', 'These technologies create an efficient way to store files as short digital hashes that can determine whether two files are the same or similar, even without the original image or video. Hashes can also be more easily shared with other companies and non-profits. For example, when we identify terrorist propaganda on our platforms, we remove it and hash it using a variety of techniques, including the algorithms we’re sharing today. Then we share the hashes with industry partners, including smaller companies, throughGIFCTso they can also take down the same content if it appears on their services.', 'PDQ and TMK+PDQF were designed to operate at high scale, supporting video-frame-hashing and real-time applications. We designed these technologies based on our experience detecting abuse across billions of posts on Facebook. We hope that by contributing back to the community we’ll enable more companies to keep their services safe and empower non-profits that work in the space. This work is in addition to our ongoing research in these areas, including ourpartnershipwith The University of Maryland, Cornell University, Massachusetts Institute of Technology, and The University of California, Berkeley to research new techniques to detect intentional adversarial manipulations of videos and photos to circumvent our systems', 'We’re announcing these technologies today to support our fourth annual cross-industry Child Safety Hackathon at Facebook’s headquarters in Menlo Park, California. The two-day event brings together nearly 80 engineers and data scientists fromTechnology Coalitionpartner companies and others to develop new technologies that help safeguard children.', 'This year’s event is focused on developing new tools to help our partners, NCMEC andThorn. For example, some teams will develop a prototype feature that will allow NCMEC’s CyberTipline case management tool to query and compare data points within other nonprofit organizations’ databases for known hashes and other key information. This will help identify children at risk and highlight high value reports. The open source code released today also will be made available to teams at the hackathon.', 'Hackathonsare an exciting way to bring people together from different organizations with a wide range of expertise to build tools that tackle problems such as the online sexual exploitation of children. All non-open-source code and prototypes developed at the event will be donated back to the Technology Coalition and our partners to be used in their child-safety efforts.', 'We will continue to expand and improve our own products and features to find harmful content. Read more about how Facebook is using technology to combat child exploitationhere.', 'Update on August 9, 2019 at 10:45AM PT:Here is a video from this year’s Child Safety Hackathon.']\n",
            "178 ['Note: For future Facebook updates about Oversight Board cases, please visit theTransparency Center.', 'InNovember, Mark Zuckerberg laid out a plan for a new way for people to appeal content decisions through an independent body. Earlier this year wereleased a draft charteroutlining a series of questions that we wanted to answer through a global input process, includingpublic consultation, to form that body.', 'Since that time we have traveled around the world hosting six in-depth workshops and 22 roundtables attended by more than 650 people from 88 different countries. We had personal discussions with more than 250 people and received over 1,200 public consultation submissions. In each of these engagements, the questions outlined in the draft charter led to thoughtful discussions with global perspectives, pushing us to consider multiple angles for how this board could function and be designed.', '', 'Today, we are releasinga reportwithappendicesthat summarize all of the feedback and recommendations we heard through those conversations, workshops and roundtables; internal research; white papers; media reports; and public proposals.', 'There are some general themes we have heard during consultation that are echoed in the report.', 'As we close this period of consultation and turn our attention to getting this up and running, including deciding on membership of the board, the feedback from the report will be used to answer the questions that were first posed in the draft charter. These answers will be released in a final charter that will govern the work of the board and will be released in August.', '', 'We’re continuing to consider who will serve on the 40-person board. This process will include sourcing, vetting, interviewing, selecting and providing training for members. In sourcing potential candidates, we have been soliciting suggestions from those who have participated in the public consultation process and the in-person workshops and roundtables. In addition we have been engaging consultants and executive search firms, and will soon be opening a nomination process. We want to make sure that we’re casting a wide net, not just looking to those experts who may already be known to us. Facebook will select the first few people and those members will then help select the remaining people.', '', 'For more on this topic, Mark is releasing the next video in his series of discussions on the future of technology and society. He sat down with Jenny Martinez, Dean of Stanford Law School and Noah Feldman, a professor at Harvard Law and advisor on the Oversight Board to discuss governance and what that looks like for the technology industry.']\n",
            "179 ['Update on May 21, 2020 at 3:52PM PT:', 'We’ve talked a lot about the proactive detection technology we use to identify hate speech and other abusive content before people report it to us.\\xa0OnMay 12,\\xa0we announced some of the progress that we’ve made.\\xa0But hate speech is always changing and new trends emerge. To stay ahead of these trends, our team has been enhancing this technology to identify new forms of\\xa0potentially inflammatory speech that hasn’t been reviewed for possible removal from our platform. In countries at risk of conflict, we may demote this content to reduce the risk of it going viral or inciting violence or hatred,\\xa0taking local context into account. We also update our list of slurs prohibited by our Community Standards. We seek input from experts\\xa0and civil society organizations everywhere as part of the process. We’re doing this in many languages, including Burmese and Sinhala, as we work to keep Facebook safe for people everywhere.', 'Originally published on June 20, 2019 at 2:00PM PT:', 'Last week, we were among the thousands who gathered atRightsCon, an international summit on human rights in the digital age, where we listened to and learned from advocates, activists, academics, and civil society. It also gave our teams an opportunity to talk about the work we’re doing to understand and address the way social media is used in countries experiencing conflict. Today, we’re sharing updates on: 1) the dedicated team we’ve set up to proactively prevent the abuse of our platform and protect vulnerable groups in future instances of conflict around the world; 2) fundamental product changes that attempt to limit virality; and 3) the principles that inform our engagement with stakeholders around the world.', 'We care about these issues deeply and write today’s post not just as representatives of Facebook, but also as concerned citizens who are committed to protecting digital and human rights and promoting vibrant civic discourse. Both of us have dedicated our careers to working at the intersection of civics, policy and tech.', 'Last year, we set up a dedicated team spanning product, engineering, policy, research and operations to better understand and address the way social media is used in countries experiencing conflict. The people on this team have spent their careers studying issues like misinformation, hate speech, and polarization. Many have lived or worked in the countries we’re focused on. Here are just a few of them:', 'Ravi, Research ManagerWith a PhD in social psychology, Ravi has spent much of his career looking at how conflicts can drive division and polarization. At Facebook, Ravi analyzes user behavior data and surveys to understand how content that doesn’t violate ourCommunity Standards— such as posts from gossip pages — can still sow division. This analysis informs how we reduce the reach and impact of polarizing posts and comments.', 'Sarah, Program ManagerBeginning as a student in Cameroon, Sarah has devoted nearly a decade to understanding the role of technology in countries experiencing political and social conflict. In 2014, she moved to Myanmar to research the challenges activists face online and to support community organizations using social media. Sarah helps Facebook respond to complex crises and develop long-term product solutions to prevent abuse — for example, how to render Burmese content in a machine-readable format so our AI tools can better detect hate speech.', 'Abhishek, Research ScientistWith a masters in computer science and a doctorate in media theory, Abhishek focuses on issues including the technical challenges we face in different countries and how best to categorize different types of violent content. For example, research in Cameroon revealed that some images of violence being shared on Facebook helped people pinpoint — and avoid — conflict areas. Nuances like this help us consider the ethics of different product solutions, like removing or reducing the spread of certain content.', 'Emilar, Policy ManagerPrior to joining Facebook, Emilar spent more than a decade working on human rights and social justice issues in Africa, including as a member of the team that developed the African Declaration on Internet Rights and Freedoms. She joined the company to work on public policy issues in Southern Africa, including the promotion of affordable, widely available internet access and human rights both on and offline.', 'Ali, Product ManagerBorn and raised in Iran in the 1980s and 90s, Ali and his family experienced violence and conflict firsthand as Iran and Iraq were involved in an eight-year conflict. Ali was an early adopter of blogging and wrote about much of what he saw around him in Iran. As an adult, Ali received his PhD in computer science but remained interested in geopolitical issues. His work on Facebook’s product team has allowed him to bridge his interest in technology and social science, effecting change by identifying technical solutions to root out hate speech and misinformation in a way that accounts for local nuances and cultural sensitivities.', 'In working on these issues, local groups have given us invaluable input on our products and programs. No one knows more about the challenges in a given community than the organizations and experts on the ground. We regularly solicit their input on our products, policies and programs, and last week wepublished the principlesthat guide our continued engagement with external stakeholders.', 'In the last year, we visited countries such as Lebanon, Cameroon, Nigeria, Myanmar, and Sri Lanka to speak with affected communities in these countries, better understand how they use Facebook, and evaluate what types of content might promote depolarization in these environments. These findings have led us to focus on three key areas:removingcontent and accounts that violate ourCommunity Standards,reducingthe spread of borderline content that has the potential to amplify and exacerbate tensions andinformingpeople about our products and the internet at large. To address content that may lead to offline violence, our team is particularly focused on combating hate speech and misinformation.', 'Hate speechisn’t allowed under our Community Standards. As weshared last year,removing this content requires supplementing user reports with AI that can proactively flag potentially violating posts. We’re continuing to improve our detection in local languages such as Arabic, Burmese, Tagalog, Vietnamese, Bengali and Sinhalese. In the past few months, we’ve been able to detect and remove considerably more hate speech than before. Globally, we increased our proactive rate — thepercent of the hate speech Facebook removed that we found before users reported it to us— from 51.5% in Q3 2018 to 65.4%in Q1 2019.', '', 'We’re also using new applications of AI to more effectively combat hate speech online. Memes and graphics that violate our policies, for example, get added to a photo bank so we can automatically delete similar posts. We’re also using AI to identify clusters of words that might be used in hateful and offensive ways, and tracking how those clusters vary over time and geography to stay ahead of local trends in hate speech. This allows us to remove viral text more quickly.', 'Still, we have a long way to go. Every time we want to use AI to proactively detect potentially violating content in a new country, we have to start from scratch and source a high volume of high quality, locally relevant examples to train the algorithms. Without this context-specific data, we risk losing language nuances that affect accuracy.', 'Globally, when it comes to misinformation, wereduce the spreadof content that’s been deemed false bythird-party fact-checkers.But in countries with fragile information ecosystems, false news can have more serious consequences, including violence. That’s why last year we updated our globalviolence and incitement policysuch that we now remove misinformation that has the potential to contribute to imminent violence or physical harm.To enforce this policy, we partner with civil society organizations who can help us confirm whether content is false and has the potential to incite violence or harm.', 'We’re also making fundamental changes to our products to address virality and reduce the spread of content that can amplify and exacerbate violence and conflict. In Sri Lanka, we have explored adding friction to message forwarding so that people can only share a message with a certain number of chat threads on Facebook Messenger. This is similar to a change we made to WhatsAppearlier this yearto reduce forwarded messages around the world. It also delivers on user feedback that most people don’t want to receive chain messages.', '', 'And, as ourCEO Mark Zuckerberg detailed last year, we have started to explore how best to discourage borderline content, or content that toes the permissible line without crossing it. This is especially true in countries experiencing conflict because borderline content, much of which is sensationalist and provocative, has the potential for more serious consequences in these countries.', '', 'We are, for example, taking a more aggressive approach against people and groups who regularly violate our policies. In Myanmar, we have started to reduce the distribution of all content shared by people who have demonstrated a pattern of posting content that violates our Community Standards, an approach that we may roll out in other countries if it proves successful in mitigating harm. In cases where individuals or organizations more directly promote or engage violence, we will ban them under our policy against dangerous individuals and organizations. Reducing distribution of content is, however, another lever we can pull to combat the spread of hateful content and activity.', 'We have also extended the use of artificial intelligence to recognize posts that may contain graphic violence and comments that are potentially violent or dehumanizing, so we can reduce their distribution while they undergo review by our Community Operations team. If this content violates our policies, we will remove it. By limiting visibility in this way, we hope to mitigate against the risk of offline harm and violence.', 'Perhaps most importantly, we continue to meet with and learn from civil society who are intimately familiar with trends and tensions on the ground and are often on the front lines of complex crises. To improve communication and better identify potentially harmful posts, we have built a new tool for our partners to flag content to us directly. We appreciate the burden and risk that this places on civil society organizations, which is why we’ve worked hard to streamline the reporting process and make it secure and safe.', 'Our partnerships have also been instrumental in promoting digital literacy in countries where many people are new to the internet. Last week, we announced a new program with GSMA called Internet One-on-One (1O1). The program, which we first launched in Myanmar with the goal of reaching 500,000 people in three months, offers one-on-one training sessions that includes a short video on the benefits of the internet and how to stay safe online. We plan to partner with other telecom companies and introduce similar programs in other countries.In Nigeria, we introduced a 12-week digital literacy program for secondary school students called Safe Online with Facebook. Developed in partnership with Re:Learn and Junior Achievement Nigeria, the program has worked with students at over 160 schools and covers a mix of online safety, news literacy, wellness tips and more, all facilitated by a team of trainers across Nigeria.', 'We know there’s more to do to better understand the role of social media in countries of conflict. We want to be part of the solution so that as we mitigate abuse and harmful content, people can continue using our services to communicate. In the wake of the horrific terrorist attacks in Sri Lanka, more than a quarter million people used Facebook’s Safety Check to mark themselves as safe and reassure loved ones. In the same vein, thousands of people in Sri Lanka used our crisis response tools to make offers and requests for help. These use cases — the good, the meaningful, the consequential — are ones that we want to preserve.', 'This is some of the most important work being done at Facebook and we fully recognize the gravity of these challenges. By tackling hate speech and misinformation, investing in AI and changes to our products, and strengthening our partnerships, we can continue to make progress on these issues around the world.']\n",
            "180 ['By Guy Rosen, VP Integrity', 'Today, we’re publishing ourthird Community Standards Enforcement Report, covering Q4 2018 and Q1 2019. This report adds a few additional data points:', 'What’s New in the Third Edition', 'In total, we are now including metrics across nine policies within our Community Standards: adult nudity and sexual activity, bullying and harassment, child nudity and sexual exploitation of children, fake accounts, hate speech, regulated goods, spam, global terrorist propaganda and violence and graphic content.', '', 'How to Make Sense of the Numbers', 'The key metrics in our report, which together track how we are doing at enforcing our Community Standards, are:', 'Prevalence:The frequency at which content that violates our Community Standards was viewed.We care most about how often content that violates our policies is actually seen by someone. Whilecontent actioneddescribes how many things we took down,prevalencedescribes how much we haven’t identified yet and people may still see. We measure it by periodically sampling content viewed on Facebook and then reviewing it to see what percent violates our standards.', 'This metric is currently available for adult nudity and sexual activity, for violence and graphic content, and for fake accounts:', 'In this report, we’re also sharing a prevalence metric for global terrorism and for child nudity and sexual exploitation for the first time. The prevalence for both areas is too low to measure using our standard mechanisms, but we are able to estimate that in Q1 2019, for every 10,000 times people viewed content on Facebook, less than three views contained content that violated each policy.', 'We continue to develop prevalence metrics for the policy areas we include in the report. You can learn more about how we measure prevalencehere.', 'Content Actioned:How much content we took action on because it violated our Community Standards.Our actions include removing the content, applying a warning screen to the content, or disabling accounts. This metric reflects how much content people post that violates our policies, and how well we can identify it.', 'For fake accounts, the amount of accounts we took action on increased due to automated attacks by bad actors who attempt to create large volumes of accounts at one time. We disabled 1.2 billion accounts in Q4 2018 and 2.19 billion in Q1 2019. We’ll continue to find more ways to counter attempts to violate our policies and Alex Schultz explains more about how we address fake accounts in aHard Questions blogwe’ve also shared today.', 'Proactive Rate:Of the content we took action on, how much was detected by our systems before someone reported it to us.This metric typically reflects how effective AI is in a particular policy area.', 'In six of the policy areas we include in this report, we proactively detected over 95% of the content we took action on before needing someone to report it. For hate speech, we now detect 65% of the content we remove, up from 24% just over a year ago when we first shared our efforts. In the first quarter of 2019, we took down 4 million hate speech posts and we continue to invest in technology to expand our abilities to detect this content across different languages and regions.', '', 'New This Report:Appeals and Correcting Our Mistakes', 'When we take action on a piece of content, we notify the person who posted it and in most cases offer them the ability to tell us if they think we made a mistake. In the third edition of the report, we have begun publishing data on how much content people appealed and how much content was restored after we initially took action.', 'Our enforcement isn’t perfect and as soon as we identify a mistake, we work to fix it. That’s why we are including how much content was restored after it was appealed, and how much content we restored on our own — even if the content wasn’t directly appealed. We restore content without an appeal for a few reasons, including:', 'We are including this information for Q1 2019 across each policy area in the report except for fake accounts:', 'The amount of content appealed in a quarter cannot be compared directly to amount of content restored within that quarter, as content restored in Q1 2019 may have been appealed in Q4 2018. Similarly, the amount of content appealed in Q1 2019 may have been actioned in Q4 2018.', 'You can learn more about how the appeals process workshere.', 'New This Report:Data on Regulated Goods', 'We have longstanding policies against illicit drug and firearms sales. For years, we have used a range of approaches to enforce our policy such as: investigating profiles, Pages, Groups, hashtags and accounts associated with violating content we’ve already removed; blocking and filtering hundreds of terms associated with drug sales; and working with experts to stay updated on the latest tactics bad actors use to mask their activity, such as new street names for drugs.', 'In the summer of 2018, we began trying to use AI to identify content that violates our regulated goods policies. This investment has enabled us to take action on more content and, in the majority of cases, to do so before people need to report it to us. In Q1 2019, we took action on about 900,000 pieces of drug sale content, of which 83.3% we detected proactively. In the same period, we took action on about 670,000 pieces of firearm sale content, of which 69.9% we detected proactively.', 'By catching more violating posts proactively, this technology lets our team focus on spotting the next trends in how bad actors try to skirt our detection.', '', 'Our Commitment to Transparency', 'Over the last year, we’ve taken a number of steps to be more transparent in how we develop our policies and how we measure our efforts to enforce them. When it comes to our policies, we began sharingthe meeting minutesfrom ourbi-weekly meetingwhere we determine updates to our policies, and now providea change logon the Community Standards website so that each month everyone can see where exactly we’ve made updates to our policies. Additionally, as part of our efforts to enable academic research,we are awarding grants for 19 research proposalsacross the world to study our content policies and how online content influences offline events.', 'Independent external review and input is an integral component to how we improve. In that spirit, we established the Data Transparency Advisory Group (DTAG) — comprised of international experts in measurement, statistics, criminology and governance — to provide an independent, public assessment of whether the metrics we share in the Community Standards Enforcement Report aremeaningful and accurate. We provided the advisory group detailed and confidential information about our enforcement processes and measurement methodologies and this week they published their independent assessment. In its assessment, the advisory group noted that the Community Standards Enforcement Report is an important exercise in transparency and that they found our approach and methodology sound and reasonable. They also highlighted other areas where we could be more open in order to build more accountability and responsiveness to the people who use our platform. These important insights will help inform our future work.', 'We will continue to bring more transparency to our work and include more information about our efforts so people can see our progress and hold us accountable on where we need to do more.', 'You can read the full reporthere, and find the guidehere.', 'Downloads:', 'Press Call TranscriptPress Call AudioData SnapshotHate Speech Proactive DetectionAppeals ChartRegulated Goods Proactive Detection', '', '']\n",
            "181 ['This post is part of ourHard Questionsseries, which addressesthe impact of our products on society.', 'By Alex Schultz, VP of Analytics', 'We’re regularly asked lots of questions about the fake account numbers in ourCommunity Standards Enforcement Report(CSER) and SEC filings. With the increase in fake account removals, and prevalence, in thelatest report, we thought now would be a good time to give more detail about how we measure fake accounts. We are also opening up even more fully to third parties, including on our fake account numbers, via theData Transparency Advisory Group(DTAG). We know it’s important to have independent verification of our methodology and our work.', 'We believe fake accounts are measured correctly within the limitations to our measurement systems (which we disclose in our CSER guide and SEC filings). That being said, although reporting fake accounts is an industry standard — and something widely asked of us — it may be a bad way to look at things:', 'As such:', 'Overall, we remain confident that the vast majority of people and activity on Facebook are genuine.', 'How We Enforce and Measure Fake Accounts', 'When it comes to abusive fake accounts, our intent is simple: find and remove as many as we can while removing as few authentic accounts as possible. We do this in three distinct ways and include data in the Community Standards Enforcement Report to provide as full a picture as possible of our efforts:', '1. Blocking accounts from being created:The best way to fight fake accounts is to stop them from getting onto Facebook in the first place. That’s why we’ve built detection technology that can detect and block accounts even before they are created. Our systems look for a number of different signals that indicate if accounts are created in mass from one location. A simple example is blocking certain IP addresses altogether so that they can’t access our systems and thus can’t create accounts.', 'What we measure:The data we include in the report about fake accounts does not include unsuccessful attempts to create fake accounts that we blocked at this stage. This is because we literally can’t know the number of attempts to create an account we’ve blocked as, for example, we block whole IP ranges from even reaching our site. While these efforts aren’t included in the report, we can estimate that every day we prevent millions of fake accounts from ever being created using these detection systems.', '2. Removing accounts when they sign-up:Our advanced detection systems also look for potential fake accounts as soon as they sign-up, by spotting signs of malicious behavior. These systems use a combination of signals such as patterns of using suspicious email addresses, suspicious actions, or other signals previously associated with other fake accounts we’ve removed. Most of the accounts we currently remove, are blocked within minutes of their creation before they can do any harm.', 'What we measure:We include the accounts we disable at this stage in our accounts actioned metric for fake accounts. Changes in our accounts actioned numbers are often the result of unsophisticated attacks like we saw in the last two quarters. These are really easy to spot and can totally dominate our numbers, even though they pose little risk to users. For example, a spammer may try to create 1,000,000 accounts quickly from the same IP address. Our systems will spot this and remove these fake accounts quickly. The number will be added to our reported number of accounts taken down, but the accounts were removed so soon that they were never considered active and thus could not contribute to our estimated prevalence of fake accounts amongst monthly active users or our publicly stated monthly active user number or even any ad impressions.', '3. Removing accounts already on Facebook:Some accounts may get past the above two defenses and still make it onto the platform. Often, this is because they don’t readily show signals of being fake or malicious at first, so we give them the benefit of the doubt until they exhibit signs of malicious activity. We find these accounts when our detection systems identify such behavior or if people using Facebook report them to us. We use a number of signals about how the account was created and is being used to determine whether it has a high probability of being fake and disable those that are.', 'What we measure:The accounts we remove at this stage are also counted in our accounts actioned metric. If these accounts are active on the platform, we would also account for them in our prevalence metric. Prevalence of fake accounts measures how many active fake accounts exist amongst our monthly active users within a given time period. Of the accounts we remove, both at sign-up and those already on the platform, over 99% of these are proactively detected by us before people report them to us. We provide that data as our metric of proactive rate in the report.', 'We believe that of all the metrics, prevalence of fake accounts is the most important to focus on.', 'It’s Important to Get the Balance Right', 'We have two main goals with fake accounts. Preventing abuse from fake accounts but also giving people the power to share through authentic accounts. We have to strike the right balance between these goals.', 'To prevent abuse, we try to identify accounts that look abusive — but even here it is possible to take action on accounts that don’t deserve it. When someone joins Facebook and sends out lots of friend requests it can look like they are a spammer but in fact are super social person, for instance users in Brazil who are rapidly adopting social media or teenagers sending a large amount of messages a day. Sometimes someone signs up and behaves oddly because they are completely new to the internet and are figuring it out, like someone in the developing world or a senior just getting online. We believe giving people the power to build community is really important and so for accounts where we aren’t sure if they are abusive we will give them time to prove to us their intent. So, both from focusing on abusive accounts (not user-misclassified pet profiles) and from giving new accounts space to prove their intent, we expect there will always be a small percent of fake accounts on our services.', 'Preventing fake accounts is just one way to stop abuse — and we have other protections once content is being produced and people are interacting with these accounts. Also fake accounts are just one way abuse happens. Authentic accounts can be abusive too. As such, to evaluate our work on keeping the community safe overall, we recommend using the full suite of metrics we offer in the CSER andespecially the prevalence metrics. Our work on fake accounts is just one driver of these.', 'In addition to the questions we get about abusive fake accounts, we also get questions about fake accounts in general as it relates to advertisers getting a return on their investment with us. In the same way we want people to share on Facebook and we know that they will only do that if they feel safe, we also know advertisers will only continue to advertise on Facebook if they get results — and we’re continuing to deliver returns for them despite the small occurrence of fake accounts.', 'We remain confident that the vast majority of people and activity on Facebook is genuine. We welcome feedback and scrutiny on fake accounts but are proud of our work to balance protecting the people and advertisers using our services while giving everyone the power to build community on Facebook.']\n",
            "182 ['One of the most significant metrics we provide in theCommunity Standards Enforcement Reportis prevalence. This video explains more about prevalence as it relates to our efforts to remove harmful content from Facebook.', 'The way content causes harm on the internet is by being seen. Given the nature of the internet, the amount of times content is seen is not evenly distributed. A small amount of content could go viral and get a lot of distribution in a very short span of time, whereas other content could be on the internet for a long time and not be seen by anyone. Any measure we use to understand our enforcement of harmful content should take that into consideration.', 'For this reason, we consider prevalence to be a critical metric because it helps us measure how violations impact people on Facebook. We care most about how often content that violates our standards is actually seen relative to the total amount of timesanycontent is seen on Facebook.', 'This is similar to measuring concentration of pollutants in the air we breathe. When measuring air quality, environmental regulators look to see what percent of air is Nitrogen Dioxide to determine how much is harmful to people. Prevalence is the internet’s equivalent — a measurement of what percent of times someone sees something that is harmful.', 'We calculate this metric by selecting a sample of content seen on Facebook and then labeling how much of it shouldn’t be there. There are four reasons why harmful content may be seen on our site:', 'To measure prevalence we focus on how much content is seen, not how much sheer content violates our rules. In other words, we don’t treat all content equally: a post seen 1 million times is 1 million times more likely to be sampled, and that’s a good thing. Again, this is also similar to air quality testing stations that take a sample of air to estimate the concentration of pollutants.', 'Prevalence (or concentration of violating materials) measures all four of the above reasons. We see a lot of attention paid to instances when people see violating content before we take it down. Ideally, we would remove all violating content before anyone ever sees it, if it was possible to perfectly moderate content. In some cases, however, the content never being detected or reported in the first place is a bigger reason harmful content is seen. We need a measure that captures all of these reasons people maybe exposed to harmful content. We believe prevalence is that measure.', 'To learn more about how we’re protecting our community from harmful content, check out our Community Standards Enforcement Report attransparency.facebook.com. You can learn more about how we measure prevalence in thecompanion guide.']\n",
            "183 ['This week, Facebook hosted our third annual Global Safety and Well-Being Summit. We were joined by over 100 organizations from 40 countries to discuss a wide range of issues including suicide prevention, raising children in the digital era and protecting the most vulnerable people online. We listen to experts and groups working for change in their online and offline communities to help us innovate responsibly and with intention. See some of the highlights below.', 'Panel Discussion: “Pushing the Boundaries: Amidst the Rising Tide of Suicide, Can Tech Help Move the Needle?”', 'Fireside Chat: “Life After Suicide: Social Media and Healing”', '(Updated on May 17, 2019 at 7:15AM PT to include above video)', '', 'Fireside Chat: “The Governance and Ethics of Tech”', 'Panel Discussion: “So Your Kids Are Online, But Will They Be Alright?”', 'Fireside Chat: “Family Toolbox in a Digital Age”', 'Oculus Showcase: Project Empathy', 'Instagram Showcase: Bullying Prevention', '', 'Breakout Sessions: “Online Safety: What We Know Now, What We Still Need to Learn and What it Means Going Forward”', 'Bullying Prevention', '', 'Combatting Harassment of Women', '', 'Child Protection', '', 'Ask Teens Anything', '', 'Community Showcase', 'We also featured people likeHallie Twomey of Scattering CJwho are building supportive communities on Facebook. After losing her son, CJ, to suicide, Hallie started a Facebook community to continue his “final journey.” Learn more about Hallie and other Facebook Community Leaders here:', '', 'See also:', '']\n",
            "184 ['Today, Facebook’s Vice President for Global Affairs and Communications Nick Clegg joined G7 government and industry leaders for a meeting in Paris on how to curb the spread of terrorism and extremism online. At the meeting, hosted by French President Emmanuel Macron and New Zealand Prime Minister Jacinda Ardern, Facebook along with Microsoft, Twitter, Google and Amazon signed up to theChristchurch Call to Action. The technology companies also committed to a nine-point plan that sets out concrete steps the industry will take to address the abuse of technology to spread terrorist content. The following is a statement from all five companies:', '“The terrorist attacks in Christchurch, New Zealand, in March were a horrifying tragedy. And so it is right that we come together, resolute in our commitment to ensure we are doing all we can to fight the hatred and extremism that lead to terrorist violence.', 'The Christchurch Call announced today expands on the Global Internet Forum to Counter Terrorism (GIFCT), and builds on our other initiatives with government and civil society to prevent the dissemination of terrorist and violent extremist content.Additionally, we are sharing concrete steps we will take that address the abuse of technology to spread terrorist content, including continued investment in technology that improves our capability to detect and remove this content from our services, updates to our individual terms of use, and more transparency for content policies and removals.', 'Terrorism and violent extremism are complex societal problems that require an all-of-society response. For our part, the commitments we are making today will further strengthen the partnership that Governments, society and the technology industry must have to address this threat.”', 'And here’s the nine-point plan:', 'As online content sharing service providers, we commit to the following:', 'Five Individual Actions', 'Terms of Use.We commit to updating our terms of use, community standards, codes of conduct, and acceptable use policies to expressly prohibit the distribution of terrorist and violent extremist content. We believe this is important to establish baseline expectations for users and to articulate a clear basis for removal of this content from our platforms and services and suspension or closure of accounts distributing such content.', 'User Reporting of Terrorist and Violent Extremist Content.We commit to establishing one or more methods within our online platforms and services for users to report or flag inappropriate content, including terrorist and violent extremist content. We will ensure that the reporting mechanisms are clear, conspicuous, and easy to use, and provide enough categorical granularity to allow the company to prioritize and act promptly upon notification of terrorist or violent extremist content.', 'Enhancing Technology.We commit to continuing to invest in technology that improves our capability to detect and remove terrorist and violent extremist content online, including the extension or development of digital fingerprinting and AI-based technology solutions.', 'Livestreaming.We commit to identifying appropriate checks on livestreaming, aimed at reducing the risk of disseminating terrorist and violent extremist content online. These may include enhanced vetting measures (such as streamer ratings or scores, account activity, or validation processes) and moderation of certain livestreaming events where appropriate. Checks on livestreaming necessarily will be tailored to the context of specific livestreaming services, including the type of audience, the nature or character of the livestreaming service, and the likelihood of exploitation.', 'Transparency Reports.We commit to publishing on a regular basis transparency reports regarding detection and removal of terrorist or violent extremist content on our online platforms and services and ensuring that the data is supported by a reasonable and explainable methodology.', 'Four Collaborative Actions', 'Shared Technology Development.We commit to working collaboratively across industry, governments, educational institutions, and NGOs to develop a shared understanding of the contexts in which terrorist and violent extremist content is published and to improve technology to detect and remove terrorist and violent extremist content more effectively and efficiently. This will include:', 'Crisis Protocols.We commit to working collaboratively across industry, governments, and NGOs to create a protocol for responding to emerging or active events, on an urgent basis, so relevant information can be quickly and efficiently shared, processed, and acted upon by all stakeholders with minimal delay. This includes the establishment of incident management teams that coordinate actions and broadly distribute information that is in the public interest.', 'Education.We commit to working collaboratively across industry, governments, educational institutions, and NGOs to help understand and educate the public about terrorist and extremist violent content online. This includes educating and reminding users about how to report or otherwise not contribute to the spread of this content online.', 'Combatting Hate and Bigotry.We commit to working collaboratively across industry to attack the root causes of extremism and hate online. This includes providing greater support for relevant research – with an emphasis on the impact of online hate on offline discrimination and violence – and supporting capacity and capability of NGOs working to challenge hate and promote pluralism and respect online.']\n",
            "185 ['By Guy Rosen, VP Integrity', 'Following the horrific terrorist attacks in New Zealand, we’ve been reviewing what more we can do to limit our services from being used to cause harm or spread hate. \\xa0As a direct result, starting today, people who have broken certain rules on Facebook — including ourDangerous Organizations and Individualspolicy — will be restricted from using Facebook Live.', 'Tackling these threats also requires technical innovation to stay ahead of the type of adversarial media manipulation we saw after Christchurchwhen some people modified the video to avoid detection in order to repost it after it had been taken down.This will require research driven across industry and academia. To that end, we’re also investing $7.5 million in new research partnerships with leading academics from three universities, designed to improve image and video analysis technology.', 'Restrictions to Live', 'The overwhelming majority of people use Facebook Live for positive purposes, like sharing a moment with friends or raising awareness for a cause they care about. Still, Live can be abused and we want to take steps to limit that abuse.', 'Before today, if someone posted content that violated our Community Standards — on Live or elsewhere — we took down their post. If they kept posting violating content we blocked them from using Facebook for a certain period of time, which also removed their ability to broadcast Live. And in some cases, we banned them from our services altogether, either because of repeated low-level violations, or, in rare cases, because of a single egregious violation (for instance, using terror propaganda in a profile picture or sharing images of child exploitation).', 'Today we are tightening the rules that apply specifically to Live. We will now apply a ‘one strike’ policy to Live in connection with a broader range of offenses. From now on, anyone who violates our most serious policies will be restricted from using Live for set periods of time – for example 30 days – starting on their first offense. For instance, someone who shares a link to a statement from a terrorist group with no context will now be immediately blocked from using Live for a set period of time.', 'We plan on extending these restrictions to other areas over the coming weeks, beginning with preventing those same people from creating ads on Facebook.', 'We recognize the tension between people who would prefer unfettered access to our services and the restrictions needed to keep people safe on Facebook. Our goal is to minimize risk of abuse on Live while enabling people to use Live in a positive way every day.', 'Investing in Research into Manipulated Media', 'One of the challenges we faced in the days after the Christchurch attack was aproliferation of many different variants of the video of the attack. People — not always intentionally — shared edited versions of the video, which made it hard for our systems to detect.', 'Although we deployed a number of techniques to eventually find these variants, including video and audio matching technology, we realized that this is an area where we need to invest in further research.', 'That’s why we’re partnering with The University of Maryland, Cornell University and The University of California, Berkeley to research new techniques to:', 'Dealing with the rise of manipulated media will require deep research and collaboration between industry and academia — we need everyone working together to tackle this challenge. These partnerships are only one piece of our efforts to partner with academics and our colleagues across industry — in the months to come, we will partner more so we can all move as quickly as possible to innovate in the face of this threat.', 'This work will be critical for our broader efforts against manipulated media, including deepfakes (videos intentionally manipulated to depict events that never occurred). We hope it will also help us to more effectively fight organized bad actors who try to outwit our systems as we saw happen after the Christchurch attack.', 'These are complex issues and our adversaries continue to change tactics. We know that it is only by remaining vigilant and working with experts, other companies, governments and civil society around the world that we will be able to keep people safe. We look forward to continuing our work together.']\n",
            "186 ['By Janelle Gale, VP of HR and Arun Chandra, VP of Scaled Operations', 'The work we do to connect people around the world would not be possible without the talented and dedicated people who do contract work at Facebook. They are employed by outside vendor partners to work either part-time or full-time and provide important services across content review, security, culinary, transportation and other teams. We value their work immensely.', 'Today we’re committing to pay everyone who does contract work at Facebook in the US a wage that’s more reflective of local costs of living. And for those who review content on our site to make sure it followsour community standards, we’re going even further. We’re going to provide them a higher base wage, additional benefits, and more supportive programs given the nature of their jobs.', 'Raising Wages', 'In 2015, weintroduceda new set of standards for people who do contract work in the US, including: a $15 minimum wage; a minimum 15 paid days off for holidays, sick time and vacation; and, for new parents that don’t receive paid leave, a $4,000 new child benefit that gives them the flexibility to take paid parental leave. Since 2016, we’ve also required vendors in the US to provide comprehensive healthcare to all of their employees assigned to Facebook.', 'In the years since, it’s become clear that $15 per hour doesn’t meet the cost of living in some of the places where we operate. After reviewing a number of factors including third-party guidelines, we’re committing to a higher standard that better reflects local costs of living. This means a raise to a minimum of $20 per hour in the San Francisco Bay Area, New York City and Washington, D.C., and $18 per hour in Seattle. We’ll be implementing these changes by mid-next year and we’re working to develop similar standards for other countries.', 'For workers in the US that review content on Facebook, we are raising wages even more. Their work is critical to keeping our community safe, and it’s often difficult. That’s why we’ve paid content reviewers more than minimum wage standards, and why we will surpass this new living wage standard as well. We’ll pay at least $22 per hour to all employees of our vendor partners based in the Bay Area, New York City and Washington, D.C.; $20 per hour to those living in Seattle; and $18 per hour in all other metro areas in the US. As with all people who do contract work, we’re working to develop similar international standards. This work is ongoing, and we’ll continue to review wages over time.', 'Caring for Content ReviewersBeyond pay, we’re taking steps to better support the well-being and resilience of the teams that review content. All content reviewers — whether full-time employees or those employed by partner companies — have access to well-being and resiliency resources. This includes onsite trained professionals for individual and group counseling. And as with all people doing contract work, content reviewers also have comprehensive health care benefits.', 'We want to go further, and we are rolling out the first of many new programs and tools developed based on feedback from psychologists on our global resiliency team and from content reviewers themselves:', 'Last month, we hosted our first annual vendor partner summit at Facebook’s Menlo Park Headquarters. Over 200 representatives from our vendor partners around the world joined us to discuss these changes and consider other ways we can better support our content reviewers. We heard great feedback and will continue to make important changes moving forward as these conversations continue.', 'AccountabilityWe’re working to make contracts across our Global Operations vendor partners consistent. This includes requirements like quality-focused incentives, no sub-contracting, overtime and premiums for nightshifts and weekends, and healthcare that meets the standards of the Affordable Care Act in the US and appropriate healthcare standards internationally.', 'It’s also really important that workers are being heard. We’re kicking off a biannual audit and compliance program this year for content review teams. This includes formal audits, unannounced onsite checks, and vendor partner self-reporting. We also have a whistleblower hotline where anyone who does contract work — including content reviewers — can raise concerns directly to Facebook. We’re working to make sure everyone knows about this hotline and feels empowered to use it.', 'Content review at our size can be challenging and we know we have more work to do. We’re committed to supporting our content reviewers in a way that puts their well-being first and we will continue to share steps forward on this important topic.']\n",
            "187 ['By Guy Rosen, VP of Integrity, and Tessa Lyons, Head of News Feed Integrity', 'Since 2016, we have used a strategy called “remove, reduce, and inform” to manage problematic content across the Facebook family of apps. This involvesremovingcontent that violates our policies,reducingthe spread of problematic content that does not violate our policies andinformingpeople with additional information so they can choose what to click, read or share. This strategy applies not only during critical times likeelections, but year-round.', 'Today in Menlo Park, we met with a small group of journalists to discuss our latest remove, reduce and inform updates to keep people safe and maintain the integrity of information that flows through the Facebook family of apps:', 'REMOVE(read more)', 'REDUCE(read more)', 'INFORM(read more)', '', 'Facebook', 'We haveCommunity Standardsthat outline what is and isn’t allowed on Facebook. They cover things like bullying, harassment and hate speech, and we remove content that goes against our standards as soon as we become aware of it. Last year, we made it easier for people to understand what we take down bypublishing our internal enforcement guidelinesand giving people the right toappeal our decisionson individual posts.', 'The Community Standards apply to all parts of Facebook, but different areas pose different challenges when it comes to enforcement. For the past two years, for example, we’ve been working on something called the Safe Communities Initiative, with the mission of protecting people from harmful groups and harm in groups. By using a combination of the latest technology, human review and user reports, we identify and remove harmful groups, whether they are public, closed or secret. We can now proactively detect many types of violating content posted in groups before anyone reports them and sometimes before few people, if any, even see them.', 'Similarly, Stories presents its own set of enforcement challenges when it comes to both removing and reducing the spread of problematic content. The format’s ephemerality means we need to work even faster to remove violating content. The creative tools that give people the ability to add text, stickers and drawings to photos and videos can be abused to mask violating content. And because people enjoy stringing together multiple Story cards, we have to view Stories as holistic — if we evaluate individual story cards in a vacuum, we might miss standards violations.', 'In addition to describing this context and history, today we discussed how we will be:', 'For more information on Facebook’s “remove” work, see these videos on thepeopleandprocessbehind our Community Standards development.', '', 'Facebook', 'There are types of content that are problematic but don’t meet the standards for removal under ourCommunity Standards, such as misinformation and clickbait. People often tell us that they don’t like seeing this kind of content and while we allow it to be posted on Facebook, we want to make sure it’s not broadly distributed.', 'Over the last two years, we’ve focused heavily onreducing misinformationon Facebook. We’re getting better at enforcing againstfake accounts and coordinated inauthentic behavior; we’re using both technology and people to fight the rise inphoto and video-based misinformation; we’ve deployed new measures to help peoplespot false newsand get morecontextabout the stories they see in News Feed; and we’ve grown our third-party fact-checking program to include 45 certified fact-checking partners who review content in 24 languages.', 'Today, members of the Facebook News Feed team discussed how we will be:', 'For more information about how we set goals for our “reduce” initiatives on Facebook,read this blog post.', 'Instagram', 'Today we discussed how Instagram is working to ensure that the content we recommend to people is both safe and appropriate for the community. We have begun reducing the spread of posts that are inappropriate but do not go againstInstagram’s Community Guidelines, limiting those types of posts from being recommended on our Explore and hashtag pages. For example, a sexually suggestive post will still appear in Feed if you follow the account that posts it, but this type of content may not appear for the broader community in Explore or hashtag pages.', '', 'Facebook', 'We’re investing in features and products that give people more information to help them decide what to read, trust and share. In the past year, we began offering more information on articles in News Feed with theContext Button, which shows the publisher’s Wikipedia entry, the website’s age, and where and how often the content has been shared. We helped Page owners improve their content with thePage Quality tab, which shows them which posts of theirs were removed for violating our Community Standards or were rated“False,” “Mixture” or “False Headline”by third-party fact-checkers. We also discussed how we will be:', 'Messenger', 'At today’s event, Messenger highlighted new and updated privacy and safety features that give people greater control of their experience and help people stay informed.', '']\n",
            "188 ['In the past year, we’ve been talking a lot about ourCommunity Standards, the rules for what content is and isn’t permitted on Facebook. We’ve explainedhow they’re enforcedand introduced theteams responsible for that work. Today, we’re sharing details on how these policies evolve.', 'Our Standards are a living set of guidelines — they must keep pace with changes happening online and in the world. In this video, we explain our policy development process, the core of which is a twice-monthly global meeting where we debate and discuss potential changes to the Community Standards. In preparation for these meetings, members of our content policy team reach out to internal and external experts, analyze data, conduct research and study relevant scholarship to inform our policy proposals. We publish the minutes of those meetingshere. This multi-step effort allows us to account for a range of perspectives and opinions across the globe, to ultimately develop stronger policies. When our policies are written or updated, we share those updates on ourCommunity Standards website.', 'See also:']\n",
            "189 ['Note: For future Facebook updates about Oversight Board cases, please visit theTransparency Center.', 'Every day, teams at Facebook make difficult decisions about what content should stay up and what should come down based on our Community Standards. But given the size of our community — and the reach of our platform — we don’t think we should be making all of these decisions on our own. InNovember, Mark Zuckerberg laid out a plan for a new way for people to appeal content decisions to an independent board. And earlier this year, wereleased a draft chartergiving more detail about its potential structure.', 'Today, we’re opening apublic consultation processto help us answer questions around the design for this Oversight Board. This is another part of our ongoing, global engagement with a wide range of organizations, think tanks and researchers to determine how best to empower this entity to render independent judgment on some of Facebook’s most important and challenging content decisions.', 'Each submission is broken into two sections: a questionnaire and free-form questions. The questionnaire responses will feed into the engagement happening in round tables and workshops around the world. The free-form questions will focus on membership, case decisions and governance, and will provide invaluable design and structural options. Responses will be accepted for the next six weeks.', 'We’re partnering with a team from the firm Baker McKenzie, who are providing project management support for this effort and will review each submission. In June, we’ll publish a report summarizing what we’ve learned through these submissions and in the broader conversations we’re having.', 'We look forward to continuing outreach and engagement that will help build a board and create accountability and oversight of our content policy and enforcement decisions. We will continue to share milestones and progress along the way.', 'To share your opinion and perspective, gohere.', '(Update on April 19, 2019 at 10:15AM PT: You can also preview the questionshere.)']\n",
            "190 ['Today we’re announcing a ban on praise, support and representation of white nationalism and white separatism on Facebook and Instagram, which we’ll start enforcing next week. It’s clear that these concepts are deeply linked to organized hate groupsand have no place on our services.', 'Our policies have long prohibited hateful treatment of people based on characteristics such as race, ethnicity or religion — and that has always included white supremacy. We didn’t originally apply the same rationale to expressions of white nationalism and white separatism because we were thinking about broader concepts of nationalism and separatism — things like American pride and Basque separatism, which are an important part of people’s identity.', 'But over the past three months our conversations with members of civil society and academics who are experts in race relations around the world have confirmed that white nationalism and white separatism cannot be meaningfully separated from white supremacy and organized hate groups. Our own review of hate figures and organizations – as defined by ourDangerous Individuals & Organizations policy– further revealed the overlap between white nationalism and white separatism and white supremacy. Going forward, while people will still be able to demonstrate pride in their ethnic heritage, we will not tolerate praise or support for white nationalism and white separatism.', 'We also need to get better and faster at finding and removing hate from our platforms. Over the past few years we have improved our ability to use machine learning and artificial intelligence to find material from terrorist groups. Last fall, we started using similar tools to extend our efforts to a range of hate groups globally, including white supremacists. We’re making progress, but we know we have a lot more work to do.', 'Our efforts to combat hate don’t stop here. As part of today’s announcement, we’ll also start connecting people who search for terms associated with white supremacy to resources focused on helping people leave behind hate groups. People searching for these terms will be directed toLife After Hate, an organization founded by former violent extremists that provides crisis intervention, education, support groups and outreach.', 'Unfortunately, there will always be people who try to game our systems to spread hate. Our challenge is to stay ahead by continuing to improve our technologies, evolve our policies and work with experts who can bolster our own efforts. We are deeply committed and will share updates as this process moves forward.', '']\n",
            "191 ['Note: For future Facebook updates about Oversight Board cases, please visit theTransparency Center.', 'The following is an op-ed by Facebook’s VP of Product Partnerships Ime Archibong. Ime is in Nairobi, Kenya this week to host Africa’s Oversight Board workshop, which will bring together civil society leaders, academia, free expression and human rights experts representing 18 countries across Sub-Saharan Africa. Their input will help us shape an Oversight Board that will have the authority to review some of Facebook’s most challenging and contentious content decisions.', 'With more than 1 billion people, and tens of thousands of languages and ethnic groups across 54 countries, Africa has a beautiful, complex tapestry of cultures.', 'Three years ago, while in Ghana, someone told me how much they felt Facebook and Instagram enabled people across the continent to capture and tell their own stories, with a speed and style that never existed before. With hundreds of millions of people across Africa using Facebook and Instagram every day to share messages, videos and images with the people and communities they care about most, this gives us the important responsibility of making complex decisions about which content we allow, and which content we take down, in line with our Community Standards.', 'Every day we grapple with our responsibility to keep our community safe while giving people freedom to express their opinions about the issues that matter the most to them. We take this responsibility seriously and know that we don’t have all the answers. We also know that we must continue to learn from experts and members of our community, in particular those of you who live and work across Africa.', 'This is why over the next year we will design a global body, an Oversight Board, which will have the authority to review some of our most challenging and contentious content decisions. It’s critical to get wide input from local experts, including academics, NGOs and civil society from across the world — and here on the continent– on how this independent body could work.', 'As part of our information gathering and consultation process, we’re hosting a workshop in Nairobi, with participants from across the Continent. Today we’re receiving guidance from civil society leaders, academia, free expression and human rights experts representing 18 countries across Sub-Saharan Africa, including: Benin, Burkina Faso, Burundi, Cameroon, Cote d’Ivoire, the DRC, Ethiopia, France, Ghana, Kenya, Malawi, Nigeria, Senegal, South Africa, Tanzania, Uganda, Zambia, and Zimbabwe. Their input is invaluable to what we’re building, so we’re taking lots of notes.', 'We are excited about deeply engaging with this group on the hard questions related to content on our platforms. We recognize that this is a complex process that will strengthen how we exercise our responsibility to people using our products. To be clear, we are not asking a group of experts to make decisions for us. We are, however, asking for their insights to help inform our thinking and hold us accountable. We’ll still be making hard decisions every day, and we accept the full weight of that responsibility.', 'The board, as currently envisioned, will consist of about 40 global experts with experience in content, privacy, free expression, human rights, journalism and safety. Where we need to, we will supplement member expertise through consultation with geographic and cultural experts to help ensure decisions are fully informed.', 'The board will exercise independent judgment when reviewing our most difficult and disputed content decisions and hold us publicly accountable if we don’t get them right. This should in time bring more perspective, accountability and transparency to our content decisions. The board will have the power to overrule or uphold Facebook’s content decisions and will be able to recommend changes or additions to policies.', 'Through workshops such as the one in Kenya, we are listening to our partners and incorporating a diverse range of perspectives from across Africa into the board’s design process. These insights are critical in designing a board that can serve our global community and uphold our values, while bringing independent judgment to controversial cases.', 'The success and the ultimate effectiveness of the Oversight Board will depend on its ability to accommodate an inclusive and diverse range of perspectives, across language, culture and experience. Above all, it’s important we achieve a diversity of backgrounds and perspectives to reflect our truly global community. While we can’t include representatives from every country and culture, Africa will be represented on the board alongside other regions, and we continue to explore ways to improve.', 'We are very much at the beginning of this process – it has not been done before, and, with input from our community across Africa, we are working hard to get it right.']\n",
            "192 ['By Guy Rosen, VP, Product Management', 'We continue to keep the people, families and communities affected by the tragedy in New Zealand in our hearts. Since the attack, we have been working directly with the New Zealand Police to respond to the attack and support their investigation. In addition, people are looking to understand how online platforms such as Facebook were used to circulate horrific videos of the terrorist attack, and we wanted to provide additional information from our review into how our products were used and how we can improve going forward.', 'Timeline', 'As wepostedearlier this week, we removed the attacker’s video within minutes of the New Zealand Police’s outreach to us, and in the aftermath, we have people working on the ground with authorities. We will continue to support them in every way we can. In light of the active investigation, police have asked us not to share certain details. At present we are able to provide the information below:', 'Safety on Facebook Live', 'We recognize that the immediacy of Facebook Live brings unique challenges, and in the past few years we’ve focused on enabling our review team to get to the most important videos faster. We use artificial intelligence to detect and prioritize videos that are likely to contain suicidal or harmful acts, we improved the context we provide reviewers so that they can make the most informed decisions and we built systems to help us quickly contact first responders to get help on the ground. We continue to focus on the tools, technology and policies to keep people safe on Live.', 'Artificial Intelligence', 'Many people have asked why artificial intelligence (AI) didn’t detect the video from last week’s attack automatically. AI has made massive progress over the years and in many areas, which has enabled us to proactively detect the vast majority of the content we remove. But it’s not perfect.', 'AI systems are based on “training data”, which means you need many thousands of examples of content in order to train a system that can detect certain types of text, imagery or video. This approach has worked very well for areas such as nudity, terrorist propaganda and also graphic violence where there is a large number of examples we can use to train our systems. However, this particular video did not trigger our automatic detection systems. To achieve that we will need to provide our systems with large volumes of data of this specific kind of content, something which is difficult as these events are thankfully rare. Another challenge is to automatically discern this content from visually similar, innocuous content – for example if thousands of videos from live-streamed video games are flagged by our systems, our reviewers could miss the important real-world videos where we could alert first responders to get help on the ground.', 'AI is an incredibly important part of our fight against terrorist content on our platforms, and while its effectiveness continues to improve, it is never going to be perfect. People will continue to be part of the equation, whether it’s the people on our team who review content, or people who use our services and report content to us. That’s why last year we more than doubled the number of people working on safety and security to over 30,000 people, including about 15,000 content reviewers, and why we encourage people to report content that they find disturbing.', 'Reporting', 'During the entire live broadcast, we did not get a single user report. This matters because reports we get while a video is broadcasting live are prioritized for accelerated review. We do this because when a video is still live, if there is real-world harm we have a better chance to alert first responders and try to get help on the ground.', 'Last year, we expanded this acceleration logic to also cover videos that were very recently live, in the past few hours. Given our focus on suicide prevention, to date we applied this acceleration when a recently live video is reported for suicide.', 'In Friday’s case, the first user report came in 29 minutes after the broadcast began, 12 minutes after the live broadcast ended. In this report, and a number of subsequent reports, the video was reported for reasons other than suicide and as such it was handled according to different procedures. As a learning from this, we are re-examining our reporting logic and experiences for both live and recently live videos in order to expand the categories that would get to accelerated review.', 'Circulation of the Video', 'The video itself received fewer than 200 views when it was live, and was viewed about 4,000 times before being removed from Facebook. During this time, one or more users captured the video and began to circulate it. At least one of these was a user on 8chan, who posted a link to a copy of the video on a file-sharing site and we believe that from there it started circulating more broadly. Forensic identifiers on many of the videos later circulated, such as a bookmarks toolbar visible in a screen recording, match the content posted to 8chan.', 'This isn’t the first time violent, graphic videos, whether live streamed or not, have gone viral on various online platforms. Similar to those previous instances, we believe the broad circulation was a result of a number of different factors:', 'People shared this video for a variety of reasons. Some intended to promote the killer’s actions, others were curious, and others actually intended to highlight and denounce the violence. Distribution was further propelled by broad reporting of theexistenceof a video, which may have prompted people to seek it out and to then share it further with their friends.', 'Blocking the Video', 'Immediately after the attack, we designated this as a terror attack, meaning that any praise, support, or representation violates our Community Standards and is not permitted on Facebook. Given the severe nature of the video, we prohibited its distribution even if shared to raise awareness, or only a segment shared as part of a news report.', 'In the first 24 hours, we removed more than 1.2 million videos of the attack at upload, which were therefore prevented from being seen on our services. Approximately 300,000 additional copies were removed after they were posted.', 'We’ve been asked why our image and video matching technology, which has been so effective at preventing the spread of propaganda from terrorist organizations, did not catch those additional copies. What challenged our approach was the proliferation of many different variants of the video, driven by the broad and diverse ways in which people shared it:', 'First, we saw a core community of bad actors working together to continually re-upload edited versions of this video in ways designed to defeat our detection.', 'Second, a broader set of people distributed the video and unintentionally made it harder to match copies. Some people may have seen the video on a computer or TV, filmed that with a phone and sent it to a friend. Still others may have watched the video on their computer, recorded their screen and passed that on. Websites and pages, eager to get attention from people seeking out the video, re-cut and re-recorded the video into various formats.', 'In total, we found and blocked over 800 visually-distinct variants of the video that were circulating. This is different from official terrorist propaganda from organizations such as ISIS – which while distributed to a hard core set of followers, is not rebroadcast by mainstream media organizations and is not re-shared widely by individuals.', 'We’re learning to better understand techniques which would work for cases like this with many variants of an original video. For example, as part of our efforts we employed audio matching technology to detect videos which had visually changed beyond our systems’ ability to recognize automatically but which had the same soundtrack.', 'Next Steps', 'Our greatest priorities right now are to support the New Zealand Police in every way we can, and to continue to understand how our systems and other online platforms were used as part of these events so that we can identify the most effective policy and technical steps. This includes:', 'What happened in New Zealand was horrific. Our hearts are with the victims, families and communities affected by this horrible attack.', 'We’ll continue to provide updates as we learn more.']\n",
            "193 ['By Chris Sonderby, VP and Deputy General Counsel', 'Our hearts go out to the victims, their families and the community affected by the horrific terrorist attacks in Christchurch. We remain shocked and saddened by this tragedy and are committed to working with leaders in New Zealand, other governments, and across the technology industry to help counter hate speech and the threat of terrorism. We continue to work around the clock to prevent this content from appearing on our site, using a combination of technology and people.', 'We have been working directly with the New Zealand Police to respond to the attack and support their investigation. We removed the attacker’s video within minutes of their outreach to us, and in the aftermath, we have been providing an on-the-ground resource for law enforcement authorities. We will continue to support them in every way we can. In light of the active investigation, police have asked us not to share certain details. While we’re still reviewing this situation, we are able to provide the information below:', 'We will continue to work around the clock on this and will provide further updates as relevant.']\n",
            "194 ['By Radha Iyengar, PhD, Head of Product Policy Research and Karuna Nain, Global Safety Policy Programs Manager', 'The sharing of intimate images online can have serious emotional and physical consequences for the people whose photographs were posted. Sometimes called “revenge porn,” it’s really a form of sexual violence that can be motivated by an intent to control, shame, humiliate, extort and terrorize victims.', 'Discovering intimate images of yourself online when you didn’t consent to them being shared is devastating. That’s why we’ve taken a careful, research-based approach that concentrates on the victims — what they experience andhow we can better protect them.', 'Over the last year, we’ve conducted our own research and partnered with many international safety organizations to review and improve our response to the sharing of what we call non-consensual intimate images (NCII) anywhere on Facebook, Messenger or Instagram. We tried to understand the experience of victims, how victims reported their experience, what barriers arose when they made a report and what support or tools they needed to feel safe on our platform. We interviewed victim support advocates and victims themselves from around the world, including Kenya, Denmark and the U.K. Last summer we brought together over 20 academics and non-profit leaders from 10 countries to improve our tools and understanding of how to support victims. This included educational information about NCII, information on where victims can go for help, and psychosocial support for those who had been victimized. For everyone, we instructed them on what precautions people can take on Facebook and other platforms to reduce their chances of being victimized.', 'Across the board it was clear that victims whose images were shared, or were threatened, feel violated, angry and embarrassed. They are scared and worried that their family, friends, and co-workers will see the images. In fact, harm for the victims continues long after the images are removed. Themental health consequencesinclude anxiety, depression, suicidal thoughts, and sometimes post-traumatic stress disorder (PTSD). There can beeconomic and professional consequencesfor victims of NCII, including lost jobs, fewer professional connections, and colleagues who tease or avoid them. It can also be difficult finding new employment. Unquestionably, in many cases the costs to victims are serious and long-lasting.', 'Based on our discussions, the consequences that victims face vary depending on the cultural context. Victims in more traditional communities may be shunned and exiled from their communities. Organizations we’ve worked with reported cases in which victims were forced to run away from home to avoid persecution and even physical harm. And many countries lack established support organizations, or viable law enforcement solutions.', 'Moving forward, our overall approach will build on the work we’ve already done and focus on three key principles we heard repeatedly from victims and experts:', 'Reporting', 'Our research indicates we can improve our reporting tools to ensure they are easier to use and don’t frustrate those who try. Victims we spoke with, for example, said they were put off by what they felt was Facebook’s robotic response to NCII — simply taking the images down but not finding a way to acknowledge the trauma that the victims endure. Other victims weren’t familiar with online reporting and weren’t sure how to navigate our processes in the first place. We also heard loud and clear that the time between when a victim reports to Facebook and when they hear a response from us is filled with anxiety and helplessness. Victims want fast but personalized responses because the damage they experience increases the longer the images remains online.', 'Based on this research, we are re-evaluating our reporting tools and processes to ensure they are straightforward, clear and empathetic. Anyone, not just the victim, can report NCII and we are working to better educate people who use Facebook on how to do that.', 'Prevention', 'Beyond reporting, we want to help potential victims who fear their intimate images may be posted and stop them before they spread. We built a proactive reporting tool in partnership with international safety organizations, survivors, and victim advocates to provide an emergency option for people to provide a photo proactively to Facebook, so it never gets shared on our platforms in the first place.You can learn more about this pilothere.', 'While this pilot has been subject to some criticism, our research with victims and feedback from organizations indicates this was an option victims generally wanted, and they wanted it built into the reporting process more specifically. To date, use of the program has been relatively low in part because many victims don’t know the program exists. And understandably, many victims are concerned about sending images to people they don’t know, so we are also working to better explain and clarify the process and safeguards in place. We also will expand this pilot to additional countries in the coming months.', 'Information', 'Almost all victims we interviewed said they would have appreciated more information and resources. These findings led us to design “Not Without My Consent,” which we launched today as a victim-centered site in ourSafety Centerto help people respond to intimate images shared without permission.', 'The goal in everything we’re doing is to improve our support and our response so we meet the needs of victims as we learn of them.']\n",
            "195 ['ByAntigone Davis, Global Head of Safety', 'When someone’s intimate images are shared without their permission it can be devastating. To protect victims, it’s long been our policy to remove non-consensual intimate images (sometimes referred to as revenge porn) when they’re reported to us — and in recent years we’ve used photo-matching technology to keep them from being re-shared. To find this content more quickly and better support victims, we’re announcing new detection technology and an online resource hub to help people respond when this abuse occurs.', 'Finding these images goes beyond detecting nudity on our platforms. By using machine learning and artificial intelligence, we can now proactively detect near nude images or videos that are shared without permission on Facebook and Instagram. This means we can find this content before anyone reports it, which is important for two reasons: often victims are afraid of retribution so they are reluctant to report the content themselves or are unaware the content has been shared. A specially-trained member of our Community Operations team will review the content found by our technology. If the image or video violates ourCommunity Standards, we will remove it, and in most cases we will also disable an account for sharing intimate content without permission. We offer an appeals process if someone believes we’ve made a mistake.', 'This new detection technology is in addition to ourpilot programjointly run with victim advocate organizations. This program gives people an emergency option to securely and proactively submit a photo to Facebook. We then create a digital fingerprint of that image and stop it from ever being shared on our platform in the first place. After receiving positive feedback from victims and support organizations, we will expand this pilot over the coming months so more people can benefit from this option in an emergency.', '“We are thrilled to see the pilot expand to incorporate more women’s safety organizations around the world, as many of the requests that we receive are from victims who reside outside of the US.”– Holly Jacobs, Founder,Cyber Civil Rights Initiative (CCRI)', 'We also want to do more to help people who have been the targets of this cruel and destructive exploitation. To do this, we’re launching “Not Without My Consent,” a victim-support hub in ourSafety Centerthat we developed together with experts. Here victims can find organizations and resources to support them, including steps they can take to remove the content from our platform and prevent it from being shared further — and they can access our pilot program. We’re also going to make it easier and more intuitive for victims to report when their intimate images were shared on Facebook. And over the coming months, we’ll build a victim support toolkit to give people around the world more information with locally and culturally relevant support. We’ll create this in partnership with theRevenge Porn Helpline(UK),Cyber Civil Rights Initiative(US),Digital Rights Foundation(Pakistan),SaferNet(Brazil) andProfessor Lee Ji-yeon(South Korea).', 'Our work fighting this abuse and supporting victims wouldn’t be possible without the help of international experts. Today, on the sidelines of the 63rd U.N. Commission on Status of Women, we’ll hold an event with Dubravka Šimonović — the U.N. Special Rapporteur on violence against women — that brings together some of these victim advocates, industry representatives and nonprofits. We’ll discuss how this abuse manifests around the world; its causes and consequences; the next frontier of challenges that need to be addressed; and strategies for deterrence. We’re looking forward to this event and we’re thankful for these partnerships as we continue to team up on this important issue.', 'You can read more about the research behind today’s announcementhere.']\n",
            "196 ['“If Facebook has created a parallel online society for a quarter of the world to live in, the question facing Monika Bickert and her team is: What kind of society is it going to be?”', 'Vanity Fair reporter Simon Van Zuylen-Wood spent months embedded with members of Facebook’s content policy team — led by former federal prosecutor Monika Bickert — who deliberate, debate and painstakingly write the company’s rules on prohibited speech on Facebook.', 'Read the full article: March 2018, “’Men Are Scum’: Inside Facebook’s War on Hate Speech”', 'See also:']\n",
            "197 ['ByMonika Bickert, VP, Global Policy Management', 'Update on September 4, 2019 at 8AM PT:We are starting to roll out more ways to connect people with authoritative information about vaccines on Facebook and Instagram.', '', 'Originally published on March 7, 2019 at 12PM PT:', 'We are working to tackle vaccine misinformation on Facebook by reducing its distribution and providing people with authoritative information on the topic. We are starting by taking a series of steps:', 'How This Will Work', 'Leading global health organizations, such as the World Health Organization and the US Centers for Disease Control and Prevention, have publicly identified verifiable vaccine hoaxes. If these vaccine hoaxes appear on Facebook, we will take action against them.', 'For example, if a group or Page admin posts this vaccine misinformation, we will exclude the entire group or Page from recommendations, reduce these groups and Pages’ distribution in News Feed and Search, and reject ads with this misinformation.', 'We also believe in providing people with additional context so they can decide whether to read, share, or engage in conversations about information they see on Facebook. We are exploring ways to give people more accurate information from expert organizations about vaccines at the top of results for related searches, on Pages discussing the topic, and on invitations to join groups about the topic. We will have an update on this soon.', 'We are fully committed to the safety of our community and will continue to expand on this work.']\n",
            "198 ['By Clair Deevy, Director of Community Affairs, Asia Pacific', 'Today we’re launchingWe Think Digital, an online education portal with interactive tutorials aimed at helping people think critically and share thoughtfully online. We designed the program in partnership with experts from across Asia Pacific, and aim to train 1 million people across 8 countries in Asia Pacific by 2020, with our resources available in 6 different languages.', 'Asia Pacific has a fast-growing internet population, with more than 2.21 billion people now online and 203 million new people joining in the past year, according to We Are Social’s 2019Digital Trends Report. We Think Digital has been designed for new and existing internet users of all ages to develop the skills they need to safely enjoy digital technology, including critical thinking and empathy.', 'We’ve developed a series of online tutorials in collaboration with journalist Saffron Howden and with support from TJ Agulto from AHA Behavioral Design; Associate Professor Michael Dezuanni from the Queensland University of Technology; Professor Katherine Chen from National Chengchi University; Chairman Wayne Chau of the Agent of Change Foundation; Executive Director Hamish Curry of the Asia Education Foundation; and Dr Damien Spry, Lecturer of Media & Communications at the University of South Australia and Visiting Fellow at Queensland University of Technology’s Digital Media Research Centre. These academics and representatives from NGOs and civil society organizations across the region all came together to address the question: what does it mean to be a Digital Citizen?', 'The topics covered include privacy, safety, security, digital discourse and knowing your digital footprint. The four modules are:', 'We’re launching this program in Singapore first, before rolling it out to the Philippines, Thailand, Indonesia, Vietnam, Taiwan. We also plan to bring this program beyond Asia Pacific to Argentina and Mexico. In Singapore, the program is supported byThe People’s Association, an organization which works to bring Singaporeans from all walks of life together through community programs. We are also forming a regional Steering Committee, whose role will be to advise Facebook on how to ensure We Think Digital can bring the most value to communities across Asia Pacific. The committee will comprise members from around the region, and its first two members are Dr. Vu Minh Khuong, Associate Professor at Lee Kuan Yew School of Public Policy, National University of Singapore, and Dr. Pijitra Tsukamoto, Associate Professor at Thailand’s Chulalongkorn University.', 'Mr Chia Tze Yee, the People’s Association’s Group Director, Engagement Group said:“Improving digital literacy and encouraging greater levels of digital citizenship benefits everyone in an increasingly connected community. The People’s Association recognizes the need to equip residents, especially seniors, with digital citizenship skills to exercise critical thinking and responsible online behaviour. We are happy to partner with Facebook to launch the We Think Digital initiative and are proud to be able to use our own ‘Seniors for Smart Nation’ programs and Silver Infocomm Wellness Ambassadors to help deliver these valuable skills to the public.”', 'Mr Lock Wai Han, Chairman of Singapore’s Media Literacy Council, Singapore’s leading voice on media literacy and cyber wellness, added:“Programs like We Think Digital that keep pace with increasing online participation and the way we consume, create or share content are important to the promotion of astute and responsible digital citizenship and online safety in Singapore and across the region. This is a positive initiative from Facebook.”', '', 'Clair Deevy,Director of Community Affairs for Asia Pacific, introducing We Think Digital at today’s launch event at Facebook Singapore', '', 'From L-R: Mr Lock Wai Han, Chairman of Singapore’s Media Literacy Council, Clair Deevy, Facebook’sDirector of Community Affairs for APAC,Mr Chia Tze Yee, the People’s Association’s Group Director for Engagement, Sandhya Devanathan, Facebook Singapore Country Director, andMrSeah Hwee Kia,\\xa0Chairman of the People’s Association’s Active Ageing Council', '', 'Participants and guests at today’s We Think Digital launch event at Facebook Singapore', 'We Think Digital builds on our work developing safety resources over the past decade, including ourSafety Center,Bullying Prevention Hub,Parents Portal, andYouth Portal. It responds to the evolution of the concept of digital literacy: from the skills needed to search for information online to connecting and engaging with a global community not defined by geography or by shared cultural understanding.', 'wethinkdigital.fb.com']\n",
            "199 ['One of the biggest questions we face is around what we allow on Facebook – and we spend a lot of time trying to get this right. This is hard and critically important. We want Facebook to be a place where you can express yourself freely and share openly with friends and family. At the same time, when people come to Facebook we always want them to feel welcome and safe.', 'This is something we takeincredibly seriously. So when ideas and opinions cross the line and amount to hate speech that may create an environment of intimidation and exclusion for certain groups in society – in some cases with potentially dangerous offline implications – we take action. Our publicCommunity Standardsstate this sort of speech is not acceptable on Facebook – and when we become aware of it, we remove it as quickly as we can. Our rules also make clear that individuals and organizations that are engaged in “organized hate” are not allowed on the platform, and that praise or support for these figures and groups is also banned. This is true regardless of the ideology they espouse.', 'Tommy Robinson’s Facebook Page has repeatedly broken these standards, posting material that uses dehumanizing language and calls for violence targeted at Muslims. He has also behaved in ways that violate our policies around organized hate. As a result, in accordance with our policies, we have removed Tommy Robinson’s official Facebook Page and Instagram profile. This is not a decision we take lightly, but individuals and organizations that attack others on the basis of who they are have no place on Facebook or Instagram.']\n",
            "200 ['ByJustin Osofsky, VP of Global Operations', 'We know there are a lot of questions, misunderstandings and accusations around Facebook’s content review practices — including how we as a company care for and compensate the people behind this important work. We are committed to working with our partners to demand a high level of support for their employees; that’s our responsibility and we take it seriously. We know there are going to be incidents of employee dissatisfaction or hardship that call our commitment into question, which is why we’re taking the steps outlined below to continue to set and enforce the expectations we have for our partners.', 'Below is a post I shared with employees over the weekend about how we approach this work. It has been edited only to remove internal links.', 'First, a bit of background. Over the past couple of years, as you know, we have substantially scaled our investment in safety and security including rapidly growing our content review teams. We’ve more than doubled this team each of the last two years, adding thousands of people to these efforts. The majority are people who work full time for our partners and work at sites managed by these partners.', 'In order to scale this quickly, we developed partnerships with highly reputable global partners like Accenture, Cognizant, Genpact and others with good standards for their employee care. For context, Accenture, Cognizant and all of our partners work on projects for multiple clients simultaneously. Accenture employs over 450,000 people in over 200 cities globally and Cognizant employs over 280,000 people. These partnerships are important because they allow us to work with established companies who have a core competency in this type of work and who are able to help us ramp with location and language support quickly. They have experience managing large workforces; scaling quickly for new issues and risks; and adapting with us as the risks to our community and product needs change over time. And, as our needs evolve and we shift focus from an area where our work has grown more mature to an emerging area, we can work in real-time with Accenture, Cognizant and our other partners to address those needs.', 'A lot of the recent questions are focused on ensuring the people working in these roles are treated fairly and with respect. We want to continue to hear from our content reviewers, our partners and even the media – who hold us accountable and give us the opportunity to improve. This is such an important issue, and our Global Ops leadership team has focused substantial attention on it and will continue to do so.', 'However, given the size at which we operate and how quickly we’ve grown over the past couple of years, we will inevitably encounter issues we need to address on an ongoing basis. Today, we already have mechanisms in place with our partners who run these sites to make sure any concerns being reported are the uncommon exception and never the norm. These mechanisms include:', 'We’ve done a lot of work in this area and there’s a lot we still need to do. Arun Chandra recently joined us to lead our vendor partner management efforts for Global Operations – including Business Integrity (BI), Product Data Operations (PDO) and Community Operations (CO). He’s focused squarely on the wellness and experience of our vendor partner employees and is driving several initiatives aimed at continuing to improve the support they receive. Some of these key initiatives include:', 'We will regularly evaluate these roles, our needs going forward, the risks, location, mix of the workforce and many more areas.', 'Put simply, after a couple of years of very rapid growth, we’re now further upgrading our work in this area to continue to operate effectively and improve at this size. Going forward, John, Arun, our Global Ops leadership team and I will continue to share our progress and steps forward on this important topic with you.']\n",
            "201 ['ByAntigone Davis, Global Head of Safety', 'Update on September 29, 2021 at 11:50AM PT:', 'Information in this article may be outdated. For current information about our suicide and self-injury content detection technology, please visit ourSafety Center. As described in the Safety Center, our algorithms are intended to help identify potential suicide and self-injury content and are not intended to diagnose or treat any mental health or other condition.', 'Originally published on February 7, 2019 at 9:54AM PT:', 'We care deeply about the safety of our community — and with the advice of experts we set policies for what is and isn’t allowed on the platform. For example, while we don’t allow people to celebrate or promote self harm or suicide, we do let people share admissions of self harm so their friends and family have an opportunity to reach out, offer support and provide help or resources. And when there’s risk of imminent harm, we work with emergency responders who can help. Today, we’re sharing updates in how we enforce our policies against self harm or suicide.', 'Since 2006 we’ve built our approach with experts in suicide prevention and safety. We seek their input on current research and best practices to ensure everyone’s safety is being considered. We constantly re-examine how we’re doing as we develop new products or see people using our services in new ways. In some cases, it might be a single experience that causes us to pause and question whether we need to make changes. And that’s what we’ve done following the tragic death of a young girl by suicide in the UK. Bringing together more than a dozen experts from around the world, many of whom helped us develop our policies in the first place, we asked them how we could better weigh two important goals that are sometimes at odds: the opportunity to get help and share paths to recovery for people who might be in harm’s way, and the possibility that we may unintentionally promote self-harm or remove content that might shame or trigger the poster to self-harm. Four main themes emerged from this discussion:', 'First, these experts unanimously reaffirmed that Facebook should allow people to share admissions of self harm and suicidal thoughts, but should not allow people to share content promoting it. They stressed the importance of giving room for people to share the challenges they are going through, including admitting thoughts or actions of self harm. They said this content, though tragic and upsetting to some, often helps people connect with support and resources, helping in their recovery and saving lives.', 'But the experts also advised that some graphic images of self-harm, particularly cutting, can have the potential to unintentionally promote self-harm even when they are shared in the context of admission or a path to recovery. As a result, based on their feedback, we will no longer allow graphic cutting images even in the context of admission and we will begin enforcing this policy in the coming weeks. To learn more about this, visit theInstagram Info Center.', 'We also discussed whether other kinds of content — like healed cutting scars shared to tell the story of recovery or certain sad memes — might unintentionally promote self-harm. This is an area where there is incomplete and sometimes competing research and the experts suggested that we continue to monitor the latest findings. We’ll do so as we continue discussions around this topic.', 'Finally, the experts emphasized the importance of building products that facilitate supportive connections, finding more opportunities to offer help and resources, and importantly, avoiding shaming people who post about their self-harm thoughts or actions. We will continue to provide resources, including messages with links to helplines, and over the coming weeks we will explore additional steps or products we can provide within Instagram and Facebook.', 'We are grateful for our continued partnership with these experts on such important issues — their guidance is crucial as we work to better protect our community.', 'Experts Consulted[Updated on February 7, 2019 at 1:30PM PT to include additional expert]:', 'Australia:Orygen – Dr. Jo Robinson', 'Brazil:Instituto Vita Alere – Dr. Karen Scavacini; Safernet – Thiago Tavares and Juliana Cunha', 'Bulgaria:Safer Internet – Georgi Apostolov', 'Canada:Kids Help Phone – Alisa Simon', 'India:ICALL Tata Institute for Social Sciences – Aparna Joshi', 'Mexico:University of Guadalajara, Neurosciences Department – Dr. Luis Miguel Sanchez-Loyo', 'Philippines:Philippines General Hospital, Child Protection Unit – Dr. Norie Balderrama', 'Thailand:Samaritans of Thailand – Trakarn Chensy', 'United Kingdom: Bristol University, Bristol Medical School – Dr. Lucy Biddle; Centre for Mental Health – Sarah Hughes; The Mix UK – Chris Martin; Samaritans – Jacqui Morrissey; Papyrus – Ged Flynn and Lisa Roxby', 'United States:Save.org– Dr. Dan Reidenberg; The National Suicide Prevention Lifeline – John Draper', '']\n",
            "202 ['Over the past year, we have repeatedly taken action against violent actors and bad content on Facebook in Myanmar. The ethnic violence happening in Myanmar is horrific and we don’t want our services to be used to spread hate, incite violence or fuel tension on the ground.', 'Our approach to this problem, like the problem itself, is multifaceted, but our purpose is clear: to reduce the likelihood that Facebook will be used to facilitate offline harm. Our tactics include identifying and removing fake accounts; finding and removing violent actors; building better tools and technology that allows us to proactively find bad content; evolving our policies; and continuing to build partnerships and programs on the ground. We have shared regular updates on this work. Since last August, we’vetaken downthree networks who were misrepresenting who they were and what they were doing,banned Myanmar military officials, given anupdateon the steps we’re taking to prevent the spread of hate and misinformation and released the findings of theHuman Rights Impact Assessmenton the role of our services in the country.', 'Today, we are taking more action, designating four more groups in Myanmar as dangerous organizations – the Arakan Army, the Myanmar National Democratic Alliance Army, Kachin Independence Army and the Ta’ang National Liberation Army. These armed groups are nowbanned from Facebookand all related praise, support and representation will be removed as soon as we become aware of it.', 'In an effort to prevent and disrupt offline harm, we do not allow organizations or individuals that proclaim a violent mission or engage in violence to have a presence on Facebook. Thisincludes terrorist activity, organized hate, mass or serial murder, human trafficking, organized violence or criminal activity. There is clear evidence that these organizations have been responsible for attacks against civilians and have engaged in violence in Myanmar, and we want to prevent them from using our services to further inflame tensions on the ground.', 'We don’t want anyone to use Facebook to incite or promote violence, no matter who they are. That’s why we are\\xa0always evaluating and analyzing our policies around violence committed by state and non-state actors. We recognize that the sources of ethnic violence in Myanmar are incredibly complex and cannot be resolved by a social media company, but we also want to do the best we can to limit incitement and hate that furthers an already deadly conflict.']\n",
            "203 ['The most frequently asked questions we receive are about Facebook’s efforts to stop the spread of misinformation, prevent election interference, and protect people’s privacy.', 'Although we didn’t do enough to anticipate some of these risks, we’ve now made fundamental changes. This past year we’ve invested record amounts in keeping people safe and strengthening our defenses against abuse. We’ve also provided people with far more control over their information and more transparency into our policies, operations and ads.', 'As we begin a new year, we want to share the steps we’ve already taken in five key areas. We still face legitimate scrutiny, but we’re not the same company we were even a year ago, and we’re determined to do more to keep people safe across our services.', '', 'Battling Election Interference and Misinformation', 'In 2016, foreign actors interfered with elections by spreading false information and sowing division between people with different views. Now that we better understand this threat, we’ve built defenses against it — and we’re working to stay a step ahead.', 'Our tactics includeblocking and removing fake accounts; finding andremoving bad actors;limiting the spread of false news and misinformation; and bringing unprecedentedtransparency to political advertising. We’ve also improved our machine learning capabilities, which allow us to be more effective in finding and removing violating behavior. These technology advances help us better identify and block bad activity, while our expert investigators manually detect more sophisticated networks.', 'As a result, we’re making real progress. We remove millions of fake accounts a day, stopping them from ever engaging in the type of coordinated information campaigns often used to interfere with elections. And we’ve improved rapid response efforts across our teams. Last year, we removed thousands of Pages, groups and accounts involved incoordinated inauthentic behavior. With each election, we get better.', 'Meanwhile, we’re working far more closely with governments, outside experts and other companies. Just 48 hours before the US midterm elections, for example, we received a tip from the FBI which allowed us to quickly take downa coordinated effortby foreign entities. Just recently we announced a new partnership with German Federal Office for Information Security, which we worked closely with during the 2017 elections there. Together we’re creating a new Integrity and Security Initiative to help guide policymaking in Germany and across the EU on election interference.', 'While misinformation is a common tool of election interference, bad actors also use fake news for other reasons — especially to make money by tricking people into clicking on something. Whatever the motivation,we’re cracking down. When something is rated “false” by a fact-checker, we’re able to reduce future impressions of that content by an average of 80%.Independent studies also show significant improvement. Le Monde found engagement with “unreliable or dubious sites” has halved in France since 2015. Two US-based academic institutions both found that engagement with false news content has declined by half since 2016.', 'There’s more to do. Security is an arms race. But we’re committed to the fight.', '', 'Strengthening Privacy and Protecting People’s Information', 'When people add information to their profile, upload a photo, or use Facebook to log into another app, they’re entrusting us with their information. We have a deep responsibility to protect it, and we know we didn’t do a good enough job securing our platform in the past. In 2014 we significantly reduced the amount of information apps on Facebook can access. We’ve investigated thousands of apps that had access to large amounts of information before we changed our platform policy in 2014. As a result we suspended more than 400 apps that violated our policies. To better safeguard people’s information, we grew the size of our security team and established a dedicated Privacy and Data Use team to focus on building stronger protections and giving people more control over their data. We also published ourprivacy principlesso people know how we approach privacy and can hold us accountable.', 'Strengthening privacy also means giving people greater control over what they share. Last year we made our privacy settingseasier to findand rolled out GDPR-style controlsaround the world.As part of this, we asked people to review what personal information they share and what data they want us to use for ad targeting. We also builtbetter toolsfor people to access and download their data. This year we’re continuing to build more controls, includingClear History, which will let people see the information we receive from the apps and websites they use, and then decide whether to clear it from their account. We’ll continue working to explain more about how data is used on Facebook and give more control and transparency over the information people share.', '', 'Prioritizing Safety and Well-Being', 'It’s on us to make sure people feel safe by keeping harmful, hateful and exploitative material off our services. Over the past two years, we’ve invested heavily intechnology and peopleto more effectively remove this bad content. We now haveover 30,000 peopleworking on safety and security — about half of whom are content reviewers working out of 20 offices around the world. Thanks to their work, along with our artificial intelligence and machine learning tools, we’ve made big strides in finding and removing content that goes against ourCommunity Standards.', 'We’re now detecting 99% of terrorist related content before it’s reported, 97% of violence and graphic content, and 96% of nudity. We regularly share our latest enforcement numbers and more in ourEnforcement Report.', 'We’re also making it easier for people to report content that they think breaks our rules. For instance, we’ve expanded our reporting tools to allow people to report when someoneelseis being bullied or harassed. This is an important change because victims of bullying aren’t always privy to what’s being said or shared about them. We’ve also introduced a way for people to appeal decisions on bullying and harassment cases, so you can now ask for a second review if you think we made a mistake by not taking down reported content.', 'Beyond enforcing our standards, we’ve updated our policies to better protect the people and communities who use our services. Last year, for instance, weupdatedour policy against credible violence to include misinformation that has the potential to contribute to imminent violence or physical harm. This is a particularly important change in countries like Myanmar where people have used our platform to share fake news meant to foment division and incite violence. Myanmar — and countries around the world where some people seek to weaponize our platform — remain a huge area of concern for us. But we’re now taking a more proactive role at addressing our responsibility. We’ve hired more language-specific content reviewers, banned individuals and organizations that have broken our rules, and built new technology to make it easier for people to report violating content and for us to catch it proactively.', 'Making sure we’re having a positive impact also means supporting people’s well-being. We want to make sure people have the power to decide when and how they engage with our services. To do this, we worked with leading mental health experts, organizations and academics tolaunch dashboardsin both Facebook and Instagram that track the amount of time spent on each app. The aim here is to give people more insight into how they spend their time. We’ve also built tools that help people control what they see on our services, so they can see more posts, photos and videos that they want to see, and avoid those they don’t.', 'We’ve improved News Feed quality to show people themost relevant postswith features likeSee First,Hide,Unfollow, andKeyword Snooze. And on Instagram, we launchedpowerful toolsto proactively care for the community — like the “You’re All Caught Up” message in Feed, keyword filtering, sensitivity screens, and offensive comment and bullying filters.', 'We still have a lot of work to do when it comes to enforcing our Community Standards and keeping our community safe — but we’ve made several steps in the right direction.', '', 'Giving People More Information About the Ads They See', 'In the past year we’ve committed to bringing greater transparency to the ads people see on Facebook. This is particularly true with ads related to politics. All political ads on Facebook and Instagram in the US must now be labeled – including a “paid for by” disclosure from the advertiser. We also launched asearchable archive for political contentthat houses these ads for up to seven years. We’ve since expanded this feature to Brazil and the UK, and will soon in India.', 'Beyond political and issue ads, people cannow see every ad a Page is running— even if the person wasn’t targeted. People can also filter ads by country and they can report an ad to us.', 'The vast majority of ads are run by legitimate businesses and organizations. But bad actors can misuse ads too. By shining a light on all ads and the Pages that run them, we’ll make it easier to root out abuse.', 'Finally, we introducednew policiesrequiring advertisers to specify the origin of their audience’s information when they bring a customer list to us.', '', 'Seeking Effective Regulation', 'Several members of Congress argue that we need more regulation of the internet. We agree. As Mark Zuckerberg testified last year, we welcome smart legislation and will work with lawmakers to achieve it.', 'We don’t want an internet that is out of control. That’s bad for us and bad for everyone. Effective legislation, we think, should reflect the need to strike balances between competing tensions. How do you reduce hate speech while protecting free expression? How do you protect privacy while promoting innovation? How do legislators maintain control without diminishing the global competitiveness of the tech sector?', 'As lawmakers around the world debate the right path, we’re moving forward on several fronts. As we mentioned above, we’ve introduced consistent privacy choices around the world. We’re working with governments to improve the safety of our platform, including a recent initiative with French regulators to reduce hate speech. And we’re establishing an independent body which people can use to appeal Facebook decisions involving potentially offensive content. Unless their decisions would somehow violate the law, we will adhere to them.', '—', 'Taken together, these measures are just one portion of what we’re doing. You can expect more this year.']\n",
            "204 ['ByNathaniel Gleicher, Head of Cybersecurity Policy', 'Updated on April 11, 2019 at 9PM PT:', 'Today we removed 234 accounts, Pages and Groups from Facebook and Instagram for engaging in coordinated inauthentic behavior as part of a domestic network in Indonesia, some of which was connected to the Saracen-linked activity we removed earlier this year. The people behind this network misled others about who they were and what they were doing. They used fake accounts and frequently posted about local and political news including topics like upcoming elections, alleged election fraud, candidate views, and alleged misconduct of political figures. As always, we took action based on the behavior of these actors, not the content they posted.', 'Here’s more on what we took down today:', 'We identified these accounts, Pages and Groups through our ongoing internal investigations ahead of the upcoming elections in Indonesia. Our analysis benefited from information shared by our partners who investigate this kind of activity. We have shared information about our investigation with relevant law enforcement and policymakers.', 'While we are making progress rooting out this abuse, as we’ve said before, it’s an ongoing challenge because the people responsible are determined. We constantly have to improve to stay ahead. That means building better technology, hiring more people and working more closely with law enforcement, security experts and other companies.', 'Originally published on January 21, 2019:', 'Today we removed 207 Facebook Pages, 800 Facebook accounts, 546 Facebook Groups, and 208 Instagram accounts, for engaging incoordinated inauthentic behavioron Facebook in Indonesia, misleading others about who they were and what they were doing. All of these Pages, accounts and groups were linked to the Saracen Group – an online syndicate in Indonesia.', 'The Saracen Group’s coordinated abuse of the platform using inauthentic accounts is a violation of our policies and we have therefore banned the entire organization from the platform.Here’s a breakdown of what we’ve found:', 'We’re taking down these Pages, groups and accounts based on their behavior, not the content they were posting. In this case, the people behind this activity coordinated with one another and used fake accounts to misrepresent themselves, and that was the basis for our action.', 'We are constantly working to detect and stop this type of activity because we don’t want our services to be used to manipulate people. Today’s announcement is just one of the many steps we have taken to prevent bad actors from abusing our platform. We will continue to invest heavily in safety and security in order to ensure that people can continue to trust the connections they make on Facebook.']\n",
            "205 ['Vice President of Global Affairs and Communications\\xa0Nick Clegg spoke today in Brussels about the changes Facebook is making to help protect our community and elections around the world. He called on governments and the tech industry to work together to design smart regulation that doesn’t stifle innovation. He also took questions from Politico\\xa0Political Editor Ryan Heath and the audience.', 'For more on the announcements Nick made, see our Newsroom posts:', 'Expanding Our Efforts to Protect Elections in 2019Charting a Course for an Oversight Board for Content Decisions']\n",
            "206 ['Note: For future Facebook updates about Oversight Board cases, please visit theTransparency Center.', 'In November,Mark Zuckerberg wroteabout his vision for how content should be governed and enforced on Facebook. He laid out a plan for a new way for people to appeal content decisions to an independent body. Today we’re releasing adraft chartergiving more detail about its potential make-up.', 'As we build out the board we want to make sure it is able to render independent judgment, is transparent and respects privacy. After initial consultation and deliberation, we’ve proposed a basic scope and structure that’s outlined in this draft charter. We’ve also identified key decisions that still need to be made, like the number of members, length of terms and how cases are selected.', 'We’ll look to answer these questions over the next six months in a series of workshops around the world where we will convene experts and organizations who work on a range of issues such as free expression, technology and democracy, procedural fairness and human rights. We’ll host these workshops in Singapore, Delhi, Nairobi, Berlin, New York, Mexico City and many more cities — soliciting feedback on how best to design a board that upholds our principles and brings independent judgment to hard cases.', 'At the same time, we know that we won’t be able to reach all stakeholders through regional workshops alone. More importantly, we don’t want to limit input or feedback to a hand-picked group of experts that we work with frequently. We’re interested in hearing from a wide range of organizations, think tanks, researchers and groups who might have proposals for how we should answer these critical questions. We’ll be announcing more about how proposals can be submitted in the coming weeks.', 'We look forward to getting additional input in how best to build a board that creates accountability and oversight of our content policy and enforcement decisions and will continue to share milestones and progress.', '']\n",
            "207 ['BySheryl Sandberg, Chief Operating Officer', 'What kind of internet do we want? It’s one of the biggest questions we face today. I believe we don’t want an internet that is out of control, where anything goes. And we don’t want an internet that is too tightly controlled, where people can’t express themselves. To rewrite the rules for the internet, it will take all of us working together – people, governments, the tech industry. I spoke about this today in Munich at the Digital Life Design, a conference about how technology is changing the world.', 'I talked about wanting an internet where people can speak up without spreading hate. Where communities can come together without interference or abuse. And where everyone can access the benefits of technology and know their privacy is protected.', 'This is what we’re trying to build at Facebook every day. We know we need to do better at anticipating risks and we need to stop abuse more quickly. But we’ve taken significant steps – including investing heavily in safety and security, protecting against election interference, cracking down on misinformation, making sure people have control over their information, and being more transparent about our policies and decisions than we have ever been before. We will never stop all the bad from happening, but we’re working more closely with governments, outside experts, and other tech companies to tackle bad actors.', 'Today we announced a new partnership with the German Federal Office for Information Security to help better protect elections in Germany and the EU. This builds on the work we’ve been doing since 2016. For example, last year we removed thousands of Pages, Groups and accounts involved in inauthentic behavior so they can’t mislead others about their identity and intentions.', 'We’re making these investments because we know we have a deep responsibility to protect the people who use our services and enable the good that people can do with technology. Every day people use our apps to stay in touch with loved ones, build supportive communities, grow businesses, and raise money for causes. This is the kind of world we stand for – and what I believe we can achieve if we all work together.']\n",
            "208 ['ByNathaniel Gleicher, Head of Cybersecurity Policy', 'Today we banned a digital marketing group in the Philippines — Twinmark Media Enterprises and all its subsidiaries — from Facebook. This organization has repeatedly violated our misrepresentation and spam policies — including throughcoordinated inauthentic behavior, the use of fake accounts, leading people to ad farms, and selling access to Facebook Pages to artificially increase distribution and generate profit. We do not want our services to be used for this type of behavior, nor do we want the group to be able to reestablish a presence on Facebook.', 'Here’s a breakdown of what we’ve removed as part of this ban:', 'Again, our decision to remove this organization, and the Pages and accounts it controls, is based on the behavior of these actors who repeatedly violated our misrepresentation and spam policies, rather than on the type of content they were posting.', 'This specific investigation began after we learned that Twinmark was selling admin rights to Facebook Pages it had created, in order to increase distribution and generate profit, which violates our spam policy. This prompted our teams to take a deeper look at a broader group of Pages and accounts associated with these users, ultimately uncovering a large network of Pages and accounts that were engaging in coordinated inauthentic behavior, the use of fake accounts, leading people to ad farms and selling access to Facebook Pages.', 'We are continuously working to uncover this kind of abuse, and we know that the people behind it — whether economically or politically motivated — will continue to evolve their tactics. Today’s announcement is just one of the many steps we have taken to prevent bad actors from abusing our platform. We will continue to invest heavily in safety and security in order to ensure that people can continue to trust the connections they make on Facebook.', 'Content Examples', 'Below is a selection of Pages and posts we have taken down as part of this network, for violating our coordinated inauthentic behavior and spam policies.', 'The following two Pages are examples of where a Page name was changed after it had built up a large following, substantially changing the Page’s subject matter. This is in violation of our Page policies, as it misleads the Page’s followers.', '', '', 'The following news articles are examples of the posts being shared by the Pages within this network, in a coordinated way.Post caption translation:“Ohhhhhhhh! So that’s how it is. For god’s sake!”', '', 'Post caption translation:“Wow 😮 is this the fruit of her diligence and perseverance? How beautiful – you won’t think that at her age she’d have such a beautiful house.”Headline translation:”[Redacted name] shows her new house that she worked so hard for”', 'Post caption translation:“[Redacted name]’s new car is fabulous, and it was given to him by this person?”Headline translation:“[Redacted name] reveals who gave her son, [Redacted name], his first car…”']\n",
            "209 ['Yesterday, The New York Times published an article about the way we moderate content on Facebook. We’ve been accused of being “ad hoc, ” “disorganized,” “secretive,” and doing things “on the cheap.” This couldn’t be further from the truth.', 'We welcome debate about how to help keep Facebook a safe place where people can express their ideas. But that debate should be based on facts, not mischaracterizations. Here’s where we disagree with the Times:', 'Our policies are public, not “secret” or “closely held.”For years, we’ve published our Community Standards, the overarching guide that outlines what is and isn’t allowed on Facebook.Earlier this yearwe went a step further and published the internal guidelines we use to enforce those standards. Anyone can view them atfacebook.com/communitystandards.', 'Our policies are carefully considered, not “ad hoc” responses.The Times is right that we regularly update our policies to account for ever-changing cultural and linguistic norms around the world. But the process is far from “ad hoc.” We make changes to our policies based on new trends that our reviewers see, feedback from inside and outside the company, as well as unexpected, and sometimes dramatic, changes on the ground. And we publish the changes we make every month.', 'What the Times refers to as a gathering “over breakfast” among “young engineers and lawyers” is, in fact, a global forum held every two weeks where we discuss potential changes to our policies. It includes experts from around the world with deep knowledge of relevant laws, online safety, counter-terrorism, operations, public policy, communications, product, and diversity. Yes, lawyers and engineers are present, but so are human rights experts, people who have studied hate and extremist organizations, former law enforcement and other public servants, and academics. As part of this process, we seek input from people outside Facebook so we can better understand multiple perspectives on safety and expression, as well as the impact of our policies on different communities.', 'Last month we startedpublishing minutesfrom these meetings, and early next year we plan to include a change log so that people can track updates to our Community Standards over time.', 'The people enforcing our policies are focused on accuracy, not quotas.The team responsible for safety on Facebook is made up of around 30,000 people, about15,000 of whom arecontent reviewersaround the world, as the Times updated its story to note. Contrary to what the story reports, content reviewers don’t have quotas for the amount of reports they have to complete. Reviewers’ compensation is not based on the amount of content they review, and our reviewers aren’t expected to rely on Google Translate as they are supplied with training and supporting resources.', 'We hire reviewers for their language expertise and cultural context — we review content in over 50 languages — and we encourage them to take the time they need to review reports. They work in more than 20 sites around the world, which resemble Facebook’s own offices, and they provide 24/7 support. As the Times notes, some reviewers are based in Morocco and the Philippines, while others are based in the United States, Germany, Latvia, Spain and other locations around the world.', 'We’ve taken a careful approach in Myanmar based on feedback from experts.When discussing our efforts to curb hate speech in Myanmar, the Times incorrectly claims that a paperwork error allowed an extremist group to remain on Facebook. In fact, we had designated the group – Ma Ba Tha – as a hate organization in April 2018, six months before The Times first contacted us for this story. While there was one outdated training deck in circulation, we immediately began removing content that represents, praises or supports the organization in April – both through proactive sweeps for this content and upon receiving user reports.', 'This was one ofseveralstepswe’ve taken in Myanmar in 2018. Another covered in the story wasour decisionto remove Facebook accounts belonging to senior military officials in Myanmar without notifying the government. We did this based on guidance from international experts, who cautioned us as to potential reactions from the military, the blame that could be placed on the government, and the risk to people’s safety on the ground.', '—We play an important role in how people communicate, and with that comes an expectation that we’ll constantly identify ways we can do better. That’s how it should be. And it’s why we constantly work with experts around the world to listen to their ideas and criticism, and make changes where they’re warranted. Throughout 2018, we’ve introduced more transparency into our policies and provided data on how we enforce them. We’ve got more in store in 2019, and we look forward to people’s feedback.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "article_meta_ds[\"Text\"] = scraped_dataset_safety\n",
        "article_meta_ds.to_excel('meta_content_safety.xlsx', index=False)\n",
        "files.download('meta_content_safety.xlsx')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "WpQQ8VAc1Rfu",
        "outputId": "7d1eeb4a-5979-4cf7-af07-21374d37e339"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_537c062f-d247-4ecb-9427-0e684f62a40c\", \"meta_content_safety.xlsx\", 366406)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Combatting Misinformation"
      ],
      "metadata": {
        "id": "3Nod8v_t8Ki_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data2 = []\n",
        "for i in range(0, 8):\n",
        "  request = requests.get(url=f\"https://about.fb.com/news/tag/misinformation/page/{i}/\")\n",
        "  parser = BeautifulSoup(request.content, \"html.parser\")\n",
        "\n",
        "  area_section = parser.find(\"div\", class_=\"archive-articles-container\")\n",
        "  article_section = area_section.find_all(\"div\", class_=\"uk-width-3-5 article-excerpt\")\n",
        "  for article in article_section:\n",
        "    try:\n",
        "        header = article.find(\"header\", class_=\"entry-header\")\n",
        "        link_source = header.find(\"a\", href=True)\n",
        "\n",
        "        article_title = link_source.get_text()\n",
        "        link = link_source.get(\"href\")\n",
        "\n",
        "        date_source = header.find(\"time\", class_=\"entry-date published\")\n",
        "        date_source2 = header.find(\"time\", class_=\"updated\")\n",
        "        date = date_source.get_text()\n",
        "        date2 = date_source2.get_text()\n",
        "\n",
        "        data2.append((link, article_title, date, date2))\n",
        "    except:\n",
        "        header = article.find(\"header\", class_=\"entry-header\")\n",
        "        link_source = header.find(\"a\", href=True)\n",
        "\n",
        "        article_title = link_source.get_text()\n",
        "        link = link_source.get(\"href\")\n",
        "\n",
        "        date_source = header.find(\"time\", class_=\"entry-date published updated\")\n",
        "        date = date_source.get_text()\n",
        "        date2 = None\n",
        "\n",
        "        data2.append((link, article_title, date, date2))\n",
        "\n",
        "article_meta_ds_2 = pd.DataFrame(data2, columns=[\"Link\", \"Article Title\" , \"Date\", \"Updated Date\"])\n",
        "\n",
        "print(article_meta_ds_2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "QgFuPI_87q_H",
        "outputId": "0a853ec6-a781-46a0-b072-ecd808b67c16"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                                 Link  \\\n",
            "0   https://about.fb.com/news/2022/11/metas-progre...   \n",
            "1   https://about.fb.com/news/2022/08/how-meta-is-...   \n",
            "2   https://about.fb.com/news/2022/07/oversight-bo...   \n",
            "3   https://about.fb.com/news/2022/07/how-metas-pr...   \n",
            "4   https://about.fb.com/news/2022/02/metas-ongoin...   \n",
            "..                                                ...   \n",
            "74  https://about.fb.com/news/2018/10/removing-ina...   \n",
            "75  https://about.fb.com/news/2018/09/expanding-fa...   \n",
            "76  https://about.fb.com/news/2018/06/hard-questio...   \n",
            "77  https://about.fb.com/news/2018/05/facing-facts...   \n",
            "78  https://about.fb.com/news/2018/05/inside-feed-...   \n",
            "\n",
            "                                        Article Title                Date  \\\n",
            "0    Sharing Our Progress on Combating Climate Change    November 6, 2022   \n",
            "1   How Meta Is Preparing for Brazil’s 2022 Elections     August 12, 2022   \n",
            "2   Meta Asks Oversight Board to Advise on COVID-1...       July 26, 2022   \n",
            "3   How Meta is Preparing for Kenya’s 2022 General...       July 20, 2022   \n",
            "4   Meta’s Ongoing Efforts Regarding Russia’s Inva...   February 26, 2022   \n",
            "..                                                ...                 ...   \n",
            "74  Removing Additional Inauthentic Activity from ...    October 11, 2018   \n",
            "75       Expanding Fact-Checking to Photos and Videos  September 13, 2018   \n",
            "76   How Is Facebook’s Fact-Checking Program Working?       June 14, 2018   \n",
            "77  Facing Facts: Facebook’s Fight Against Misinfo...        May 23, 2018   \n",
            "78  PBS Wraps 4-Part Series on ‘Junk News,’ Featur...        May 22, 2018   \n",
            "\n",
            "         Updated Date                                               Text  \n",
            "0   November 11, 2022  [Update on November 11, 2022 at 8:00AM PT:, Me...  \n",
            "1     August 16, 2022  [Update on August 16, 2022 at 10:30AM PT:, As ...  \n",
            "2       June 16, 2023  [Update on June 16, 2023 at 6:00AM PT:, Today,...  \n",
            "3       July 20, 2022  [Today, we’re sharing an update on our work to...  \n",
            "4      April 18, 2022  [Jump to latest newsUkrainian translation,Russ...  \n",
            "..                ...                                                ...  \n",
            "74      June 22, 2020  [ByNathaniel Gleicher, Head of Cybersecurity P...  \n",
            "75      June 22, 2020  [By Antonia Woodford, Product Manager, We know...  \n",
            "76      June 22, 2020  [Hard Questions isa seriesfrom Facebook that a...  \n",
            "77      June 22, 2020  [ByJohn Hegeman, Head of News Feed, Over the l...  \n",
            "78      June 22, 2020  [On May 16, PBS NewsHour aired the fourth and ...  \n",
            "\n",
            "[79 rows x 5 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "scraped_dataset_misinfo = []\n",
        "\n",
        "for idx, row in article_meta_ds_2.iterrows():\n",
        "  article_request = requests.get(url=row['Link'])\n",
        "  parser = BeautifulSoup(article_request.content, \"html.parser\")\n",
        "\n",
        "  text_section = parser.find(\"div\", class_=\"uk-width-2-3@m article-container\")\n",
        "  paragraphs = text_section.find_all(\"p\")\n",
        "\n",
        "  cleaned_text = [para.get_text(strip=True) for para in paragraphs]\n",
        "  scraped_dataset_misinfo.append(cleaned_text)\n",
        "  print(idx, cleaned_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "e-tI5vW7_HFH",
        "outputId": "034c0340-9b75-4ebd-8914-b053928df933"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 ['Update on November 11, 2022 at 8:00AM PT:', 'Meta has become afounding member of the Asia Clean Energy Coalition,which will advocate for eliminating barriers to corporate renewable energy purchasing in Asia.', 'Originally published on November 6, 2022 at 11:00PM PT:', 'As leaders and experts convene in Egypt for COP27, we’re outlining progress on our climate commitments and announcing expanded tools to help our communities take action against climate change. Like previous years, we’re focusing on how we can leverage our technologies, apps and operational strategy to demonstrate our commitment to solutions.', 'Since 2020, we’ve achieved net zero greenhouse gas emissions for our global operations as they are now supported by 100% renewable energy. We’ve also set ambitious goals to achieve net zero value chain emissions and to restore more water than we consume in our global operations in 2030. Reducing our emissions and helping our suppliers to do the same is our top priority to reach our climate target.', 'This year, weannounced a new partnershipwith Stripe, Alphabet, Shopify and McKinsey Sustainability to launch Frontier, an advanced market commitment to help scale emerging carbon removal technologies that are crucial to tackling climate change.', 'As evidenced by the COVID-19 pandemic, we have an essential role to play during global crises in connecting people to accurate information. That’s why we’ve built and expanded a number of tools to provide authoritative information about the realities of climate change.', 'We’vecreated a new pagethatexplains our holistic approach to addressing climate content and misinformation on our apps. Our investment in theClimate Misinformation Grant Programis forging new partnerships and initiatives, and ourPublic Ad Librarygives an extra layer of transparency into all climate ads.', '', '', 'After ourlargest-ever global survey about climate changethis past spring painted a picture of deep concern among respondents, we have seen meaningful change happen when communities come together. More than 40 million people around the world are part of at least one of the 24,000 Facebook Groups dedicated to the discovery, protection and appreciation of the earth and our environment.', '', 'We’re testing a new feature in Facebook Groups, called Climate Pledges, which leverages the power ofcommunities to enable climate action. Developed with inputs from the UN Environment Programme and UN’s ActNow, the Climate Pledges feature contains expert-backed climate solutions to spark conversation and help people understand the most impactful actions they can take. Group admins can choose the solutions most relevant to their communities, invite group members to join, provide support and offer tips to keep everyone accountable. For example, a solar panel group admin may choose to activate the “Switch to renewable energy” pledge and group members commit to joining it together. Group members can also discover relevant content, including Reels, from across Facebook which they can then localize to their communities.', '', 'OurBoost Guide to GreenProgram has reached 1.3 million small and medium-sized businesses (“SMBs”) on how to become greener.We released anew reportin October, in partnership with Accenture, which explores the relationship between SMBs and climate action, and how digital technology can support them. OurData for Goodprogram also provided data from our small business surveys to the World Trade Organization, which published areporton small businesses’ experiences and challenges related to climate change.', 'We also launched theClimate Perceptions Index, developed by theSocial Progress Imperative, using datafrom our 2022Climate Change Opinion Survey. It offers information on the societal implications of climate change with new data on people’s awareness of climate change, their perception of its risks and their commitment to climate action.', 'Finally, we have collaborated with the World Resources Institute on prevention campaigns to reduce food waste, reaching more than 40 million people in Germany and the UK. We’ll use the insights we gain from these campaigns toinformfuture work.']\n",
            "1 ['Update on August 16, 2022 at 10:30AM PT:', 'As part of our work to protect the 2022 election in Brazil, we will prohibit ads calling into question the legitimacy of the upcoming election.', 'Originally published on August 12, 2022 at 6:00AM PT:', 'Today, we want to share our work to protect the integrity of presidential elections taking place in Brazil in October 2022. In recent years, we’ve increased our efforts to combat misinformation by investing in teams, technology and partnerships to ensure the safety of people using Meta’s platforms.', 'Since 2016, we’ve quadrupled our security and integrity workforce to more than 40,000 people globally. Last year alone, we invested nearly $5 billion in both areas.', 'We know that local knowledge is essential for this work to be effective, so we also have a large team of specialists based in Brazil who have a deep understanding of the situation. These efforts are intensified as the election approaches, and our work to protect the integrity of our platforms will continue after the vote.', 'Removing content that violates our policies on voter suppression, such as posts that discourage people from voting, is among our many responses to potential interference in the electoral process. We take many actions to prevent hate speech or the incitement of violence on our platforms.', 'Currently, 99.7% of the fake accounts we remove from Facebook are deleted by artificial intelligence, before they are reported by users. We also investigate and disrupt networks that use fake accounts in a coordinated way to influence public debate.', 'Closer to October, we will activate an Elections Operations Center focused on Brazil, an initiative we’ve implemented since 2018, to bring together experts from across the company – including intelligence, data science, engineering, research, operations, public policy and legal teams. They work together to identify potential threats on our platforms in real time, accelerating our response time.', 'In partnership with Brazil’s Superior Electoral Court (TSE), in December 2021 we started adding a label to posts about political elections on Facebook and Instagram, directing people to reliable information on the Electoral Justice website. In the first two months after its launch, the label led to a 10-fold increase in visits to the Electoral Justice portal.', 'Between the end of April and the beginning of May, we posted reminders on Facebook for users to request or update their voter cards. The content was seen by the majority of adults using Facebook in Brazil and more than three\\xa0 million people clicked to see more information. Closer to the upcoming election, we will again display reminders on Facebook and Instagram about voting day to raise awareness among voters and reduce abstention rates.', 'For the first time, the TSE will be able to report content directly on Facebook and Instagram that may violate our policies. We will analyze the reports once they are received.', 'WhatsApp launched an extrajudicial channel of communication in the 2020 municipal election to receive complaints from the TSE. The focus is on quick response to potential cases of bulk messaging, which is forbidden by local electoral law and by the app’s terms of service.', 'We also developed a virtual assistant on WhatsApp with the TSE, as we did during Brazil’s 2020 municipal election. The chatbot is accessible through the number +55 61 9637-1078. It allows voters to interact directly with the electoral authority and receive relevant information about the vote.', 'Meta has hosted training sessions for electoral officials all over Brazil to explain our actions to curb misinformation, share details on how Facebook and Instagram work, and detail our content rules, which we call our Community Standards and Community Guidelines. We also offer workshops to candidates and their campaign teams.', 'The partnership with the TSE also includes booklets with information for the electoral community and a guide to combating online violence against women in politics, also supported by the Women’s Democracy Network (WDN) – Brazil Chapter.', 'We remove content on Facebook and Instagram that discourages voting or interferes with voting, such as incorrect information about the election date or candidates’ numbers.', 'We also work with independent fact-checking organizations to verify the veracity of reported posts that don’t violate our Community Standards. When fact-checkers mark a post as false, we reduce its reach on Facebook and Instagram.', 'People who still see this content in their feeds will see it covered with a label and a link directing them to more information from the fact-checker. In July, we increased the number of partners in our fact-checking initiative in Brazil from four to six including: Agência Lupa, AFP, Aos Fatos, Estadão Verifica, Reuters Fact Check and UOL Confere.', 'Since messages on WhatsApp are end-to-end encrypted, we fight misinformation on WhatsApp through measures to reduce message virality.', 'Messages forwarded on WhatsApp are identified with a tag. Since 2020, messages with five or more forwards can be resent to just one conversation, which has led to a 70% global reduction in the number of frequently forwarded messages. This year, we implemented a new forwarding limit on WhatsApp: now, any forwarded message can only be forwarded again to one WhatsApp group at a time.', 'In 2018, we launched our transparency tools for ads about politics and elections on Facebook and Instagram in Brazil. In 2020, we began requiring advertisers who wish to run ads about elections or politics to complete an authorization process and include “Paid for by” disclaimers on these ads. This year, we’ve expanded that requirement to ads about social issues such as economics, security and education.', 'All posts with the “Paid for by” disclaimer go to the Ad Library, where they are stored for seven years. The tool is open and provides anyone with detailed information about political ads including\\xa0 the ad source account, audience demographics and estimated spending range, among other data.', 'Protecting the integrity of the Brazilian election in 2022 on our apps is a priority for Meta. We will continue to share updates on how we move forward with this work.', 'Seemore information about our work on elections.']\n",
            "2 ['Update on June 16, 2023 at 6:00AM PT:', 'Today, we are releasing our response to the recommendations the Oversight Board made in their Covid-19 misinformationPolicy Advisory Opinion.', 'We will take a more tailored approach to our Covid-19 misinformation rules consistent with the Board’s guidance and our existing policies. In countries that have a Covid-19 public health emergency declaration, we will continue to remove content for violating our Covid-19 misinformation policies given the risk of imminent physical harm. We are consulting with health experts to understand which claims and categories of misinformation could continue to pose this risk. Our Covid-19 misinformation rules will no longer be in effect globally as the global public health emergency declaration that triggered those rules has been lifted.', 'To learn more about our response to the board, visit ourTransparency Center.', 'Originally published on July 26, 2022 at 5:00AM PT:', 'Meta is asking the Oversight Board for advice on whether measures to address dangerous COVID-19 misinformation, introduced in extraordinary circumstances at the onset of the pandemic, should remain in place as many, though not all, countries around the world seek to return to more normal life.', 'Misinformation related to COVID-19 has presented unique risks to public health and safety over the last two years and more. To keep our users safe while still allowing them to discuss and express themselves on this important topic, we broadened our harmful misinformation policy in the early days of the outbreak in January 2020. Before this, Meta only removed misinformation when local partners with relevant expertise told us a particular piece of content (like a specific post on Facebook) could contribute to a risk of imminent physical harm. The change meant that, for the first time, the policy would provide for removal of entire categories of false claims on a worldwide scale.', 'As a result, Meta has removed COVID-19 misinformation on an unprecedented scale. Globally, more than 25 million pieces of content have been removed since the start of the pandemic. Under this policy, Meta began removing false claims about masking, social distancing and the transmissibility of the virus. In late 2020, when the first vaccine became available, we also began removing further false claims, such as the vaccine being harmful or ineffective. Meta’s policy currentlyprovides for removal of 80 distinct false claimsabout COVID-19 and vaccines.', 'Meta remains committed to combating COVID-19 misinformation and providing people with reliable information. As the pandemic has evolved, the time is right for us to seek input from the Oversight Board about our measures to address COVID-19 misinformation, including whether those introduced in the early days of an extraordinary global crisis remains the right approach for the months and years ahead. The world has changed considerably since 2020. We now haveMeta’s COVID-19 Information Center, and guidance from public health authorities is more readily available. Meta’s COVID-19 Information Center has connected over two billion people across 189 countries to helpful, authoritative COVID-19 information.', 'The pandemic itself has also evolved. In many countries, where vaccination rates are relatively high, life is increasingly returning to normal. But this isn’t the case everywhere and the course of the pandemic will continue to vary significantly around the globe — especially in countries with low vaccination rates and less developed healthcare systems.It is important that any policy Meta implements be appropriate for the full range of circumstances countries find themselves in.', 'Meta is fundamentally committed to free expression and we believe our apps are an important way for people to make their voices heard. But some misinformation can lead to an imminent risk of physical harm, and we have a responsibility not to let this content proliferate. The policies in ourCommunity Standardsseek to protect free expression while preventing this dangerous content. But resolving the inherent tensions between free expression and safety isn’t easy, especially when confronted with unprecedented and fast-moving challenges, as we have been in the pandemic. That’s why we are seeking the advice of the Oversight Board in this case. Its guidance will also help us respond to future public health emergencies.', 'The Oversight Board was established to exercise independent judgment, operating as an expert-led check and balance for Meta, with the ability to make binding decisions on specific content cases and to offer non-binding advisory opinions on its policies. We are requesting an advisory opinion from the Oversight Board on whether Meta’s current measures to address COVID-19 misinformation under our harmful health misinformation policy continue to be appropriate,or whether we should address this misinformation through other means, like labeling or demoting it either directly or through our third-party fact-checking program.']\n",
            "3 ['Today, we’re sharing an update on our work to help ensure a safe and secure General Election in Kenya on August 9.', 'We’ve been preparing for the country’s 2022 election over the past year with the help of a dedicated team that’s working closely with election authorities and trusted partners in the country. Additionally, we’ve invested in people and technology to help reduce the spread of misinformation, detect and remove hate speech, improve digital literacy and help make political advertising more transparent.', 'Meta has establishedoperations centresfor major elections around the world since 2018, including in Kenya.', 'Our team dedicated to the Kenyan election includes experts from Kenya and people who have spent a significant amount of time in the country, which we believe is critical to understanding the local landscape. With their help, we continue to respond to potential problems and abuse that might emerge in the country.', 'In order to quickly identify and remove content that violates ourCommunity Standards, we use a combination of artificial intelligence, human review and user reports. Our Community Standards include strict rules against hate speech, voter suppression, harassment and inciting violence, among others. We’ve also built more advanced detection technology, quadrupled the size of our global team focused on safety and security to more than 40,000 people and hired more content reviewers to review content across our apps in more than 70 languages — including Swahili.In thesix months leading up to April 30, 2022, we took action on more than 37,000 pieces of content for violating ourHate Speech policieson Facebook and Instagram in Kenya. During that same period, we also took action on more than 42,000 pieces of content that violated ourViolence & Incitement policies.', 'Informed by local challenges around increased abuse against female public figures, we formed a working group for the protection of female public figures during the Kenya elections. Partnering with local civil society organisations such as Kenya Women Parliamentary Association (KEWOPA), Pollicy and UN Women, we trained women members of Parliament, aspirants and human rights defenders toutilise our safety tools and resourcesto ensure a safer experience across our technologies. We also continue to work with participants to further understand the gender-based slurs used online in local languages, with the aim of helping to address these during the elections.', 'To reduce misinformation and lower the risk of problematic content in Kenya ahead of and during the elections, we’re temporarily reducing the distribution of content from those who have repeatedly or severely violated our policies.', 'In 2021 we announced new rules for WhatsApp that included reducing the number of people you can send a highly forwarded WhatsApp message to, to justone chat at a time. Since then, we’ve seen a 70% drop in the number of highly forwarded messages on WhatsApp. We also introduced this forward limit on Messenger, so messages can only be forwarded to five people or groups at a time. We know that limiting forwarding is an effective way to slow the spread of viral misinformation and harmful content that has the potential to cause offline harm.', 'We remove the most serious kinds of misinformation from Facebook and Instagram, such as content that is intended to suppress voting or could contribute to imminent violence or physical harm. During the Kenyan elections, based on guidance from local partners, this will specifically include false claims that people with weapons are guarding polling stations, false claims that polling stations have been damaged and photos and videos shared out of context depicting ballot-stuffing or violence.', 'For content that doesn’t violate these particular policies, we’ve partnered with independent third-party fact-checkers in Kenya — AFP, Pesa Check and Africa Check, who review content in both English and Swahili. When a piece of content is reviewed and rated as false, we reduce its distribution and add a warning label with additional information.', 'In addition to combating the spread of misinformation on our platforms, we’re working with local partners to improve digital and media literacy in Kenya. Programs likeMy Digital Worldare focused on raising awareness amongst youth, teachers, parents and guardians on topics such as online safety, privacy, digital citizenship, news and media literacy, delivered through live webinars. We also partnered withiEARN Kenyato provide teachers and parents with lessons on how to safely guide people through the digital world. We also work with UNESCO, through the EU-funded project Social Media for Peace in Kenya. This programme aims to address concerns around the use of digital communication tools as platforms to spread harmful content.', 'We’re also taking to the airwaves on local radio in Kenya, to educate listeners on how to spot hate speech and misinformation, and what actions to take. These have been running in multiple local languages including Luo, Kalenjin, Kikuyu, Swahili as well as English.', 'Our Ad Transparency tools help people understand who’s behind the political ads they see on Facebook and Instagram. Advertisers who want to runpolitical ads in Kenya must undergo a verification process to verify their identity and that they live in the country. We then run additional checks to ensure their compliance with our policies, and political ads must be labelled with a “Paid for by” disclaimer to show who’s behind it.In the six months leading up to April 30, about 36,000 ad submissions targeted to Kenya were rejected before they ran for not completing the authorization process or not attaching a disclaimer.', 'We also ensure that political ads run in Kenya are included in ourAds Libraryso everyone can see what ads are running, see information about targeting and find out how much money was spent. People can also personalise their feeds and choose to see fewerpolitical ads.', 'Helping to build informed and engaged communities is central to our work around elections. In Kenya, we’ll have an “I Voted” sticker on Instagram. And on Election Day, we’ll remind people in the country that it’s time to vote with a notification on top of their Facebook Feed as well.']\n",
            "4 ['Jump to latest newsUkrainian\\xa0translation,Russian translation', 'Update on March 17, 2022 at 9:00AM PT:', 'We’re continuing to see our community come together to help people fleeing the war in Ukraine. Today, we’re sharing a few updates to make it easier for people to get information and offer support.', '', 'Update on March 11, 2022 at 4:00PM PT:', 'Head of Instagram Adam Mosseri responded to Russia’s decision to block access to Instagram:', '', 'A post shared by Adam Mosseri (@mosseri)', '', 'Update on March 11, 2022 at 3:30PM PT:', 'President, Global Affairs Nick Clegg’s statement to reports that the Russian government is considering designating Meta as an extremist organization for its policies in support of speech:', 'There has been a lot of coverage and discussion of how we are applying our policies to speech in the context of Putin’s invasion of Ukraine.', 'I want to be crystal clear: our policies are focused on protecting people’s rights to speech as an expression of self-defense in reaction to a military invasion of their country. The fact is, if we applied our standard content policies without any adjustments we would now be removing content from ordinary Ukrainians expressing their resistance and fury at the invading military forces, which would rightly be viewed as unacceptable.', 'To be clear, we are only going to apply this policy in Ukraine itself. We have no quarrel with the Russian people. There is no change at all in our policies on hate speech as far as the Russian people are concerned. We will not tolerate Russophobia or any kind of discrimination, harassment or violence towards Russians on our platform.', 'This is a temporary decision taken in extraordinary and unprecedented circumstances. We will be keeping the situation under review in the period ahead.', 'Update on March 8, 2022 at 9:00PM PT:', 'As the humanitarian crisis deepens, today we are announcing additional steps to help our community access crucial resources and take action to support people in need.', 'Helping People Access Resources', 'This slideshow requires JavaScript.', 'Helping People Show Support for Ukraine', '', 'Update on March 8, 2022 at 8:00AM PT:', 'Today, we’re sharing updates that we’re making on Instagram to help keep people in Ukraine and Russia safe and reduce the spread of misinformation.', 'Keeping Information and Associations Private on Instagram:To help protect our communities in Ukraine and Russia, we’ll now be hiding information about people’s followers, who they’re following, and people who are following each other for private accounts based in these two countries.', 'This means that people following private accounts based in Ukraine and Russia will no longer be able to see who those accounts are following, or who follows them. We’re also not showing these accounts in other people’s follower or following lists, or in our “mutual follows” feature. We notified private accounts in Ukraine and Russia letting them know about this change.', 'We’re also highlighting tools likeYour ActivityandDownload Your Informationto accounts in Ukraine and Russia. Your Activity \\u200b\\u200ballows people to bulk delete content they’ve posted like photos and videos, as well as their previous likes and comments.Download Your Informationallows people to get a copy of their Instagram data.', '', 'Addressing Russian State-Controlled Media on Instagram:Following last week’s announcement that we’ve begun demoting posts containing links to Russian state-controlled media on Facebook, starting today, Stories that contain a link sticker pointing to a Russian state-controlled media website on Instagram will be placed lower in the Stories tray. We’ll also label these Stories to let people know that they lead to Russian state-controlled media websites.', '', 'These changes are in addition to steps we’ve already taken to make content from accounts run by Russian state-controlled media harder to find on Instagram, and to provide more transparency if people try to share content from these accounts.', 'Specifically, we’re downranking posts from Russian state-controlled media in Feed, and placing them lower in the Stories tray. We’re also showing people a notice before they reshare content from these accounts in their Stories, letting them know that the content comes from Russian state-controlled media. If people still choose to reshare these posts to their Stories, we will place those Stories lower in the tray.', '', 'Lastly, we’re not recommending posts from Russian state-controlled media accounts in Explore and Reels, and we’re making these accounts harder to find in Search.', 'Update on March 4, 2022 at 3:00PM\\xa0 PT:', 'Despite the Russian government’s announcement that they will be blocking Facebook, we are working to keep our services available to the greatest extent possible. However, due to the difficulties of operating in Russia at this time, ads targeting people in Russia will be paused, and advertisers within Russia will no longer be able to create or run ads anywhere in the world, including within Russia.', 'Update on March 4, 2022 at 11:15AM PT:', 'Update on Russia’s Decision to Block Access to Facebook:As a result of the Russian government’s decision to block access to Facebook in the Russian Federation, soon millions of ordinary Russians will find themselves cut off from reliable information, deprived of their everyday ways of connecting with family and friends and silenced from speaking out. We will continue to do everything we can to restore our services so they remain available to people to safely and securely express themselves and organize for action.', 'Update on Restricting Access to RT and Sputnik:Earlier this week, we announced that we’d be restricting access to RT and Sputnik across the EU given the exceptional circumstances. Consistent with that action, and following a request from the UK government, we will also be restricting access to RT and Sputnik in the UK at this time.', 'Update on March 3, 2022 at 4:50PM PT:', 'Increasing Our Support for Humanitarian Efforts: Today, we’re committing $15 million to support humanitarian efforts in Ukraine and neighboring countries. This includes $5 million in direct donations to UN agencies and more than a dozen nonprofits, including International Medical Corps who will be using these funds to deploy mobile medical units to Ukraine and Internews to support at-risk journalists and human rights defenders in the region. We’re also donating to UNICEF to scale up lifesaving support for children and families in Ukraine and the region.The remaining $10 million will be provided as ad credits, helping nonprofit organizations raise the funds they need to respond and deliver essential information to people impacted by the violence.', 'Update on March 1, 2022 at 6:05PM PT:', 'Update on State-Controlled Media Outlets:In addition to restricting access to RT and Sputnik across the EU, we are now globally demoting content from Facebook Pages and Instagram accounts from Russian state-controlled media outlets and making them harder to find across our platforms.', 'We have also begun to demote posts that contain links to Russian state-controlled media websites on Facebook. In the days ahead, we will label these links and provide more information to people before they share or click on them to let them know that they lead to Russian state-controlled media websites. We plan on putting similar measures in place on Instagram.', 'We already label Facebook Pages and Instagram accounts from Russian state-controlled media outlets so people know where this information comes from. By providing this additional transparency, we aim to give people more context if they want to share direct links to Russian state-controlled media websites or when others see someone’s post that contains a link to one of these sites.', 'Reliable Access to Trusted Information:Ukraine’s State Emergency Services has launched an information helpline on WhatsApp. The free service will connect users to critical updates, reliable and trustworthy information, as well as details about emergency response procedures. To use the free helpline on WhatsApp, simply save the number+380676785917in your phone contacts and then text the word почати (begin) in a WhatsApp message to get started.', 'How Our Community Is Helping:Throughout this war and humanitarian crisis, we’ve seen people across the world use our tools to make their voices heard and support each other. For example, since February 23, more than $20 million has been raised for nonprofits on Facebook and Instagram in support of humanitarian efforts for Ukraine.(Updated on March 2, 2022 at 10AM PT to reflect the latest fundraising amount.)We’ve also seen Facebook Groups created to help those in need, including a group of 200,000 Romanian volunteers and donors coordinating transportation and accommodations for refugees. And a group of more than 300,000 in Poland is offering housing, clothing, medication and rides from the border to help those in need.', 'Today, we’re also announcing that as part of ourData for Good program, we’re making aggregated data on social connections available to trusted organizations working to provide medical services and support to refugees, like Direct Relief, which is using this data to better understand where people might be going so they can best support communities in need.', 'Update on February 28, 2022 at 5:55PM PT:', 'We have received requests from a number of governments and the European Union to take further steps in relation to Russian state-controlled media. Given the exceptional nature of the current situation, we will be restricting access to RT and Sputnik across the EU at this time.', 'As of this morning, we’ve made encrypted one-to-one chats available on Instagram for all adults in Ukraine and Russia. We’ll also show notifications at the top of people’s direct message inboxes to let them know they can switch to an encrypted conversation if they want to. End-to-end encrypted chats are already available as an option on Messenger and by default on WhatsApp. This update is not available to business accounts on Instagram.', 'Update on February 27, 2022 at 9:00PM PT:', 'We took down a network run by people in Ukraine and Russia targeting Ukraine for violating our policy againstcoordinated inauthentic behavior. They ran websites posing as independent news entities and created fake personas across many social media platforms including Facebook, Instagram, Twitter, YouTube, Telegram, Odnoklassniki and VK.', 'We’ve also seen increased targeting of Ukrainian military and public figures by Ghostwriter, a threat actor that has beentrackedfor some time by the security community. We encourage people in Ukraine and Russia to adopt stronger account security measures — like two-factor authentication — to protect their information in the midst of this invasion. We continue to roll out privacy and security measures to help people in Ukraine and Russia protect their accounts from being targeted.', 'Learn more about oursecurity updates in Ukraine.', 'Update on February 27, 2022 at 11:45AM PT:', 'We have been in contact with the government of Ukraine. At their request, we have restricted access to several accounts in Ukraine, including those belonging to some Russian state media organizations. We are also reviewing other government requests to restrict Russian state-controlled media.', 'Originally published on February 26, 2022 at 11:50AM PT:', 'Our thoughts are with everyone affected by the war in Ukraine. We are taking extensive steps across our apps to help ensure the safety of our community and support the people who use our services — both in Ukraine and around the world.', 'The following are some of the specific steps we have taken regarding Russia’s invasion of Ukraine:', 'We’ve added several safety features in Ukraine in response to the situation on the ground.', 'We are taking additional steps to enforce our Community Standards and Community Guidelines, not only in Ukraine and Russia but also in other countries globally where content may be shared.', 'We are taking extensive steps to fight the spread of misinformation on our services and continuing to consult with outside experts.', 'We providegreater transparencyon accounts from state-controlled media outlets, including Russian-based RT and Sputnik, because they combine the influence of a media organization with the strategic backing of a state, and we believe people should know if the news they read is coming from a publication that may be under the influence of a government.', 'We remain vigilant to emerging trends and stand ready to take additional action to meet the demands of this ongoing conflict.', 'Оновлено 17 березня 2022 року о 9:00AM PT:', 'Ми продовжуємо спостерігати за об’єднанням нашої спільноти, що має на меті допомагати людям, які тікають від війни в Україні. Сьогодні ми хочемо поділитися деякими оновленнями, які допоможуть людям легше отримувати інформацію та надавати підтримку.', '', 'Оновлено 11 березня 2022 року о 4:00PM PT:', 'Глава Instagram Адам Моссері відповів на рішення Росії заблокувати доступ до Instagram:', '', 'A post shared by Adam Mosseri (@mosseri)', '', 'Оновлено 11 березня 2022 року о 3:30PM PT:', 'Заява Ніка Клегга, президента відділу з міжнародних справ у Мета, у відповідь на повідомлення про те, що російський уряд розглядає можливість включення компанії Мета в список екстремістських організацій за її політику на підтримку деяких висловлювань:', 'Було багато повідомлень і дискусій про те, як ми застосовуємо нашу Політику щодо свободи слова в контексті вторгнення Путіна в Україну.', 'Я хочу бути щирим: наша політика спрямована на захист прав людей на свободу слова, яка є одним з проявів самооборони, у відповідь на військове вторгнення в їхню країну. Справа в тому, що якби ми застосовували нашу стандартну політику щодо контенту без будь-яких коригувань, ми б зараз видаляли контент простих українців, які виражають свій опір і лють по відношенню до військових сил, які вторглися в їхню державу. Такі наші дії були б справедливо розцінені як неприйнятні.', 'Для ще більшої ясності, ми збираємося застосовувати цю політику тільки на території України. У нас немає ніяких непорозумінь з російським народом. У нашій політиці щодо мови ворожнечі немає ніяких змін в тому, що стосується росіян. Ми не потерпимо русофобії або будь-якого виду дискримінації, переслідування або насильства по відношенню до росіян на нашій платформі.', 'Це тимчасове рішення, прийняте в надзвичайних і безпрецедентних обставинах. Ми будемо стежити за розвитком цієї ситуації в майбутньому.', 'Оновлено 8 березня о 9:00PM PT:', 'Сьогодні ми оголошуємо про запровадження додаткових заходів, які допоможуть нашій спільноті отримати доступ до найважливіших ресурсів, а також вжити заходів для підтримки людей, які цього потребують, у зв’язку із подальшим розвитком\\xa0 гуманітарної кризи.', 'Допомога людям у доступі до ресурсів', 'Допомагаємо людям демонструвати їхню підтримку Україні', 'Оновлено 8 березня 2022 року о 8:00AM PT:', 'Сьогодні ми ділимося нашими оновленнями в Instagram, які мають допомогти захистити людей в Україні та Росії, а також зменшити поширення дезінформації.', 'Збереження конфіденційності інформації та зв’язків в Instagram:з метою захисту наших спільнот в Україні та Росії, відтепер ми будемо приховувати інформацію про Ваших підписників, підписки та взаємні підписки. Ці зміни стосуються приватних облікових записів людей, які проживають на території цих двох країн.', 'Це означає, що люди, які стежать за приватними акаунтами користувачів з України та Росії, більше не зможуть побачити, за ким стежать ці акаунти або хто стежить за ними. Ми також не будемо показувати ці облікові записи серед підписників інших людей, а також у нашій функції “взаємні підписки”. Ми вже повідомили власників приватних акаунтів з України та Росії про ці зміни.', 'Власникам акаунтів в Україні та Росії ми також нагадуємо про існування таких функцій як: “Ваша активність” та “Завантажити інформацію”. Функція “Ваша активність” дозволяє людям масово видаляти розміщений ними контент, наприклад, фотографії та відео, а також попередні лайки і коментарі. “Завантажити\\xa0 інформацію” дозволяє людям отримати копію своїх даних в Instagram.', 'Наша відповідь російським державним ЗМІ в Instagram:Минулого тижня ми оголосили про початок зниження рейтингів постів, що містять посилання на російські державні ЗМІ у Facebook. А вже від сьогодні Stories, що містять стікер з посиланням на сайт російського державного ЗМІ в Instagram, будуть розміщуватися в кінці стрічки. Ми також будемо відповідним чином позначати ці Stories для інформування людей про те що ці посилання ведуть на сайти російських державних ЗМІ.', 'Ці зміни доповнюють кроки, які ми вже встигли зробити, щоб контент від російських державних ЗМІ було складніше знайти в Instagram. Крім цього, це було зроблено для забезпечення більшої прозорості, якщо люди намагатимуться поділитися інформацією, розміщеною на сторінках цих ЗМІ.', 'Зокрема, ми знижуємо рейтинг постів від російських державних ЗМІ у загальній стрічці, а також розміщуємо їх далі у стрічці Stories. Крім цього, перш ніж люди захочуть зробити репост будь-якої інформації з цих сторінок до себе у Stories, ми сповіщатимемо їх, що інформація належить російським державним ЗМІ. Якщо люди все ж вирішать зробити репост з тих сторінок до себе у Stories, ми розмістимо ці історії далі в стрічці.', 'Підсумовуючи, ми не рекомендуємо публікувати інформацію зі сторінок російських державних ЗМІ в Explore і Reels, а також ускладнюємо пошук таких акаунтів.', 'Оновлено 4 березня 2022 року о 3.00PM PT:', 'Незважаючи на оголошення російського уряду про блокування Facebook на території країни, ми працюємо над тим, щоб наші послуги залишалися доступними якомога довше. Однак через труднощі в функціонуванні на території Росії, рекламу орієнтовану на її мешканців, буде призупинено. Крім цього, російські рекламодавці більше не матимуть змогу створювати або показувати рекламу в будь якій точці світу, в тому числі в Росії.', 'Оновлено 4 березня 2022 року о 11:15PM PT:', 'Актуальна інформація щодо рішення Росії про блокування доступу до Facebook: У результаті рішення російського уряду про блокування доступу до Facebook на території Російської Федерації, незабаром мільйони звичайних росіян будуть відрізані від достовірної інформації, позбавлені своїх повсякденних способів спілкування з родиною та друзями та не матимуть можливості вільно висловити свої думки. Ми продовжуватимемо робити все можливе задля відновлення наших послуг в країні, щоб вони залишалися доступними для людей, які хочуть безпечно та вільно висловлювати свою думку та організовуватись до дій.', 'Актуальна інформація щодо обмеження доступу до RT і Sputnik: Раніше цього тижня ми вже оголосили, що обмежимо доступ до RT і Sputnik на території всього Європейського Союзу з огляду на виняткові обставини. Відповідно до цього рішення та на прохання уряду Великобританії, на цей час ми також обмежимо доступ до RT і Sputnik у Великій Британії.', 'Оновленo 3 березня 2022 року о 4:50 PM PT:', 'Збільшуємо нашу гуманітарну допомогу:Сьогодні ми виділяємо 15 мільйонів доларів на гуманітарну допомогу для України та сусідніх країн. З них 5 мільйонів доларів у вигляді прямих пожертвувань будуть перераховані понад десятьом некомерційним організаціям, а також агенціям ООН.\\xa0 До цих організацій належать Міжнародний медичний корпус, який використовуватиме ці кошти для розгортання мобільних медичних підрозділів в Україні, та Інтерньюз, що підтримуватиме\\xa0 журналістів і правозахисників, які перебувають в зонах ризику. Ми також надамо кошти для ЮНІСЕФ з метою збільшення життєво необхідної допомоги дітям та сім’ям в Україні і в цілому регіоні. 10 мільйонів доларів у вигляді рекламних купонів будуть надані некомерційним організаціям, щоб допомогти їм зібрати необхідні кошти для реагування на потреби людей та надання необхідної інформації тим, хто постраждав від жорстокостих подій.', 'Оновлено 1 березня 2022 року о 6:05 PM PT:', 'Актуальна інформація щодо державних ЗМІ: Ми обмежуємо доступ до RT і Sputnik на території ЄС. Крім того, ми глобально знижуємо рейтинг сторінок Facebook і акаунтів Instagram, що належать російським державним ЗМІ, тому їх складніше знайти на наших платформах.', 'Ми також почали знижувати рейтинг дописів на Facebook, що містять посилання на сайти російських державних ЗМІ. У найближчі дні ми будемо відповідно позначати ці посилання і надавати людям більше інформації про те, що дані веб-адреси ведуть на сайти російських державних ЗМІ, ще перед тим, як користувачі вирішать перейти за посиланнями, або поділитись ними з іншими. Ми плануємо вжити аналогічних заходів також в Instagram.', 'Ми вже позначаємо сторінки в Facebook і акаунти в Instagram російських державних ЗМІ, щоб люди знали, звідки надходить інформація. З метою забезпечення прозорості, ми прагнемо надавати людям більше контексту в моменті, коли вони хочуть поділитися посиланнями російських державних ЗМІ, або ж коли бачать публікації, що містять ці посилання.', 'Надійний доступ до достовірної інформації:Державна служба з надзвичайних ситуацій України запустила інформаційну гарячу лінію в WhatsApp. Ця безкоштовна послуга дозволяє користувачам отримувати важливі сповіщення, надійну і достовірну інформацію, а також детальні інструкції про те,як варто реагувати в надзвичайних ситуаціях. Щоб скористатися безкоштовною гарячою лінією в WhatsApp, просто збережіть номер +380676785917 в контактах телефону, а потім напишіть слово “почати”(або“begin”)в чаті WhatsApp, для того, щоб її активувати.', 'Допомога від нашої спільноти:протягом цієї кризи ми бачимо, як люди по всьому світу використовують наші інструменти, щоб підтримувати один одного і давати про себе знати. Наприклад, на підтримку некомерційних організацій, що надають гуманітарну допомогу Україні, з 23 лютого на Facebook і Instagram було зібрано понад 20 мільйонів доларів. Ми також помітили численні групи в Facebook, створені для надання\\xa0 допомоги людям, котрим вона необхідна. До цих груп належить спільнота з 200 000 румунських волонтерів та донорів, які координують надання транспорту та житла для біженців, а також польська група з більш ніж 300 000 учасників, що забирає постраждалих людей з кордону, пропонує їм житло, одяг та медикаменти.', 'Сьогодні ми оголошуємо, що в рамках нашої програми “Data for Good” ми ділимося доступом\\xa0 до збору даних\\xa0 з довіреними організаціями, які працюють над тим, щоб надати біженцям допомогу, зокрема медичну. Серед них є організація Direct Relief, яка використовує наші дані з метою дізнатися більше про те, куди саме направляються біженці, щоб допомогти їм.', 'Оновлено 28 лютого 2022 року о 5:55PM PT:', 'Ми отримали низку запитів від ряду урядів і Європейського Союзу про вжиття подальших заходів по відношенню до російських ЗМІ, контрольованих державою. Враховуючи винятковий характер даної ситуації, ми будемо обмежувати доступ до таких ЗМІ, як RT і Sputnik на всій території ЄС.', 'Починаючи від сьогоднішнього ранку, ми зробиличати з наскрізним шифруваннямдоступними в Instagram для всіх дорослих користувачів в Україні та в Росії. Сповіщення про можливість створення чатів з наскрізним шифруванням, люди зможуть побачити зверху своєї скриньки для\\xa0 приватних повідомлень. Наскрізні зашифровані чати вже доступні в Messenger та за замовчуванням WhatsApp. Але це оновлення не буде доступним для бізнес-акаунтів в Instagram.', 'Оновлено 27 лютого 2022 року о 9:00 PM PT:', 'Ми видалили мережу націлену на Україну, якою керували люди Росії та України, за порушення нашої політики протискоординованої неавтентичної поведінки.Ці люди керували веб-сайтами, видаючи себе за незалежні ЗМІ, та створювали фальшиві облікові засоби на багатьох платформах в соціальних мережах, включаючи Facebook, Instagram, Twitter, YouTube, Telegram, “Однокласники” та Вконтакті.', 'Ми також спостерігаємо активізацію атак на українських військових та громадських діячів з боку Ghostwriter – злочинної кіберорганізації, яка вже деякий часвідстежуєтьсяспільнотою безпеки. Ми закликаємо жителів України та Росії вжити жорсткіших заходів щодо безпеки своїх облікових записів – наприклад, двофакторну аутентифікацію – для захисту своєї інформації в ситуації\\xa0 вторгнення.Ми продовжуємо впроваджувати заходи щодо конфіденційності та безпеки для допомоги людям в Україні та Росії, в цілях захиститу їх облікових записів від атак.', 'Дізнайтесь більше про нашіоновлення щодо безпеки в Україні.', 'Оновлено 27 лютого 2022 року о 11:45AM PT:', 'Ми знаходимося в контакті з урядом України. На його прохання ми обмежили доступ до декількох облікових записів в Україні, включаючи облікові записи, що належать деяким російським державним ЗМІ. Ми також розглядаємо інші запити українського уряду про обмеження доступу до інших російських державних ЗМІ.', '26 лютого 2022 року', 'Ми разом в думках з усіма, хто постраждав від війни в Україні. Ми впроваджуємо значні заходи в наших додатках, щоб забезпечити нашу спільноту і підтримати людей, які користуються нашими послугами — як в Україні, так і по всьому світу.', 'Нижче наведені деякі з конкретних дій, які були впроваджені у зв’язку з вторгненням Росії в Україну.', 'Зважаючи на ситуацію в Україні\\xa0 ми додали декілька функцій безпеки:', 'Ми вживаємо додаткових заходів, щоб забезпечити дотримання наших Стандартів та основних принципів спільноти не лише в Україні та Росії, а й в інших країнах світу, де контент може бути поширеним.', 'Ми вживаємо широких заходів для боротьби з поширенням неправдивої інформації на наших сервісах і продовжуємо консультуватись в справі цього з зовнішніми експертами.', 'Ми забезпечуємобільшу прозорістьоблікових записів державних ЗМІ, включаючи російські RT і Sputnik, оскільки вони поєднують в собі вплив медійної організації і стратегічну підтримку держави. Ми також вважаємо, що люди повинні знати, чи надходять новини, з якими вони ознайомлюються, від ЗМІ, перебуваючого під впливом уряду.', 'Ми як і раніше пильно стежимо за виникаючими тенденціями і готові зробити додаткові дії відповідно до вимог ситуації, що склалася.', 'Ми знаходимося в контакті з урядом України. На їх прохання ми обмежили доступ до кількох облікових засо\\xa0 в Україні, включаючи рахунк, що належать деяким російським державним ЗМІ. Ми також розглядаємо інші запити уряду про обмеження доступу до російських державних ЗМІ.', 'Обновление от 17 марта 2022, 9:00AM PT:', 'Мы по-прежнему наблюдаем, что наше сообщество объединяется, чтобы помочь людям, которые спасаются от войны в Украине. Сегодня мы делимся несколькими обновлениями, которые помогут людям еще проще получать информацию и оказывать поддержку.', '', 'Обновление от 11 марта 2022 года в 4:00PM PT:', 'Глава Instagram Адам Моссери отреагировал на решение российских властей заблокировать доступ к платформе:', '', 'A post shared by Adam Mosseri (@mosseri)', '', 'Обновление от 11 марта 2022 года в 3:30PM PT:', 'Заявление Ника Клегга, President, Global Affairs, Meta, в ответ на сообщения о том, что российское правительство рассматривает вопрос о включении Meta в список экстремистских организаций за ее политику в поддержку высказываний:', 'Было много освещения в СМИ и обсуждений того, как мы применяем нашу политику в отношении высказываний, касающихся вторжения Путина в Украину.', 'Я хочу быть предельно ясным: наша политика направлена на защиту прав людей на свободу слова как выражения самообороны в ответ на военное вторжение в их страну. Дело в том, что если бы мы применяли нашу стандартную политику в отношении контента без каких-либо корректировок, мы бы сейчас удаляли контент простых украинцев, выражающих свое сопротивление и ярость в отношении вторгшихся военных сил, что справедливо было бы расценено как неприемлемый подход.', 'Для ясности, мы собираемся применять эту политику только в самой Украине. У нас нет вражды с российским народом. В нашей политике в отношении языка ненависти нет никаких изменений в том, что касается россиян. Мы не потерпим русофобии или любого вида дискриминации, преследования или насилия по отношению к россиянам на нашей платформе.', 'Это временное решение, принятое в чрезвычайных и беспрецедентных обстоятельствах. Мы будем следить за предстоящим развитием ситуации.', 'Обновление от 8 марта 9:00PM PT:', 'В связи с усугублением гуманитарного кризиса, сегодня мы объявляем о дополнительных шагах, которые помогут нашему сообществу получить доступ к важнейшим ресурсам и поддержать тех, кто нуждается в этом.', 'Помощь с доступом к ресурсам', 'Обновление раздела “Помощь сообщества”: Мы обновляем раздел “Помощь сообщества” как центральный ресурс на Facebook, где украинцы и другие жители региона могут найти достоверную информацию от местных агентств ООН и обществ Красного Креста. Сюда входит информация о том, куда обращаться за медицинской помощью, как оставаться в безопасности и как получить помощь – как в Украине, так и после пересечения границы с соседними странами. Также существует информационная горячая линия Государственной службы по чрезвычайным ситуациям Украины в WhatsApp, которая позволяет людям получать важную информацию, включая процедуры реагирования на чрезвычайные ситуации. Ссылка на “Помощь сообщества” появится в верхней части лент Facebook и Instagram для людей в Украине или тех, кто недавно выехал в соседние страны, чтобы они знали, что этот ресурс доступен. Он также будет доступен во всем мире на страницеfacebook.com/community_help_ukraine, а также в топе результатов для соответствующих поисковых запросов в Facebook.', 'Добавление ресурсов для ментального здоровья:Мы добавим новые советы и ресурсы от международных организаций, включая Всемирную организацию здравоохранения (ВОЗ) и Международный медицинский корпус (ММК), связанные с психическим здоровьем, в разделеЦентра эмоционального здоровья в Facebook. Эти ресурсы будут доступны по всему миру на украинском, русском и английском языках и будут предлагать информацию о том, что делать во время стресса, и как оказать поддержку детям во время кризиса.', 'Мы поддерживаем организации в их стремлении донести важные сообщения до тех, кто пострадал от кризиса, с помощью бесплатных рекламных кампаний на наших платформах. Вот один из примеров: ВОЗ распространяет информацию о грудном вскармливании для перемещенных матерей, а Международный медицинский корпус (ММК) делится советами о том, как поддержать психическое здоровье.', 'Помощь пользователям в выражении поддержки Украине', 'Обновление от 8 марта 2022 года, 8:00 AM PT:', 'Сегодня мы делимся обновлениями в Instagram, которые помогут обеспечить безопасность людей в Украине и России и уменьшить распространение дезинформации.', 'Сохранение конфиденциальности информации и связей в Instagram:Чтобы помочь защитить наши сообщества в Украине и России, мы будем скрывать информацию о подписчиках, подписках, и о людях, которые друг на друга подписаны, для закрытых аккаунтов из этих двух стран.', 'Это означает, что люди, подписанные на закрытые аккаунты из Украины и России, больше не смогут видеть, кто подписан на эти аккаунты и на кого подписаны они. Мы также не будем показывать эти аккаунты в списках подписчиков и подписок других людей, а также во “взаимных подписках”. Мы уведомили закрытые аккаунты в Украине и России, чтобы они знали об этом изменении.', 'Мы также обращаем внимание аккаунтов в Украине и России на такие инструменты, как “Ваша активность” и “Скачать вашу информацию”. Первый позволяет пользователям массово удалять размещенный ими контент, например, фотографии и видео, а также их лайки и комментарии. Второй инструмент позволяет людям получить копию своих данных Instagram.', 'Российские СМИ, контролируемые государством, в Instagram:В продолжение наших действий по понижению в выдаче постов со ссылками на российские государственные СМИ в Facebook, с сегодняшнего дня Stories в Instagram, содержащие стикер со ссылкой на сайт российского государственного СМИ, будут размещаться ниже в панели Stories. Мы также будем маркировать эти Stories, чтобы люди знали, что они ведут на сайты российских государственных СМИ.', 'Эти изменения дополняют шаги, которые мы уже предприняли, чтобы сделать контент с аккаунтов российских государственных СМИ более трудно обнаруживаемым в Instagram и обеспечить большую прозрачность, когда пользователи пытаются делиться контентом с этих аккаунтов.', 'В частности, мы понижаем в выдаче посты российских государственных СМИ в новостной ленте и размещаем их ниже в панели Stories. Мы также показываем людям уведомление перед репостом контента с этих аккаунтов в Stories, сообщая им, что это контент российских государственных СМИ. Если пользователи все же решат репостнуть эти посты в свои Stories, мы поместим эти Stories ниже в выдаче.', 'Наконец, мы не будем рекомендовать посты российских государственных СМИ во вкладках “Интересное” и Reels, а также усложним поиск этих аккаунтов.', 'Обновление от 4 марта 2022 в 3:00PM PT:', 'Несмотря на заявление российских\\xa0 властей о блокировке Facebook, мы работаем над тем, чтобы наши услуги были доступны, насколько это возможно. Однако, в связи с трудностями работы в России в настоящее время, показ рекламы, таргетированной на людей в России, будет приостановлен, а рекламодатели в России больше не смогут создавать или запускать рекламу для любой точки мира, включая Россию.', 'Обновление от 4 марта 2022 в 11:15AM PT:', 'Обновление касательно решения российских властей заблокировать доступ к Facebook:В результате решения российских властей заблокировать доступ к Facebook на территории Российской Федерации, вскоре миллионы простых россиян окажутся отрезанными от достоверной информации, лишенными повседневных способов связи с семьей и друзьями и возможности высказывать свое мнение. Мы будем продолжать делать все возможное для восстановления наших сервисов, чтобы люди могли безопасно выражать свое мнение и координировать действия.', 'Обновление касательно ограничения доступа к RT и Sputnik:Ранее мы объявили о том, что ограничим доступ к RT и Sputnik на территории ЕС, учитывая исключительные обстоятельства. В соответствии с этим решением и по просьбе правительства Великобритании мы также ограничиваем доступ к RT и Sputnik в Великобритании.', 'Обновление от 3 марта 2022 в 4:50PM PT:', 'Увеличение гуманитарной помощи: Сегодня мы выделяем 15 миллионов долларов на поддержку гуманитарных усилий в Украине и соседних странах. Это включает 5 миллионов долларов в виде прямых пожертвований агентствам ООН и более чем десятку некоммерческим организациям, включая Международный медицинский корпус, который будет использовать эти средства для развертывания мобильных медицинских пунктов в Украине. Помощь также будет направлена Internews для поддержки подвергающихся риску журналистов и правозащитников в регионе. Мы также предоставляем средства ЮНИСЕФ для расширения усилий по оказанию жизненно важной помощи детям и семьям в Украине и регионе. Остальные 10 миллионов долларов будут предоставлены в виде рекламных купонов. Они помогут некоммерческим организациям в сборе средств, необходимых для реагирования и предоставления важной информации людям, пострадавшим в результате военных действий.', 'Обновление от 1 марта 2022 года 6:05 PM PT:', 'Обновление информации о СМИ, контролируемых государством:В дополнение к ограничению доступа к RT и Sputnik на территории ЕС, теперь во всем мире мы также понижаем в выдаче контент со страниц Facebook и аккаунтов Instagram российских государственных СМИ, а также затрудняем их поиск на наших платформах.', 'Мы также начали понижать в выдаче посты, содержащие ссылки на сайты российских государственных СМИ в Facebook. В ближайшие дни мы будем помечать эти ссылки и предоставлять людям больше контекста об источнике информации, прежде чем они поделятся ими или нажмут на них, чтобы они знали, что они ведут на сайты российских государственных СМИ. Мы планируем принять аналогичные меры в Instagram.', 'Мы уже маркируем страницы в Facebook и Instagram аккаунты российских СМИ, контролируемых государством, чтобы люди знали, откуда поступает эта информация. Обеспечивая дополнительную прозрачность, мы стремимся дать людям больше контекста, если они хотят поделиться прямыми ссылками на сайты российских государственных СМИ или когда другие видят чей-то пост, содержащий ссылку на один из этих сайтов.', 'Надежный доступ к достоверной информации: Государственная служба Украины по чрезвычайным ситуациям запустила информационную горячую линию в WhatsApp. Бесплатная услуга позволит пользователям получать важные обновления, надежную и достоверную информацию, а также подробные сведения о процедурах реагирования на чрезвычайные ситуации. Чтобы воспользоваться бесплатным телефоном доверия в WhatsApp, просто сохраните номер +380676785917 в контактах телефона, а затем напишите слово “почати” (начать) в сообщении WhatsApp, чтобы начать общение.', 'Как наше сообщество помогает:На протяжении всего этого кризиса мы видим, как люди по всему миру используют наши инструменты, чтобы быть услышанными и поддержать друг друга. Например, с 23 февраля на платформах Facebook и Instagram было собрано более 20 миллионов долларов для некоммерческих организаций в поддержку гуманитарной помощи для Украины. Мы также видели группы в Facebook, созданные для помощи нуждающимся, включая группу из 200 000 румынских волонтеров и доноров, координирующих транспортировку и размещение беженцев, или польскую группу из более чем 300 000 участников, предлагающую пострадавшим помощь слогистикой после пересечения границы,а также с жильем, одеждой и медикаментами.', 'Сегодня мы также объявляем, что в рамках нашей программы “Data for Good” мы предоставляем агрегированные данные о социальных связях доверенным организациям, работающим над предоставлением медицинских услуг и поддержки беженцам. Например, таким как Direct Relief, которая использует эти данные для лучшего понимания того, куда могут направляться люди, чтобы лучше поддерживать нуждающиеся сообщества.', 'Обновление28 февраля 2022в5:55 PM PT:', 'Мы получили запросы от ряда государств и Европейского союза о принятии дальнейших мер в отношении российских СМИ, контролируемых государством. Учитывая исключительный характер ситуации, мы будем ограничивать доступ к RT и Sputnik на всей территории ЕС в настоящее время.', 'Начиная с сегодняшнего утра, мы сделали зашифрованные приватные чаты доступными в Instagram для всех взрослых пользователей из Украины и России. Мы также будем показывать уведомления в верхней части чатов в Instagram Direct, чтобы дать пользователям знать, что они могут переключиться на зашифрованный чат, если захотят. Сквозные зашифрованные чаты уже доступны в качестве опции в Messenger и по умолчанию в WhatsApp. Это обновление недоступно для бизнес-аккаунтов в Instagram.', 'Обновление 27 февраля 2022 в 9:00PM PT:', 'Мы удалили сеть аккаунтов, которая таргетировалась на Украину и управлялась людьми из Украины и России, за нарушение нашей политики противскоординированного недостоверного поведения. Они управляли веб-сайтами, которые выдавали себя за независимые новостные организации, и создавали фальшивые личности во многих социальных сетях, включая Facebook, Instagram, Twitter, YouTube, Telegram, “Одноклассники” и VK.', 'Мы также наблюдаем активизацию атак на украинских военных и общественных деятелей со стороны Ghostwriter – агента угроз, которого уже некоторое времяотслеживаетсообщество экспертов по безопасности. Мы призываем жителей Украины и России принять более высокие меры безопасности учетных записей – например, двухфакторную аутентификацию – для защиты своей информации в условиях этого вторжения.Мы продолжаем внедрять меры по обеспечению конфиденциальности и безопасности, чтобы помочь жителям Украины и России защитить свои аккаунты от атак.', 'Узнайте большео наших обновлениях безопасности в Украине.', 'Обновление от 27 февраля 2022 г. в 11:45 AM PT:', 'Мы находимся в контакте с правительством Украины. По их просьбе мы ограничили доступ к нескольким аккаунтам в Украине, в том числе принадлежащим некоторым российским государственным СМИ. Мы также рассматриваем запрос других правительств об ограничении российских СМИ, контролируемых государством.', 'От 26 февраля 2022 г. в 11:50 AM PT:', 'Наши мысли с теми, кого затронула война в Украине. Мы предпринимаем целый ряд мер на всех наших приложениях, чтобы обеспечить безопасность нашего сообщества и поддержать людей, которые пользуются нашими услугами – как в Украине, так и по всему миру.', 'Ниже перечислены конкретные шаги, предпринятые нами в связи с вторжением России в Украину.', 'В ответ на складывающуюся обстановку, мы добавили несколько функций безопасности в Украине', 'Мы предпринимаем дополнительные шаги по контролю за соблюдением наших Норм сообщества и Принципов сообщества не только в Украине и России, но и в других странах мира, где может распространяться контент.', 'Мы предпринимаем масштабные меры по борьбе с распространением дезинформации на наших сервисах и продолжаем консультироваться со сторонними экспертами.', 'Мы обеспечиваембольшую прозрачностьаккаунтов государственных СМИ, включая российские RT и Sputnik, поскольку они сочетают в себе влияние медийных организаций со стратегической поддержкой государства. Мы считаем, что люди должны знать, поступают ли новости, которые они читают, от издания, которое может находиться под влиянием правительства.', 'Мы по-прежнему бдительно следим за развитием событий и готовы предпринять дополнительные действия в соответствии с требованиями сложившейся ситуации.']\n",
            "5 ['Our technologies offer a critically important space for people to exercise their human rights, where they can express themselves, shine a light on important issues and hold those in power to account. And, we know that people can misuse technology to heighten existing social tensions and suppress people’s fundamental rights. In line with ourCorporate Human Rights Policy, we conduct human rights impact assessments to better understand the role our technologies play in society, including how to help prevent and mitigate related risks.', 'Today, we’re publishing thefindings of the independent human rights impact assessmentwe commissioned in the Philippines, along with details onhow we’ve respondedto the recommendations in the assessment. We recognize that complex challenges outlined in the report may continue to evolve, and so will our approach and strategies to build systems that help promote human rights.', 'The assessment found that Meta technologies, in addition to being widely used in the Philippines, do play an important and positive role in providing access to economic opportunities, giving voice to people and being essential tools for monitoring and defending human rights during the COVID-19 pandemic. It also highlights salient human rights risks in the Philippines, including concerns about the misuse of our technologies formisinformation and disinformation, online harassment and incitement of violence.We’vetaken concrete steps to mitigate these risks and others identified in the report, and we’ll continue to do so to help keep people safe.', 'Article One, a specialized human rights and ethics consulting firm, completed the assessment in accordance with theUN Guiding Principles on Business and Human Rights. The research methodology included qualitative interviews with journalists, child protection specialists and civil society activists, as well as a survey of 2,000 people that use Facebook in the Philippines. The assessment also used an innovative methodology of combining traditional methods of stakeholder consultation with a quantitative survey that captured the experiences of a wide range of Filipino citizens. It was also framed to understand the experiences and risks of a variety of vulnerable groups, including LGBTQ+, journalists and others.', 'The Meta Response outlines our response to Article One’s recommendations. We are committing to implement, or have implemented, 24 recommendations; partly implement 7 recommendations; and we’re assessing feasibility of another 9. We’re sharing these insights and actions from our due diligence, aligned with our human rights policy.', 'As our response notes, we’ve made progress towards many of the recommendations in the report, and we know there is more to do. Here’s an update on our work to address some of the key areas identified in the report:', 'This assessment is an important step forward for us and our work in the Philippines. How we address safety, security and human rights is not static. We’re constantly working to evolve our products, policies and processes to create better outcomes.']\n",
            "6 ['Recent events have focused the world’s attention on the conflict in Ethiopia. Our thoughts are with the people of Ethiopia, both in the country and in the diaspora, during this difficult time. But while the international attention that these events are getting may be new, our work to prevent our platform from being abused in Ethiopia is not.', 'For more than two years, we’ve been implementing a comprehensive strategy to keep people in the country safe on our platform given the severe, longstanding risks of conflict.', 'Two years ago we moved Ethiopia to the category of countries that we believe are at the highest risk for conflict and violence, enabling the development of both proactive solutions that we can implement when crises arise, and a long-term strategy to keep people safe. We’ve been doing this despite the fact that the country’s lower internet adoption means that less than 10% of the population uses Facebook. For the millions of Ethiopians who rely on our services as a source of information and communication, our focus is threefold:', 'Ethiopia is an especially challenging environment to address these issues, in part because there are multiple languages spoken in the country.\\xa0 Over the past two years, we’ve significantly improved our reporting and enforcement tools. We can now review content in the top four languages spoken and those central to the conflict (Amharic, Oromo, Somali, Tigrinya). We’ve also made it easier for Ethiopians as well as specialized international and local human rights and civil society organizations to tell us when they see potentially violating content, so we can investigate it for possible violations.\\xa0 We also have technology to identify hate speech in Amharic and Oromo before anyone reports it to us. These efforts are industry-leading.', 'As a result of these efforts, between May and October 2021, we took action on more than 92,000 pieces of content in Ethiopia on Facebook and Instagram for violations of our Community Standards prohibiting hate speech, about 98% of which was detected before it was reported by people to us.', 'In June 2021, we alsoremoveda network of fake accounts posting critical commentary of opposition politicians/groups in Amharic.\\xa0 The people behind these posts used coordinated, inauthentic accounts as a central part of their efforts to mislead people about who they were and what they were up to. In March 2021, weremovedaccounts in Egypt that targeted Ethiopia, Sudan, and Turkey.', 'As the local situation deteriorated, and as weapproached electionsin June and again in September, we took a number of additional steps:', 'Then as now, our teams are working around the clock and we’ve activated our Integrity Operation Center — bringing togethersubject matter experts from across the company to respond in real time to problems and abuses.', 'Given the rapidly evolving situation, and informed by conversations we’ve had with human rights activists, journalists and civil society groups in Ethiopia and the diaspora about security concerns, we’ve taken additional steps in recent days. We recently launched a new safety feature in Ethiopia calledLock Profilethat allows people to restrict anyone who isn’t their friend from downloading, enlarging, or sharing their profile photo. It also prevents non-friends from seeing posts or other photos on their timeline, regardless of when they may have posted it. We’ve also put temporary measures in place to restrict views of peoples’ Friends List on their profile pages and remove results from “Search this profile.”', 'While safety work in Ethiopia has been going on for a long time, we know that the risks on the ground right now are higher. And since we recognize that local context and language-specific expertise is essential for this work, we will remain in close communication with people on the ground, along with partner institutions and non-governmental organizations as the days and weeks progress. This will help us take the right actions and make the right calls. We remain vigilant to emerging trends and stand ready to take additional action to meet the demands of this ongoing human rights situation.']\n",
            "7 ['Climate change is the greatest threat we all face — and the need to act grows more urgent every day. The science is clear and unambiguous. As world leaders, advocates, environmental groups and others meet in Glasgow this week at COP26, we want to see bold action agreed to, with the strongest possible commitments to achieve net zero targets that help limit warming to 1.5˚C.', 'We are going to play our part too. As a global business that connects more than 3 billion people every month, we have an opportunity and a responsibility to make a real difference.', 'That starts with getting our own house in order. Starting last year, we achieved net zero emissions for our global operations, and we’re supported by 100% renewable energy. To achieve this we’ve reduced our greenhouse gas emissions by 94% since 2017. We invest enough in wind and solar energy to cover all our operations. And for the remaining emissions, we support projects that remove emissions from the atmosphere.', 'We’ve also set ambitious goals for our suppliers to be net zero and for our operations to restore more water than we use by 2030. Since our first wind contract in 2013, we’ve contracted over seven gigawatts of new solar and wind energy, all in the same power grids where our data centers are located, which are some of the most efficient in the world. We are also implementing measures to reduce our business travel emissions, and joining the Sustainable Aviation Buyers Alliance as a founding member to help accelerate the path to net zero air travel by driving investment in sustainable aviation fuel.', 'But this is not enough. Social media companies have the power to connect people with each other to make a difference at scale, amplify marginalized voices and share powerful information. Every day we see people use our services to raise awareness, organize for action, and make their voices heard on a wide range of environmental issues. We want to play our part by helping people find accurate, science-led information while also tackling misinformation.', 'Last year, we launched theClimate Science Centeron Facebook to connect people with factual resources from the world’s leading climate organizations, like the Intergovernmental Panel on Climate Change, UN Environment Program and more than 200 others. They can also find steps they can take in their own lives to combat climate change. Today, we are starting to expand it to more than 100 countries. And we’re also adding a new section that shows countries’ greenhouse gas emissions as compared to their commitments and targets, so people can better understand where their country is today and what more needs to be done.', 'Earlier this year, westarted addinginformational labelsto some posts on climate changedirecting people to the Climate Science Center to find out more.We’re now expanding these labels on posts inmore than a dozen countries, including for the first time in Belgium, Brazil, India, Indonesia, Mexico, the Netherlands, Spain and Taiwan.', '', 'We have a responsibility to tackle climate misinformation on our services, which is why we partner with more than 80 independent fact-checking organizations globally to review and rate content, including content about climate change. When they rate content as false, we reduce its distribution so fewer people see it and we show a warning label with more context. And we apply penalties to people who repeatedly share false information.', 'Ahead of COP26, we’ve also activated a feature we use during critical public events to utilize keyword detection so related content is easier for fact-checkers to find — because speed is especially important during such events. This feature is available to fact-checkers for content in English, Spanish, Portuguese, Indonesian, German, French and Dutch. Learn more about how we’retackling climate change misinformation.', 'According to asurvey conducted by our Data for Good teamin partnership with the Yale Program in Climate Change Communication, a majority of people in all 31 countries surveyed said that climate change is at least somewhat important to them personally. Substantial numbers of people also said that they would “definitely” or “probably” participate in a citizens’ campaign to reduce climate change.', 'We’re also supporting the UN by encouraging conversations around climate change and helping people take action. With the help ofSpectrm, the UN will soon be launching an updated version of its ActNow chat experiencewith 10 new actions you can take to combat climate change. It’s available onMessengerthrough the app,Instagramand theUN website. In time for COP26, Messenger is supporting the work of the UNFCCC by also releasing new camera stickers that can help you strike up a conversation by visually showing your support for the planet in your next Story or chat on Messenger and Instagram, or conversation in Messenger Kids.', '', '', 'We’re launching asustainability training programto support businesses on our apps to take climate action, reduce their carbon emissions and help grow their business in a sustainable way. We are starting this month with businesses in the UK and Spain, with a particular focus on restaurants, hospitality and food producers. The program will expand to France, Italy and other countries next year.', 'During COP26 in Glasgow, we’ll be featuring experts and scientists in new content designed to inform and inspire action. We have a live studio at the event itself where we’ll be hosting a series of conversations with leading voices on climate change. We’re launching a new podcast series calledClimate Talkshosted by Sophia Li. We’ll be live-streaming aSay It With Scienceconversation on Facebook Live covering health and climate change. On@instagram, we’ve launched the editorial seriesOur Planet in Crisis, which features the stories of activists and organizers who are dedicated to spreading awareness and empowering others to take action in their local communities.', 'These are just some of the steps we’re taking as a company and as a platform to try and make a positive difference. Our goal isn’t just to be one of the most sustainable companies, but to make it easier for our users and employees to be too. If we all play our part — from world leaders and governments, to private companies and individuals — we can rise to this challenge together.']\n",
            "8 ['Over the past two decades, Facebook has empowered people around the world with a wealth of social and economic benefits. It has made social connection and free expression possible on a massive scale. This can be especially important for people who are in places that are experiencing conflict and violence.', 'Facebook supports people’s right to express themselves freely, regardless of where they are in the world. Freedom of expression is a foundational human right and enables many other rights.\\xa0 But we know that technologies for free expression, information and opinion can also be abused to spread hate and misinformation — a challenge made even worse in places where there is a heightened risk of conflict and violence. This requires developing both short-term solutions that we can implement when crises arise and having a long-term strategy to keep people safe. Here is our approach.', 'Since 2018, we’ve haddedicated teams spanning product, engineering, policy, research and operations to better understand and address the way social media is used in countries experiencing conflict.Many of these individuals have experience working on conflict, human rights and humanitarian issues, as well as addressing areas like misinformation, hate speech and polarization. Many have lived or worked in the countries we’ve identified as highest risk and speak relevant languages. They are part of the over 40,000 people we have working on safety and security, including global content review teams in over 20 sites around the world reviewing content in over 70 languages.', 'In the last two years, we’ve hired more people with language, country and topic expertise. For example, we’ve increased the number of team members with work experience in Myanmar and Ethiopia to include former humanitarian aid workers, crisis responders and policy specialists. And we’ve hired more people who can review content in Amharic, Oromo, Tigrinya, Somali and Burmese. Adding more language expertise has been a key focus area for us. This year alone, we’ve hired content moderators in 12 new languages, including Haitian Creole, Kirundi, Tswana and Kinyarwanda.', 'Our teams have developed an industry-leading process for reviewing and prioritizing which countries have the highest risk of offline harm and violence every six months. We make these determinations in line with the UN Guiding Principles on Business and Human Rights and following a review of these factors:', 'Using this prioritization process, wedevelop longer-term strategies to prepare for, respond to and mitigate the impacts of harmful offline events in the countries we deem most at risk.This allows us to act quickly to remove content that violates our policies and take other protective measures while still protecting freedom of expression and other human rights principles. Recent examples include our preparations forelections inMyanmar,Ethiopia,Indiaand Mexico.', 'In a crisis, we will determine what kind of support and teams we need to dedicate to a particular country or language, and for how long we need to keep them in place. This might include deploying our Integrity Product Operations Centers model to monitor and respond to threats in real time. It can also include seeking to ensure our integrity systems and resources are robust and ready where there may be ongoing risk of political unrest, or building temporary product levers ahead of a protest or a culturally sensitive event — all while ensuring that we have teams ready to support unplanned events, suchresponding to thecoupin Myanmar.', 'We know that we face a number of challenges with this work and it is a complex and often adversarial space — there is no one-size-fits-all solution. Many of these offline issues have existed for decades or longer, and media services have a long history of being abused by those seeking to assert or maintain power or incite violence. But, we know our work to keep our global community safe will never be finished and it requires ongoing vigilance and investments. That’s what we’ve done for many years and we will continue doing it going forward.']\n",
            "9 ['How technology companies grapple with complex issues is being heavily scrutinized, and often, without important context. There is a lot more to the story. What is getting lost in this discussion is some of the important progress we’ve made as a company and the positive impact that it is having across many key areas.', 'We firmly believe that ongoing research and candid conversations about our impact are some of the most effective ways to identify emerging issues and get ahead of them. This doesn’t mean we find and fix every problem right away. But because of this approach, together with other changes, we have made significant progress across a number of important areas, including privacy, safety and security, to name a few. Just as the world has changed a lot, so has Facebook.', 'In the past, we didn’t address safety and security challenges early enough in the product development process. Instead, we made improvements reactively in response to a specific abuse. But we have fundamentally changed that approach. Today, we embed teams focusing specifically on safety and security issues directly into product development teams, allowing us to address these issues during our product development process, not after it. Products also have to go through an Integrity Review process, similar to thePrivacy Review process, so we can anticipate potential abuses and build in ways to mitigate them. Here are a few examples of how far we’ve come.', 'Some of the most important changes we’ve made in recent years have been in prioritizing safety and security. As a result:', 'We have alsochanged our approach to protecting people’s privacyas a company. This includes investing in and expanding ourPrivacy Checkup, which today is used by tens of millions of people every month to manage their settings and control their experience on Facebook,and launching tools likeOff-Facebook ActivityandWhy Am I Seeing This?that show people how their information is used and let them more easily manage settings.', 'Misinformation has been a challenge on and off the internet for many decades. People are understandably concerned about how it will be handled for future internet technologies. At Facebook, we’ve begun addressing this comprehensively — rather than treating it as a single problem with a single solution. This means we’ve gotten better at addressing this complex challenge. We’ve worked to develop and expand our systems to reduce misinformation and promote reliable information. As a result:', 'Most importantly, we’ve also changed not justwhatwe build buthowwe build so that when we launch new products, they are more likely to have effective privacy, security and safety protections already built in. For example:', '', 'You canread moreabout the direction of our responsible innovation efforts fromMargaret Stewart, VP of Product Design & Responsible Innovation at Facebook.', 'Yes, we’ve made progress. But we also know that there will always be examples of things we miss and things we take down by mistake. There is no perfect here. Collaborating with experts, policymakers and others has made us better, and continued collaboration will be key to making sure our progress continues. And that’s our plan.', 'Read more about our efforts on ournew page, which features updated information and figures, to give a sense of where things have improved and where we still have more work to do. OurTransparency Centeris also a comprehensive destination for our integrity and transparency efforts. Also, see atimeline of our integrity efforts since 2016.', '', 'For more, visitabout.facebook.com/progress.']\n",
            "10 ['Update on November 11, 2022 at 8:00AM PT:', 'Meta has become afounding member of the Asia Clean Energy Coalition,which will advocate for eliminating barriers to corporate renewable energy purchasing in Asia.', 'Originally published on November 6, 2022 at 11:00PM PT:', 'As leaders and experts convene in Egypt for COP27, we’re outlining progress on our climate commitments and announcing expanded tools to help our communities take action against climate change. Like previous years, we’re focusing on how we can leverage our technologies, apps and operational strategy to demonstrate our commitment to solutions.', 'Since 2020, we’ve achieved net zero greenhouse gas emissions for our global operations as they are now supported by 100% renewable energy. We’ve also set ambitious goals to achieve net zero value chain emissions and to restore more water than we consume in our global operations in 2030. Reducing our emissions and helping our suppliers to do the same is our top priority to reach our climate target.', 'This year, weannounced a new partnershipwith Stripe, Alphabet, Shopify and McKinsey Sustainability to launch Frontier, an advanced market commitment to help scale emerging carbon removal technologies that are crucial to tackling climate change.', 'As evidenced by the COVID-19 pandemic, we have an essential role to play during global crises in connecting people to accurate information. That’s why we’ve built and expanded a number of tools to provide authoritative information about the realities of climate change.', 'We’vecreated a new pagethatexplains our holistic approach to addressing climate content and misinformation on our apps. Our investment in theClimate Misinformation Grant Programis forging new partnerships and initiatives, and ourPublic Ad Librarygives an extra layer of transparency into all climate ads.', '', '', 'After ourlargest-ever global survey about climate changethis past spring painted a picture of deep concern among respondents, we have seen meaningful change happen when communities come together. More than 40 million people around the world are part of at least one of the 24,000 Facebook Groups dedicated to the discovery, protection and appreciation of the earth and our environment.', '', 'We’re testing a new feature in Facebook Groups, called Climate Pledges, which leverages the power ofcommunities to enable climate action. Developed with inputs from the UN Environment Programme and UN’s ActNow, the Climate Pledges feature contains expert-backed climate solutions to spark conversation and help people understand the most impactful actions they can take. Group admins can choose the solutions most relevant to their communities, invite group members to join, provide support and offer tips to keep everyone accountable. For example, a solar panel group admin may choose to activate the “Switch to renewable energy” pledge and group members commit to joining it together. Group members can also discover relevant content, including Reels, from across Facebook which they can then localize to their communities.', '', 'OurBoost Guide to GreenProgram has reached 1.3 million small and medium-sized businesses (“SMBs”) on how to become greener.We released anew reportin October, in partnership with Accenture, which explores the relationship between SMBs and climate action, and how digital technology can support them. OurData for Goodprogram also provided data from our small business surveys to the World Trade Organization, which published areporton small businesses’ experiences and challenges related to climate change.', 'We also launched theClimate Perceptions Index, developed by theSocial Progress Imperative, using datafrom our 2022Climate Change Opinion Survey. It offers information on the societal implications of climate change with new data on people’s awareness of climate change, their perception of its risks and their commitment to climate action.', 'Finally, we have collaborated with the World Resources Institute on prevention campaigns to reduce food waste, reaching more than 40 million people in Germany and the UK. We’ll use the insights we gain from these campaigns toinformfuture work.']\n",
            "11 ['Update on August 16, 2022 at 10:30AM PT:', 'As part of our work to protect the 2022 election in Brazil, we will prohibit ads calling into question the legitimacy of the upcoming election.', 'Originally published on August 12, 2022 at 6:00AM PT:', 'Today, we want to share our work to protect the integrity of presidential elections taking place in Brazil in October 2022. In recent years, we’ve increased our efforts to combat misinformation by investing in teams, technology and partnerships to ensure the safety of people using Meta’s platforms.', 'Since 2016, we’ve quadrupled our security and integrity workforce to more than 40,000 people globally. Last year alone, we invested nearly $5 billion in both areas.', 'We know that local knowledge is essential for this work to be effective, so we also have a large team of specialists based in Brazil who have a deep understanding of the situation. These efforts are intensified as the election approaches, and our work to protect the integrity of our platforms will continue after the vote.', 'Removing content that violates our policies on voter suppression, such as posts that discourage people from voting, is among our many responses to potential interference in the electoral process. We take many actions to prevent hate speech or the incitement of violence on our platforms.', 'Currently, 99.7% of the fake accounts we remove from Facebook are deleted by artificial intelligence, before they are reported by users. We also investigate and disrupt networks that use fake accounts in a coordinated way to influence public debate.', 'Closer to October, we will activate an Elections Operations Center focused on Brazil, an initiative we’ve implemented since 2018, to bring together experts from across the company – including intelligence, data science, engineering, research, operations, public policy and legal teams. They work together to identify potential threats on our platforms in real time, accelerating our response time.', 'In partnership with Brazil’s Superior Electoral Court (TSE), in December 2021 we started adding a label to posts about political elections on Facebook and Instagram, directing people to reliable information on the Electoral Justice website. In the first two months after its launch, the label led to a 10-fold increase in visits to the Electoral Justice portal.', 'Between the end of April and the beginning of May, we posted reminders on Facebook for users to request or update their voter cards. The content was seen by the majority of adults using Facebook in Brazil and more than three\\xa0 million people clicked to see more information. Closer to the upcoming election, we will again display reminders on Facebook and Instagram about voting day to raise awareness among voters and reduce abstention rates.', 'For the first time, the TSE will be able to report content directly on Facebook and Instagram that may violate our policies. We will analyze the reports once they are received.', 'WhatsApp launched an extrajudicial channel of communication in the 2020 municipal election to receive complaints from the TSE. The focus is on quick response to potential cases of bulk messaging, which is forbidden by local electoral law and by the app’s terms of service.', 'We also developed a virtual assistant on WhatsApp with the TSE, as we did during Brazil’s 2020 municipal election. The chatbot is accessible through the number +55 61 9637-1078. It allows voters to interact directly with the electoral authority and receive relevant information about the vote.', 'Meta has hosted training sessions for electoral officials all over Brazil to explain our actions to curb misinformation, share details on how Facebook and Instagram work, and detail our content rules, which we call our Community Standards and Community Guidelines. We also offer workshops to candidates and their campaign teams.', 'The partnership with the TSE also includes booklets with information for the electoral community and a guide to combating online violence against women in politics, also supported by the Women’s Democracy Network (WDN) – Brazil Chapter.', 'We remove content on Facebook and Instagram that discourages voting or interferes with voting, such as incorrect information about the election date or candidates’ numbers.', 'We also work with independent fact-checking organizations to verify the veracity of reported posts that don’t violate our Community Standards. When fact-checkers mark a post as false, we reduce its reach on Facebook and Instagram.', 'People who still see this content in their feeds will see it covered with a label and a link directing them to more information from the fact-checker. In July, we increased the number of partners in our fact-checking initiative in Brazil from four to six including: Agência Lupa, AFP, Aos Fatos, Estadão Verifica, Reuters Fact Check and UOL Confere.', 'Since messages on WhatsApp are end-to-end encrypted, we fight misinformation on WhatsApp through measures to reduce message virality.', 'Messages forwarded on WhatsApp are identified with a tag. Since 2020, messages with five or more forwards can be resent to just one conversation, which has led to a 70% global reduction in the number of frequently forwarded messages. This year, we implemented a new forwarding limit on WhatsApp: now, any forwarded message can only be forwarded again to one WhatsApp group at a time.', 'In 2018, we launched our transparency tools for ads about politics and elections on Facebook and Instagram in Brazil. In 2020, we began requiring advertisers who wish to run ads about elections or politics to complete an authorization process and include “Paid for by” disclaimers on these ads. This year, we’ve expanded that requirement to ads about social issues such as economics, security and education.', 'All posts with the “Paid for by” disclaimer go to the Ad Library, where they are stored for seven years. The tool is open and provides anyone with detailed information about political ads including\\xa0 the ad source account, audience demographics and estimated spending range, among other data.', 'Protecting the integrity of the Brazilian election in 2022 on our apps is a priority for Meta. We will continue to share updates on how we move forward with this work.', 'Seemore information about our work on elections.']\n",
            "12 ['Update on June 16, 2023 at 6:00AM PT:', 'Today, we are releasing our response to the recommendations the Oversight Board made in their Covid-19 misinformationPolicy Advisory Opinion.', 'We will take a more tailored approach to our Covid-19 misinformation rules consistent with the Board’s guidance and our existing policies. In countries that have a Covid-19 public health emergency declaration, we will continue to remove content for violating our Covid-19 misinformation policies given the risk of imminent physical harm. We are consulting with health experts to understand which claims and categories of misinformation could continue to pose this risk. Our Covid-19 misinformation rules will no longer be in effect globally as the global public health emergency declaration that triggered those rules has been lifted.', 'To learn more about our response to the board, visit ourTransparency Center.', 'Originally published on July 26, 2022 at 5:00AM PT:', 'Meta is asking the Oversight Board for advice on whether measures to address dangerous COVID-19 misinformation, introduced in extraordinary circumstances at the onset of the pandemic, should remain in place as many, though not all, countries around the world seek to return to more normal life.', 'Misinformation related to COVID-19 has presented unique risks to public health and safety over the last two years and more. To keep our users safe while still allowing them to discuss and express themselves on this important topic, we broadened our harmful misinformation policy in the early days of the outbreak in January 2020. Before this, Meta only removed misinformation when local partners with relevant expertise told us a particular piece of content (like a specific post on Facebook) could contribute to a risk of imminent physical harm. The change meant that, for the first time, the policy would provide for removal of entire categories of false claims on a worldwide scale.', 'As a result, Meta has removed COVID-19 misinformation on an unprecedented scale. Globally, more than 25 million pieces of content have been removed since the start of the pandemic. Under this policy, Meta began removing false claims about masking, social distancing and the transmissibility of the virus. In late 2020, when the first vaccine became available, we also began removing further false claims, such as the vaccine being harmful or ineffective. Meta’s policy currentlyprovides for removal of 80 distinct false claimsabout COVID-19 and vaccines.', 'Meta remains committed to combating COVID-19 misinformation and providing people with reliable information. As the pandemic has evolved, the time is right for us to seek input from the Oversight Board about our measures to address COVID-19 misinformation, including whether those introduced in the early days of an extraordinary global crisis remains the right approach for the months and years ahead. The world has changed considerably since 2020. We now haveMeta’s COVID-19 Information Center, and guidance from public health authorities is more readily available. Meta’s COVID-19 Information Center has connected over two billion people across 189 countries to helpful, authoritative COVID-19 information.', 'The pandemic itself has also evolved. In many countries, where vaccination rates are relatively high, life is increasingly returning to normal. But this isn’t the case everywhere and the course of the pandemic will continue to vary significantly around the globe — especially in countries with low vaccination rates and less developed healthcare systems.It is important that any policy Meta implements be appropriate for the full range of circumstances countries find themselves in.', 'Meta is fundamentally committed to free expression and we believe our apps are an important way for people to make their voices heard. But some misinformation can lead to an imminent risk of physical harm, and we have a responsibility not to let this content proliferate. The policies in ourCommunity Standardsseek to protect free expression while preventing this dangerous content. But resolving the inherent tensions between free expression and safety isn’t easy, especially when confronted with unprecedented and fast-moving challenges, as we have been in the pandemic. That’s why we are seeking the advice of the Oversight Board in this case. Its guidance will also help us respond to future public health emergencies.', 'The Oversight Board was established to exercise independent judgment, operating as an expert-led check and balance for Meta, with the ability to make binding decisions on specific content cases and to offer non-binding advisory opinions on its policies. We are requesting an advisory opinion from the Oversight Board on whether Meta’s current measures to address COVID-19 misinformation under our harmful health misinformation policy continue to be appropriate,or whether we should address this misinformation through other means, like labeling or demoting it either directly or through our third-party fact-checking program.']\n",
            "13 ['Today, we’re sharing an update on our work to help ensure a safe and secure General Election in Kenya on August 9.', 'We’ve been preparing for the country’s 2022 election over the past year with the help of a dedicated team that’s working closely with election authorities and trusted partners in the country. Additionally, we’ve invested in people and technology to help reduce the spread of misinformation, detect and remove hate speech, improve digital literacy and help make political advertising more transparent.', 'Meta has establishedoperations centresfor major elections around the world since 2018, including in Kenya.', 'Our team dedicated to the Kenyan election includes experts from Kenya and people who have spent a significant amount of time in the country, which we believe is critical to understanding the local landscape. With their help, we continue to respond to potential problems and abuse that might emerge in the country.', 'In order to quickly identify and remove content that violates ourCommunity Standards, we use a combination of artificial intelligence, human review and user reports. Our Community Standards include strict rules against hate speech, voter suppression, harassment and inciting violence, among others. We’ve also built more advanced detection technology, quadrupled the size of our global team focused on safety and security to more than 40,000 people and hired more content reviewers to review content across our apps in more than 70 languages — including Swahili.In thesix months leading up to April 30, 2022, we took action on more than 37,000 pieces of content for violating ourHate Speech policieson Facebook and Instagram in Kenya. During that same period, we also took action on more than 42,000 pieces of content that violated ourViolence & Incitement policies.', 'Informed by local challenges around increased abuse against female public figures, we formed a working group for the protection of female public figures during the Kenya elections. Partnering with local civil society organisations such as Kenya Women Parliamentary Association (KEWOPA), Pollicy and UN Women, we trained women members of Parliament, aspirants and human rights defenders toutilise our safety tools and resourcesto ensure a safer experience across our technologies. We also continue to work with participants to further understand the gender-based slurs used online in local languages, with the aim of helping to address these during the elections.', 'To reduce misinformation and lower the risk of problematic content in Kenya ahead of and during the elections, we’re temporarily reducing the distribution of content from those who have repeatedly or severely violated our policies.', 'In 2021 we announced new rules for WhatsApp that included reducing the number of people you can send a highly forwarded WhatsApp message to, to justone chat at a time. Since then, we’ve seen a 70% drop in the number of highly forwarded messages on WhatsApp. We also introduced this forward limit on Messenger, so messages can only be forwarded to five people or groups at a time. We know that limiting forwarding is an effective way to slow the spread of viral misinformation and harmful content that has the potential to cause offline harm.', 'We remove the most serious kinds of misinformation from Facebook and Instagram, such as content that is intended to suppress voting or could contribute to imminent violence or physical harm. During the Kenyan elections, based on guidance from local partners, this will specifically include false claims that people with weapons are guarding polling stations, false claims that polling stations have been damaged and photos and videos shared out of context depicting ballot-stuffing or violence.', 'For content that doesn’t violate these particular policies, we’ve partnered with independent third-party fact-checkers in Kenya — AFP, Pesa Check and Africa Check, who review content in both English and Swahili. When a piece of content is reviewed and rated as false, we reduce its distribution and add a warning label with additional information.', 'In addition to combating the spread of misinformation on our platforms, we’re working with local partners to improve digital and media literacy in Kenya. Programs likeMy Digital Worldare focused on raising awareness amongst youth, teachers, parents and guardians on topics such as online safety, privacy, digital citizenship, news and media literacy, delivered through live webinars. We also partnered withiEARN Kenyato provide teachers and parents with lessons on how to safely guide people through the digital world. We also work with UNESCO, through the EU-funded project Social Media for Peace in Kenya. This programme aims to address concerns around the use of digital communication tools as platforms to spread harmful content.', 'We’re also taking to the airwaves on local radio in Kenya, to educate listeners on how to spot hate speech and misinformation, and what actions to take. These have been running in multiple local languages including Luo, Kalenjin, Kikuyu, Swahili as well as English.', 'Our Ad Transparency tools help people understand who’s behind the political ads they see on Facebook and Instagram. Advertisers who want to runpolitical ads in Kenya must undergo a verification process to verify their identity and that they live in the country. We then run additional checks to ensure their compliance with our policies, and political ads must be labelled with a “Paid for by” disclaimer to show who’s behind it.In the six months leading up to April 30, about 36,000 ad submissions targeted to Kenya were rejected before they ran for not completing the authorization process or not attaching a disclaimer.', 'We also ensure that political ads run in Kenya are included in ourAds Libraryso everyone can see what ads are running, see information about targeting and find out how much money was spent. People can also personalise their feeds and choose to see fewerpolitical ads.', 'Helping to build informed and engaged communities is central to our work around elections. In Kenya, we’ll have an “I Voted” sticker on Instagram. And on Election Day, we’ll remind people in the country that it’s time to vote with a notification on top of their Facebook Feed as well.']\n",
            "14 ['Jump to latest newsUkrainian\\xa0translation,Russian translation', 'Update on March 17, 2022 at 9:00AM PT:', 'We’re continuing to see our community come together to help people fleeing the war in Ukraine. Today, we’re sharing a few updates to make it easier for people to get information and offer support.', '', 'Update on March 11, 2022 at 4:00PM PT:', 'Head of Instagram Adam Mosseri responded to Russia’s decision to block access to Instagram:', '', 'A post shared by Adam Mosseri (@mosseri)', '', 'Update on March 11, 2022 at 3:30PM PT:', 'President, Global Affairs Nick Clegg’s statement to reports that the Russian government is considering designating Meta as an extremist organization for its policies in support of speech:', 'There has been a lot of coverage and discussion of how we are applying our policies to speech in the context of Putin’s invasion of Ukraine.', 'I want to be crystal clear: our policies are focused on protecting people’s rights to speech as an expression of self-defense in reaction to a military invasion of their country. The fact is, if we applied our standard content policies without any adjustments we would now be removing content from ordinary Ukrainians expressing their resistance and fury at the invading military forces, which would rightly be viewed as unacceptable.', 'To be clear, we are only going to apply this policy in Ukraine itself. We have no quarrel with the Russian people. There is no change at all in our policies on hate speech as far as the Russian people are concerned. We will not tolerate Russophobia or any kind of discrimination, harassment or violence towards Russians on our platform.', 'This is a temporary decision taken in extraordinary and unprecedented circumstances. We will be keeping the situation under review in the period ahead.', 'Update on March 8, 2022 at 9:00PM PT:', 'As the humanitarian crisis deepens, today we are announcing additional steps to help our community access crucial resources and take action to support people in need.', 'Helping People Access Resources', 'This slideshow requires JavaScript.', 'Helping People Show Support for Ukraine', '', 'Update on March 8, 2022 at 8:00AM PT:', 'Today, we’re sharing updates that we’re making on Instagram to help keep people in Ukraine and Russia safe and reduce the spread of misinformation.', 'Keeping Information and Associations Private on Instagram:To help protect our communities in Ukraine and Russia, we’ll now be hiding information about people’s followers, who they’re following, and people who are following each other for private accounts based in these two countries.', 'This means that people following private accounts based in Ukraine and Russia will no longer be able to see who those accounts are following, or who follows them. We’re also not showing these accounts in other people’s follower or following lists, or in our “mutual follows” feature. We notified private accounts in Ukraine and Russia letting them know about this change.', 'We’re also highlighting tools likeYour ActivityandDownload Your Informationto accounts in Ukraine and Russia. Your Activity \\u200b\\u200ballows people to bulk delete content they’ve posted like photos and videos, as well as their previous likes and comments.Download Your Informationallows people to get a copy of their Instagram data.', '', 'Addressing Russian State-Controlled Media on Instagram:Following last week’s announcement that we’ve begun demoting posts containing links to Russian state-controlled media on Facebook, starting today, Stories that contain a link sticker pointing to a Russian state-controlled media website on Instagram will be placed lower in the Stories tray. We’ll also label these Stories to let people know that they lead to Russian state-controlled media websites.', '', 'These changes are in addition to steps we’ve already taken to make content from accounts run by Russian state-controlled media harder to find on Instagram, and to provide more transparency if people try to share content from these accounts.', 'Specifically, we’re downranking posts from Russian state-controlled media in Feed, and placing them lower in the Stories tray. We’re also showing people a notice before they reshare content from these accounts in their Stories, letting them know that the content comes from Russian state-controlled media. If people still choose to reshare these posts to their Stories, we will place those Stories lower in the tray.', '', 'Lastly, we’re not recommending posts from Russian state-controlled media accounts in Explore and Reels, and we’re making these accounts harder to find in Search.', 'Update on March 4, 2022 at 3:00PM\\xa0 PT:', 'Despite the Russian government’s announcement that they will be blocking Facebook, we are working to keep our services available to the greatest extent possible. However, due to the difficulties of operating in Russia at this time, ads targeting people in Russia will be paused, and advertisers within Russia will no longer be able to create or run ads anywhere in the world, including within Russia.', 'Update on March 4, 2022 at 11:15AM PT:', 'Update on Russia’s Decision to Block Access to Facebook:As a result of the Russian government’s decision to block access to Facebook in the Russian Federation, soon millions of ordinary Russians will find themselves cut off from reliable information, deprived of their everyday ways of connecting with family and friends and silenced from speaking out. We will continue to do everything we can to restore our services so they remain available to people to safely and securely express themselves and organize for action.', 'Update on Restricting Access to RT and Sputnik:Earlier this week, we announced that we’d be restricting access to RT and Sputnik across the EU given the exceptional circumstances. Consistent with that action, and following a request from the UK government, we will also be restricting access to RT and Sputnik in the UK at this time.', 'Update on March 3, 2022 at 4:50PM PT:', 'Increasing Our Support for Humanitarian Efforts: Today, we’re committing $15 million to support humanitarian efforts in Ukraine and neighboring countries. This includes $5 million in direct donations to UN agencies and more than a dozen nonprofits, including International Medical Corps who will be using these funds to deploy mobile medical units to Ukraine and Internews to support at-risk journalists and human rights defenders in the region. We’re also donating to UNICEF to scale up lifesaving support for children and families in Ukraine and the region.The remaining $10 million will be provided as ad credits, helping nonprofit organizations raise the funds they need to respond and deliver essential information to people impacted by the violence.', 'Update on March 1, 2022 at 6:05PM PT:', 'Update on State-Controlled Media Outlets:In addition to restricting access to RT and Sputnik across the EU, we are now globally demoting content from Facebook Pages and Instagram accounts from Russian state-controlled media outlets and making them harder to find across our platforms.', 'We have also begun to demote posts that contain links to Russian state-controlled media websites on Facebook. In the days ahead, we will label these links and provide more information to people before they share or click on them to let them know that they lead to Russian state-controlled media websites. We plan on putting similar measures in place on Instagram.', 'We already label Facebook Pages and Instagram accounts from Russian state-controlled media outlets so people know where this information comes from. By providing this additional transparency, we aim to give people more context if they want to share direct links to Russian state-controlled media websites or when others see someone’s post that contains a link to one of these sites.', 'Reliable Access to Trusted Information:Ukraine’s State Emergency Services has launched an information helpline on WhatsApp. The free service will connect users to critical updates, reliable and trustworthy information, as well as details about emergency response procedures. To use the free helpline on WhatsApp, simply save the number+380676785917in your phone contacts and then text the word почати (begin) in a WhatsApp message to get started.', 'How Our Community Is Helping:Throughout this war and humanitarian crisis, we’ve seen people across the world use our tools to make their voices heard and support each other. For example, since February 23, more than $20 million has been raised for nonprofits on Facebook and Instagram in support of humanitarian efforts for Ukraine.(Updated on March 2, 2022 at 10AM PT to reflect the latest fundraising amount.)We’ve also seen Facebook Groups created to help those in need, including a group of 200,000 Romanian volunteers and donors coordinating transportation and accommodations for refugees. And a group of more than 300,000 in Poland is offering housing, clothing, medication and rides from the border to help those in need.', 'Today, we’re also announcing that as part of ourData for Good program, we’re making aggregated data on social connections available to trusted organizations working to provide medical services and support to refugees, like Direct Relief, which is using this data to better understand where people might be going so they can best support communities in need.', 'Update on February 28, 2022 at 5:55PM PT:', 'We have received requests from a number of governments and the European Union to take further steps in relation to Russian state-controlled media. Given the exceptional nature of the current situation, we will be restricting access to RT and Sputnik across the EU at this time.', 'As of this morning, we’ve made encrypted one-to-one chats available on Instagram for all adults in Ukraine and Russia. We’ll also show notifications at the top of people’s direct message inboxes to let them know they can switch to an encrypted conversation if they want to. End-to-end encrypted chats are already available as an option on Messenger and by default on WhatsApp. This update is not available to business accounts on Instagram.', 'Update on February 27, 2022 at 9:00PM PT:', 'We took down a network run by people in Ukraine and Russia targeting Ukraine for violating our policy againstcoordinated inauthentic behavior. They ran websites posing as independent news entities and created fake personas across many social media platforms including Facebook, Instagram, Twitter, YouTube, Telegram, Odnoklassniki and VK.', 'We’ve also seen increased targeting of Ukrainian military and public figures by Ghostwriter, a threat actor that has beentrackedfor some time by the security community. We encourage people in Ukraine and Russia to adopt stronger account security measures — like two-factor authentication — to protect their information in the midst of this invasion. We continue to roll out privacy and security measures to help people in Ukraine and Russia protect their accounts from being targeted.', 'Learn more about oursecurity updates in Ukraine.', 'Update on February 27, 2022 at 11:45AM PT:', 'We have been in contact with the government of Ukraine. At their request, we have restricted access to several accounts in Ukraine, including those belonging to some Russian state media organizations. We are also reviewing other government requests to restrict Russian state-controlled media.', 'Originally published on February 26, 2022 at 11:50AM PT:', 'Our thoughts are with everyone affected by the war in Ukraine. We are taking extensive steps across our apps to help ensure the safety of our community and support the people who use our services — both in Ukraine and around the world.', 'The following are some of the specific steps we have taken regarding Russia’s invasion of Ukraine:', 'We’ve added several safety features in Ukraine in response to the situation on the ground.', 'We are taking additional steps to enforce our Community Standards and Community Guidelines, not only in Ukraine and Russia but also in other countries globally where content may be shared.', 'We are taking extensive steps to fight the spread of misinformation on our services and continuing to consult with outside experts.', 'We providegreater transparencyon accounts from state-controlled media outlets, including Russian-based RT and Sputnik, because they combine the influence of a media organization with the strategic backing of a state, and we believe people should know if the news they read is coming from a publication that may be under the influence of a government.', 'We remain vigilant to emerging trends and stand ready to take additional action to meet the demands of this ongoing conflict.', 'Оновлено 17 березня 2022 року о 9:00AM PT:', 'Ми продовжуємо спостерігати за об’єднанням нашої спільноти, що має на меті допомагати людям, які тікають від війни в Україні. Сьогодні ми хочемо поділитися деякими оновленнями, які допоможуть людям легше отримувати інформацію та надавати підтримку.', '', 'Оновлено 11 березня 2022 року о 4:00PM PT:', 'Глава Instagram Адам Моссері відповів на рішення Росії заблокувати доступ до Instagram:', '', 'A post shared by Adam Mosseri (@mosseri)', '', 'Оновлено 11 березня 2022 року о 3:30PM PT:', 'Заява Ніка Клегга, президента відділу з міжнародних справ у Мета, у відповідь на повідомлення про те, що російський уряд розглядає можливість включення компанії Мета в список екстремістських організацій за її політику на підтримку деяких висловлювань:', 'Було багато повідомлень і дискусій про те, як ми застосовуємо нашу Політику щодо свободи слова в контексті вторгнення Путіна в Україну.', 'Я хочу бути щирим: наша політика спрямована на захист прав людей на свободу слова, яка є одним з проявів самооборони, у відповідь на військове вторгнення в їхню країну. Справа в тому, що якби ми застосовували нашу стандартну політику щодо контенту без будь-яких коригувань, ми б зараз видаляли контент простих українців, які виражають свій опір і лють по відношенню до військових сил, які вторглися в їхню державу. Такі наші дії були б справедливо розцінені як неприйнятні.', 'Для ще більшої ясності, ми збираємося застосовувати цю політику тільки на території України. У нас немає ніяких непорозумінь з російським народом. У нашій політиці щодо мови ворожнечі немає ніяких змін в тому, що стосується росіян. Ми не потерпимо русофобії або будь-якого виду дискримінації, переслідування або насильства по відношенню до росіян на нашій платформі.', 'Це тимчасове рішення, прийняте в надзвичайних і безпрецедентних обставинах. Ми будемо стежити за розвитком цієї ситуації в майбутньому.', 'Оновлено 8 березня о 9:00PM PT:', 'Сьогодні ми оголошуємо про запровадження додаткових заходів, які допоможуть нашій спільноті отримати доступ до найважливіших ресурсів, а також вжити заходів для підтримки людей, які цього потребують, у зв’язку із подальшим розвитком\\xa0 гуманітарної кризи.', 'Допомога людям у доступі до ресурсів', 'Допомагаємо людям демонструвати їхню підтримку Україні', 'Оновлено 8 березня 2022 року о 8:00AM PT:', 'Сьогодні ми ділимося нашими оновленнями в Instagram, які мають допомогти захистити людей в Україні та Росії, а також зменшити поширення дезінформації.', 'Збереження конфіденційності інформації та зв’язків в Instagram:з метою захисту наших спільнот в Україні та Росії, відтепер ми будемо приховувати інформацію про Ваших підписників, підписки та взаємні підписки. Ці зміни стосуються приватних облікових записів людей, які проживають на території цих двох країн.', 'Це означає, що люди, які стежать за приватними акаунтами користувачів з України та Росії, більше не зможуть побачити, за ким стежать ці акаунти або хто стежить за ними. Ми також не будемо показувати ці облікові записи серед підписників інших людей, а також у нашій функції “взаємні підписки”. Ми вже повідомили власників приватних акаунтів з України та Росії про ці зміни.', 'Власникам акаунтів в Україні та Росії ми також нагадуємо про існування таких функцій як: “Ваша активність” та “Завантажити інформацію”. Функція “Ваша активність” дозволяє людям масово видаляти розміщений ними контент, наприклад, фотографії та відео, а також попередні лайки і коментарі. “Завантажити\\xa0 інформацію” дозволяє людям отримати копію своїх даних в Instagram.', 'Наша відповідь російським державним ЗМІ в Instagram:Минулого тижня ми оголосили про початок зниження рейтингів постів, що містять посилання на російські державні ЗМІ у Facebook. А вже від сьогодні Stories, що містять стікер з посиланням на сайт російського державного ЗМІ в Instagram, будуть розміщуватися в кінці стрічки. Ми також будемо відповідним чином позначати ці Stories для інформування людей про те що ці посилання ведуть на сайти російських державних ЗМІ.', 'Ці зміни доповнюють кроки, які ми вже встигли зробити, щоб контент від російських державних ЗМІ було складніше знайти в Instagram. Крім цього, це було зроблено для забезпечення більшої прозорості, якщо люди намагатимуться поділитися інформацією, розміщеною на сторінках цих ЗМІ.', 'Зокрема, ми знижуємо рейтинг постів від російських державних ЗМІ у загальній стрічці, а також розміщуємо їх далі у стрічці Stories. Крім цього, перш ніж люди захочуть зробити репост будь-якої інформації з цих сторінок до себе у Stories, ми сповіщатимемо їх, що інформація належить російським державним ЗМІ. Якщо люди все ж вирішать зробити репост з тих сторінок до себе у Stories, ми розмістимо ці історії далі в стрічці.', 'Підсумовуючи, ми не рекомендуємо публікувати інформацію зі сторінок російських державних ЗМІ в Explore і Reels, а також ускладнюємо пошук таких акаунтів.', 'Оновлено 4 березня 2022 року о 3.00PM PT:', 'Незважаючи на оголошення російського уряду про блокування Facebook на території країни, ми працюємо над тим, щоб наші послуги залишалися доступними якомога довше. Однак через труднощі в функціонуванні на території Росії, рекламу орієнтовану на її мешканців, буде призупинено. Крім цього, російські рекламодавці більше не матимуть змогу створювати або показувати рекламу в будь якій точці світу, в тому числі в Росії.', 'Оновлено 4 березня 2022 року о 11:15PM PT:', 'Актуальна інформація щодо рішення Росії про блокування доступу до Facebook: У результаті рішення російського уряду про блокування доступу до Facebook на території Російської Федерації, незабаром мільйони звичайних росіян будуть відрізані від достовірної інформації, позбавлені своїх повсякденних способів спілкування з родиною та друзями та не матимуть можливості вільно висловити свої думки. Ми продовжуватимемо робити все можливе задля відновлення наших послуг в країні, щоб вони залишалися доступними для людей, які хочуть безпечно та вільно висловлювати свою думку та організовуватись до дій.', 'Актуальна інформація щодо обмеження доступу до RT і Sputnik: Раніше цього тижня ми вже оголосили, що обмежимо доступ до RT і Sputnik на території всього Європейського Союзу з огляду на виняткові обставини. Відповідно до цього рішення та на прохання уряду Великобританії, на цей час ми також обмежимо доступ до RT і Sputnik у Великій Британії.', 'Оновленo 3 березня 2022 року о 4:50 PM PT:', 'Збільшуємо нашу гуманітарну допомогу:Сьогодні ми виділяємо 15 мільйонів доларів на гуманітарну допомогу для України та сусідніх країн. З них 5 мільйонів доларів у вигляді прямих пожертвувань будуть перераховані понад десятьом некомерційним організаціям, а також агенціям ООН.\\xa0 До цих організацій належать Міжнародний медичний корпус, який використовуватиме ці кошти для розгортання мобільних медичних підрозділів в Україні, та Інтерньюз, що підтримуватиме\\xa0 журналістів і правозахисників, які перебувають в зонах ризику. Ми також надамо кошти для ЮНІСЕФ з метою збільшення життєво необхідної допомоги дітям та сім’ям в Україні і в цілому регіоні. 10 мільйонів доларів у вигляді рекламних купонів будуть надані некомерційним організаціям, щоб допомогти їм зібрати необхідні кошти для реагування на потреби людей та надання необхідної інформації тим, хто постраждав від жорстокостих подій.', 'Оновлено 1 березня 2022 року о 6:05 PM PT:', 'Актуальна інформація щодо державних ЗМІ: Ми обмежуємо доступ до RT і Sputnik на території ЄС. Крім того, ми глобально знижуємо рейтинг сторінок Facebook і акаунтів Instagram, що належать російським державним ЗМІ, тому їх складніше знайти на наших платформах.', 'Ми також почали знижувати рейтинг дописів на Facebook, що містять посилання на сайти російських державних ЗМІ. У найближчі дні ми будемо відповідно позначати ці посилання і надавати людям більше інформації про те, що дані веб-адреси ведуть на сайти російських державних ЗМІ, ще перед тим, як користувачі вирішать перейти за посиланнями, або поділитись ними з іншими. Ми плануємо вжити аналогічних заходів також в Instagram.', 'Ми вже позначаємо сторінки в Facebook і акаунти в Instagram російських державних ЗМІ, щоб люди знали, звідки надходить інформація. З метою забезпечення прозорості, ми прагнемо надавати людям більше контексту в моменті, коли вони хочуть поділитися посиланнями російських державних ЗМІ, або ж коли бачать публікації, що містять ці посилання.', 'Надійний доступ до достовірної інформації:Державна служба з надзвичайних ситуацій України запустила інформаційну гарячу лінію в WhatsApp. Ця безкоштовна послуга дозволяє користувачам отримувати важливі сповіщення, надійну і достовірну інформацію, а також детальні інструкції про те,як варто реагувати в надзвичайних ситуаціях. Щоб скористатися безкоштовною гарячою лінією в WhatsApp, просто збережіть номер +380676785917 в контактах телефону, а потім напишіть слово “почати”(або“begin”)в чаті WhatsApp, для того, щоб її активувати.', 'Допомога від нашої спільноти:протягом цієї кризи ми бачимо, як люди по всьому світу використовують наші інструменти, щоб підтримувати один одного і давати про себе знати. Наприклад, на підтримку некомерційних організацій, що надають гуманітарну допомогу Україні, з 23 лютого на Facebook і Instagram було зібрано понад 20 мільйонів доларів. Ми також помітили численні групи в Facebook, створені для надання\\xa0 допомоги людям, котрим вона необхідна. До цих груп належить спільнота з 200 000 румунських волонтерів та донорів, які координують надання транспорту та житла для біженців, а також польська група з більш ніж 300 000 учасників, що забирає постраждалих людей з кордону, пропонує їм житло, одяг та медикаменти.', 'Сьогодні ми оголошуємо, що в рамках нашої програми “Data for Good” ми ділимося доступом\\xa0 до збору даних\\xa0 з довіреними організаціями, які працюють над тим, щоб надати біженцям допомогу, зокрема медичну. Серед них є організація Direct Relief, яка використовує наші дані з метою дізнатися більше про те, куди саме направляються біженці, щоб допомогти їм.', 'Оновлено 28 лютого 2022 року о 5:55PM PT:', 'Ми отримали низку запитів від ряду урядів і Європейського Союзу про вжиття подальших заходів по відношенню до російських ЗМІ, контрольованих державою. Враховуючи винятковий характер даної ситуації, ми будемо обмежувати доступ до таких ЗМІ, як RT і Sputnik на всій території ЄС.', 'Починаючи від сьогоднішнього ранку, ми зробиличати з наскрізним шифруваннямдоступними в Instagram для всіх дорослих користувачів в Україні та в Росії. Сповіщення про можливість створення чатів з наскрізним шифруванням, люди зможуть побачити зверху своєї скриньки для\\xa0 приватних повідомлень. Наскрізні зашифровані чати вже доступні в Messenger та за замовчуванням WhatsApp. Але це оновлення не буде доступним для бізнес-акаунтів в Instagram.', 'Оновлено 27 лютого 2022 року о 9:00 PM PT:', 'Ми видалили мережу націлену на Україну, якою керували люди Росії та України, за порушення нашої політики протискоординованої неавтентичної поведінки.Ці люди керували веб-сайтами, видаючи себе за незалежні ЗМІ, та створювали фальшиві облікові засоби на багатьох платформах в соціальних мережах, включаючи Facebook, Instagram, Twitter, YouTube, Telegram, “Однокласники” та Вконтакті.', 'Ми також спостерігаємо активізацію атак на українських військових та громадських діячів з боку Ghostwriter – злочинної кіберорганізації, яка вже деякий часвідстежуєтьсяспільнотою безпеки. Ми закликаємо жителів України та Росії вжити жорсткіших заходів щодо безпеки своїх облікових записів – наприклад, двофакторну аутентифікацію – для захисту своєї інформації в ситуації\\xa0 вторгнення.Ми продовжуємо впроваджувати заходи щодо конфіденційності та безпеки для допомоги людям в Україні та Росії, в цілях захиститу їх облікових записів від атак.', 'Дізнайтесь більше про нашіоновлення щодо безпеки в Україні.', 'Оновлено 27 лютого 2022 року о 11:45AM PT:', 'Ми знаходимося в контакті з урядом України. На його прохання ми обмежили доступ до декількох облікових записів в Україні, включаючи облікові записи, що належать деяким російським державним ЗМІ. Ми також розглядаємо інші запити українського уряду про обмеження доступу до інших російських державних ЗМІ.', '26 лютого 2022 року', 'Ми разом в думках з усіма, хто постраждав від війни в Україні. Ми впроваджуємо значні заходи в наших додатках, щоб забезпечити нашу спільноту і підтримати людей, які користуються нашими послугами — як в Україні, так і по всьому світу.', 'Нижче наведені деякі з конкретних дій, які були впроваджені у зв’язку з вторгненням Росії в Україну.', 'Зважаючи на ситуацію в Україні\\xa0 ми додали декілька функцій безпеки:', 'Ми вживаємо додаткових заходів, щоб забезпечити дотримання наших Стандартів та основних принципів спільноти не лише в Україні та Росії, а й в інших країнах світу, де контент може бути поширеним.', 'Ми вживаємо широких заходів для боротьби з поширенням неправдивої інформації на наших сервісах і продовжуємо консультуватись в справі цього з зовнішніми експертами.', 'Ми забезпечуємобільшу прозорістьоблікових записів державних ЗМІ, включаючи російські RT і Sputnik, оскільки вони поєднують в собі вплив медійної організації і стратегічну підтримку держави. Ми також вважаємо, що люди повинні знати, чи надходять новини, з якими вони ознайомлюються, від ЗМІ, перебуваючого під впливом уряду.', 'Ми як і раніше пильно стежимо за виникаючими тенденціями і готові зробити додаткові дії відповідно до вимог ситуації, що склалася.', 'Ми знаходимося в контакті з урядом України. На їх прохання ми обмежили доступ до кількох облікових засо\\xa0 в Україні, включаючи рахунк, що належать деяким російським державним ЗМІ. Ми також розглядаємо інші запити уряду про обмеження доступу до російських державних ЗМІ.', 'Обновление от 17 марта 2022, 9:00AM PT:', 'Мы по-прежнему наблюдаем, что наше сообщество объединяется, чтобы помочь людям, которые спасаются от войны в Украине. Сегодня мы делимся несколькими обновлениями, которые помогут людям еще проще получать информацию и оказывать поддержку.', '', 'Обновление от 11 марта 2022 года в 4:00PM PT:', 'Глава Instagram Адам Моссери отреагировал на решение российских властей заблокировать доступ к платформе:', '', 'A post shared by Adam Mosseri (@mosseri)', '', 'Обновление от 11 марта 2022 года в 3:30PM PT:', 'Заявление Ника Клегга, President, Global Affairs, Meta, в ответ на сообщения о том, что российское правительство рассматривает вопрос о включении Meta в список экстремистских организаций за ее политику в поддержку высказываний:', 'Было много освещения в СМИ и обсуждений того, как мы применяем нашу политику в отношении высказываний, касающихся вторжения Путина в Украину.', 'Я хочу быть предельно ясным: наша политика направлена на защиту прав людей на свободу слова как выражения самообороны в ответ на военное вторжение в их страну. Дело в том, что если бы мы применяли нашу стандартную политику в отношении контента без каких-либо корректировок, мы бы сейчас удаляли контент простых украинцев, выражающих свое сопротивление и ярость в отношении вторгшихся военных сил, что справедливо было бы расценено как неприемлемый подход.', 'Для ясности, мы собираемся применять эту политику только в самой Украине. У нас нет вражды с российским народом. В нашей политике в отношении языка ненависти нет никаких изменений в том, что касается россиян. Мы не потерпим русофобии или любого вида дискриминации, преследования или насилия по отношению к россиянам на нашей платформе.', 'Это временное решение, принятое в чрезвычайных и беспрецедентных обстоятельствах. Мы будем следить за предстоящим развитием ситуации.', 'Обновление от 8 марта 9:00PM PT:', 'В связи с усугублением гуманитарного кризиса, сегодня мы объявляем о дополнительных шагах, которые помогут нашему сообществу получить доступ к важнейшим ресурсам и поддержать тех, кто нуждается в этом.', 'Помощь с доступом к ресурсам', 'Обновление раздела “Помощь сообщества”: Мы обновляем раздел “Помощь сообщества” как центральный ресурс на Facebook, где украинцы и другие жители региона могут найти достоверную информацию от местных агентств ООН и обществ Красного Креста. Сюда входит информация о том, куда обращаться за медицинской помощью, как оставаться в безопасности и как получить помощь – как в Украине, так и после пересечения границы с соседними странами. Также существует информационная горячая линия Государственной службы по чрезвычайным ситуациям Украины в WhatsApp, которая позволяет людям получать важную информацию, включая процедуры реагирования на чрезвычайные ситуации. Ссылка на “Помощь сообщества” появится в верхней части лент Facebook и Instagram для людей в Украине или тех, кто недавно выехал в соседние страны, чтобы они знали, что этот ресурс доступен. Он также будет доступен во всем мире на страницеfacebook.com/community_help_ukraine, а также в топе результатов для соответствующих поисковых запросов в Facebook.', 'Добавление ресурсов для ментального здоровья:Мы добавим новые советы и ресурсы от международных организаций, включая Всемирную организацию здравоохранения (ВОЗ) и Международный медицинский корпус (ММК), связанные с психическим здоровьем, в разделеЦентра эмоционального здоровья в Facebook. Эти ресурсы будут доступны по всему миру на украинском, русском и английском языках и будут предлагать информацию о том, что делать во время стресса, и как оказать поддержку детям во время кризиса.', 'Мы поддерживаем организации в их стремлении донести важные сообщения до тех, кто пострадал от кризиса, с помощью бесплатных рекламных кампаний на наших платформах. Вот один из примеров: ВОЗ распространяет информацию о грудном вскармливании для перемещенных матерей, а Международный медицинский корпус (ММК) делится советами о том, как поддержать психическое здоровье.', 'Помощь пользователям в выражении поддержки Украине', 'Обновление от 8 марта 2022 года, 8:00 AM PT:', 'Сегодня мы делимся обновлениями в Instagram, которые помогут обеспечить безопасность людей в Украине и России и уменьшить распространение дезинформации.', 'Сохранение конфиденциальности информации и связей в Instagram:Чтобы помочь защитить наши сообщества в Украине и России, мы будем скрывать информацию о подписчиках, подписках, и о людях, которые друг на друга подписаны, для закрытых аккаунтов из этих двух стран.', 'Это означает, что люди, подписанные на закрытые аккаунты из Украины и России, больше не смогут видеть, кто подписан на эти аккаунты и на кого подписаны они. Мы также не будем показывать эти аккаунты в списках подписчиков и подписок других людей, а также во “взаимных подписках”. Мы уведомили закрытые аккаунты в Украине и России, чтобы они знали об этом изменении.', 'Мы также обращаем внимание аккаунтов в Украине и России на такие инструменты, как “Ваша активность” и “Скачать вашу информацию”. Первый позволяет пользователям массово удалять размещенный ими контент, например, фотографии и видео, а также их лайки и комментарии. Второй инструмент позволяет людям получить копию своих данных Instagram.', 'Российские СМИ, контролируемые государством, в Instagram:В продолжение наших действий по понижению в выдаче постов со ссылками на российские государственные СМИ в Facebook, с сегодняшнего дня Stories в Instagram, содержащие стикер со ссылкой на сайт российского государственного СМИ, будут размещаться ниже в панели Stories. Мы также будем маркировать эти Stories, чтобы люди знали, что они ведут на сайты российских государственных СМИ.', 'Эти изменения дополняют шаги, которые мы уже предприняли, чтобы сделать контент с аккаунтов российских государственных СМИ более трудно обнаруживаемым в Instagram и обеспечить большую прозрачность, когда пользователи пытаются делиться контентом с этих аккаунтов.', 'В частности, мы понижаем в выдаче посты российских государственных СМИ в новостной ленте и размещаем их ниже в панели Stories. Мы также показываем людям уведомление перед репостом контента с этих аккаунтов в Stories, сообщая им, что это контент российских государственных СМИ. Если пользователи все же решат репостнуть эти посты в свои Stories, мы поместим эти Stories ниже в выдаче.', 'Наконец, мы не будем рекомендовать посты российских государственных СМИ во вкладках “Интересное” и Reels, а также усложним поиск этих аккаунтов.', 'Обновление от 4 марта 2022 в 3:00PM PT:', 'Несмотря на заявление российских\\xa0 властей о блокировке Facebook, мы работаем над тем, чтобы наши услуги были доступны, насколько это возможно. Однако, в связи с трудностями работы в России в настоящее время, показ рекламы, таргетированной на людей в России, будет приостановлен, а рекламодатели в России больше не смогут создавать или запускать рекламу для любой точки мира, включая Россию.', 'Обновление от 4 марта 2022 в 11:15AM PT:', 'Обновление касательно решения российских властей заблокировать доступ к Facebook:В результате решения российских властей заблокировать доступ к Facebook на территории Российской Федерации, вскоре миллионы простых россиян окажутся отрезанными от достоверной информации, лишенными повседневных способов связи с семьей и друзьями и возможности высказывать свое мнение. Мы будем продолжать делать все возможное для восстановления наших сервисов, чтобы люди могли безопасно выражать свое мнение и координировать действия.', 'Обновление касательно ограничения доступа к RT и Sputnik:Ранее мы объявили о том, что ограничим доступ к RT и Sputnik на территории ЕС, учитывая исключительные обстоятельства. В соответствии с этим решением и по просьбе правительства Великобритании мы также ограничиваем доступ к RT и Sputnik в Великобритании.', 'Обновление от 3 марта 2022 в 4:50PM PT:', 'Увеличение гуманитарной помощи: Сегодня мы выделяем 15 миллионов долларов на поддержку гуманитарных усилий в Украине и соседних странах. Это включает 5 миллионов долларов в виде прямых пожертвований агентствам ООН и более чем десятку некоммерческим организациям, включая Международный медицинский корпус, который будет использовать эти средства для развертывания мобильных медицинских пунктов в Украине. Помощь также будет направлена Internews для поддержки подвергающихся риску журналистов и правозащитников в регионе. Мы также предоставляем средства ЮНИСЕФ для расширения усилий по оказанию жизненно важной помощи детям и семьям в Украине и регионе. Остальные 10 миллионов долларов будут предоставлены в виде рекламных купонов. Они помогут некоммерческим организациям в сборе средств, необходимых для реагирования и предоставления важной информации людям, пострадавшим в результате военных действий.', 'Обновление от 1 марта 2022 года 6:05 PM PT:', 'Обновление информации о СМИ, контролируемых государством:В дополнение к ограничению доступа к RT и Sputnik на территории ЕС, теперь во всем мире мы также понижаем в выдаче контент со страниц Facebook и аккаунтов Instagram российских государственных СМИ, а также затрудняем их поиск на наших платформах.', 'Мы также начали понижать в выдаче посты, содержащие ссылки на сайты российских государственных СМИ в Facebook. В ближайшие дни мы будем помечать эти ссылки и предоставлять людям больше контекста об источнике информации, прежде чем они поделятся ими или нажмут на них, чтобы они знали, что они ведут на сайты российских государственных СМИ. Мы планируем принять аналогичные меры в Instagram.', 'Мы уже маркируем страницы в Facebook и Instagram аккаунты российских СМИ, контролируемых государством, чтобы люди знали, откуда поступает эта информация. Обеспечивая дополнительную прозрачность, мы стремимся дать людям больше контекста, если они хотят поделиться прямыми ссылками на сайты российских государственных СМИ или когда другие видят чей-то пост, содержащий ссылку на один из этих сайтов.', 'Надежный доступ к достоверной информации: Государственная служба Украины по чрезвычайным ситуациям запустила информационную горячую линию в WhatsApp. Бесплатная услуга позволит пользователям получать важные обновления, надежную и достоверную информацию, а также подробные сведения о процедурах реагирования на чрезвычайные ситуации. Чтобы воспользоваться бесплатным телефоном доверия в WhatsApp, просто сохраните номер +380676785917 в контактах телефона, а затем напишите слово “почати” (начать) в сообщении WhatsApp, чтобы начать общение.', 'Как наше сообщество помогает:На протяжении всего этого кризиса мы видим, как люди по всему миру используют наши инструменты, чтобы быть услышанными и поддержать друг друга. Например, с 23 февраля на платформах Facebook и Instagram было собрано более 20 миллионов долларов для некоммерческих организаций в поддержку гуманитарной помощи для Украины. Мы также видели группы в Facebook, созданные для помощи нуждающимся, включая группу из 200 000 румынских волонтеров и доноров, координирующих транспортировку и размещение беженцев, или польскую группу из более чем 300 000 участников, предлагающую пострадавшим помощь слогистикой после пересечения границы,а также с жильем, одеждой и медикаментами.', 'Сегодня мы также объявляем, что в рамках нашей программы “Data for Good” мы предоставляем агрегированные данные о социальных связях доверенным организациям, работающим над предоставлением медицинских услуг и поддержки беженцам. Например, таким как Direct Relief, которая использует эти данные для лучшего понимания того, куда могут направляться люди, чтобы лучше поддерживать нуждающиеся сообщества.', 'Обновление28 февраля 2022в5:55 PM PT:', 'Мы получили запросы от ряда государств и Европейского союза о принятии дальнейших мер в отношении российских СМИ, контролируемых государством. Учитывая исключительный характер ситуации, мы будем ограничивать доступ к RT и Sputnik на всей территории ЕС в настоящее время.', 'Начиная с сегодняшнего утра, мы сделали зашифрованные приватные чаты доступными в Instagram для всех взрослых пользователей из Украины и России. Мы также будем показывать уведомления в верхней части чатов в Instagram Direct, чтобы дать пользователям знать, что они могут переключиться на зашифрованный чат, если захотят. Сквозные зашифрованные чаты уже доступны в качестве опции в Messenger и по умолчанию в WhatsApp. Это обновление недоступно для бизнес-аккаунтов в Instagram.', 'Обновление 27 февраля 2022 в 9:00PM PT:', 'Мы удалили сеть аккаунтов, которая таргетировалась на Украину и управлялась людьми из Украины и России, за нарушение нашей политики противскоординированного недостоверного поведения. Они управляли веб-сайтами, которые выдавали себя за независимые новостные организации, и создавали фальшивые личности во многих социальных сетях, включая Facebook, Instagram, Twitter, YouTube, Telegram, “Одноклассники” и VK.', 'Мы также наблюдаем активизацию атак на украинских военных и общественных деятелей со стороны Ghostwriter – агента угроз, которого уже некоторое времяотслеживаетсообщество экспертов по безопасности. Мы призываем жителей Украины и России принять более высокие меры безопасности учетных записей – например, двухфакторную аутентификацию – для защиты своей информации в условиях этого вторжения.Мы продолжаем внедрять меры по обеспечению конфиденциальности и безопасности, чтобы помочь жителям Украины и России защитить свои аккаунты от атак.', 'Узнайте большео наших обновлениях безопасности в Украине.', 'Обновление от 27 февраля 2022 г. в 11:45 AM PT:', 'Мы находимся в контакте с правительством Украины. По их просьбе мы ограничили доступ к нескольким аккаунтам в Украине, в том числе принадлежащим некоторым российским государственным СМИ. Мы также рассматриваем запрос других правительств об ограничении российских СМИ, контролируемых государством.', 'От 26 февраля 2022 г. в 11:50 AM PT:', 'Наши мысли с теми, кого затронула война в Украине. Мы предпринимаем целый ряд мер на всех наших приложениях, чтобы обеспечить безопасность нашего сообщества и поддержать людей, которые пользуются нашими услугами – как в Украине, так и по всему миру.', 'Ниже перечислены конкретные шаги, предпринятые нами в связи с вторжением России в Украину.', 'В ответ на складывающуюся обстановку, мы добавили несколько функций безопасности в Украине', 'Мы предпринимаем дополнительные шаги по контролю за соблюдением наших Норм сообщества и Принципов сообщества не только в Украине и России, но и в других странах мира, где может распространяться контент.', 'Мы предпринимаем масштабные меры по борьбе с распространением дезинформации на наших сервисах и продолжаем консультироваться со сторонними экспертами.', 'Мы обеспечиваембольшую прозрачностьаккаунтов государственных СМИ, включая российские RT и Sputnik, поскольку они сочетают в себе влияние медийных организаций со стратегической поддержкой государства. Мы считаем, что люди должны знать, поступают ли новости, которые они читают, от издания, которое может находиться под влиянием правительства.', 'Мы по-прежнему бдительно следим за развитием событий и готовы предпринять дополнительные действия в соответствии с требованиями сложившейся ситуации.']\n",
            "15 ['Our technologies offer a critically important space for people to exercise their human rights, where they can express themselves, shine a light on important issues and hold those in power to account. And, we know that people can misuse technology to heighten existing social tensions and suppress people’s fundamental rights. In line with ourCorporate Human Rights Policy, we conduct human rights impact assessments to better understand the role our technologies play in society, including how to help prevent and mitigate related risks.', 'Today, we’re publishing thefindings of the independent human rights impact assessmentwe commissioned in the Philippines, along with details onhow we’ve respondedto the recommendations in the assessment. We recognize that complex challenges outlined in the report may continue to evolve, and so will our approach and strategies to build systems that help promote human rights.', 'The assessment found that Meta technologies, in addition to being widely used in the Philippines, do play an important and positive role in providing access to economic opportunities, giving voice to people and being essential tools for monitoring and defending human rights during the COVID-19 pandemic. It also highlights salient human rights risks in the Philippines, including concerns about the misuse of our technologies formisinformation and disinformation, online harassment and incitement of violence.We’vetaken concrete steps to mitigate these risks and others identified in the report, and we’ll continue to do so to help keep people safe.', 'Article One, a specialized human rights and ethics consulting firm, completed the assessment in accordance with theUN Guiding Principles on Business and Human Rights. The research methodology included qualitative interviews with journalists, child protection specialists and civil society activists, as well as a survey of 2,000 people that use Facebook in the Philippines. The assessment also used an innovative methodology of combining traditional methods of stakeholder consultation with a quantitative survey that captured the experiences of a wide range of Filipino citizens. It was also framed to understand the experiences and risks of a variety of vulnerable groups, including LGBTQ+, journalists and others.', 'The Meta Response outlines our response to Article One’s recommendations. We are committing to implement, or have implemented, 24 recommendations; partly implement 7 recommendations; and we’re assessing feasibility of another 9. We’re sharing these insights and actions from our due diligence, aligned with our human rights policy.', 'As our response notes, we’ve made progress towards many of the recommendations in the report, and we know there is more to do. Here’s an update on our work to address some of the key areas identified in the report:', 'This assessment is an important step forward for us and our work in the Philippines. How we address safety, security and human rights is not static. We’re constantly working to evolve our products, policies and processes to create better outcomes.']\n",
            "16 ['Recent events have focused the world’s attention on the conflict in Ethiopia. Our thoughts are with the people of Ethiopia, both in the country and in the diaspora, during this difficult time. But while the international attention that these events are getting may be new, our work to prevent our platform from being abused in Ethiopia is not.', 'For more than two years, we’ve been implementing a comprehensive strategy to keep people in the country safe on our platform given the severe, longstanding risks of conflict.', 'Two years ago we moved Ethiopia to the category of countries that we believe are at the highest risk for conflict and violence, enabling the development of both proactive solutions that we can implement when crises arise, and a long-term strategy to keep people safe. We’ve been doing this despite the fact that the country’s lower internet adoption means that less than 10% of the population uses Facebook. For the millions of Ethiopians who rely on our services as a source of information and communication, our focus is threefold:', 'Ethiopia is an especially challenging environment to address these issues, in part because there are multiple languages spoken in the country.\\xa0 Over the past two years, we’ve significantly improved our reporting and enforcement tools. We can now review content in the top four languages spoken and those central to the conflict (Amharic, Oromo, Somali, Tigrinya). We’ve also made it easier for Ethiopians as well as specialized international and local human rights and civil society organizations to tell us when they see potentially violating content, so we can investigate it for possible violations.\\xa0 We also have technology to identify hate speech in Amharic and Oromo before anyone reports it to us. These efforts are industry-leading.', 'As a result of these efforts, between May and October 2021, we took action on more than 92,000 pieces of content in Ethiopia on Facebook and Instagram for violations of our Community Standards prohibiting hate speech, about 98% of which was detected before it was reported by people to us.', 'In June 2021, we alsoremoveda network of fake accounts posting critical commentary of opposition politicians/groups in Amharic.\\xa0 The people behind these posts used coordinated, inauthentic accounts as a central part of their efforts to mislead people about who they were and what they were up to. In March 2021, weremovedaccounts in Egypt that targeted Ethiopia, Sudan, and Turkey.', 'As the local situation deteriorated, and as weapproached electionsin June and again in September, we took a number of additional steps:', 'Then as now, our teams are working around the clock and we’ve activated our Integrity Operation Center — bringing togethersubject matter experts from across the company to respond in real time to problems and abuses.', 'Given the rapidly evolving situation, and informed by conversations we’ve had with human rights activists, journalists and civil society groups in Ethiopia and the diaspora about security concerns, we’ve taken additional steps in recent days. We recently launched a new safety feature in Ethiopia calledLock Profilethat allows people to restrict anyone who isn’t their friend from downloading, enlarging, or sharing their profile photo. It also prevents non-friends from seeing posts or other photos on their timeline, regardless of when they may have posted it. We’ve also put temporary measures in place to restrict views of peoples’ Friends List on their profile pages and remove results from “Search this profile.”', 'While safety work in Ethiopia has been going on for a long time, we know that the risks on the ground right now are higher. And since we recognize that local context and language-specific expertise is essential for this work, we will remain in close communication with people on the ground, along with partner institutions and non-governmental organizations as the days and weeks progress. This will help us take the right actions and make the right calls. We remain vigilant to emerging trends and stand ready to take additional action to meet the demands of this ongoing human rights situation.']\n",
            "17 ['Climate change is the greatest threat we all face — and the need to act grows more urgent every day. The science is clear and unambiguous. As world leaders, advocates, environmental groups and others meet in Glasgow this week at COP26, we want to see bold action agreed to, with the strongest possible commitments to achieve net zero targets that help limit warming to 1.5˚C.', 'We are going to play our part too. As a global business that connects more than 3 billion people every month, we have an opportunity and a responsibility to make a real difference.', 'That starts with getting our own house in order. Starting last year, we achieved net zero emissions for our global operations, and we’re supported by 100% renewable energy. To achieve this we’ve reduced our greenhouse gas emissions by 94% since 2017. We invest enough in wind and solar energy to cover all our operations. And for the remaining emissions, we support projects that remove emissions from the atmosphere.', 'We’ve also set ambitious goals for our suppliers to be net zero and for our operations to restore more water than we use by 2030. Since our first wind contract in 2013, we’ve contracted over seven gigawatts of new solar and wind energy, all in the same power grids where our data centers are located, which are some of the most efficient in the world. We are also implementing measures to reduce our business travel emissions, and joining the Sustainable Aviation Buyers Alliance as a founding member to help accelerate the path to net zero air travel by driving investment in sustainable aviation fuel.', 'But this is not enough. Social media companies have the power to connect people with each other to make a difference at scale, amplify marginalized voices and share powerful information. Every day we see people use our services to raise awareness, organize for action, and make their voices heard on a wide range of environmental issues. We want to play our part by helping people find accurate, science-led information while also tackling misinformation.', 'Last year, we launched theClimate Science Centeron Facebook to connect people with factual resources from the world’s leading climate organizations, like the Intergovernmental Panel on Climate Change, UN Environment Program and more than 200 others. They can also find steps they can take in their own lives to combat climate change. Today, we are starting to expand it to more than 100 countries. And we’re also adding a new section that shows countries’ greenhouse gas emissions as compared to their commitments and targets, so people can better understand where their country is today and what more needs to be done.', 'Earlier this year, westarted addinginformational labelsto some posts on climate changedirecting people to the Climate Science Center to find out more.We’re now expanding these labels on posts inmore than a dozen countries, including for the first time in Belgium, Brazil, India, Indonesia, Mexico, the Netherlands, Spain and Taiwan.', '', 'We have a responsibility to tackle climate misinformation on our services, which is why we partner with more than 80 independent fact-checking organizations globally to review and rate content, including content about climate change. When they rate content as false, we reduce its distribution so fewer people see it and we show a warning label with more context. And we apply penalties to people who repeatedly share false information.', 'Ahead of COP26, we’ve also activated a feature we use during critical public events to utilize keyword detection so related content is easier for fact-checkers to find — because speed is especially important during such events. This feature is available to fact-checkers for content in English, Spanish, Portuguese, Indonesian, German, French and Dutch. Learn more about how we’retackling climate change misinformation.', 'According to asurvey conducted by our Data for Good teamin partnership with the Yale Program in Climate Change Communication, a majority of people in all 31 countries surveyed said that climate change is at least somewhat important to them personally. Substantial numbers of people also said that they would “definitely” or “probably” participate in a citizens’ campaign to reduce climate change.', 'We’re also supporting the UN by encouraging conversations around climate change and helping people take action. With the help ofSpectrm, the UN will soon be launching an updated version of its ActNow chat experiencewith 10 new actions you can take to combat climate change. It’s available onMessengerthrough the app,Instagramand theUN website. In time for COP26, Messenger is supporting the work of the UNFCCC by also releasing new camera stickers that can help you strike up a conversation by visually showing your support for the planet in your next Story or chat on Messenger and Instagram, or conversation in Messenger Kids.', '', '', 'We’re launching asustainability training programto support businesses on our apps to take climate action, reduce their carbon emissions and help grow their business in a sustainable way. We are starting this month with businesses in the UK and Spain, with a particular focus on restaurants, hospitality and food producers. The program will expand to France, Italy and other countries next year.', 'During COP26 in Glasgow, we’ll be featuring experts and scientists in new content designed to inform and inspire action. We have a live studio at the event itself where we’ll be hosting a series of conversations with leading voices on climate change. We’re launching a new podcast series calledClimate Talkshosted by Sophia Li. We’ll be live-streaming aSay It With Scienceconversation on Facebook Live covering health and climate change. On@instagram, we’ve launched the editorial seriesOur Planet in Crisis, which features the stories of activists and organizers who are dedicated to spreading awareness and empowering others to take action in their local communities.', 'These are just some of the steps we’re taking as a company and as a platform to try and make a positive difference. Our goal isn’t just to be one of the most sustainable companies, but to make it easier for our users and employees to be too. If we all play our part — from world leaders and governments, to private companies and individuals — we can rise to this challenge together.']\n",
            "18 ['Over the past two decades, Facebook has empowered people around the world with a wealth of social and economic benefits. It has made social connection and free expression possible on a massive scale. This can be especially important for people who are in places that are experiencing conflict and violence.', 'Facebook supports people’s right to express themselves freely, regardless of where they are in the world. Freedom of expression is a foundational human right and enables many other rights.\\xa0 But we know that technologies for free expression, information and opinion can also be abused to spread hate and misinformation — a challenge made even worse in places where there is a heightened risk of conflict and violence. This requires developing both short-term solutions that we can implement when crises arise and having a long-term strategy to keep people safe. Here is our approach.', 'Since 2018, we’ve haddedicated teams spanning product, engineering, policy, research and operations to better understand and address the way social media is used in countries experiencing conflict.Many of these individuals have experience working on conflict, human rights and humanitarian issues, as well as addressing areas like misinformation, hate speech and polarization. Many have lived or worked in the countries we’ve identified as highest risk and speak relevant languages. They are part of the over 40,000 people we have working on safety and security, including global content review teams in over 20 sites around the world reviewing content in over 70 languages.', 'In the last two years, we’ve hired more people with language, country and topic expertise. For example, we’ve increased the number of team members with work experience in Myanmar and Ethiopia to include former humanitarian aid workers, crisis responders and policy specialists. And we’ve hired more people who can review content in Amharic, Oromo, Tigrinya, Somali and Burmese. Adding more language expertise has been a key focus area for us. This year alone, we’ve hired content moderators in 12 new languages, including Haitian Creole, Kirundi, Tswana and Kinyarwanda.', 'Our teams have developed an industry-leading process for reviewing and prioritizing which countries have the highest risk of offline harm and violence every six months. We make these determinations in line with the UN Guiding Principles on Business and Human Rights and following a review of these factors:', 'Using this prioritization process, wedevelop longer-term strategies to prepare for, respond to and mitigate the impacts of harmful offline events in the countries we deem most at risk.This allows us to act quickly to remove content that violates our policies and take other protective measures while still protecting freedom of expression and other human rights principles. Recent examples include our preparations forelections inMyanmar,Ethiopia,Indiaand Mexico.', 'In a crisis, we will determine what kind of support and teams we need to dedicate to a particular country or language, and for how long we need to keep them in place. This might include deploying our Integrity Product Operations Centers model to monitor and respond to threats in real time. It can also include seeking to ensure our integrity systems and resources are robust and ready where there may be ongoing risk of political unrest, or building temporary product levers ahead of a protest or a culturally sensitive event — all while ensuring that we have teams ready to support unplanned events, suchresponding to thecoupin Myanmar.', 'We know that we face a number of challenges with this work and it is a complex and often adversarial space — there is no one-size-fits-all solution. Many of these offline issues have existed for decades or longer, and media services have a long history of being abused by those seeking to assert or maintain power or incite violence. But, we know our work to keep our global community safe will never be finished and it requires ongoing vigilance and investments. That’s what we’ve done for many years and we will continue doing it going forward.']\n",
            "19 ['How technology companies grapple with complex issues is being heavily scrutinized, and often, without important context. There is a lot more to the story. What is getting lost in this discussion is some of the important progress we’ve made as a company and the positive impact that it is having across many key areas.', 'We firmly believe that ongoing research and candid conversations about our impact are some of the most effective ways to identify emerging issues and get ahead of them. This doesn’t mean we find and fix every problem right away. But because of this approach, together with other changes, we have made significant progress across a number of important areas, including privacy, safety and security, to name a few. Just as the world has changed a lot, so has Facebook.', 'In the past, we didn’t address safety and security challenges early enough in the product development process. Instead, we made improvements reactively in response to a specific abuse. But we have fundamentally changed that approach. Today, we embed teams focusing specifically on safety and security issues directly into product development teams, allowing us to address these issues during our product development process, not after it. Products also have to go through an Integrity Review process, similar to thePrivacy Review process, so we can anticipate potential abuses and build in ways to mitigate them. Here are a few examples of how far we’ve come.', 'Some of the most important changes we’ve made in recent years have been in prioritizing safety and security. As a result:', 'We have alsochanged our approach to protecting people’s privacyas a company. This includes investing in and expanding ourPrivacy Checkup, which today is used by tens of millions of people every month to manage their settings and control their experience on Facebook,and launching tools likeOff-Facebook ActivityandWhy Am I Seeing This?that show people how their information is used and let them more easily manage settings.', 'Misinformation has been a challenge on and off the internet for many decades. People are understandably concerned about how it will be handled for future internet technologies. At Facebook, we’ve begun addressing this comprehensively — rather than treating it as a single problem with a single solution. This means we’ve gotten better at addressing this complex challenge. We’ve worked to develop and expand our systems to reduce misinformation and promote reliable information. As a result:', 'Most importantly, we’ve also changed not justwhatwe build buthowwe build so that when we launch new products, they are more likely to have effective privacy, security and safety protections already built in. For example:', '', 'You canread moreabout the direction of our responsible innovation efforts fromMargaret Stewart, VP of Product Design & Responsible Innovation at Facebook.', 'Yes, we’ve made progress. But we also know that there will always be examples of things we miss and things we take down by mistake. There is no perfect here. Collaborating with experts, policymakers and others has made us better, and continued collaboration will be key to making sure our progress continues. And that’s our plan.', 'Read more about our efforts on ournew page, which features updated information and figures, to give a sense of where things have improved and where we still have more work to do. OurTransparency Centeris also a comprehensive destination for our integrity and transparency efforts. Also, see atimeline of our integrity efforts since 2016.', '', 'For more, visitabout.facebook.com/progress.']\n",
            "20 ['A lot has been said about Facebook this week. A series of articles published by theWall Street Journalhas focused on some of the most difficult issues we grapple with as a company — from content moderation and vaccine misinformation, to algorithmic distribution and the well-being of teens. These are serious and complex issues, and it is absolutely legitimate for us to be held to account for how we deal with them. But these stories have contained deliberate mischaracterizations of what we are trying to do, and conferred egregiously false motives to Facebook’s leadership and employees.', 'At the heart of this series is an allegation that is just plain false: that Facebook conducts research and then systematically and willfully ignores it if the findings are inconvenient for the company. This impugns the motives and hard work of thousands of researchers, policy experts and engineers at Facebook who strive to improve the quality of our products, and to understand their wider (positive and negative) impact. It’s a claim which could only be made by cherry-picking selective quotes from individual pieces of leaked material in a way that presents complex and nuanced issues as if there is only ever one right answer.', 'With any research, there will be ideas for improvement that are effective to pursue and ideas where the tradeoffs against other important considerations are worse than the proposed fix. The fact that not every idea that a researcher raises is acted upon doesn’t mean Facebook teams are not continually considering a range of different improvements. At the same time, none of these issues can be solved by technology companies alone, which is why we work in close partnership with researchers, regulators, policymakers and others.', 'But none of that collaborative work is helped by taking a deliberately lop-sided view of the wider facts. For example, to suggest that misinformation has somehow overwhelmed our COVID-19 vaccine response ignores the most important fact: that vaccine hesitancy among Facebook’s US users has declined by about 50% since January. TheJournalarticle goes on to discuss at length how pro-vaccine posts are undermined by negative comments, once again burying a crucial point: that health organizations continue posting because their own measurements show how their posts on our platforms effectively promote vaccines, despite negative comments.', 'Similarly, to suggest that the research community is settled in its view on the intersection between social media and well-being is simply not the case. The truth is that research into the impact social media has on people is still relatively nascent and evolving, and social media itself is changing rapidly.Some researchers arguethat we need more evidence to understand social media’s impact on people. Each study has limitations and caveats, so no single study is going to be conclusive. We need to rely on an ever-growing body of multi-method research and expert input.', 'What would be really worrisome is if Facebook didn’t do this sort of research in the first place. The reason we do it is to hold up a mirror to ourselves and ask the difficult questions about how people interact at scale with social media. These are often complex problems where there are no easy answers — notwithstanding the wish to reduce them to an attention-grabbing newspaper headline.', 'Facebook understands the significant responsibility that comes with operating a global platform. We take it seriously, and we don’t shy away from scrutiny and criticism. But we fundamentally reject this mischaracterization of our work and impugning of the company’s motives. I wish there were easy answers to these issues, and that choices we might make wouldn’t come with difficult trade-offs. That is not the world we live in. We will continue to invest in research into these serious and complex issues. We will continue to ask ourselves the hard questions. And we will continue to improve our products and services as a result.']\n",
            "21 ['A recentreport by the Intergovernmental Panel on Climate Change (IPCC)underscored that while we can’t stop global warming from intensifying over the next 30 years, action we take now could still help slow or even stabilize rising temperatures. We know this is an important issue to our community. In a survey that we ran earlier this year on Facebook, in partnership with the Yale Program on Climate Change Communication, wefound that more than 6 in 10 peopleacross all countries and territories surveyed want more information about climate change.', 'Today, we’re announcing several new measures tohelp our community engage with climate topics andensure people have access to reliable information while reducing misinformation:', 'Last year, we launched the Climate Science Information Center in four countries to connect people with science-based information on climate change. We’ve since expanded to 16 countries with more than 3.8 million followers and over 100,000 daily visitors. One key learning from the past year is that while providing authoritative information is an important first step, we can add additional features to better inform and engage our community on climate change. This is why we’re renaming the hub to the Climate Science Center and are adding new modules like a quiz featurein collaboration with the IPCCto test their knowledge about climate change and a feature that provides people with information about climate-related crises, starting with wildfires.', '', 'We’re taking steps to make sure people have access to reliable information while reducing climate misinformation, even as it makes up a small amount of the overall climate content on our apps. We’re announcing aClimate Misinformation grant program, administered by the International Fact Checking Network, to support organizations working to combat climate misinformation. Through our $1 million investment in this new grant program, we’ll invest in proposals that build alliances between fact-checkers, climate experts and other organizations to support projects that focus on combating climate misinformation.', 'In consultation with climate communication experts from the Yale Program on Climate Change Communication, University of Cambridge and Monash University, we’re also adding new facts to theFacts About Climate Change sectionof the Climate Science Center like “Sea levels have risen an average of eight inches globally since 1880.” and “The way scientists predict changes in climate patterns has proven to be reliable.” These facts debunk common climate myths and provide reliable information from leading climate organizations.', 'Starting duringClimate Week, September 20-26, we will highlight creators and advocates who raise awareness of climate change on our apps. We’ll also be launching a special food sustainability video with Sydel Curry-Lee on Facebook Watch, featuring a number of climate creators on@Instagramand highlighting several environmental advocates in an effort to inspire and inform others on@Facebook. We’ll also continue our support of theSay It With Science serieson Facebook, where the UN Foundation and IPCC bring together scientists and youth advocates to present the latest climate science to our community.', 'We continue to be inspired by all the ways our community is tackling climate change — from the 6 million people in Facebook Groups dedicated to protecting our environment to the 3.5 million people who have raised more than $130 million for environmental causes on Facebook and Instagram.']\n",
            "22 ['Today we’re publishing theCommunity Standards Enforcement Reportfor the second quarter of 2021. This report provides metrics on how we enforced our policies from April through June. This is our 10th report andsome of our long-term trends include:', 'In addition to our Community Standards Enforcement Report, this quarter we’re also sharing:', 'We’re committed to sharing meaningful data so we can be held accountable for our progress, even if the data shows areas where we need to do better.', 'Today, we’re also releasing thefirst in a series of reportsthat will give an overview of themost widely-viewed contentin Facebook’s News Feed, starting with the top 20 most viewed domains, links, Pages and posts in the US. These reports are public in theTransparency Centerand we will include them with each quarterly Community Standards Enforcement Report going forward.', 'COVID-19 is still a major public health issue, and we are committed to helping people get authoritative information, including vaccine information. We continue to remove harmful COVID-19 misinformation and prohibit ads that try to exploit the pandemic for financial gain. Since the start of the pandemic through June:', 'We’ve provided authoritative information to help improve vaccine acceptance, connecting 2 billion people to resources from health experts through our COVID-19 Information Center and educational pop-ups on Facebook and Instagram and helping 4 million people in the US alone access vaccines through our vaccine finder tool.', 'We know frompublic health researchthat people are more likely to get vaccinated if they see others in their community doing so. In countries where vaccines are available to most people, we ramped up our efforts to show when friends and neighbors share their support for vaccines through profile frames and stickers.', 'For people in the US on Facebook, vaccine hesitancy has declined by 50%. Globally, we have also seen vaccine acceptance rising. For example, ourCOVID-19 Trends and Impact Survey data which we conduct in partnership with Carnegie-Mellon and University of Maryland has since the beginning of the year shown vaccine acceptance rising by 35 percent in France, 25 percent in Indonesia, and 20 percent in Nigeria.', 'Prevalence of hate speech on Facebook continued to decrease for the third quarter in a row. In Q2, it was 0.05%, or 5 views per 10,000 views, down from 0.05-0.06%, or 5 to 6 views per 10,000 views in Q1.', '', 'We removed31.5 million pieces of hate speech content from Facebook, compared to 25.2 million in Q1, and 9.8 million from Instagram, up from 6.3 million in Q1. This is due to continued improvement in our proactive detection.Our investments in AI enable us to detect more kinds of hate speech violations on Facebook and Instagram. This technology helps us enforce our policies across billions of users and multiple languages. Steady, continuous AI improvements and advancements, such as theReinforcement Integrity Optimizer (RIO), enable our AI models to spot hate speech using real-world data and improve over time.', 'Keeping children safe on our apps is critical. Previously, we reported one metric, child nudity and sexual exploitation of children. In our latest report, we’ve added more data and created two new reporting categories under the broader topic of child endangerment: 1) nudity and physical abuse and 2) sexual exploitation.', '', 'We changed this to provide a more detailed, transparent overview of our efforts in this space to child safety experts, academics and the general public.', 'In Q2 2021, we improved our proactive detection technology on videos and expanded our media-matching technology on Facebook, allowing us to remove more old, violating content. Both enabled us to take action on more violating content.', 'In addition to new categories and ongoing improvements in reducing prevalence, we saw steady progress across many problem areas.', 'On Facebook in Q2 we took action on:', 'On Instagram in Q2 we took action on:']\n",
            "23 ['In recent weeks, there has been a debate about whether the global problem of COVID-19 vaccine misinformation can be solved simply by removing 12 people from social media platforms. People who have advanced this narrative contend that these 12 people are responsible for 73% of online vaccine misinformation on Facebook. There isn’t any evidence to support this claim. Moreover, focusing on such a small group of people distracts from the complex challenges we all face in addressing misinformation about COVID-19 vaccines.', 'That said, any amount of COVID-19 vaccine misinformation that violates our policies is too much by our standards — and we have removed over three dozen Pages, groups and Facebook or Instagram accounts linked to these 12 people, including at least one linked to each of the 12 people, for violating our policies. We have also imposed penalties on nearly two dozen additional Pages, groups or accounts linked to these 12 people, like moving their posts lower in News Feed so fewer people see them or not recommending them to others. We’ve applied penalties to some of their website domains as well so any posts including their website content are moved lower in News Feed. The remaining accounts associated with these individuals are not posting content that breaks our rules, have only posted a small amount of violating content, which we’ve removed, or are simply inactive. In fact, these 12 people are responsible for about just 0.05% of all views of vaccine-related content on Facebook. This includes all vaccine-related posts they’ve shared, whether true or false, as well as URLs associated with these people.', 'The reportupon which the faulty narrative is based analyzed only a narrow set of 483 pieces of content over six weeks from only 30 groups, some of which are as small as 2,500 users.They are in no way representative of the hundreds of millions of posts that people have shared about COVID-19 vaccines in the past months on Facebook. Further, there is no explanation for how the organization behind the report identified the content they describe as “anti-vax” or how they chose the 30 groups they included in their analysis. There is no justification for their claim that their data constitute a “representative sample” of the content shared across our apps.', 'Focusing on these 12 individuals misses the forest for the trees. We have worked closely with leading health organizations since January 2020 to identify and remove COVID-19 misinformation that could contribute to a risk of someone spreading or contracting the virus.Since the beginning of the pandemic across our entire platform, we have removed over 3,000 accounts, Pages and groups for repeatedly violating our rules against spreading COVID-19 and vaccine misinformation and removed more than 20 million pieces of content for breaking these rules.', 'None of this is to suggest that our work is done or that we are satisfied. Tracking and combating vaccine misinformation is a complex challenge, made more difficult by the lack of common definitions about what constitutes misinformation, and the reality that guidance from scientific and health experts has evolved and will continue to evolve throughout the pandemic. That’s why we’re continuing to work with external experts and governments to make sure that we are approaching these issues in the right way and making adjustments if necessary. In the meantime, we will continue doing our part to show people reliable information about COVID-19 vaccines from health experts and help people get vaccinated.']\n",
            "24 ['At a time when COVID-19 cases are rising in America, the Biden administration has chosen to blame a handful of American social media companies. While social media plays an important role in society, it is clear that we need a whole of society approach to end this pandemic. And facts — not allegations — should help inform that effort. The fact is that vaccine acceptance among Facebook users in the US has increased. These and other facts tell a very different story to the one promoted by the administration in recent days.', 'Since April 2020, we’ve been collaborating with Carnegie Mellon University and University of Maryland on a global survey to gather insights about COVID-19 symptoms, testing, vaccination rates and more. This is the largest survey of its kind, with over 70 million total responses, and more than 170,000 responses daily across more than 200 countries and territories. For people in the US on Facebook, vaccine hesitancy has declined by 50%; and they are becoming more accepting of vaccines every day.', 'Since January, vaccine acceptance on the part of Facebook users in the US has increased by 10-15 percentage points (70% → 80-85%) and racial and ethnic disparities in acceptance have shrunk considerably (some of the populations that had the lowest acceptance in January had the highest increases since). The results of this survey arepublicand we’ve shared them — alongside other data requested by the administration — with the White House, the CDC and other key partners in the federal government.', 'The data shows that 85% of Facebook users in the US have been or want to be vaccinated against COVID-19. President Biden’s goal was for 70% of Americans to be vaccinated by July 4. Facebook is not the reason this goal was missed.', '', 'In fact, increased vaccine acceptance has been seen on and off Facebook, with many leaders throughout the US working to make that happen.We employed similar tactics in the UK and Canada, which have similar rates of Facebook usage to the US, and those countries have achieved more than 70% vaccination of eligible populations. This all suggests there’s more than Facebook to the outcome in the US.', 'Now vaccination efforts are rightly turning to increasing access and availability for harder-to-reach people. That’s why we recentlyexpanded our pop-up vaccine clinicsin low-income and underserved communities.To help promote reliable vaccine information to communities with lower access to vaccines, we are using theCDC’s Social Vulnerability Index. This is a publicly available dataset that crisis and health responders often use to identify communities most likely to need support, as higher vulnerability areas have hadlower COVID-19 vaccination coverage.', 'We have been doing our part in other areas, too:', 'And when we see misinformation about COVID-19 vaccines, we take action against it.', 'In fact, we’vealready taken actionon all eight ofthe Surgeon General’s recommendationson what tech companies can do to help. And we are continuing to work with health experts to update the list of false claims we remove from our platform.We publish these rulesfor everyone to read and scrutinize, and we update them regularly as we see new trends emerge.', 'The Biden Administration is calling for a whole of society approach to this challenge. We agree. As a company, we have devoted unprecedented resources to the fight against the pandemic, pointing people to reliable information and helping them find and schedule vaccinations. And we will continue to do so.']\n",
            "25 ['Today, we’re sharing an update on our election integrity work ahead of Ethiopia’s general election on June 21st. This work will continue in the lead up to, during and after the vote, and builds on ourlongstanding effortsin understanding and addressing the way social media is used in Ethiopia. It includes our efforts to detect and remove hate speech and content that incites violence, our ongoing work to reduce the spread of misinformation, our efforts to improve digital literacy, and the steps we’re taking to make political advertising more transparent.', 'These efforts are informed by the conversations we’re having with human rights groups, NGOs, local civil society organisations, and regional experts within Facebook. They are being implemented by a team purpose-built to focus on the Ethiopian election. Because local understanding is critical to doing this work effectively, our team includes a number of people in and from Ethiopia including experts in topics like misinformation, hate speech, elections and disinformation.', 'Facebook opened its firstElections Operations Center in 2018, ahead of the elections held that year in the United States and Brazil.Since then, we’ve run operations centers for major elections around the world, including the upcoming elections in Ethiopia.', 'At the onset of the COVID-19 pandemic, our Elections Operation Center transitioned from a physical to a virtual work space. However, we’re still bringing together subject matter experts from across the company — including from our threat intelligence, data science, engineering, research, operations, policy and legal teams — so we can respond in real time to potential problems and abuses we see emerging in Ethiopia.', 'OurCommunity Standards— which set out what is and isn’t allowed on Facebook — cover a number of areas relevant to elections, including policies against harassment and incitement to violence, as well as detailed hate speech policies that ban attacks on people based on characteristics like ethnicity or religion. When we become aware of content that violates these rules we remove it.', 'We’ve significantly improved and simplified our reporting tools to make it easier for Ethiopians to tell us when they see violating content, so we can investigate. To further broaden awareness of our policies in Ethiopia, we’ve run online ad and radio campaigns and held training sessions with activists, civil society organizations, small and medium sized businesses owners, government agencies and members of the local media. We’ve also established dedicated reporting channels for specialized international and local human rights and civil society organizations to make sure we can quickly review problematic content they identify for possible violations, and continue to work with local partners who provide us with feedback that we incorporate into our policies and programs.', 'Alongside these efforts to improve reporting, we’ve also invested in proactive detection technology that helps us catch violating content before people report it to us. We’re now using this technology to proactively identify hate speech in Amharic and Oromo, alongside over 40 other languages globally.', 'Over the last few years, we’ve tripled the size of the global team working on safety and security to over 35,000 and hired more content reviewers who are native speakers of Amharic, Oromo and Somali, while having the capacity to review content in Tigrinya.', 'These investments are having an impact: between March 2020 and March 2021, we removed87,000pieces of hate speech in Ethiopia, about89%of which were detected proactively.', 'We are taking additional temporary steps ahead of, and during the election to reduce the distribution of content and comments that our proactive detection technology identifies as likely containing hate speech, or violence and incitement, while our teams investigate it. This content will be removed if we determine it violates our policies.', 'In addition to our standard practice of removing accounts that repeatedly violate our Community Standards, we are also continuing to reduce the distribution of content posted from accounts that have recently and repeatedly posted violating content in countries facing heightened risks. This means fewer people in Ethiopia will see content from these repeat offenders located in those countries.', 'Because we know it’s important for people to see accurate information on Facebook and Instagram, we are working to fight the spread of misinformation on our services in Ethiopia. We remove the most serious kinds of misinformation, such as content that is intended to suppress voting or which could cause violence or physical harm. For content which doesn’t violate these particular rules, we’ve partnered with independent third-party fact-checking partners in Ethiopia — Pesa Check and AFP — to ascertain whether something is misinformation or false news.\\xa0 When they review and rate a piece of content as false, we reduce its distribution so fewer people see it and add a warning label with more information for anyone who does see it. In general, when a warning screen is placed on a post, 95% of the time people don’t click past it.', 'We often see people try to deceive, abuse or cause harm by sharing news articles that are taken out of context, or outdated or misleading images accompanied by false claims and misinformation. To address this, we’ve temporarily expanded our misinformation policy in Ethiopia. We are removing out of context imagery which makes false allegations about the perpetrators, severity or targets of violence in Ethiopia. This is based on guidance from over 50 local partners and independent experts who have told us these specific claims could result in violence or physical harm. We’ve also launched tools which notify peoplewhen a news article they’re about to share is more than 90 days old. People will also see a message when they attempt to share specific types of images, including photos that are over a year old, warning them that the image they are about to share could be harmful or misleading.(Updated on August 16, 2021 at 9:39AM PT to further clarify how we are addressing out of context imagery in Ethiopia.)', 'We believe political discussion and debate should be transparent to every voter, which is why over the past few years we’ve introduced a number of tools that provide more information about political ads on Facebook and Instagram.In March this year,we made these political ads transparency tools mandatory in Ethiopia. As a result, anybody who wants to run political ads in Ethiopia must now go through a verification process to prove who they are and that they live in Ethiopia. We then run additional checks to ensure compliance with our policies. Political ads in Ethiopia will be labelled with a “paid by” disclaimer, so you can see who paid for them. We also put political ads that run in Ethiopia in our Ads Library so that everyone can see what ads are running, information about targeting, and how much was spent. This fully searchable archive will store these ads for seven years. In addition to providing more transparency, earlier this year we also announced that we are rolling out new controls so that people can choose to see fewer social issue, electoral, and political ads. When people use these controls, they’ll no longer see ads that run with a “Paid for by” disclaimer. These changes mean that political advertising on Facebook and Instagram is now more transparent than other forms of election campaigning, whether that’s billboards, newspaper ads, direct mail, leaflets or targeted emails.', 'Finally, we’re also investing in digital literacy in Ethiopia through our work with local partners. We’ve partnered with the Center for African Leadership Studies to implement “My Digital World”, a series of live webinars which has seen us engage with over 7,000 people in the country on topics such as online safety, privacy, digital citizenship, news and media literacy.\\xa0 We’verolled out amedia literacy campaign, aimed at educating and informing people on how to detect potential false news, and ran billboard advertising campaigns across Addis Ababa, the first of its kind across Africa, focused on informing and educating people on how to stay safe online and use social media responsibly.']\n",
            "26 ['Today, we’re launching new ways to inform people if they’re interacting with content that’s been rated by a fact-checker as well as taking stronger action against people who repeatedly share misinformation on Facebook. Whether it’s false or misleading content about COVID-19 and vaccines, climate change, elections or other topics, we’re making sure fewer people see misinformation on our apps.', 'We want to give people more information before they like a Page that has repeatedly shared content that fact-checkers have rated, so you’ll see a pop up if you go to like one of these Pages. You can also click to learn more, including that fact-checkers said some posts shared by this Page include false information and a link to more information about our fact-checking program. This will help people make an informed decision about whether they want to follow the Page.', '', 'Since launching our fact-checking program in late 2016, our focus has been on reducing viral misinformation. We’ve taken stronger action against Pages, Groups, Instagram accounts and domains sharing misinformation and now, we’re expanding some of these efforts to include penalties for individual Facebook accounts too. Starting today, we will reduce the distribution of all posts in News Feed from an individual’s Facebook account if they repeatedly share content that has been rated by one of our fact-checking partners. We already reduce a single post’s reach in News Feed if it has been debunked.', 'We currently notify people when they share content that a fact-checker later rates, and now we’ve redesigned these notifications to make it easier to understand when this happens. The notification includes the fact-checker’s article debunking the claim as well as a prompt to share the article with their followers. It also includes a notice that people who repeatedly share false information may have their posts moved lower in News Feed so other people are less likely to see them.', '']\n",
            "27 ['Originally published inMorning Consult.', 'This week, the House Energy and Commerce Committee will examine how technology platforms like Facebook are tackling misinformation online. It is tempting to think about misinformation as a single challenge that can be solved with a single solution. But unfortunately, that’s not the case. Thinking of it that way also misses the opportunity to address it comprehensively. Tackling misinformation actually requires addressing several challenges including fake accounts, deceptive behavior, and misleading and harmful content. As the person responsible for the integrity of our products, I wanted to provide an update on how we approach each of them.', 'Let’s start with fake accounts. We take a hard line against this activity and block millions of fake accounts each day, most of them at the time of creation. Between October and December of 2020, we disabled more than 1.3 billion of them. We also investigate and take down covert foreign and domestic influence operations that rely on fake accounts. Over the past three years, we’ve removed over 100 networks ofcoordinated inauthentic behavior(CIB) from our platform and keep the public informed about our efforts through our monthly CIB reports.', 'We also crack down on deceptive behavior. We’ve found that one of the best ways to fight this behavior is by disrupting the economic incentives structure behind it. We’ve built teams and systems to detect and enforce against inauthentic behavior tactics behind a lot of clickbait. We also use artificial intelligence to help us detect fraud and enforce our policies against inauthentic spam accounts.', 'Misinformation can also be posted by people, even in good faith. To address this challenge, we’ve built a global network of more than 80 independent fact-checkers, who review content in more than 60 languages. When they rate something as false, we reduce its distribution so fewer people see it and add a warning label with more information for anyone who sees it. We know that when a warning screen is placed on a post, 95% of the time people don’t click to view it. We also notify the person who posted it and we reduce the distribution of Pages, Groups, and domains who repeatedly share misinformation. For the most serious kinds of misinformation, such as false claims about COVID-19 and vaccines and content that is intended to suppress voting, we will remove the content.', 'Over the past several years, we have invested in protecting our community and we now have over 35,000 people working on these challenges. We’re making progress thanks to these significant investments in both people and in technology such asArtificial Intelligence. Since the pandemic began,we’ve used our AI systems to take down COVID-19-related material that global health experts have flagged as misinformation and then detect copies when someone tries to share them. As a result, we’ve removed more than 12 million pieces of content about COVID-19 and vaccines.', 'But it’s not enough to just limit misinformation that people might see. We also connect people to reliable information from trusted experts. We do this through centralized hubs like ourCOVID-19 Information Center,Climate Science Information CenterorUS 2020 Voting Information Center, labels that we attach to certain posts with reliable information from experts, and notifications that we run in people’s feeds on both Facebook and Instagram.', 'Despite all of these efforts, there are some who believe that we have a financial interest in turning a blind eye to misinformation. The opposite is true. We have every motivation to keep misinformation off of our apps and we’ve taken many steps to do so at the expense of user growth and engagement.', 'For example, in 2018 wechanged our News Feed ranking systemto connect people to meaningful posts from their friends and family. We made this change knowing that it would reduce some of the most engaging forms of content, like short form video, and lead to people spending less time on Facebook — which is exactly what happened. The amount of time people spent on Facebookdecreased by roughly 5%in the quarter where we made this change.', 'As with every integrity challenge, our enforcement will never be perfect even though we are improving it all the time. While nobody can eliminate misinformation from the internet entirely, we continue using research, teams, and technologies to tackle it in the most comprehensive and effective way possible.']\n",
            "28 ['Update on October 20, 2021 at 9:00AM PT:', 'Today, we’re announcing new measures to keep Facebook Groups safe.', 'To continue limiting the reach of people who break our rules, we’ll start demoting all Groups content from members who have broken our Community Standards, anywhere on Facebook. These demotions will get more severe as they accrue more violations.', 'This measure will help reduce the ability of members who break our rules from reaching others in their communities, and builds on the existing restrictions placed upon members who violate Community Standards. These current penalties include restricting their ability to post, comment, add new members to a group or create new groups.', 'We also want to make sure that our enforcement is transparent and fair. That’s why we’re announcing Flagged by Facebook. This feature shows admins content that has been flagged for removal before it is shown to the broader community.', '', 'Admins can then either review and remove the content themselves, or ask for a review by Facebook and provide additional feedback on why they think that piece of content should remain on the platform. Flagged by Facebook involves admins in content review earlier in the process, before members receive a strike and content is removed.', 'Flagged by Facebook is in addition to the existing ability foradmins to appealwhen something is taken down for violating our Community Standards. This provides more fairness for communities and helps ensure that the right call is being made when it comes to enforcing our policies.', 'Originally published on March 17, 2021 at 8:00AM PT:', 'It’s important to us that people can discover and engage safely with Facebook groups so that they can connect with others around shared interests and life experiences. That’s why we’vetaken actionto curb the spread of harmful content, like hate speech and misinformation, and made it harder for certain groups to operate or be discovered, whether they’re Public or Private. When a group repeatedly breaks our rules, we take it down entirely.', 'Today we’re sharing the latest in ourongoing work to keep Groups safe, which includes our thinking on how to keep recommendations safe as well as reducing privileges for those who break our rules. These changes will roll out globally over the coming months.', 'We know we have a greater responsibility when we are amplifying or recommending content. As we work to make sure that potentially harmful groups aren’t recommended to people, we try to be careful not to penalize high-quality groups on similar topics. The tension we navigate isn’t between our business interests and removing low-quality groups — it’s about taking action on potentially harmful groups while still ensuring that community leaders can grow their groups that follow the rules and bring people value. We try to balance this carefully in our recommendations guidelines, which can be foundhere.', 'As behaviors evolve on our platform, though, we recognize we need to do more. This is why we recently removed civic and political groups, as well as newly created groups, from recommendations in the US.', 'While people can still invite friends to these groups or search for them, we have now started to expand these restrictions globally. This builds on restrictions we’ve made to recommendations, like removing health groups from these surfaces, as well as groups that repeatedly share misinformation.', 'We are also adding more nuance to our enforcement. When a group starts to violate our rules, we will now start showing them lower in recommendations, which means it’s less likely that people will discover them. This is similar to our approach in News Feed, where we show lower quality posts further down, so fewer people see them.', 'We believe that groups and members that violate our rules should have reduced privileges and reach, with restrictions getting more severe as they accrue more violations, until we remove them completely. And when necessary in cases ofsevere harm, we will outright remove groups and people without these steps in between.', 'We’ll start to let people know when they’re about to join a group that has Community Standards violations, so they can make a more informed decision before joining. We’ll limit invite notifications for these groups, so people are less likely to join. For existing members, we’ll reduce the distribution of that group’s content so that it’s shown lower in News Feed. We think these measures as a whole, along with demoting groups in recommendations, will make it harder to discover and engage with groups that break our rules.', '', 'We will also start requiring admins and moderators to temporarily approve all posts when that group has a substantial number of members who have violated our policies or were part of other groups that were removed for breaking our rules. This means that content won’t be shown to the wider group until an admin or moderator reviews and approves it. If an admin or moderator repeatedly approves content that breaks our rules, we’ll take the entire group down.', 'When someone has repeated violations in groups, we will block them from being able to post or comment for a period of time inanygroup. They also won’t be able to invite others to any groups, and won’t be able to create new groups. These measures are intended to help slow down the reach of those looking to use our platform for harmful purposes and build onexisting restrictionswe’ve put in place over the last year.', 'There is always more to do to keep Facebook Groups safe, and we will continue to build and invest to make sure people can rely on these places for connection and support.']\n",
            "29 ['We’ve already connected over 2 billion people to authoritative COVID-19 information, and today as access to COVID-19 vaccines expands, we’re going even further and aiming to help bring 50 million people one step closer to getting vaccinated.', 'To do this, we’re helping peoplelearn more about COVID-19 vaccines and find out when and where they can get one through our apps.Some of the ways we are doing this:', 'By working closely with national and global health authorities and using our scale to reach people quickly, we’re doing our part to help people get credible information, get vaccinated and come back together safely.', 'We’ve partnered with Boston Children’s Hospital to offer a tool on Facebook in the US to help people identify places nearby to get the vaccine. The locations in this tool are provided by VaccineFinder and include hours of operation, contact info and links to make an appointment. You can access this tool in theCOVID-19 Information Centerand it will be supported in 71 different languages. We plan to expand to other countries as vaccines are available more widely.', '', '', '', 'Today, we’re bringing the COVID-19 Information Center to Instagram all around the world. This portal, which we launched in the Facebook app last March, helps people discover the latest information about the virus from local health ministries and the World Health Organization. We’re also releasing new stickers on Instagram Stories, so people can inspire others to get vaccinated when it becomes available to them. Learn more about these efforts on theInstagram blog.', '', 'To date, 3 billion messages have been sent by governments, nonprofits and international organizations to citizens through official WhatsApp chatbots on COVID-19. We’re now working directly with health authorities and governments to get people registered for vaccinations, including:', 'Since the beginning of the COVID-19 pandemic, we have partnered withministries of health and health-focused organizations in more than 170 countries by providing free ads, enabling partners to share their own public health guidance on COVID-19 and information about the COVID-19 vaccine. For underserved countries and vulnerable populations such as ethnic minorities and refugees, we also partner with expert local and international NGOs, such as International Medical Corps, who are providing tailored COVID-19 information in local languages. In addition, we continue to work with international bodies like the European Union and African Union in support of their COVID-19 responses. For example, we have helped the European Parliament run a multilingual ad campaign in their 27 Member States, featuring short in-feed videos on Facebook and Instagram. Within a month, the campaign drove strong awareness and consideration, generating more than100 million viewsand close to 2 million link clicks across all Member States.', 'We’re also supporting the United Nations’“Only Together” campaign calling for fair and equitable access to COVID-19 vaccines around the world. In the coming days, we will be launching in-feed informational messages to promote content posted by health organizations who are participating in the UN’s campaign.', 'In February, in consultation with leading health organizations, including the World Health Organization, weexpanded the list of false claimswe will remove during the pandemic to include additional debunked claims about the coronavirus and vaccines. Since launching our new policy applying both to old and new content, we have removed an additional 2 million pieces of content from Facebook and Instagram. The majority of this additional content was previously subject to warning screens, and is now removed from the platform.', 'We’re continuing to expand our efforts to address COVID-19 vaccine misinformation by adding labels to Facebook and Instagram posts that discuss the vaccines. These labels contain credible information about the safety of COVID-19 vaccines from the World Health Organization. For example, we’re adding a label on posts that discuss the safety of COVID-19 vaccines that notes COVID-19 vaccines go through tests for safety and effectiveness before they’re approved. This label is rolling out globally in English, Spanish, Indonesian, Portuguese, Arabic and French, and we are adding additional languages in the coming weeks.', '', 'In the coming weeks, we’re rolling out labels on all posts generally about COVID-19 vaccines that point people to the COVID-19 Information Center globally, and plan to add additional targeted labels about COVID-19 vaccine subtopics. We will also add an additional screen when someone goes to share a post on Facebook and Instagram with an informational COVID-19 vaccine label. It will provide more information so people have the context they need to make informed decisions about what to share.', 'Building on our goal to promote authoritative information about COVID-19 vaccines, we have implemented several temporary measures to further limit the spread of potentially harmful COVID-19 and vaccine information during the pandemic. Some of these measures include:', 'Today, we are bringing new data and insights on vaccine attitudes to Facebook Data for Good’sCOVID-19 map and dashboard. These visualizations are designed to provide information to inform and monitor vaccine rollouts in over 200 countries and territories. The dashboard is updated in near real time with data collected by our partners at Carnegie Mellon University and University of Maryland as part of theCOVID-19 Symptom Survey. For example, globally, the top two reasons why respondents say they do not intend to get vaccinated are fear of side effects and waiting to see if vaccines are safe. Facebook does not host the surveys nor collect survey participant responses, and only has access to public, aggregated survey data provided by the universities. This data can help inform messaging tactics and policy decisions at a regional level. More insights and trends for the US can be foundhere.', '', 'We’re also making it easy to track how COVID-19 vaccine information is being spread on social media throughCrowdTangle’s COVID-19 Live Displays. Publishers, global aid organizations, journalists and others can access real-time, global streams of vaccine-related posts on Facebook, Instagram and Reddit in 34 languages. CrowdTangle also offers Live Displays for 104 countries and all 50 states in the US to help aid organizations and journalists track posts and trends at a regional level as well.']\n",
            "30 ['Update on May 19, 2021 at 4:00AM PT:', 'Today, we’re expanding our informational labels to some posts about climate change in Canada, France, Germany, Ireland, Nigeria, South Africa and the US. These labels will link to the Climate Science Information Center where people can findfactual information from leading climate organizations and resources to take action against climate change.', 'Originally published on February 18, 2021 at 3:00AM PT:', 'Knowledge is power, especially when it comes to combating climate change. We’re expanding and improving ourClimate Science Information Center, and introducing new ways for people to discover it.', 'The Climate Science Information Center connects people on Facebook with science-based news, approachable information and actionable resources from the world’s leading climate change organizations. The center includes detailed deep dives that go beyond the basic facts, as well as ways to get involved.It also has information relevant to where you live. The center is already available in France, Germany, the UK and US, from today our center will also be available in Belgium, Brazil, Canada, India, Indonesia, Ireland, Mexico, the Netherlands, Nigeria, Spain, South Africa and Taiwan.', '', 'Along with expanding the center, we’re improving it. We added a section that features facts that debunk common climate myths — including too much carbon dioxide in the atmosphere harms the earth’s plant life and polar bear populations are declining because of global warming. To debunk the myths with current and specific facts, we’ve brought in climate communication experts from the George Mason University, the Yale Program on Climate Change Communication and the University of Cambridge.', '', 'We already direct people to the Climate Science Information Center when they search for climate-related terms, and will keep doing that where the center is available. In countries where it isn’t, we will soon direct people to theUN Environment Programme, a leading global environmental authority.', 'We’re also starting to add informational labels to some posts on climate in the UK that direct people to the center, and we plan to expand to more countries soon.', '', 'As Nancy Groves, of the UN Environmental Programme, puts it: “A healthy planet depends on everyone, everywhere and that starts with people having access to accurate and timely information. We look forward to continuing to work with Facebook on this new effort to dispel myths and to provide access to the latest science on the climate emergency.”']\n",
            "31 ['We’re running the largest worldwide campaign to promote authoritative information about COVID-19 vaccines by:', 'A year ago, COVID-19 was declared a public health emergency and since then, we’ve helped health authorities reach billions of people with accurate information and supported health and economic relief efforts. We’ve connected over 2 billion people from 189 countries to reliable information about the coronavirus through our COVID-19 Information Center and informational messages, and we’ve removed more than 12 million pieces of content on Facebook and Instagram containing misinformation that could lead to imminent physical harm. We’ve partnered with governments in more than 120 countries, as well as multilateral organizations like the World Health Organization (WHO) and UNICEF, to deliver timely information about COVID-19, including through helplines on WhatsApp.', 'We’ve provided researchers and public health officials with real-time data and tools to help inform disease forecasting and understand the effectiveness of prevention measures. Through our Data for Good program, we’ve partnered with over 450 organizations in nearly 70 countries, the vast majority of which are leveraging our tools to support the COVID-19 response in their communities. And our publicly available datasets were downloaded over a million times in the last year by nonprofits, public health officials and researchers.', 'But there’s still a long road ahead, and in 2021 we’re focused on supporting health leaders and public officials in their work to vaccinate billions of people against COVID-19. Building trust and confidence in these vaccines is critical, so we’re launching the largest worldwide campaign to help public health organizations share accurate information about COVID-19 vaccines and encourage people to get vaccinated as vaccines become available to them.', 'As public officials roll out information on COVID-19 vaccine availability, we’ll help people find where and when they can get vaccinated — similar to how we helped people find information about where and when to vote during elections. Starting this week in the US, we’ll feature links in the COVID-19 Information Center to local ministry of health websites to help people understand whether they’re eligible to get vaccinated and how to do so. And in the coming weeks, as more information becomes available, we’ll continue to expand this feature to more countries and improve it to make it easier for people to see where and when they can get vaccinated in just a few taps.', 'We’re working with health organizations and community leaders to run campaigns on our platform promoting accurate information about COVID-19 vaccines and encouraging people to get vaccinated. We’re giving $120 million in ad credits to help health ministries, NGOs and UN agencies reach billions of people around the world with COVID-19 vaccine and preventive health information. And we’re providing training and marketing support to help governments and health organizations move quickly and reach the right people with the latest vaccine information.', 'We’ll soon bring theCOVID-19Information Center to Instagram so people can access the latest information about COVID-19 vaccines across our apps.We’re also helping health authorities and governments share timely vaccine information over WhatsApp and provide answers to people’s questions. We partnered with the government in Indonesia to create a helpline on WhatsApp that shares information on vaccine availability first with medical workers, and eventually with the general public. In just 5 days, 500,000 medical workers — out of 1.3 million in the country — accessed the service. Other governments and health authorities, including the South Africa government and the WHO, are starting to create similar helplines to provide the latest vaccine information.', 'We’re also working to amplify content that directly serves communities where vaccine intent and access may be lower. In the US, we’re partnering with the Johns Hopkins Bloomberg School of Public Health to reach Native American communities, Black communities and Latinx communities, among others, with science and evidence-based content that addresses the questions and concerns these communities have.We’re also working with AARP to reach Americans over 50 with educational content about COVID-19 vaccines, including Spanish-language content designed to reach Latinx and Hispanic communities.', 'This builds on the work we’ve done with health organizations over the past year to increase adoption of COVID-19 preventive behaviors, such as wearing a mask. We put reminders at the top of Facebook and Instagram to wear a mask. And we reached over 26 million people with our public figure campaignencouraging people to #WearAMask, resulting in a 7-point increase in people reporting that wearing a mask in public is very or extremely important. We’ll use insights and best practices from this work to inform vaccine information campaigns and support health authorities in building confidence in COVID-19 vaccines.', 'In addition to sharing reliable information, we are expanding our efforts to remove false claims on Facebook and Instagram about COVID-19, COVID-19 vaccines and vaccines in general during the pandemic. Today, following consultations with leading health organizations, including theWHO, we’re expanding the list of false claims we will remove to include additional debunked claims about COVID-19 and vaccines. Learn more about how we’recombating COVID-19 and vaccine misinformation.', 'Last year, we began collaborating withCarnegie Mellon UniversityDelphi Research Groupand the University of Maryland on COVID-19 surveys about symptoms people are experiencing, mask wearing behaviors and access to care. These surveys are conducted by our academic partners and Facebook does not receive individual survey responses. With over 50 million responses to date, the survey program is one of the largest ever conducted and has helped health researchers better monitor and forecast the spread of COVID-19. It’s also the only source of global data on mask wearing, which has helped public health officials around the world in their COVID-19 response efforts. The Institute of Health Metrics and Evaluation used insights from the surveys to inform several mask mandates in countries such as Poland, which achieved a significant increase in mask wearing.', 'The survey data shows that people’s willingness to get a COVID-19 vaccine varies widely across the world, with over 90% of people in Denmark saying they would take a COVID-19 vaccine compared to 71% in Argentina and 62% in the Philippines. And in the US, less than 60% of Black or African American people reported they would be likely to get a COVID-19 vaccine. So to help guide the effective delivery of COVID-19 vaccines, the survey data will provide a better understanding oftrends in vaccine intentacross sociodemographics, race, geography and more. The scale of the survey will also allow for faster updates on changes in trends, such as whether vaccine intent is going up or down in California in a given week and better insights on how vaccine intent varies at a local level. We’ll share these new insights includingvaccine attitudes at a county levelin the US as well asglobally.', 'Data has proved critical in informing the fight against COVID-19. In 2020, we launched new datasets, maps and tools to support researchers, nonprofits and governments in their COVID-19 response, and in 2021, we’ll continue to provide helpful data and insights to understand vaccine attitudes, build trust in vaccines through reliable information and support vaccination efforts.', 'For more information about how we’re providing data to aid in the fight against COVID-19, check out our2020 Data for Good Annual Report. And to learn more about how we’re supporting COVID-19 relief efforts and keeping people informed, visit ourCOVID-19 action page.']\n",
            "32 ['Jump to latest news', 'Facebook is supporting the global public health community’s work to keep people safe and informed during the coronavirus public health crisis. We’re also working to address the long-term impacts by supporting industries in need and making it easier for people to find and offer help in their communities.', 'Here’s an overview of how we’re providing access to accurate information, supporting relief efforts and keeping people connected. We’ll continue to add to this post as we announce updates.', '1. Ensuring everyone has access to accurate information and removing harmful content', '2. Supporting health and economic relief efforts', '3. Keeping people connected', 'Updating Our Ad Policy for COVID-19 Vaccines', 'Given the recent approval of COVID-19 vaccines, we want people to be able to safely promote information about these vaccines on Facebook. We will now allow ads that highlight the ability of a COVID-19 vaccine to prevent someone from contracting the virus, as well as ads promoting ways to safely access a COVID-19 vaccine. We’ll continue to prohibit content that tries to exploit the pandemic for commercial gain. And ads or organic posts that promote the sale of a COVID-19 vaccine, such as attempts to sell COVID-19 vaccine kits or expedited access to the vaccine, will be rejected. We will also reject ads that claim the vaccine is a cure for the virus.', 'It will take some time to train our systems and teams on these policies, and we expect enforcement to ramp up over the coming weeks and months.', 'Providing Aid to Diverse Suppliers through Receivables Financing', 'In response to the ongoing impact of the COVID-19 pandemic – particularly the challenges facing minority and women-owned businesses – we recently launchedThe Facebook Receivables Financing Programto support US-based suppliers. This one-year financing program allowsminority, women, veteran, LGBTQ and disability-owned companies that are headquartered in the US and have been paid directly by Facebook in 2019 or 2020 to have their invoices paid now instead of in the 60 to 120 day period it normally takes to get paid for work they’ve already done. Our goal with this program is to help level the playing field by providing businesses with access to more working capital.', 'We’ll do this by providing immediate cash for work suppliers have done and pay they’re owed by other, non-Facebook, companies. Suppliers can upload eligible invoices to the Receivables Financing platform and get funded in a few days. We partnered with Supplier Success, a minority-owned business with extensive experience providing receivables financing, to administer our Receivable Financing platform and collaborated with Crowdz.io to operate a seamless and secure platform to safely buy receivables. Together, Supplier Success and Crowdz.io will collect the suppliers’ invoices from their customers, and Facebook will reinvest the collected receivables to purchase additional invoices. Facebook is not making any return on these funds.', 'Removing False Claims About COVID-19 Vaccines', 'Given the recent news that COVID-19 vaccines will soon be rolling out around the world, over the coming weeks we will start removing false claims about these vaccines that have been debunked by public health experts on Facebook and Instagram. This is another way that we are applying our policy to remove misinformation about the virus that could lead to imminent physical harm. This could include false claims about the safety, efficacy, ingredients or side effects of the vaccines. For example, we will remove false claims that COVID-19 vaccines contain microchips, or anything else that isn’t on the official vaccine ingredient list. We will also remove conspiracy theories about COVID-19 vaccines that we know today are false: like specific populations are being used without their consent to test the vaccine’s safety. We will not be able to start enforcing these policies overnight. Since it’s early and facts about COVID-19 vaccines will continue to evolve, we will regularly update the claims we remove based on guidance from public health authorities as they learn more.', 'We will also continue to help people stay informed about these vaccines by promoting authoritative sources of information through ourCOVID-19 Information Center.', 'Mark Zuckerberg is live with Dr. Anthony Fauci, America’s top infectious disease expert, to discuss progress toward a COVID-19 vaccine and how we can slow the spread of the virus this holiday season.', 'Connecting People to Mental Health Resources', 'Experts agree that COVID-19 has exacerbated mental health challenges around the world, and the repercussions will be felt for years to come. We’ve been working with leading authorities around the world — like NAMI, Kids Help Phone and It’s OK to Talk — to invest in the critical areas of mental health support, including handling financial stress, parenting support, coping with loss and grief, managing substance use and taking care of overall emotional health. Today we’re introducing Emotional Health, acentralized resource centeron the Facebook app with tips and information from leading experts. The resource will be available globally, with locally relevant information from mental health officials.', 'Learn moreabout how we’remaking it easier for people to get the support they need for themselves and others who might be struggling.', '', 'Allowing the Promotion and Sale of Hand Sanitizer and Surface Disinfecting Wipes', 'In March, we temporarily banned ads and commerce listings forhand sanitizer and surface disinfecting wipesto help protect against scams, inflated prices and hoarding. Since then, we’ve continued to monitor trends and activity around COVID-19 to better understand how people are using our platform and advertising tools during the pandemic. Today we’re scaling back this temporary ban to allow people to promote and trade hand sanitizer and surface disinfecting wipes on our apps.', 'Supporting Teachers, Parents and Students This Back-To-School Season', 'Back-to-school looks different this year due to COVID-19, and parents, teachers and students around the world are facing a myriad of challenges, from remote teaching and learning, balancing work and home responsibilities, and most importantly, maintaining the safety and well-being of everyone involved. To help, we’re launching anEducator Hubto support teachers and providing resources across our apps to help people stay connected and take care of each other. The Educator Hub will help teachers find or build their online communities and discover guides and other resources for the classroom and beyond.Learn more.', 'Mark Zuckerberg is live with Dr. Anthony Fauci, America’s top infectious disease expert. They’ll discuss the US’ response to COVID-19, progress on a vaccine, and what we need to do next to stop the spread of the virus.', 'We continue working to keep people safe and informed about COVID-19. We have connected over 2 billion people to resources from health authorities through ourCOVID-19 Information Centerand pop-ups on Facebook and Instagram with over 600 million people clicking through to learn more. Since January, people have raised over $100 million for COVID-19 related fundraisers on Facebook and Instagram. Over half of those donations were under $25.', 'FactsAboutCOVID-19', 'To further limit the spread of misinformation, this week we are launching a dedicated section of theCOVID-19 Information Centercalled Facts about COVID-19.It will debunk common myths that have been identified by the World Health Organization such as drinking bleach will prevent the coronavirus or that taking hydroxychloroquine can prevent COVID-19. This is the latest step in our ongoing work to fight misinformation about the pandemic.', '', 'Global Reminders to Wear Face Coverings', 'With the rise in COVID-19 cases in the US and in many other parts of the world, we are expanding our alerts reminding people to wear face coverings internationally as recommended by health authorities. These alerts have been running at the top of Facebook and Instagram in the US since early July. Starting this week, we will expand them to more countries globally.', 'With the rise in COVID-19 cases in the US, we’re putting an alert at the top of Facebook and Instagram to remind everyone to wear face coverings and find more prevention tips from the CDC in our COVID-19 Information Center.', 'Launching Summer of Support', 'Over the past few months, many businesses have changed the way they operate, and many more are looking for ways to pivot and move forward. Today we’re kicking off our Boost with FacebookSummer of Supportprogram to help millions of people get training in the digital skills they need to succeed. Over the next six weeks, we’ll offer free online training, live sessions and conversations on topics such as reimagining customer support, transitioning from brick and mortar to digital, and more. You can learn more about Summer of Support and other ways we’re supporting businesseshere.', 'Expanding Our Blood Donations Feature', 'COVID-19 has led to blood shortages around the world due to shelter in place orders limiting the ability for people to donate. To help, we’re expanding our FacebookBlood Donations featureto connect more people to their local blood banks, so they know when there is a shortage and where it is safe to donate. The Blood Donations feature is now available in South Africa, Senegal, Kenya, Burkina Faso, Côte d’Ivoire and Egypt as well as the US, India, Brazil, Pakistan and Bangladesh.We’re also working with partners in India and Brazil to connect people with more local blood banks and hospitals through the Blood Donations feature. And in the US, we’re excited to announce a new partnership withAABBto connect people to hospital blood banks.', '', 'Allowing the Promotion of Non-Medical Masks on Facebook and Instagram', 'Since the World Health Organization declared COVID-19 a global pandemic, governments and authorities around the world have evolved their guidance on the need to wear masks. In March, wetemporarily banned ads and commerce listings for maskson our apps to help protect against scams, misleading medical claims, medical supply shortages, inflated prices and hoarding. Since then, we’ve continued to monitor trends and activity around COVID-19 to better understand how people are using our platform and advertising tools during the pandemic.', 'Many health authorities now advise wearing non-medical masks – and in some places masks are required for activities like taking public transportation or visiting a store – and we’ve seen people and businesses of all sizes working to fill this need. So we’re scaling back this temporary ban to allow people to promote and trade non-medical masks, including those that are homemade or handmade, in organic posts, ads and commerce listings on Facebook and Instagram. We will still maintain a temporary ban on selling medical masks, such as surgical or N95 masks, to prevent people from exploiting the pandemic for financial gain.You can learn more about how we define non-medical masks and advertiser restrictions for these adshere.', 'Releasing New Data for Good Tools', 'Today we’re releasing new visualizations and datasets publicly to help researchers, NGOs and others combat the COVID-19 pandemic. You can learn more about these and our other Data for Good toolshere.', 'Tomorrow on#GivingTuesdayNowwe’re expandingCommunity Helpto make it easier for people to support local businesses and nonprofits. Starting tomorrow, people will be able to find gift cards and vouchers to support local businesses, donate to local nonprofit fundraisers, sign up to become a blood donor and find local job opportunities — all inCommunity Help.', '', 'Partnering with ITDRC and NetHope to Address the Digital Divide', 'The coronavirus pandemic has underscored the importance of internet connectivity. While many people have shifted their lives online, there are still more than 3.5 billion people, including more than18 million Americans, who lack reliable internet access. To help, we’re partnering with the Information Technology Disaster Resource Center (ITDRC) and NetHope to provide internet connectivity to communities most impacted by COVID-19. The goal of these partnerships is to better understand the unique barriers these communities face in getting online and create the programs and infrastructure needed to increase the availability and affordability of high-quality internet access.', 'Update on Content Review Work', 'Throughout the COVID-19 crisis, we’ve worked to keep both our workforce and the people who use our platforms safe. Last monthwe announcedthat we would temporarily send our content reviewers home. Since then we’ve shared updates on changes we’ve made to keep our platform safe during this time, including increasing the use of automation, carefully prioritizing user reports, and temporarily altering our appeals process.', 'We’ve also asked some of our full-time employees to review content related to real-world harm like child safety and suicide and self-injury. It’s become clear in recent weeks that our offices are unlikely to return to business as usual in the near future. Some of our full-time employees will continue to review sensitive content, butas Mark referenced last weekwe will begin working with our partners to bring a small number of content reviewers back to offices to support these efforts in the coming weeks.', 'Returning to the office will be voluntary. We’ll also work with our partners to put protections in place to keep content reviewers safe. These will include: greatly reducing building capacity in these offices to ensure government guidelines on physical distancing can be observed, implementing strict cleaning protocols and providing personal protective equipment like masks and gloves as well as temperature checks at the beginning of every shift.', 'As the situation evolves, we’ll continue to share changes we make to keep both our community and the people who review content on our platforms safe.', 'Facebook Joins Open COVID Patent Pledge', 'Today Facebook joined Amazon, Hewlett Packard, IBM, and Microsoft in signing theOpen COVID Patent Pledgeto help make patents freely available in the fight against COVID-19. The pledge allows people to useour patentsto advance innovation that may help in ending the COVID-19 pandemic and minimizing the impact of the disease —\\xa0without any uncertainty around intellectual property rights or fear of litigation.', 'Sharing COVID-19 Symptom Maps and Expanding Survey Globally to Help Predict Disease Spread', 'Today Carnegie Mellon University (CMU) Delphi Research Center made public theinitial resultsof their US symptom survey wepromoted on Facebook. Using aggregate data from Carnegie Mellon, Facebook produced its first report andnew interactive maps, which we plan to update daily through this outbreak. Mark Zuckerberg wrote in theWashington Postabout how surveys like this can be an important tool in fighting COVID-19 and announced that we’re working with faculty from the University of Maryland to expand the program globally.', '', 'Limiting the Spread of COVID-19 Misinformation', 'Today we shared someadditional stepswe’re taking to combat COVID-19 related misinformation and make sure people have the accurate information they need to stay safe.', 'Making It Easier to Support Businesses on Instagram', 'We’re making it easier for people to support the businesses they love through gift cards, online food orders and fundraisers all on Instagram.Learn more.', '', 'Getting Expert Insights on How We Can Safely Re-Open Society', 'Mark Zuckerberg and Priscilla Chan are live with Dr. Tom Frieden, the former director of the CDC and founder of Resolve to Save Lives. They’ll discuss how we can contain the spread of COVID-19 and how we should approach reopening society.', 'Helping the WHO Share Timely Information on Messenger', 'Today the World Health Organization (WHO) launched an interactive experience on Messenger to provide accurate and timely information about the coronavirus outbreak. People will now be able tomessage the WHOwith questions about COVID-19 and get quick answers for free. The WHO created this Messenger experience with support fromSprinklras part of theprogramwe recently announced to pair developer partners with health organizations to help them connect with people and deliver critical information during the COVID-19 outbreak.Learn more.', 'Connecting People to Well-Being Tips and Resources', 'The COVID-19 pandemic has forced people around the world to adjust to new routines, cope with loneliness, job loss, grief and more. And it’s tough for all of us in different ways, not just physically but mentally. To help, we’re sharing tips from experts to stay well, supporting the work of mental health organizations, and giving you tools to manage your time on Facebook.', '', 'Helping People Get Reliable Information In Groups and Local Alerts', 'As people are turning to Groups to connect with communities they care about and get support during this time, we want to make it easy to find and share reliable information in groups. Here are a few things we’re doing:', '', 'In addition, we more than doubled the number of state and local governments and health agencies onboarded toFacebook local alerts, so we now have more than 2,000 partners using the tool to communicate timely information to their communities.', 'New Tools to Help Health Researchers Track and Combat COVID-19', 'Today we’reannouncingnew Data for Good tools to support health researchers and nonprofits:', '', 'Helping Small Businesses', 'Today we’re sharing an update on our efforts to help small businesses get through this challenging time. These include:', 'Making It Easier for People to Request or Offer Help in Their Communities', 'Today we’re announcing Community Help, a place for people to request or offer help to neighbors, such as volunteering to deliver groceries or donating to a local food pantry or fundraiser. You can access Community Help in the COVID-19 Information Center on Facebook or by visitingfacebook.com/covidsupport. We’re starting to roll it out in the US, the UK, France, Australia and Canada in the next few days, and we’re working to bring it to more countries in the coming weeks.', '', '', 'Donating $25 Million to Support Healthcare Workers', 'Mark Zuckerberg and Priscilla Chan are live with Governor Gavin Newsom to talk about California’s response to the COVID-19 outbreak. They’ll discuss the urgent need for more healthcare workers and Facebook’s $25 million donation to help support healthcare workers on the front line.', 'Investing $100 Million in the News Industry', 'The news industry is working under extraordinary conditions to keep people informed during the COVID-19 pandemic. Today we’reannouncingan additional $100-million investment to support journalists — including $25 million in emergency grant funding for local news through the Facebook Journalism Project, and an extra $75 million in marketing to get money to publishers around the world at a time when their advertising revenue is declining.', 'This investment is in addition to the support we’ve already pledged to the news industry in response to COVID-19:$1 million in grantsfor local news,$1 million in grantsfor fact-checking organizations, and a$1-million donationto the International Fact-Checking Network.', 'Launching the Messenger Coronavirus Community Hub', 'Today, we’re launching theMessenger Coronavirus Community Hubwith tips and resources to keep people connected to their friends, family, colleagues and community, and prevent the spread of misinformation. It also includes advice on how to recognize and avoid scams and misinformation online.Read moreabout how you can use Messenger to stay connected and informed during this time.', 'Helping Young People Safely Navigate the Internet', 'Today we’re launching our digital literacy program,Get Digital, to provide lessons and resources to help young people develop the competencies and skills they need to more safely navigate the internet. These resources are designed to be used by educators and families both in the classroom and at home, but they’ve become even more important as young people spend more time on their devices while at home during the COVID-19 outbreak.', 'Get Digital will help young people learn how to:', 'It will also help them discover how technology can be used for civic and political engagement. And it can help them develop digital skills, such as understanding algorithms, and explore programming and more to help prepare them for future careers in technology.', 'We’re partnering with UNESCO, the International Society for Technology in Education (ISTE), National PTA, and EVERFI to distribute our new digital literacy tools to parents and educators around the world. Lessons are drawn from the Youth and Media team at the Berkman Klein Center for Internet & Society at Harvard University, which has made them freely available worldwide under a Creative Commons license, and the Greater Good Science Center.', 'Sharing Tips for People Working Remotely', 'Remote work can be challenging whether you’re balancing caregiving and work, trying to lead a dispersed team, or adjusting to a new routine and responsibilities. That’s why we created an online resource with tips to help our global team stay connected, be productive and do their best work, wherever they’re working. We’re sharing it publicly today in case it’s helpful to others as many adjust to working remotely during this challenging time. Check out ourremote work resources.', 'Combating COVID-19 Misinformation Across Our Apps', 'Today we shared anoverviewof how we’re connecting people to reliable information and taking aggressive steps to combat COVID-19 misinformation across our apps.', 'Keeping Our Apps Stable and Reliable', 'As more people around the world are physically distancing themselves from others, we’ve seen people using our apps more than ever. Today, we shared some data to give context onthe load we’re managing. Our apps were built to withstand spikes, but the usage growth from COVID-19 is unprecedented across the industry. We’re monitoring usage patterns carefully, making our systems more efficient and adding capacity when needed, and we’re doing everything we can to keep our apps stable and reliable during this time.', 'Helping People Stay Informed and Connected on Instagram', 'Today we announcedupdatesto help people stay informed, safe and connected on Instagram during this challenging time. These include:', 'Helping Government Health Organizations Use Messenger', 'Today we’re announcing two initiatives to help government health organizations in their response to the coronavirus outbreak using Messenger.', 'Read moreabout how we’re leveraging Messenger’s reach, tools and technology to help people stay connected and informed during this time.', 'Launching the WHO Health Alert on WhatsApp', 'Today we launched theWorld Health Organization’s Health Alert on WhatsApp. TheWHO Health Alertis free to use and will answer common questions about COVID-19. It provides timely, reliable information about how to prevent the spread of the coronavirus as well as travel advice, coronavirus myth debunking and more. Tocontact the WHO Health Alert, save the number +41 79 893 1892 in your phone contacts and then text the word ‘Hi’ in a WhatsApp message to get started. The service is initially launching in English but will be available in all six United Nations languages (English, Arabic, Chinese, French, Russian and Spanish) within the coming weeks.', 'It’s an honor to work with@WHOto provide this simple service to get the latest information directly from the experts right on WhatsApp. Tap the link below to get started. Share these tips and de-bunked rumors with your friends and family 🙏https://t.co/WWhbKccdABpic.twitter.com/EYCuAliCk2', '— WhatsApp (@WhatsApp)March 20, 2020', '', 'Keeping Our Platform Safe With Remote and Reduced Content Review', 'We recently announced that we’re temporarilysending content reviewers home. We want to make sure our platform remains a safe place for people to connect during this time, but with a reduced and remote workforce, below are some ways our content review processes will be impacted.', 'Policy Enforcement:We will continue to enforce our policies and prioritize preventing and disrupting harm across our platform. We are conducting human rights due diligence, looking at potential risks, and putting in place contingency plans that both prioritize the safety of our content reviewers and support the integrity of our platform. As Mark Zuckerberg discussed ona press call, for example, we have shifted certain content review work to full time employeesand are focusingon areas including child safety, terrorism, suicide and self-injury, and harmful content related to COVID-19.', 'Some contract reviewers will work from home, but with a reduced and remote workforce, we will now rely more on our automated systems to detect and remove violating content and disable accounts.As a result, we expect to make more mistakes, and reviews will take longer than normal, but we will continue to monitor how our systems are performing and make adjustments. In addition, reviewing content can be challenging, and working from home presents new obstacles in providing support to our teams, but we’re working to ensure our content reviewers have the resources and help they need during this time.', 'User Reports:When people report content to us that they believe violates our policies, they will see a new message letting them knowthat we have fewer content reviewers available and will prioritize reported content that has the greatest potential \\u200bto harm our community. This means some reports will not be reviewed as quickly as they used to be and we will not get to some reports at all.', 'Appeals:Normally when we remove content, we offer the person who posted it the option to request that we review the content again if they think we made a mistake. Now, given our reduced workforce, we’ll give people the option to tell us that they disagree with our decision and we’ll monitor that feedback to improve our accuracy, but we likely won’t review content a second time.', 'We’re working hard to minimize any impact on people as they use Facebook, Instagram and Messenger during this time, but we know some may feel this impact either when reporting content to us or appealing content we remove.', 'We’re doing everything we can to keep our global teams and the community that uses our apps safe while continuing to provide the services people and businesses rely on.', 'Getting Expert Health Tips and Information From Dr. Fauci', 'Mark Zuckerberg is live with Dr. Anthony Fauci, America’s top infectious disease expert involved in leading our government’s response to COVID-19. They’ll discuss how we can all help fight the spread of the coronavirus and what governments are doing to respond to the pandemic.', 'Banning Ads for Hand Sanitizer, Disinfecting Wipes and COVID-19 Testing Kits', 'In addition to masks, we’re now also banning ads and commerce listings for hand sanitizer, surface disinfecting wipes and COVID-19 testing kits. And if we see people selling these products in organic posts on Facebook or Instagram, we’ll remove them.', \"We’ll be ramping up our automated enforcement for ads and commerce next week.  If we see abuse around these products in organic posts, we'll remove those, too (2/2)\", '— Rob Leathern (@robleathern)March 19, 2020', '', 'Minimizing Disruptions for Businesses and Partners on OurPlatform', 'As we announcedon Monday,we’re working with our partners to send home all contract workers who perform content review, until further notice. Since this includes people who review ads and monetized content, we wanted to share more about what this means for advertisers, publishers and creators that use our tools.', 'For Advertisers', 'We use a combination of people and technology to review ads on Facebook and Instagram, and our automated systems already play a big role in that process. Nowwith a reduced and remote workforce, we’re relying on automated technology even more.This may mean:', 'For Content Creators and Publishers', 'All monetized content goes through brand safety reviews. This includes Instant Articles and videos with in-stream ads. Since our ability to review new content is now limited, we won’t be able to approve all content for monetization. We’re working on how to support partners at this time.', 'As this situation continues to evolve, we may need to make further changes to our systems. While we’re working to minimize disruptions for businesses and partners, we will inevitably make mistakes. We will do our best to address any issues as quickly as we can and continue to provide updates.', 'Press Call Recap', 'This morning on a press call, Mark Zuckerberg shared how we’re supporting people and businesses affected by the coronavirus outbreak and how we’re working with health authorities to make sure everyone can access accurate information. He also announced a newCoronavirus Information Centeron Facebook to help people find information and tips, and he shared how we’re giving governments and emergency services around the world free access to Workplace. Read the fulltranscript from his press call.', 'Offering Workplace to Government and Emergency Organizations for Free', 'Starting today, we’re offering Workplace Advanced to government agencies and emergency services free of charge for 12 months. These organizations play a vital role during the coronavirus outbreak, whether it’s acting as first responders or coordinating public information. Workplace can help inform and connect their employees, allowing them to share critical information in real-time and enabling leadership to reach employees via live videos, posts and more.Read moreabout how we’re supporting emergency services and government organizations during this time.', '', 'Launching the Coronavirus Information Center on Facebook', 'Today we’re announcing the Coronavirus (COVID-19) Information Center, featured at the top of News Feed, to provide a central place for people to get the latest news and information as well as resources and tips to stay healthy and support their family and community.', 'It includes real-time updates from national health authorities and global organizations such as the World Health Organization, as well as helpful articles, videos and posts about social distancing and preventing the spread of COVID-19.', 'People can also follow the Coronavirus Information Center to receive updates from health authorities directly in their News Feed. And starting in the US, people will see features to help them connect with local groups and ask for or offer help within their community.', 'We’re rolling out the information center in Italy, France, Germany, Spain, the UK and the US within the next 24 hours, and we’ll expand it to more countries in the coming days.', '', 'Helping People Stay Connected Using WhatsApp', 'In these uncertain times, reliable communication is critical. That’s why we’ve nearly doubled server capacity for WhatsApp and continue to see strong reliability as people place more voice and video calls around the world. In addition, today we launched aninformation hubwith tips on how healthcare workers, educators and local businesses can stay connected using WhatsApp. We also donated $1 million to the International Fact-Checking Network (IFCN) to expand the presence of local fact-checkers on WhatsApp.', 'We’re grateful to@who@undp@uniceffor coordinating the response to this crisis including using@WhatsAppto do so. Already several ministries of health are providing updates to citizens on WhatsApp and we will expand these services together.', '— Will Cathcart (@wcathcart)March 18, 2020', '', 'Supporting Fact-Checkers and Local News Organizations', 'To support fact-checkers in their work around COVID-19, we’re partnering with The International Fact-Checking Network (IFCN) to launch a$1 million grant programto increase their capacity during this time.', 'We’re also supporting local news organizations as they deal with unexpected costs of covering COVID-19 and provide increased coverage during this time. To help, the Facebook Journalism Project is partnering with the Lenfest Institute for Journalism and the Local Media Association to offer a total of$1 million in grants to local news organizationscovering COVID-19 in the US and Canada.', 'Investing $100 Million in Small Businesses', 'We’re creating a $100 million grant program to help small businesses around the world impacted by the coronavirus.', 'Keeping Our People and Our Platforms Safe', 'To keep our people safe, we recently requested that anyone who can work from home do so in all of our offices around the world. We are also continuing to take the necessary steps to keep our platform safe.', 'Over the past couple of years we’ve substantially scaled up our investments in safety and security, including by rapidly growing content review teams and expanding our machine learning capabilities.For both our full-time employees and contract workforce there is some work that cannot be done from home due to safety, privacy and legal reasons.We have taken precautions to protect our workers by cutting down the number of people in any given office, implementing recommended work from home globally, physically spreading people out at any given office and doing additional cleaning. Given the rapidly evolving public health concerns, we are taking additional steps to protect our teams andwill be working with our partners over the course of this week to sendall contract workers who perform content review home, until further notice. We’ll ensure that all workers are paid during this time.', 'We believe the investments we’ve made over the past three years have prepared us for this situation. With fewer people available for human review we’ll continue to prioritize imminent harm and increase our reliance on proactive detection in other areas to remove violating content. We don’t expect this to impact people using our platform in any noticeable way. That said, there may be some limitations to this approach and we may see some longer response times and make more mistakes as a result.', 'These are unprecedented times, but the safety and security of our platform will continue.\\xa0 We are grateful to all of our teams working hard to continue doing the essential work to keep our community safe.', 'Working With Industry Partners', 'Joint industry statement from Facebook, Google, LinkedIn, Microsoft, Reddit, Twitter and YouTube', '“We are working closely together on COVID-19 response efforts. We’re helping millions of people stay connected while also jointly combating fraud and misinformation about the virus, elevating authoritative content on our platforms, and sharing critical updates in coordination with government healthcare agencies around the world. We invite other companies to join us as we work to keep our communities healthy and safe.”', '', 'Matching $20 Million in Donations to Support COVID-19 Relief Efforts', 'We’rematching $20 million in donationsto support COVID-19 relief efforts.', 'Connecting People With Credible Health Information on Instagram', 'We shared updates on our efforts to support the Instagram community during this time.', 'To help people get relevant and up-to-date resources, we will start showing more information from@WHOand local health ministries at the top of Instagram’s Feed in some countries.pic.twitter.com/czAHYItlEx', '— Instagram Comms (@InstagramComms)March 13, 2020', '', 'To thank the health workers who have been working tirelessly to keep their communities safe, we developed a sticker for people to show their gratitude on Instagram. This will be available in the stickers gallery.pic.twitter.com/BS5IKAWBuL', '— Instagram Comms (@InstagramComms)March 13, 2020', '', 'Supporting Businesses and Community Leaders', 'To help people stay safe and informed during the COVID-19 outbreak, we’re providing additional resources to our community. We shared a blog post on ourCommunity Hubto provide accurate information on disease prevention and connect community leaders with tools to help them manage their community. We also created aBusiness Resource Hubthat includes tips and trainings to help businesses navigate challenges during the COVID-19 outbreak and support their customers during this time.', 'Expanding Access to Facebook Local Alerts', 'In addition, we’re helping local governments and emergency response organizations more easily communicate with their communities. As COVID-19 has spread in the US, local governments have used Facebook to share critical information with their communities about this fast evolving situation. Because of the increasing need to get timely and accurate information to local communities, we’re expanding access to Facebook local alerts to even more municipal governments, state and local emergency response organizations and law enforcement agencies. State and local public health agencies will now also have the ability to push out timely, accurate information to their local communities. And we’ll provide additionaltraining to partnersas they start using local alerts to share best practices for using the tool most effectively.', 'Eligible organizations and government agencies canrequest access to the local alerts tool here.', 'Banning Ads and Commerce Listings for Medical Face Masks', 'We are temporarily banning advertisements and commerce listings, like those on Marketplace, that sell medical face masks. We’ll begin to enforce this change over the next few days. We already prohibit people from making health or medical claims related to the coronavirus in product listings on commerce surfaces, including those listings that guarantee a product will prevent someone from contracting it. We also have a dedicated channel for local governments to share listings they believe violate local laws. Our teams are monitoring the COVID-19 situation closely and will make necessary updates to our policies if we see people trying to exploit this public health emergency.', 'Update: We’re banning ads and commerce listings selling medical face masks. We’re monitoring COVID19 closely and will make necessary updates to our policies if we see people trying to exploit this public health emergency. We’ll start rolling out this change in the days ahead.', '— Rob Leathern (@robleathern)March 7, 2020', '', 'Removing COVID-19 Misinformation on Instagram', 'Today we shared updates about the changes we’ve made to keep the Instagram community safe and informed on COVID-19.', 'We’re removing known harmful misinformation related to COVID-19, and when someone taps on a hashtag related to COVID-19, we show resources from@WHO,@CDCand local health authorities.pic.twitter.com/Dw2Y8ZwfaI', '— Instagram Comms (@InstagramComms)March 6, 2020', '', 'Finally, we’re thinking through a longer term solution to help connect people searching COVID-19 related terms with credible information. In the meantime, we’re showing the accounts of leading health organizations in these searches to better connect people to credible resources.pic.twitter.com/RUNwJh94Cf', '— Instagram Comms (@InstagramComms)March 6, 2020', '', 'Supporting Global Health Organizations With Free Ads and More', 'CEO Mark Zuckerberg posted about the latest steps Facebook is taking.', 'As world health officials issue new guidance and warnings about coronavirus (COVID-19), we’re continuing our work to connect people to information from regional and local health organizations and limit the spread of misinformation and harmful content about the virus.', 'Connecting People to Accurate Information and Helpful Resources', 'Anyone who searches for information related to the virus on Facebook is shown educational pop-ups on top of search results connecting them to expert health organizations including the World Health Organization (WHO). We’ve launched these globallyover the last few weeksin all languages on Facebook, directing people to the WHO. In several countries we are directing people to their local ministry of health. For example, in the US we are directing people to information from the Centers for Disease Control and Prevention (CDC) and in Singapore, we’re directing people to the Singapore Ministry of Health. Moreover, in countries where the WHO has reported person-to-person transmission and deaths, we’ve shown additional messages to people toward the top of News Feed with more information.', '', 'Exploitative Tactics in Ads', 'Yesterday we put a new policy into effect to protect people from those trying to exploit this emergency for financial gain. This means we are now prohibiting ads for products that refer to the coronavirus in ways intended to create a panic or imply that their products guarantee a cure or prevent people from contracting it. For example, ads for face masks that imply they are the only ones still available or claim that they are guaranteed to prevent the virus from spreading will not be allowed to run on our platforms.', 'Today, the World Health Organization (WHO) declared the coronavirus a public health emergency of international concern. As the global public health community works to keep people safe, Facebook is supporting their work in several ways, most especially by working to limit the spread of misinformation and harmful content about the virus and connecting people to helpful information. Here are some specific steps we are taking.', 'Our global network of third-party fact-checkers are continuing their work reviewing content and debunking false claims that are spreading related to the coronavirus. When they rate information as false, we limit its spread on Facebook and Instagram and show people accurate information from these partners. We also send notifications to people who already shared or are trying to share this content to alert them that it’s been fact-checked.', 'We will also start to remove content with false claims or conspiracy theories that have been flagged by leading global health organizations and local health authorities that could cause harm to people who believe them. We are doing this as an extension of our existing policies to remove content that could cause physical harm. We’re focusing on claims that are designed to discourage treatment or taking appropriate precautions. This includes claims related to false cures or prevention methods — like drinking bleach cures the coronavirus — or claims that create confusion about health resources that are available. We will also block or restrict hashtags used to spread misinformation on Instagram, and are conducting proactive sweeps to find and remove as much of this content as we can.', 'Our platforms are already being used to help people connect with accurate information about the situation, including from global and regional health organizations. We’ve been closely coordinating with leading health organizations to make this easier and more accessible for people using Facebook and Instagram.', 'For example, we will help people get relevant and up-to-date information from partners through messages on top of News Feed on Facebook; these will be deployed based on guidance from the WHO. When people search for information related to the virus on Facebook or tap a related hashtag on Instagram, we willsurface an educational pop-up with credible information. We have also provided free advertising credits to enable organizations to run coronavirus education campaigns on Facebook and Instagram in affected regions and are discussing ways to provide additional assistance and support to health authorities.', 'We are empowering leading researchers at Harvard University’s School of Public Health and National Tsing Hua University in Taiwan by sharing aggregated and anonymized mobility data and high resolution population density maps to help inform their forecasting models for the spread of the virus as part of our broader Data for Good program. We may expand these efforts to a broader set of partners in the coming weeks. We are also helping partners understand how people are talking about the issue online through tools like CrowdTangle to better inform their efforts.', 'Not all of these steps are fully in place. It will take some time to roll them out across our platforms and step up our enforcement methods.', 'We will provide updates on additional steps we are taking in coordination with global and regional partners as the situation continues to evolve.']\n",
            "33 ['Update on January 5, 2021 at 1:33PM PT:', 'Following the Georgia runoff elections, Georgia will re-join the existing nationwide pause on social issue, elections and political ads.', 'Originally published on December 15, 2020 at 11:30AM PT:', 'We are maintaining our temporary pause for ads about social issues, elections or politics in the US. However, in recent weeks we’ve heard feedback from experts and advertisers across the political spectrum about the importance of expressing voice and using our tools to reach voters ahead of Georgia’s runoff elections. We agree that our ad tools are an important way for people to get information about these elections. So we have developed a process to allow advertisers to run ads with the purpose of reaching voters in Georgia about Georgia’s runoff elections.', 'Starting tomorrow, Wednesday December 16 at 9AM PT, we will begin enabling advertisers who are authorized to run ads about social issues, elections or politics to run ads specifically in Georgia. We will prioritize onboarding advertisers with direct involvement in these elections, including the campaigns, state and local elections officials, and state and national political parties. Advertisers who have previously completed the authorizations process to run these types of ads and have a need to run them for these elections, can learn morehere. We will reject ads that target locations outside of Georgia or that are not about the elections for violating ourAdvertising Policies. And, we will continue to prohibit any ad that includes content debunked by third-party fact-checkers or delegitimizes the Georgia runoff elections.', 'We’re also helping people register and vote in Georgia by putting reliable information at the top of Facebook and Instagram. This included information about how and when to register ahead of last week’s deadline, and how to request a mail ballot. Starting this week, we’re showing people how to find polling place times and locations for early voting, followed by how to return their mail ballots, then how to vote on Election Day. Our notifications link to the Georgia Secretary of State’s website and are available in English and Spanish on Facebook and Instagram, as well as several additional languages on Facebook.', '', '', 'We will also label content that tries to delegitimize voting in these elections. This includes content with claims like, “vote-by-mail leads to fraud.” When we become aware of content like this, we will add a label to it from the Bipartisan Policy Center with accurate information that addresses the underlying claim. And, if someone goes to share the content we have labeled, they will first see a message directing them to ourVoting Information Center, which provides reliable election information.', '', 'Finally, we are deploying the teams and technology we used in the general election to fight voter suppression, misinformation and interference in the Georgia elections. This includes:']\n",
            "34 ['Supporting elections across Africa continues to be a priority and we’ve dedicated unprecedented resources both locally and globally, with protecting election integrity at the center of this work. This update provides an overview of our ongoing work inreducing misinformation,removing voter suppression, preventing election interference, supporting civic engagement and increasing transparency in political advertising.', 'Here are some of the steps we’re taking:', 'We’re working hard to fight the spread of misinformation on our services because we know that people want to see accurate information on Facebook and Instagram – and so do we. Our updated policies allow us to remove misinformation which could lead to imminent violence or physical harm, and also remove misinformation which could prevent people from voting, such as false news related to the dates, location, time and voting methods. Over the past year we’ve expanded our work withindependent fact-checking organisationsacross Africa to review and rate the accuracy of content shared on Facebook and Instagram. We work with organisations such as Dubawa, Africa Check, Pesa Check, AFP, Congo Check and France 24 – all of which are certified by the International Fact Checking Network. The program now covers 18 countries across Sub-Saharan Africa and also supports languages such as Swahili, Wolof, Igbo, Yoruba, Zulu and Setswana.', 'We want to make sure people know how to spot false news and alert us about it. That’s why we continue to run campaigns focused on providing educational tips on how to spot false news like‘Three Questions To Help Stamp Out False News.’These campaigns are available in local languages and run across both local radio and on Facebook. We are also continuing to run education ads focused on hate speech, that explain how it’s defined and actions people can take.', '', '', 'We believe political discussion and debate should be transparent to every voter, which is why over thepast few years we’ve introduced tools that provide more information about political ads on Facebook and Instagram. Since launching our political ads transparency tool in 2019, we’ve expanded this to cover a number of countries across Sub-Saharan Africa. We encourage anybody who wants to run ads about elections or politics to go through a verification process to confirm their identity and that they live in the country they are targeting. In a growing number of countries across Sub-Saharan Africa we have made this process mandatory. We run additional checks to ensure compliance with our policies, and every political ad is labelled with a “paid by” disclaimer so you can see who paid for them. We also store all political ads in ourAds Libraryso that everyone can see what ads are running, who saw the ads and how much was spent. These changes mean that political advertising on Facebook and Instagram is now more transparent than other forms of election campaigning such as billboards, newspaper ads, direct mail, leaflets or targeted emails.', 'Helping to build informed and civically engaged communities is central to our work around elections. For example, in countries like Ghana, Ivory Coast and Guinea we’ve engaged in conversations with civic stakeholders such as the Electoral Commissions and civil society organisations. Focusing on how Facebook can be a positive tool for civic engagement and the steps they can take to stay safe while using our platforms. We’ve also conducted virtual trainings on ads enforcement and civic engagement with political parties in these same countries. We continue to roll out a number of products and features across Facebook and Instagram, including Election Day reminders at the top of Facebook’s News Feed to encourage people to vote, and Security Megaphones to remind page admins of political groups to further secure their accounts usingTwo-Factor Authentication. We’ve also trained parties, and candidates on security best practices, and how to avoid common threats online.', 'This slideshow requires JavaScript.', '', 'Keeping people safe on Facebook and Instagram is always our top priority and this is especially important during elections. Since 2016 we have tripled the size of the teams working on safety and security to more than 35,000 people. We’ve hired more systems engineers, security experts and content reviewers, including native language speakers in Swahili, Amharic, Zulu, Somali, Oromo and Hausa, to name a few examples. We’ve also pioneered the use of artificial intelligence to find and remove harmful content more quickly. Between April and June of this year weremovedover 15 million pieces of graphic and violent content globally, detecting over 99% proactively, before anyone had to report it.', 'Our efforts to keep people safe also include using different tools to reduce harmful content from certain accounts and as hate speech evolves. To further limit the spread of potentially inflammatory content, we continue to temporarily demote content in the News Feeds of users in Ethiopia, and other countries across Africa if it comes from those who repeatedly and severely violate our policies, whether or not those repeat violators are located in the country.', 'As we do in other languages, we’ve also started using our technology to stay ahead of new trends in hate speech in Amharic and Oromo. We identify new forms of potentially violating speech that hasn’t yet been reviewed for possible removal from our platform and demote this content to reduce the risk of it going viral or inciting violence or hatred, taking local context into account.', 'Alongside our local experts on the continent, we continue to work on-the-ground with NGOs and civil society across many African countries to enable us to better understand challenges and how we can tackle them more effectively. This work continues to be instrumental, with local partners giving us feedback that we incorporate into our policies and programs.', 'We’re committed to making Facebook and Instagram places where people feel safe, can access accurate and transparent information and, most importantly, make their voices heard.']\n",
            "35 ['In Augustwe shared an updateon the work we’re doing to prepare for the November elections in Myanmar. Today, we’re announcing some additional steps aimed at protecting the integrity of that election on our platform.', 'Demoting Likely Hate Speech', 'As weannounced in May, and in keeping with our commitment to the UN Guiding Principles on Business and Human Rights, Facebook is taking additional steps to combat hate speech in countries that are in conflict or at risk of conflict.', 'To decrease the risk of problematic content going viral in Myanmar and potentially inciting violence or hatred ahead of or during the election, we will significantly reduce the distribution of content that our proactive detection technology identifies as likely hate speech. This content will be removed if determined to violate our policies, but its distribution will remain reduced until that determination is made.', 'Under our existingCommunity Standards, we remove certain slurs that we determine to be hate speech. To complement that effort, we are using technology to identify new words and phrases associated with hate speech in Myanmar, and are either removing posts with that language or reducing their distribution. We are constantly revising and updating the list of Myanmar-specific, prohibited words and phrases.', 'Improving Efforts to Reduce Repeat Offender Content', 'In addition to our standard practice of removing accounts that repeatedly violate our Community Standards, we will also improve our efforts totemporarily reduce the distribution of content from accounts that have recently and repeatedly violated our policies. This includes providing additional information to those whose accounts are affected.', 'Expanding Misinformation Labels to the Burmese Language', 'As part of our efforts to tackle misinformation, we work with third-party fact-checkers around the world, including three partners in Myanmar who are certified by theInternational Fact-Checking Network, to provide people with additional context about the content they’re seeing on Facebook. For example, when people come across information rated false by our third-party fact-checkers, a screen warns them of this. Now, we’re expanding these warning screens to include the Burmese language.', 'Directing People to Authoritative Voting Information', 'We recognize it is important for people to be able to access reliable information about elections and voting especially during a campaign period. That is why we are helping to direct people to authoritative sources of election information, where they can learn how to check voter lists, as well as voting times and locations. This includes making the Facebook pages of theUnion Election Commission,Vote MMandFirst Time Youth Voters for 2020much more accessible to users.', 'Digital Literacy Training in Myanmar', 'We’ve also been working across Myanmar to train civil society organizations and reporterson journalist safety, media and digital literacy, as well as Facebook’s Community Standards and third-party fact-checking programs. As part of this effort, we’ve held a monthly television talk-show on digital literacy called Tea Talks, that focuses on issues like online bullying and account security.', 'We’ve also introduced tools to newsrooms in Myanmar such asCrowdTangle, a public insights tool from Facebook that makes it easy to follow, analyze and report on what’s happening with public content on social media.', 'And in June, we held a month of webinars on election best practices with 50 people from 13 different news organizations in Myanmar, including ethnic media.', 'Looking ahead, we will continue to support our news partners in Myanmar beyond the election. And we’ll continue to scale up our Community Standards enforcement efforts to meet the challenge of protecting elections and keeping people safe, now and in the future.']\n",
            "36 ['People turn to Facebook Groups to connect with others who share their interests, but even if they decide to make a group private, they have to play by the same rules as everyone else. Our Community Standards apply to public and private groups, and our proactive detection tools work across both. That means even if someone doesn’t report an issue to us, ourAI can detect potentially violating contentand we can remove it.Today we’re sharing an update on ourongoing work to keep groups safe, including a number of changes to reduce harmful content and misinformation.', 'Over the last year, we removed about 1.5 million pieces of content in groups for violating our policies onorganized hate, 91% of which we found proactively. We also removed about 12 million pieces of content in groups for violating our policies onhate speech, 87% of which we found proactively.', 'That’s what we do for posts within groups. When it comes to groups themselves, we will take an entire group down if it repeatedly breaks our rules or if it was set up with the intent to violate our standards. Over the last year, we took down more than 1 million groups for violating these policies.', 'We’re taking further steps to stop people who repeatedly violate our Community Standards from being able to create new groups. Ourexisting recidivism policystops the admins of a group from creating another group similar to one we removed. Going forward, admins and moderators of groups taken down for policy violations will not be able to createanynew groups for a period of time.', 'For members who haveanyCommunity Standards violations in a group, their posts in that group will now require approval for the next 30 days. This stops their post from being seen by others until an admin or moderator approves it. If admins or moderators repeatedly approve posts that violate our Community Standards, we will remove the group.', 'Admins are at the heart of fostering the purpose and culture of their groups. Sometimes admins may step down or leave their groups. Our proactive detection continues to operate in these groups, but we know that active admins can help maintain the community and promote more productive conversations. So we now suggest admin roles to members who may be interested. A number of factors go into these suggestions, including whether people have a history of Community Standards violations.', 'In the coming weeks, we’ll beginarchivinggroups that have been without an admin for some time. Moving forward, when a single remaining admin chooses to step down, they can invite members to become admins. If no invited members accept, we will suggest admin roles to members who may be interested. If no one accepts, we’ll archive the group.', '', 'Facebook Groups, including health groups, can be a positive space for giving and receiving support during difficult life circumstances. At the same time, it’s crucial that people get their health information from authoritative sources. To prioritize connecting people with accurate health information, we are starting to no longer show health groups in recommendations. People can still invite friends to health groups or search for them.', 'For more information on the kinds of content we recommend, including groups, see ourrecommendations guidelines, which werecently made public.', 'This summer we continued to take action against groups tied to violence. Webanned a violent US-based anti-government networkconnected to the boogaloo movement and removed 106 of their groups. We alsoexpanded our policyto address organizations and movements that have demonstrated significant risks to public safety, including QAnon, US-based militia organizations and anarchist groups that support violent acts amid protests.', 'We now limit the spread of these groups by removing them from recommendations, restricting them from search, and soon reducing their content in News Feed. We also remove these groups when they discuss potential violence, even if they use veiled language and symbols. For example, we removed790 groups linked to QAnonunder this policy.', 'To combat misinformation across Facebook, we take a “remove, reduce, inform” approach that leverages a global network of independent fact-checkers. For Facebook Groups, this work includes:', 'We know there is more to do to keep groups safe on Facebook, and we’ll keep improving our technology and policies to ensure groups remain places where people can connect and find support.']\n",
            "37 ['Climate change is real. The science is unambiguous and the need to act grows more urgent by the day. As a global company that connects more than 3 billion people across our apps every month, we understand the responsibility Facebook has and we want to make a real difference.', 'Every day we see our community confronting this challenge – from people making small but meaningful changes like recycling, turning off lights, using public transport or cycling, to those using our tools to organize for change in their communities or to raise more than $80 million for environmental causes.', 'Facebook’s global operations will achieve net zero carbon emissions and be 100% supported by renewable energy this year. But getting our own house in order is only the start. That’s why today, ahead of Climate Week, we are announcing a new Climate Science Information Center to connect people with science-based information, and an ambitious new net zero emissions target for our company’s value chain.', '', 'One of the biggest lessons we have learned from the COVID-19 pandemic is how powerful Facebook can be for connecting people to accurate, expert advice and information during a global crisis. Now, we are taking a similar approach to the climate crisis by launching a newClimate Science Information Center on Facebookto connect people to factual and up-to-date climate information. We have modeled the center and the information within it on our COVID-19 Information Center that has, so far, directed more than 2 billion people to information from health authorities, with more than 600 million people clicking through to learn more.', 'The Climate Science Information Center is a dedicated space on Facebook with factual resources from the world’s leading climate organizations and actionable steps people can take in their everyday lives to combat climate change. The Center will feature facts, figures and data from the Intergovernmental Panel on Climate Change (IPCC) and their global network of climate science partners, including the UN Environment Programme (UNEP), The National Oceanic and Atmospheric Administration (NOAA), World Meteorological Organization (WMO), The Met Office and others. We will also include posts from relevant sources to highlight climate science news.', 'The Center will launch in France, Germany, the UK and US to start and will roll out to other countries soon.', '', 'Beyond our goal of reducing our operational greenhouse gas emissions by 75% this year, we will achieve net zero emissions for our operations. We are also setting an ambitious goal to reach net zero emissions for our value chain – including emissions from suppliers and other factors such as employee commuting and business travel – in 2030. We are committing to the Science Based Target Initiative, aligning our corporate climate goals with the latest science. Over the next decade, Facebook will work to reduce carbon emissions from our operations and value chain, including by working with suppliers on their own goals, helping the development of new carbon removal technologies and making our facilities as efficient as possible.', '', 'We’re committed to tackling climate misinformation. We partner with more than 70 independent fact-checking organizations globally, covering more than 60 languages. These fact-checkers can and do rate climate science content. As with all types of claims debunked by our fact-checkers, we reduce the distribution of these posts in News Feed and apply a warning label on top of these posts both on Facebook and Instagram so people understand that the content has been rated false.', 'Climate change is a crisis we will only be able to address if we all work together on a global scale. We are taking important steps to reduce our emissions and arm our global community with science-based information to make informed decisions and tools to take action. We hope these efforts demonstrate that Facebook is committed to playing its part and helping to inspire real action in our community.']\n",
            "38 ['Today, Mark Zuckerberg announced additional steps we’re taking to help secure the integrity of the US elections by encouraging voting, connecting people to authoritative information, and reducing the risks of post-election confusion.', '']\n",
            "39 ['As a part of our ongoing efforts to provide people with a safer, more private messaging experience, today we’re introducing a forwarding limit on Messenger, so messages can only be forwarded to five people or groups at a time. Limiting forwarding is an effective way to slow the spread of viral misinformation and harmful content that has the potential to cause real world harm.', 'We believe controlling the spread of misinformation is critical as the global COVID-19 pandemic continues and we head toward major elections in the US, New Zealand and other countries. We’ve taken steps to provide people with greater transparency and accurate information. OurCoronavirus (COVID-19) Community Hubgives people access to up-to-date information and resources designed to help them stay safe. And ourVoting Information Centerand voter registration notifications ensure people know how to register to vote and encourage them to make their voices heard. We are introducing a forwarding limit on Messenger to help curb the efforts of those looking to cause chaos, sow uncertainty or inadvertently undermine accurate information.', 'We want Messenger to be a safe and trustworthy platform to connect with friends and family.Earlier this year weintroducedfeatureslike safety notifications, two-factor authentication, and easier ways to block and report unwanted messages. This new feature provides yet another layer of protection by limiting the spread of viral misinformation or harmful content, and we believe it will help keep people safer online.']\n",
            "40 ['Update on February 2, 2021 at 5:45PM PT:', 'This week, the military in Myanmar took control of the government in a coup and detained senior officials from the ruling National League for Democracy (NLD). We’re treating the situation in Myanmar as an emergency and reducing the distribution of content that likely violates our hate speech and incitement policies, as well as content that praises or supports post-election violence including a coup.', 'Learn more about howFacebook is protecting elections.', 'On November 8, Myanmar voters will go to the polls for the second democratic election in the country’s recent history. Beginning next week, political parties and candidates in the Southeast Asian nation will vie for the national and regional leadership in what is anticipated to be a hotly contested campaign complicated by the COVID-19 pandemic, as all elections are in 2020.', 'Despite the challenges that November presents, Facebook continues to focus on our responsibility to ensure the integrity of Myanmar’s election on our platform. We also recognize Myanmar’s complex social and political context and are sensitive to the tumultuous changes and the serious violence that took place since the country’s last election in 2015.', 'This is why many teams at Facebook have worked over the past few years to better understand how our platform is used in Myanmar and how we can play a part in helping to prevent harm.We’ve also built a team that is dedicated to Myanmar. This includes people who spend significant time on the ground working with civil society partners who are advocating on a range of human and digital rights issues across Myanmar’s diverse, multi-ethnic society.Our goal is to understand and address current issues and those that are on the horizon.', 'We remain committed to advancing the social and economic benefits of Facebook in Myanmar. Although we know that this work will continue beyond November, we acknowledge that Myanmar’s 2020 general election will be an important marker along the journey.', 'Today, we’re sharing some important updates on the work that we’ve done and will continue to do in the lead up to the vote and some of the progress that we have made. This includes improving our ability to detect and remove hate speech and content that incites violence, our ongoing work to reduce the spread of harmful misinformation, the removal of inauthentic networks in Myanmar that seek to manipulate public opinion, and our engagement with key stakeholders in Myanmar to ensure that Facebook is responsive to local needs', 'Facebook has expanded our misinformation policy in Myanmar so that we will now remove misinformation that could lead to voter suppressionor damage the integrity of the electoral process. Working with local partners,between now and 22 November, we will remove verifiable misinformation and unverifiable rumors that are assessed as having the potential to suppress the vote or damage the integrity of the electoral process.', 'For example, we would removeposts falsely claiming a candidate is a Bengali, not a Myanmar citizen, and thus ineligible.', 'We also recognize that there are certain types of content, such as hate speech, that could lead to imminent, offline harm but that could also suppress the vote.We have a clear and detailed policy againsthate speech, and we remove violating content as soon as we become aware of it.', 'To do this, we’ve invested significantly in proactive detection technology to help us catch violating content more quickly. We also use AI to proactively identify hate speech in 45 languages, including Burmese.', 'We have continued to invest in improving this technology and our overall enforcement against hate speech as the election approaches.In the second quarter of 2020, we took action against 280,000 pieces of content in Myanmar for violations of our Community Standards prohibiting hate speech, of which we detected 97.8% proactively before it was reported to us.This is up significantly from Q1 2020, when we took action against 51,000 pieces of content for hate speech violations, detecting 83% proactively.', 'We’re also introducing more transparency when it comes to issue, electoral and political ads, going far beyond the standard in print and broadcast media. As of this month, all these ads in Myanmarmust have a “Paid for by” disclaimer attached to them to show the organization or person behind the ad. All ads about social issues, elections or politics are also stored in our searchableAd Libraryfor seven years which include additional insights about them to help journalists, regulators, researchers, watchdog groups and others learn more about ads and help hold advertisers and Facebook accountable.', 'We also want to make sure people are using Facebook authentically, and that they understand who is speaking to them.To that end, we are working with two partners in Myanmar to verify the official national Facebook Pages of political parties. So far, more than 40 political parties have been given a verified badge.\\u200b This provides a blue tick on the Facebook Page of a party and makes it easier for users to differentiate a real, official political party page from unofficial pages, which is important during an election campaign period.', 'To provide people using the platform with additional context before they share images that are more than a year old and could be potentially harmful or misleading, we introduced an Image Context reshare product in Myanmar in June.Out-of-context images are often used todeceive, confuse and cause harm. With this product, userswill be shown a message when they attempt to share specific types of images, including photos that are over a year old and that may come close to violating Facebook’s guidelines on violent content. We warn people that the image they are about to share could be harmful or misleading will be triggered using a combination of artificial intelligence (AI) and human review.', 'We have also introduced a new feature that limits the number of times a message can be forwarded to five.These limits are a proven method of slowing the spread of viral misinformation that has the potential to cause real world harm. This safety feature is available in Myanmar and, over the course of the next few weeks, we will be making it available to Messenger users worldwide.', 'We introduced ourthird-party fact-checking programin Myanmar in March as part of our ongoing integrity efforts to reduce the spread of misinformation and improve the quality of the news people find online. We now have three fact-checking partners in Myanmar – BOOM, AFP Fact Check and Fact Crescendo.', 'We’re constantly working to find and stop coordinated campaigns that seek to manipulate public debate across our apps. In 2019 alone, we took down over 50 networks worldwide for engaging incoordinated inauthentic behavior (CIB), including ahead of major democratic elections.', 'Since 2018, we’ve identified and disrupted six networks engaging inCoordinated Inauthentic Behaviorin Myanmar. These networks of accounts, Pages and Groups were masking their identities to mislead people about who they were and what they were doing by manipulating public discourse and misleading people about the origins of content.']\n",
            "41 ['Today the Biden campaign released a petition and open letter to Facebook. Our response can be found below.', 'We live in a democracy, where the elected officials decide the rules around campaigns. Two weeks ago the President of the United States issued an executive order directing Federal agencies to prevent social media sites from engaging in activities like fact-checking political statements. This week, the Democratic candidate for President started a petition calling on us to do the exact opposite. Just as they have done with broadcast networks — where the US government prohibits rejecting politicians’ campaign ads — the people’s elected representatives should set the rules, and we will follow them. There is an election coming in November and we will protect political speech, even when we strongly disagree with it.']\n",
            "42 ['Yesterday the Wall Street Journal published astoryclaiming that Facebook “shut down efforts to make the site less divisive” and “largely shelved” internal research on whether social media increases polarization. Unfortunately, this particular story wilfully ignored critical facts that undermined its narrative.', 'The piece uses a couple of isolated initiatives we decided against as evidence that we don’t care about the underlying issues—and it ignored the significant efforts we did make. The piece disregarded how our research, andresearch we continue to commission, informed dozens of other changes and new products. It also ignored other measures we’ve taken to fight polarization. As a result, readers were left with the impression we are ignoring an issue that in fact we have invested heavily in.', 'Here are just some of the initiatives we’ve made over the past three years to address factors that can contribute to polarization:', 'Recalibrating News Feed', 'In 2018we made a fundamental changeto the way content is surfaced in people’s News Feed to prioritize posts from friends and family over news content. This was based on extensive research that found people derive more meaningful conversations and experiences when they engage with people they know rather than by passively consuming content.', 'This was one of many changes we’ve made to Facebook’s News Feed to try and minimize the amount of divisive news content people see. We’vereduced clickbait headlines. We’vereduced links to misleading and spammy posts. And we’veimproved how comments are rankedto show people those that are more relevant and of higher quality.', 'Building a Robust Integrity Team', 'Over the past four years, we’ve built a global team of more than 35,000 people working across the company on issues to secure the safety and security of our services, including those related to polarization.We’ve removed billions of fake accounts. We made it easier to see who is behind political ads. And we’ve updated our privacy settings and built new tools to give people more control over their information.', 'Restricting Recommendations', 'We’ve added more restrictions to the types of Pages and Groups that we recommend to people. Through our tools, we can detect many types of violating content posted in Groups before people report it to us. If Pages and Groupsrepeatedlyshare content that violates our Community Standards, or is rated false by fact-checkers, we reduce their distribution, remove them from recommendations, and weremove the abilityfor Pages to monetize and advertise. We also remove entire Pages and Groups who repeatedly post violating content. When reviewing a Group to decide whether or not to take it down, we will look at admin and moderator content violations, including posts by members that they have approved, as a stronger signal that the Group violates our standards.', 'Combating Hate Speech', 'Another way we reduce polarization is byprohibiting speechthat attacks people based on what we call protected characteristics — race, ethnicity, national origin, religious affiliation, sexual orientation, caste, sex, gender, gender identity, and serious disease or disability hate speech on our platforms. We’ve expanded our proactive detection technology to find such content faster and in more languages. Today almost 90% of hate speech we remove is detected by our systems before anyone reports it to us.', 'Reducing Misinformation and Removing Content That Could Cause Physical Harm', 'Misinformation is often a tool used in polarizing content and fighting it has been a key focus.', 'In December of 2016, we launched anindependent fact-checking programthat became the basis for evaluating whether content posted to Facebook is actually true. Content found to be false by our fact-checking partners is labelled and down-ranked in News Feed. We’ve sinceexpanded the program to Instagramand now have more than 60 fact-checking partners covering more than 50 languages around the world.', 'Andwe’ve updated our policiesto remove misinformation that has the potential to contribute to imminent violence, physical harm, and voter suppression.', 'Finally, the Journal examined a rigorous process we instituted called ‘eat your veggies’ that was designed to vet new products before they were shipped. The process was put in place as a response to valid criticism, including from the media, that tech companies weren’t doing enough to anticipate unintended uses of their products.', 'We’ve taken a number of important steps to reduce the amount of content that could drive polarization on our platform, sometimes at the expense of revenues. This job won’t ever be complete because at the end of the day, online discourse is an extension of society and ours is highly polarized. But it is our job to reduce polarization’s impact on how people experience our products. We are committed to doing just that.']\n",
            "43 ['Freedom of expression is a foundational human right that allows for the free flow of information. We’re reminded how vital this is, in particular, as the world grapples with COVID-19 and accurate and authoritative information is more important than ever. Human rights defenders know this and fight for these freedoms every day. For Facebook, which stands for giving people voice, these rights are core to why we exist.', 'Today, we’re releasing the findings of three independent human rights impact assessments we commissioned in 2018 to evaluate the role of our services in Sri Lanka, Indonesia and Cambodia, along with details on how we’ve responded to the recommendations in each assessment. The assessments build on the work we’ve done over the last two years, beginning with creation of a human rights team to inform our policies, products, programs and partnerships around the world.', 'Since then, we’ve formalized an approach to determine which countries require more investment, including increased staffing, product changes and research. We have committed toexpanding end-to-end encryption, a security function that is already core to WhatsApp, to all of our messaging products to protect people’s private messages, including journalists and human rights defenders. In October of last year, weupdated the values that underpin our Community Standardsto specifically reference human rights principles. And earlier this year, the Global Network Initiative (GNI), completedits biennial assessment of Facebook, which determined the company is making good-faith efforts to implement the GNI Principles with improvement over time. The assessor reported Facebook had “strengthened its systematic review of both privacy and freedom of expression.”', 'The assessments we’re releasing today underscore the role our services play in providing voice to people, promoting civic and political engagement, and shining a light on human rights issues and abuse, especially in places where activists, human rights defenders and vulnerable communities don’t otherwise have a platform.', 'They also highlight the threats to people’s rightsand encourage us to respond more resolutely. We accept this responsibility, and acknowledge the human rights impacts outlined in these reports. We will continue to strive to keep people safe and their information secure.', 'Why and How We Do Human Rights Impact Assessments', 'We’re committed to understanding the role our platforms play offline and how Facebook’s products and policies can evolve to create better outcomes. Engaging independent experts and evaluating our work through the lens of global human rights principles is key to achieving this goal.', 'The three assessments we commissioned were conducted in accordance with theUN Guiding Principles on Business and Human Rights. The assessment of Facebook’s role in Cambodia was completed by BSR, and the assessments of Sri Lanka and Indonesia by Article One.', 'While the three assessments focus on Cambodia, Indonesia and Sri Lanka, the recommendations in each report have implications for other contexts, countries and regions in which Facebook is used.This reflects the universal nature of human rights, the global reach of our products, and the intersectionality of the impacts identified.', 'HRIA Recommendations and Our Progress', 'The reports each made similar recommendations to help us better protect human rights, including:', 'We welcome the recommendations and have taken steps towards filling these gaps, as our responses demonstrate.', 'Over the last two years, we have formalized an approach for prioritizing countries at risk of conflict and tailoring policy and product solutions to account for the unique needs of each. In Sri Lanka, for example, we are reducing the distribution of frequently reshared messages, which are often associated with clickbait and misinformation. These demotions seek to respect the guidance on permissible limits to freedom of expression under Article 19 of the ICCPR.', 'We have also taken lessons from Cambodia, where government surveillance of internet and social media use is pervasive. We expanded the ways that users can keep their accounts secure and started encouraging people to use authenticator apps rather than SMS for more secure two-factor authentication.', 'We also madekey updates to our Community Standards. For example, in 2018, we adopted a policy to remove verified misinformation that contributes to the risk of imminent physical harm, which we later expanded to apply to unverifiable rumors. The policy, which is global in scope, is especially applicable to conflict-affected areas, and has been used to remove content in Sri Lanka and Indonesia. We further updated our policies to protect vulnerable groups, including veiled women, LGBTQ+ individuals and human rights activists whose “outing” might increase risks of offline harm. We began using proactive detection technology to identify potentially violating hate speech, developing machine learning capabilities in Sinhala and Bahasa Indonesia. And we expanded our policies against voter interference, which proved critical ahead of elections in Sri Lanka and Indonesia in 2019, and will be equally important ahead of Cambodian elections in 2022 and 2023.', 'We increased staffing significantly, hiring policy leads and program managers in Sri Lanka, Indonesia and Cambodia, and expanding the number of content reviewers who speak Sinhala, Tamil, Bahasa Indonesia, Javanese and Khmer. With bigger and more specialized teams, we’ve formalized engagement with civil society organizations, many of whom serve asa regular and invaluable source of inputas we make updates to our Community Standards to account for new types of abuse. Our investment in civil society has further extended to digital and media literacy programs and economic initiatives like#SheMeansBusiness. We also strengthened our local fact-checking partnerships in Sri Lanka and Indonesia, and we’re always looking to expand the program with organizations certified by the International Fact-Checking Network.', 'As we work to protect human rights and mitigate the adverse impacts of our platform, we have sought to communicate more transparently and build trust with rights holders. We also aim to use our presence in places like Sri Lanka, Indonesia and Cambodia to advance human rights, as outlined in the UN Guiding Principles on Business and Human Rights and in Article One and BSR’s assessments. In particular, we are deeply troubled by the arrests of people who have used Facebook to engage in peaceful political expression, and will continue to advocate for freedom of expression and stronger protections of user data.', 'Final Note', 'The progress we’ve laid out here represents the beginning of our work in Sri Lanka, Indonesia and Cambodia, not the end. Facebook learns from every human rights impact assessment we undertake, and these reports are critical to changing how we operate to better support communities around the world. We have a long road ahead, but sharing some of the progress we’ve made is part of our commitment to demonstrating action and accountability.', 'Article One undertook its Human Rights Impact Assessments in Indonesia and Sri Lanka during 2018, using a methodology informed by guidance from the UN Guiding Principles on Business and Human Rights as well as Article One’s award-winning process for and experience in conducting human rights impact assessments around the world. The Indonesia HRIA involved interviews with 35 organizations, and the HRIA for Sri Lanka reflects interviews with 29 organizations, as well as focus groups of 150 participants. Both assessments encompassed interviews with relevant Facebook employees, and were funded by Facebook. Article One retained editorial control of its contents.', 'BSR undertook its Human Rights Impact Assessment (HRIA) of Cambodia in late 2018 and early 2019, using a methodology based on the UN Guiding Principles on Business and Human Rights (UNGPs). It involved interviews with 35 affected rights holders and stakeholders in Cambodia, as well as in-country research and interviews with relevant Facebook employees. The HRIA was funded by Facebook, though BSR retained editorial control of its contents.', 'Human Rights Impact Assessments', 'Facebook’s Responses']\n",
            "44 ['Today we’re publishing the fifth edition of ourCommunity Standards Enforcement Report, providingmetricson how well we enforced our policies from October 2019 through March 2020. We’ve spent the last few years building tools, teams and technologies to help protect elections from interference, prevent misinformation from spreading on our apps and keep people safe from harmful content. So when the COVID-19 crisis emerged, we had the tools and processes in place to move quickly and we were able to continue finding and removing content that violates our policies. When we temporarily sent our content reviewers home due to the COVID-19 pandemic, we increased our reliance on these automated systems and prioritized high-severity content for our teams to review in order to continue to keep our apps safe during this time.', 'This report includes data only through March 2020 so it does not reflect the full impact of the changes we made during the pandemic. We anticipate we’ll see the impact of those changes in our next report, and possibly beyond, and we will be transparent about them. For example, for the past seven weeks we couldn’t always offer the option to appeal content decisions and account removals, so we expect the number of appeals to be much lower in our next report. We also prioritized removing harmful content over measuring our efforts, so we may not be able to calculate the prevalence of violating content during this time. Today’s report shows the impact of advancements we’ve made in the technology we use to proactively find and remove violating content.', 'What’s New in This Report?', 'We are now including metrics across 12 policies on Facebook and metrics across 10 policies on Instagram. The report introduces Instagram data in four issue areas: Hate Speech, Adult Nudity and Sexual Activity, Violent and Graphic Content, and Bullying and Harassment. For the first time, we are also sharing data on the number of appeals people make on content we’ve taken action against on Instagram, and the number of decisions we overturn either based on those appeals or when we identify the issue ourselves. We’ve also added data on our efforts to combat organized hate on Facebook and Instagram. You can learn more about these efforts and the progress we’ve madehere.', 'Progress in Finding and Removing Violating Content', 'We improved our technology that proactively finds violating content, which helped us remove more violating content so fewer people saw it.', '', 'Over the last six months, we’ve started to use technology more to prioritize content for our teams to review based on factors like virality and severity among others. Going forward, we plan to leverage technology to also take action on content, including removing more posts automatically. This will enable our content reviewers to focus their time on other types of content where more nuance and context are needed to make a decision.', 'The Community Standards Enforcement Report is published in conjunction with our bi-annualTransparency Reportthat shares numbers on government requests for user data, content restrictions based on local law, intellectual property take-downs and internet disruptions.', 'In the future we’ll share Community Standards Enforcement Reports quarterly, so our next report will be released in August.']\n",
            "45 ['We’re constantly working to find and stop coordinated campaigns that seek to manipulate public debate across our apps. In 2019 alone, we took down over 50 networks worldwide for engaging in coordinated inauthentic behavior (CIB), including ahead of major democratic elections.', 'These efforts are led by a cross-disciplinary team focused on finding and disrupting both the most sophisticated influence operations aimed to manipulate public debate as well as high volume inauthentic behaviors like spam and fake engagement. Over the past several years, our team has grown to over 200 people with expertise ranging from open source research, to threat investigations, cyber security, law enforcement and national security, investigative journalism, engineering, product development, data science and academic studies in disinformation.', 'You can find more information about our previous enforcement actionshere.', 'Purpose of This Report', 'Over the past three years, we’ve shared our findings about coordinated inauthentic behavior we detect and remove from our platforms. As part of regular CIB reports, we’re sharing information about all networks we take down over the course of a month to make it easier for people to see progress we’re making in one place.', 'What is CIB?', 'While we investigate and enforce against any type of inauthentic behavior — including fake engagement, spam and artificial amplification — we approach enforcement against these mostly financially-motivated activities differently from how we counter foreign interference or domestic influence operations. We routinely take down less sophisticated, high-volume inauthentic behaviors like spam and we do not announce these enforcement actions when we take them.', 'We view influence operations as coordinated efforts to manipulate public debate for a strategic goal where fake accounts are central to the operation. There are two tiers of these activities that we work to stop: 1) coordinated inauthentic behavior in the context of domestic, non-state campaigns (CIB) and 2) coordinated inauthentic behavior on behalf of a foreign or government actor (FGI).', 'Coordinated Inauthentic Behavior (CIB)When we find domestic, non-government campaigns that include groups of accounts and Pages seeking to mislead people about who they are and what they are doing while relying on fake accounts, we remove both inauthentic and authentic accounts, Pages and Groups directly involved in this activity.', 'Foreign or Government Interference (FGI)If we find any instances of CIB conducted on behalf of a government entity or by a foreign actor, we apply the broadest enforcement measures including the removal of every on-platform property connected to the operation itself and the people and organizations behind it.', 'Continuous EnforcementWe monitor for efforts to re-establish a presence on Facebook by networks we previously removed for CIB. Using both automated and manual detection, we continuously remove accounts and Pages connected to networks we took down in the past.', 'This month, we removed eight networks of accounts, Pages and Groups. Two of them — from Russia and Iran — focused internationally (FGI), and the remaining six — in the US, Georgia, Myanmar and Mauritania — targeted domestic audiences in their respective countries (CIB). We have shared information about our findings with law enforcement, policymakers and industry partners.', 'We know that people looking to mislead others — whether through phishing, scams, or influence operations — try to leverage crises to advance their goals, and the coronavirus pandemic is no different. All of the networks we took down for CIB in April were created before the COVID-19 pandemic began, however, we’ve seen people behind these campaigns opportunistically use coronavirus-related posts among many other topics to build an audience and drive people to their Pages or off-platform sites. The majority of the networks we took down this month were still trying to grow their audience or had a large portion of engagement on their Pages generated by their own accounts.', 'Networks Removed in April, 2020:', 'We are making progress rooting out this abuse, but as we’ve said before, it’s an ongoing effort. We’re committed to continually improving to stay ahead. That means building better technology, hiring more people and working more closely with law enforcement, security experts and other companies.', 'See thedetailed reportfor more information.']\n",
            "46 ['Update on May 26, 2021 at 3:30PM PT:', 'In light of ongoing investigations into the origin of COVID-19 and in consultation with public health experts, we will no longer remove the claim that COVID-19 is man-made or manufactured from our apps. We’re continuing to work with health experts to keep pace with the evolving nature of the pandemic and regularly update our policies as new facts and trends emerge.', 'Update on February 8, 2021 at 10:00AM PT:', 'Today, we are expanding our efforts to remove false claims on Facebook and Instagram about COVID-19, COVID-19 vaccines and vaccines in general during the pandemic. Since December, we’veremoved false claimsabout COVID-19 vaccines that have been debunked by public health experts. Today, following consultations with leading health organizations, including the World Health Organization (WHO), we are expanding the list of false claims we will remove to includeadditional debunked claimsabout the coronavirus and vaccines. This includes claims such as:', 'The full list of claims is availablehere, and we alreadyprohibit these claimsin ads. These new policies will help us continue to take aggressive action against misinformation about COVID-19 and vaccines.', 'We will begin enforcing this policy immediately, with a particular focus on Pages, groups and accounts that violate these rules, and we’ll continue to expand our enforcement over the coming weeks. Groups, Pages and accounts on Facebook and Instagram that repeatedly share these debunked claims may be removed altogether. We are also requiring some admins for groups with admins or members who have violated our COVID-19 policies to temporarily approve all posts within their group. Claims about COVID-19 or vaccines that do not violate these policies will still be eligible for review by our third-party fact-checkers, and if they are rated false, they will be labeled and demoted.', 'Finally, we are continuing to improve Search results on our platforms. When people search for vaccine or COVID-19 related content on Facebook, we promote relevant, authoritative results and provide third-party resources to connect people to expert information about vaccines. On Instagram, in addition to surfacing authoritative results in Search, in the coming weeks we’re making it harder to find accounts in search that discourage people from getting vaccinated.', 'As we noted last monthin response to guidance from the Oversight Board, we are committed to providing more transparency around these policies. You can read the detailed updates in Facebook’sCommunity Standardsand in ourHelp Center.As the situation evolves, we’ll continue to review content on our platforms, assess trends in language and engage with experts to provide additional policy guidance to keep people safe during this crisis.', 'Update on December 15, 2020 at 7:00PM PT:', 'Today, we’re updating the messages we send to people who have interacted with misinformation about COVID-19 on Facebook that we’ve since removed. In April, we started showing these messages in News Feed to people who liked, commented on or reacted to posts with misinformation that we removed for violating our policy. Since then, we’ve done research to better understand what’s most helpful for people, and we’ve redesigned these as more personalized notifications to more clearly connect people with credible and accurate information about COVID-19.', 'Now, people will:', '', 'Update on May 12, 2020 at 9:30AM PT:', 'During the month of April, we put warning labels on about 50 million pieces of content related to COVID-19 on Facebook, based on around 7,500 articles by our independent fact-checking partners.', 'Originally published April 16, 2020 at 6:00AM PT:', 'Ever since COVID-19 was declared a global public health emergency in January, we’ve been working to connect people to accurate information from health experts and keep harmful misinformation about COVID-19 from spreading on our apps.', 'We’ve now directed over 2 billion people to resources from the WHO and other health authorities through our COVID-19 Information Center and pop-ups on Facebook and Instagram with over 350 million people clicking through to learn more.', 'But connecting people to credible information is only half the challenge. Stopping the spread of misinformation and harmful content about COVID-19 on our apps is also critically important. That’s why we work with over 60 fact-checking organizations that review and rate content in more than 50 languages around the world. In the past month, we’ve continued to grow our program to add more partners and languages.Since the beginning of March, we’ve added eight new partners and expanded our coverage to more than a dozen new countries. For example, we added MyGoPen in Taiwan, the AFP and dpa in the Netherlands,Reuters in the UK, and others.', 'To further support the work of our fact-checking partners during this time, we recently announcedthe first round of recipientsof our $1 million grant program in partnership with the International Fact-Checking Network. We’ve given grants to 13 fact-checking organizations around the world to support projects in Italy, Spain, Colombia, India, the Republic of Congo, and other nations. We will announce additional recipients in the coming weeks.', 'Once a piece of content is rated false by fact-checkers, we reduce its distribution and show warning labels with more context. Based on one fact-check, we’re able to kick off similarity detection methods that identify duplicates of debunked stories. For example, during the month of March, we displayed warnings on about 40 million posts related to COVID-19 on Facebook, based on around 4,000 articles by our independent fact-checking partners. When people saw those warning labels, 95% of the time they did not go on to view the original content. To date, we’ve also removed hundreds of thousands of pieces of misinformation that could lead to imminent physical harm. Examples of misinformation we’ve removed include harmful claims like drinking bleach cures the virus and theories like physical distancing is ineffective in preventing the disease from spreading.', 'Today we’re sharing some additional steps we’re taking to combat COVID-19 related misinformation and make sure people have the accurate information they need to stay safe.', 'Informing People Who Interacted With Harmful COVID-19 Claims', 'We’re going to start showing messages in News Feed to people who have liked, reacted or commented on harmful misinformation about COVID-19 that we have since removed. These messages will connect people to COVID-19 mythsdebunked by the WHOincluding ones we’ve removed from our platform for leading to imminent physical harm. We want to connect people who may have interacted with harmful misinformation about the virus with the truth from authoritative sources in case they see or hear these claims again off of Facebook. People will start seeing these messages in the coming weeks.', '', 'Making It Easier for People to Get the Facts', 'To make it easier for people to find accurate information about COVID-19, we recently added a new section to our COVID-19 Information Center called Get the Facts. It includes fact-checked articles from our partners that debunk misinformation about the coronavirus. The fact-check articles are selected by our News curation team and updated every week. This is now available in the US. We will soon add it toFacebook Newsin the US as well.', '', 'As this pandemic evolves, we’ll continue focusing on the most effective ways to keep misinformation and dangerous hoaxes about COVID-19 off our apps and ensure people have credible information from health experts to stay safe and informed.']\n",
            "47 ['With billions of people unable to see their friends and family in person due to COVID-19, people are relying on WhatsApp more than ever to communicate. People are talking to doctors, teachers, and isolated loved ones via WhatsApp during this crisis. That’s why all your messages and calls on WhatsApp are end-to-end encrypted by default to give you a secure place for your most personal conversations.', 'Last year we introduced users to the concept of messages that have been forwarded many times. These messages are labeled withdouble arrowsto indicate they did not originate from a close contact. In effect, these messages are less personal compared to typical messages sent on WhatsApp. We are now introducing a limit so that these messages can only be forwarded to one chat at a time.', 'As a private messaging service, we’ve taken several steps over the years to help keep conversations intimate. For example, we previously setlimits on forwarded messagesto constrain virality. At the time, we saw a 25% decrease in total message forwards globally.', 'Is all forwarding bad? Certainly not. We know many users forward helpful information, as well as funny videos, memes, and reflections or prayers they find meaningful. In recent weeks, people have also used WhatsApp to organizepublic momentsof support for frontline health workers. However, we’ve seen a significant increase in the amount of forwarding which users have told us can feel overwhelming and can contribute to the spread of misinformation. We believe it’s important to slow the spread of these messages down to keep WhatsApp a place for personal conversation.', 'In addition to this change, we are working directly with NGOs and governments, including the World Health Organization and over 20 national health ministries, to help connect people with accurate information. Together these trusted authorities have sent hundreds of millions of messages directly to people requesting information and advice. You can learn more about these efforts, as well as how to submit potential myths, hoaxes and rumors tofact-checking organizationson ourWhatsApp Coronavirus Information Hub.', 'We believe that now more than ever people need to be able to connect privately. Our teams are hard at work to keep WhatsApp running reliably during this unprecedented global crisis. We’ll continue to listen to your feedback and improve ways for people to share with each other on WhatsApp.']\n",
            "48 ['Today is Census Day in the US — and it comes at a particularly difficult moment. Making sure that everyone gets counted is hard enough in normal times but during an unprecedented public health emergency it is a major challenge. People are understandably much more concerned about their health, their loved ones, and in many cases, their jobs and livelihoods.', 'But the census really matters. It has important and long-lasting implications — it determines everything from congressional representation to how federal funding for schools, highways, hospitals, fire stations and other resources are distributed. It is that funding — and the services it provides — that we rely on when crises hit.', 'Too often in our past, some communities and groups have been undercounted. That is completely unacceptable and we need to do everything in our power to make sure everyone can take part. The ability to complete the census online for the first time gives the technology sector a unique opportunity and responsibility to help make sure every person is counted. Here’s what Facebook is doing:', 'Helping Everyone Get Counted', 'We’ve partnered with the US Census Bureau and other nonprofits to help get out the count.', 'Last week, we launched notifications at the top of Facebook and Instagram so when people visit their feeds, they see more information about the census and a reminder to complete it. More than 11 million people on Facebook and Instagram clicked through the notifications to the Census Bureau’s website where they can fill out the census.', '', 'We have been working with and supporting state and local governments to provide training in how to use digital tools. The Census Bureau also helped us identify civil rights organizations, nonprofit groups and others who are experts in reaching under-represented communities to receive these trainings. And we are supporting the Count All Kids campaign — created after more than 10% of young children were missed in the last census — so every child in this country gets the representation they deserve.', 'Protecting the Census from Interference', 'To make sure everyone is counted, we also need to stop efforts to suppress participation. Weannounced our census interference policieslast December so that we could train our teams and our AI systems to find and remove violating content before counting began in earnest. We’re using our virtual Election Operations Center that brings together more than 40 subject matter experts from across the company for real-time monitoring for misinformation or abuse related to the election or census. The team is made up of specialists from our threat intelligence, data science, software engineering, research, community operations and legal teams. They’re trained to quickly investigate spikes in misinformation, hate speech, or census or voter suppression — and take action when warranted.', 'We’re also equipping agencies and organizations with tools to more quickly identify and flag potentially suppressive content. CrowdTangle is a Facebook tool to track how public content spreads online, which we’re providing to local officials, the Census Bureau and partners they helped us identify. They’ll get full access, dedicated support and training for free so they can monitor for potential misinformation and suppressive content. We’ll also providePublic Live Displays for all 50 statesto help people track census content on the local level, just as we have for local elections.', 'We know that people directly involved in running the census may be targeted by hackers and foreign adversaries, so we’re working with Census Bureau officials to further secure their accounts through enrollment inFacebook Protect. This program requires them to turn on two-factor authentication and provides additional monitoring for hacking.', 'We’re grateful for the partnership from the Census Bureau and other experts and advocacy groups, including civil rights groups, that have made us more capable in promoting an accurate and fair census. In the coming months, we will continue to encourage everyone to complete the census and stop people from abusing our platforms.']\n",
            "49 ['Ever since the World Health Organization (WHO) declared COVID-19 a global public health emergency, we’ve been working to connect people to accurate information and taking aggressive steps to stop misinformation and harmful content from spreading. Today we’re sharing an update on these efforts across our apps.', '', 'On Facebook and Instagram:In January, we started showing educational pop-ups connecting people to information from the WHO, the CDC and regional health authorities toward the top of News Feed in countries with reported person-to-person transmissions and in all countries when people search for COVID-19 related information. We show similar pop-ups at the top of Instagram Feed in the hardest hit countries and when anyone taps on a COVID-19 relatedhashtag.', 'Last week, we launched the COVID-19 Information Center, which is now featured at the top of News Feed on Facebook in several countries and includes real-time updates from national health authorities and global organizations, such as the WHO. The COVID-19 Information Center will be available globally soon.', 'Through these efforts across Facebook and Instagram, we’ve directed more than 1 billion people to resources from health authorities including the WHO – more than 100 million of whom clicked through to learn more.', 'We’re also giving the WHO as many free ads as they need and millions in ad credits to other health authorities so they can reach people with timely messages.', 'On WhatsApp: People can sign up to receive theWHO Health Alerton WhatsApp,a daily report with the latest numbers of COVID-19 cases. It also includes tips on how to prevent the spread of the disease as well as answers to commonly asked questions that people can easily send to their friends and family. We’re also working directly with health ministries in the UK, India, Indonesia, Singapore, Israel, South Africa and other countries to provide similar health updates specific to those nations. In the last week, over 100 million messages have been sent by these organizations to WhatsApp users. In addition, we donated $1 million to the International Fact-Checking Network to expand the presence offact-checking organizations on WhatsApp, so people can submit rumors they find directly to fact-checkers. More information is available atwhatsapp.com/coronavirus.', 'On Messenger: We’re connecting government health organizations and UN health agencies with ourdeveloper partnerswho can help them use Messenger most effectively to share timely information with people and speed up their replies to commonly asked questions. Agencies such asUNICEF,Argentina’s Ministry of HealthandPakistan’s Ministry of National Health Services, Regulations & Coordinationare already using Messenger to ensure people have the latest information about COVID-19.', 'On Facebook and Instagram:We remove COVID-19 related misinformation thatcould contribute to imminent physical harm.We’ve removed harmful misinformation since 2018, including false information about the measles in Samoa where it could have furthered an outbreak and rumors about the polio vaccine in Pakistan where it risked harm to health aid workers. Since January, we’ve applied this policy to misinformation about COVID-19 to remove posts that make false claims about cures, treatments, the availability of essential servicesor the location and severity of the outbreak. We regularly update the claims that we remove based on guidance from the WHO and other health authorities. For example, we recently started removing claims that physical distancing doesn’t help prevent the spread of the coronavirus. We’ve also banned ads and commerce listings that imply a product guarantees a cure or prevents people from contracting COVID-19.', 'For claims that don’t directly result in physical harm, like conspiracy theories about the origin of the virus, we continue to work with our network of over 55 fact-checking partners covering over 45 languages to debunk these claims. To support the global fact-checking community’s work on COVID-19, wepartnered with the Independent Fact-Checking Network to launch a$1 million grant programto increase their capacity during this time.', 'Once a post is rated false by a fact-checker, we reduce its distribution so fewer people see it, and we show strong warning labels and notifications to people who still come across it, try to share it or already have. This helps give more context when these hoaxes appear elsewhere online, over SMS or offline in conversations with friends and family.On Instagram, we remove COVID-19 accounts from recommendations and we’re working to remove some COVID-19 related content from Explore, unless posted by a credible health organization.', 'On WhatsApp and Messenger:We’ve built clear labels that show people when they have received a forwarded message, or chain message, so they know when they are receiving something that was not written by their immediate contacts. We’ve also set a limit on the number of times messages can be forwarded on WhatsApp to reduce the spread of viral messages, and we use advanced machine learning to identify and ban accounts engaged in mass messaging. Similarly, we’ll soon begin testing stricter limits on Messenger to control the number of chats someone can forward a message to at one time.', 'This is an evolving crisis, so as world health officials issue new guidance and warnings about COVID-19, we’ll continue working with them to ensurepeople have access to accurate and authoritative information across all of our apps.']\n",
            "50 ['People share millions of photos and videos on Facebook every day, creating some of the most compelling and creative visuals on our platform. Some of that content is manipulated, often for benign reasons, like making a video sharper or audio more clear. But there are people who engage in media manipulation in order to mislead.', 'Manipulations can be made through simple technology like Photoshop or through sophisticated tools that use artificial intelligence or “deep learning” techniques to create videos that distort reality – usually called “deepfakes.” While these videos are still rare on the internet, they present a significant challenge for our industry and society as their use increases.', 'Today we want to describe how we are addressing both deepfakes and all types of manipulated media. Our approach has several components, from investigatingAI-generated content and deceptive behaviors like fake accounts, to partnering with academia, government and industry to exposing people behind these efforts.', 'Collaboration is key. Across the world, we’ve been driving conversations with more than 50 global experts with technical, policy, media, legal, civic and academic backgrounds to inform our policy development and improve the science of detecting manipulated media.', 'As a result of these partnerships and discussions, we are strengthening our policy toward misleading manipulated videos that have been identified as deepfakes. Going forward, we will remove misleading manipulated media if it meets thefollowing criteria:', 'This policy does not extend to content that is parody or satire, or video that has been edited solely to omit or change the order of words.', 'Consistent with our existing policies, audio, photos or videos, whether a deepfake or not, will be removed fromFacebookif they violate any of our otherCommunity Standardsincluding those governing nudity, graphic violence, voter suppression and hate speech.', 'Videos that don’t meet these standards for removal are stilleligible for review by one ofour independent third-party fact-checkers,which include over 50 partners worldwide fact-checking in over 40 languages. If a photo or video is rated false or partly false by a fact-checker, we significantly reduce its distribution in News Feed and reject it if it’s being run as an ad.And critically, people who see it, try to share it, or have already shared it, will see warnings alerting them that it’s false.', 'This approach is critical to our strategy and one we heard specifically from our conversations with experts. If we simply removed all manipulated videos flagged by fact-checkers as false, the videos would still be available elsewhere on the internet or social media ecosystem. By leaving them up and labelling them as false, we’re providing people with important information and context.', 'Our enforcement strategy against misleading manipulated media also benefits from our efforts to root out the people behind these efforts. Just last month, we identified and removed a network using AI-generated photos to conceal their fake accounts. Our teams continue to proactively hunt for fake accounts and other coordinated inauthentic behavior.', 'We are also engaged in the identification of manipulated content, of which deepfakes are the most challenging to detect. That’s why last September we launched theDeep Fake Detection Challenge, which has spurred people from all over the world to produce more research and open source tools to detect deepfakes. This project, supported by $10 million in grants, includes a cross-sector coalition of organizations including the Partnership on AI, Cornell Tech, the University of California Berkeley, MIT, WITNESS, Microsoft, the BBC and AWS, among several others in civil society and the technology, media and academic communities.', 'In a separate effort, we’ve partnered with Reuters, the world’s largest multimedia news provider, to help newsrooms worldwide to identify deepfakes and manipulated media through afree online training course. News organizations increasingly rely on third parties for large volumes of images and video, and identifying manipulated visuals is a significant challenge. This program aims to support newsrooms trying to do this work.', 'As these partnerships and our own insights evolve, so too will our policies toward manipulated media. In the meantime, we’re committedto investing within Facebook and working with other stakeholders in this area to find solutions with real impact.']\n",
            "51 ['Next year, all US households will be able to complete the US census online for the first time. As the format of the census evolves, so do the ways that people share information about the census. This means we have to be more vigilant about protecting against census interference across posts and ads on Facebook and Instagram and help promote an accurate count of every person in the country.', 'Today, we are announcing a new census interference policy that bans misleading information about when and how to participate in the census and the consequences of participating. We are also introducing a new advertising policy that prohibits ads that portray census participation as useless or meaningless or advise people not to participate in the census. These policies are due in large part to the work being done with the civil rights community through our civil rights audit and represent the culmination of a months-long process between Facebook, the US Census Bureau and experts with diverse backgrounds to develop thoughtful rules around prohibiting census interference on our platforms and making sure people can use their voice to be counted.', 'Updating Our Community Standards to Ban Census Interference', 'Our census interference policy will prohibit:', 'We will begin enforcement next month and use a combination of technology and people to proactively identify content that may violate this policy. All content surfaced will be assessed by a team of reviewers who will benefit from the training and guidance of a consultant with census expertise. And as with voter interference, content that violates our census interference policy will not be allowed to remain on our platforms asnewsworthyeven if posted by a politician.', 'Content that does not violate this policy, but may still be inaccurate, will be eligible for fact-checking byour third-party partnersand, if rated false, will havemore prominent labelsand will be ranked lower in News Feed. We will also fight against potential misinformation by sharing accurate, non-partisan information about how to participate in the census in consultation with the US Census Bureau.', 'It’s important to note that our census interference policy is one of several policies that protect against abusive behavior that may be related to the census. Ourviolence and incitement policies, for example, prohibit threats of and incitement to violence. We don’t allow attempts to gather sensitive personal information by deceptive or invasive methods as laid out under ourcybersecurity policies. We also have policies to protect againstprivacy violationsif we were to learn about the posting or sharing of hacked census data or phishing attempts to gain access to personally identifiable information. Similarly, ourbullying and harassment policiesaim to protect against potential harassment or intimidation.', 'Banning Ads that Aim to Limit Census Participation', 'While all ads must adhere to our Community Standards and therefore cannot include things like harassment or threats of violence, we are also introducing a new advertising policy that prohibits ads that portray census participation as useless or meaningless or advise people not to participate in the census. In addition, ads about the census will be subject to the increased transparency requirements for issue ads. This means any advertiser who wants to run an ad about the census will have to complete our strengthened authorization process for ads about social issues, elections or politics and include a disclaimer on such ads so people know who paid for them. These ads will be saved in our Ad Library for at least seven years.', 'Partnering with the US Census Bureau and Other Experts', 'Our work to help protect the census from interference is strengthened thanks to input from Members of Congress, the Census Bureau and other experts. We support thebipartisan resolution introducedby Senators Schatz and Murkowski to ensure the census is fair and accurate, and to encourage everyone in the US to be counted. We have also met with Census officials multiple times to brief them on our plans and coordinate with them to disrupt census interference, and we’re working with the Census Bureau to identify trusted partners who will be able to flag potentially suppressive census content on Facebook and Instagram.', 'We’ve set up a multi-disciplinary team across product, engineering, policy, operations and legal to work on protecting and promoting the census. We are also using our operations center for real-time monitoring of potential census interference so that we can quickly address any abuse.', 'We are also working with local officials and Census Bureau partners by giving them access toCrowdTangledisplays, a Facebook tool used to track how content spreads online. CrowdTangle has already helped fact-checkers and local governments ahead of elections by monitoring for potential misinformation and suppressive content, so we plan to use the same tools and preparedness mechanisms to monitor census-related content on Facebook and Instagram. We have also joined Get Out The Count efforts in partnership with the Census Bureau and will continue to train organizations identified by the Bureau on how to encourage census participation.', 'We must do our part to ensure an accurate census count, which is critical for the distribution of federal funds, the apportioning of electoral representatives and the functioning of a democracy. We believe that the partnerships, policies and products we’ve developed this year have put us on strong footing heading into next year’s census.']\n",
            "52 ['We’ve made significant progress reducing misinformation through our partnership with some of the world’s leading fact-checkers.Today, we’re announcing a new pilot program built to leverage the Facebook community. It will allow fact-checkers to quickly see whether a representative group of Facebook users found a claim to be corroborated or contradicted. Our goal is to help fact-checkers address false content faster.', 'The program will have community reviewers work as researchers to find information that can contradict the most obvious online hoaxes or corroborate other claims. These community reviewers are not Facebook employees but instead will be hired as contractors through one of our partners. They are not making final decisions themselves. Instead, their findings will be shared with the third-party fact-checkers as additional context as they do their own official review.', 'For example, if there is a post claiming that a celebrity has died and community reviewers don’t find any other sources reporting that news — or see a report that the same celebrity is performing later that day — they can flag that the claim isn’t corroborated. Fact-checkers will then see this information as they review and rate the post.', 'We started exploring this ideaearlier this year. Since then, we’ve worked with experts and partners across many fields to understand how we can better support our fact-checking partners in their effort to review content faster.', 'Here’s how it will work:', 'To ensure the pool of community reviewers represents the diversity of people on Facebook, we’re partnering with YouGov, a global public opinion and data company. YouGov conducted an independent study of community reviewers and Facebook users. They determined thatthe requirements used to select community reviewers led to a pool that is representative of the Facebook community in the US and reflects the diverse viewpoints — including political ideology — of Facebook users. They also found the judgments of corroborating claims by community reviewers were consistent with what most people using Facebook would conclude.We’re piloting this process in the US over the coming months and we’ll closely evaluate how it’s working through our own research, help from academics and feedback from our third-party fact-checking partners. We believe that by combining the expertise of third-party fact-checkers with a group of community-based reviewers, we can evaluate misinformation faster and make even more progress reducing its prevalence on Facebook.']\n",
            "53 ['We want you to trust what you see on Instagram. Photo and video based misinformation is increasingly a challenge across our industry, and something our teams have been focused on addressing. In May of this year, we began working withthird-party fact-checkersin the US to help identify, review and label false information. These partners independently assess false information to help us catch it and reduce its distribution. Today, we’re expanding our fact-checking program globally to allow fact-checking organizations around the world to assess and rate misinformation on our platform.', 'What Does This Mean?', 'When content has beenratedas false or partly false by a third-party fact-checker, we reduce its distribution by removing it from Explore and hashtag pages. In addition,it will be labeledso people can better decide for themselves what to read, trust, and share.\\xa0When these labels are applied, they will appear to everyone around the world viewing that content – in feed, profile, stories, and direct messages.', 'We use image matching technology to find further instances of this content and apply the label, helping reduce the spread of misinformation. In addition, if something is rated false or partly false on Facebook, starting today we’ll automatically label identical content if it is posted on Instagram (and vice versa).\\xa0The label will link out to the rating from the fact-checker and provide links to articles from credible sources that debunk the claim(s) made in the post.\\xa0We make content from accounts that repeatedly receive these labels harder to find by removing it from Explore and hashtag pages.', 'To determine which content should be sent to fact-checkers for review, we use a combination of feedback from our community and technology. Earlier this year, we added a “False Information” feedback option, and these reports, along with other signals, help us to better identify and take action on potentially false information.', 'Today’s expansion is an important step in our ongoing efforts to fight misinformation on Instagram. For more information, visit the InstagramHelp Center.']\n",
            "54 ['Today, leaders from our offices in London and Menlo Park, California spoke with members of the press about Facebook’s efforts to prepare for the upcoming General Election in the UK on December 12, 2019. The following is a transcript of their remarks.', 'Rebecca Stimson, Head of UK Public Policy, Facebook', 'We wanted to bring you all together, now that the UK General Election is underway, to set out the range of actions we are taking to help ensure this election is transparent and secure – to answer your questions and to point you to the various resources we have available.', 'There has already been a lot of focus on the role of social media within the campaign and there is a lot of information for us to set out.', 'We have therefore gathered colleagues from both the UK and our headquarters in Menlo Park, California, covering our politics, product, policy and safety teams to take you through the details of those efforts.', 'I will just say a few opening remarks before we dive into the details', 'Helping protect elections is one of our top priorities and over the last two years we’ve made some significant changes – these broadly fall into three camps:', 'So taking these in turn.', 'Transparency', 'On the issue of transparency. We’ve tightened our rules to make political ads much more transparent, so people can see who is trying to influence their vote and what they are saying.', 'We’ll discuss this in more detail shortly, but to summarize:', 'Taken together these changes mean that political advertising on Facebook and Instagram is now more transparent than other forms of election campaigning, whether that’s billboards, newspaper ads, direct mail, leaflets or targeted emails.', 'This is the first UK general election since we introduced these changes and we’re already seeing many journalists using these transparency tools to scrutinize the adverts which are running during this election – this is something we welcome and it’s exactly why we introduced these changes.', 'Defense', 'Turning to the stronger defenses we have put in place.', 'Nathaniel will shortly set out in more detail our work to prevent foreign interference and coordinated inauthentic behavior. But before he does I want to be clear right up front how seriously we take these issues and our commitment to doing everything we can to prevent election interference on our platforms.', 'So just to highlight one of the things he will be talking about – we have, as part of this work, cracked down significantly on fake accounts.', 'We now identify and shut down millions of fake accounts every day, many just seconds after they were created.', 'Investment', 'And lastly turning to investment in these issues.', 'We now have more than 35,000 people working on safety and security. We have been building and rolling out many of the new tools you will be hearing about today. And as Ella will set out later, we have introduced a number of safety measures including a dedicated reporting channel so that all candidates in the election can flag any abusive and threatening content directly to our teams.', 'I’m also pleased to say that – now the election is underway – we have brought together an Elections Taskforce of people from our teams across the UK, EMEA and the US who are already working together every day to ensure election integrity on our platforms.', 'The Elections Taskforce will be working on issues including threat intelligence, data science, engineering, operations, legal and others. It also includes representatives from WhatsApp and Instagram.', 'As we get closer to the election, these people will be brought together in physical spaces in their offices – what we call our Operations Centre.', 'It’s important to remember that the Elections Taskforce is an additional layer of security on top of our ongoing monitoring for threats on the platform which operates 24/7.', 'And while there will always be further improvements we can and will continue to make, and we can never say there won’t be challenges to respond to, we are confident that we’re better prepared than ever before.', 'Political Ads', 'Before I wrap up this intro section of today’s call I also want to address two of the issues that have been hotly debated in the last few weeks – firstly whether political ads should be allowed on social media at all and secondly whether social media companies should decide what politicians can and can’t say as part of their campaigns.', 'As Mark Zuckerberg has said, we have considered whether we should ban political ads altogether. They account for just 0.5% of our revenue and they’re always destined to be controversial.', 'But we believe it’s important that candidates and politicians can communicate with their constituents and would be constituents.', 'Online political ads are also important for both new challengers and campaigning groups to get their message out.', 'Our approach is therefore to make political messages on our platforms as transparent as possible, not to remove them altogether.', 'And there’s also a really difficult question – if you were to consider banning political ads, where do you draw the line – for example, would anyone advocate for blocking ads for important issues like climate change or women’s empowerment?', 'Turning to the second issue – there is also a question about whether we should decide what politicians and political parties can and can’t say.', 'We don’t believe a private company like Facebook should censor politicians. This is why we don’t send content or ads from politicians and political parties to our third party fact-checking partners.', 'This doesn’t mean that politicians can say whatever they want on Facebook. They can’t spread misinformation about where, when or how to vote. They can’t incite violence. We won’t allow them to share content that has previously been debunked as part of our third-party fact-checking program. And we of course take down content that violates local laws.', 'But in general we believe political speech should be heard and we don’t feel it is right for private companies like us to fact-check or judge the veracity of what politicians and political parties say.', 'Facebook’s approach to this issue is in line with the way political speech and campaigns have been treated in the UK for decades.', 'Here in the UK – an open democracy with a vibrant free press – political speech has always been heavily scrutinized but it is not regulated.', 'The UK has decided that there shouldn’t be rules about what political parties and candidates can and can’t say in their leaflets, direct mails, emails, billboards, newspaper ads or on the side of campaign buses.', 'And as we’ve seen when politicians and campaigns have made hotly contested claims in previous elections and referenda, it’s not been the role of the Advertising Standards Authority, the Electoral Commission or any other regulator to police political speech.', 'In our country it’s always been up to the media and the voters to scrutinize what politicians say and make their own minds up.', 'Nevertheless, we have long called for new rules for the era of digital campaigning.', 'Questions around what constitutes a political ad, who can run them and when, what steps those who purchase political ads must take, how much they can spend on them and whether there should be any rules on what they can and can’t say – these are all matters that can only be properly decided by Parliament and regulators.', 'Legislation should be updated to set standards for the whole industry – for example, should all online political advertising be recorded in a public archive similar to our Ad Library and should that extend to traditional platforms like billboards, leaflets and direct mail?', 'We believe UK electoral law needs to be brought into the 21st century to give clarity to everyone – political parties, candidates and the platforms they use to promote their campaigns.', 'In the meantime our focus has been to increase transparency so anyone, anywhere, can scrutinize every ad that’s run and by whom.', 'I will now pass you to the team to talk you through our efforts in more detail.', 'Nathaniel Gleicher, Head of Cybersecurity Policy, Facebook', 'My team leads all our efforts across our apps to find and stop what we call influence operations, coordinated efforts to manipulate or corrupt public debate for a strategic goal.', 'We also conduct regular red team exercises, both internally and with external partners to put ourselves into the shoes of threat actors and use that approach to identify and prepare for new and emerging threats. We’ll talk about some of the products of these efforts today.', 'Before I dive into some of the details, as you’re listening to Rob, Antonia, and I, we’re going to be talking about a number of different initiatives that Facebook is focused on, both to protect the UK general election and more broadly, to respond to integrity threats. I wanted to give you a brief framework for how to think about these.', 'The key distinction that you’ll hear again and again is a distinction between content and behavior. At Facebook, we have policies that enable to take action when we see content that violates our Community Standards.', 'In addition, we have the tools that we use to respond when we see an actor engaged in deceptive or violating behavior, and we keep these two efforts distinct. And so, as you listen to us, we’ll be talking about different initiatives we have in both dimensions.', 'Under content for example, you’ll hear Antonia talk about misinformation, about voter suppression, about hate speech, and about other types of content that we can take action against if someone tries to share that content on our platform.', 'Under the behavioral side, you’ll hear me and you’ll hear Rob also mention some of our work around influence operations, around spam, and around hacking.', 'I’m going to focus in particular on the first of these, influence operations; but the key distinction that I want to make is when we take action to remove someone because of their deceptive behavior, we’re not looking at, we’re not reviewing, and we’re not considering the content that they’re sharing.', 'What we’re focused on is the fact that they are deceiving or misleading users through their actions. For example, using networks of fake accounts to conceal who they are and conceal who’s behind the operation. So we’ll refer back to these, but I think it’s helpful to distinguish between the content side of our enforcement and the behavior side of our enforcement.', 'And that’s particularly important because we’ve seen some threat actors who work to understand where the boundaries are for content and make sure for example that the type of content they share doesn’t quite cross the line.', 'And when we see someone doing that, because we have behavioral enforcement tools as well, we’re still able to make sure we’re protecting authenticity and public debate on the platform.', 'In each of these dimensions, there are four pillars to our work. You’ll hear us refer to each of these during the call as well, but let me just say that these four fit together, and no one of these by themselves would be enough, but all four of the together give us a layered approach to defending public debate and ensuring authenticity on the platform.', 'We have expert investigative teams that conduct proactive investigations to find, expose, and disrupt sophisticated threat actors. As we do that, we learn from those investigations and we build automated systems that can disrupt any kind of violating behavior across the platform at scale.', 'We also, as Rebecca mentioned, build transparency tools so that users, external researchers and the press can see who is using the platform and ensure that they’re engaging authentically. It also forces threat actors who are trying to conceal their identity to work harder to conceal and mislead.', 'And then lastly, one of the things that’s extremely clear to us, particularly in the election space, is that this is a whole of society effort. And so, we work closely with partners in government, in civil society, and across industry to tackle these threats.', 'And we’ve found that where we could be most effective is where we bring the tools we bring to the table, and then can work with government and work with other partners to respond and get ahead of these challenges as they emerge.', 'One of the ways that we do this is through proactive investigations into the deceptive efforts engaged in by bad actors. Over the last year, our investigative teams, working together with our partners in civil society, law enforcement, and industry, have found and stopped more than 50 campaigns engaged in coordinated inauthentic behavior across the world.', 'This includes an operation we removed in May that originated from Iran and targeted a number of countries, including the UK. As we announced at the time, we removed 51 Facebook accounts, 36 pages, seven groups, and three Instagram accounts involved in coordinated inauthentic behavior.', 'The page admins and account owners typically posted content in English or Arabic, and most of the operation had no focus on a particular country, although there were some pages focused on the UK and the United States.', 'Similarly, in March we announced that we removed a domestic UK network of about 137 Facebook and Instagram accounts, pages, and groups that were engaged in coordinated inauthentic behavior.', 'The individuals behind these accounts presented themselves as far right and anti-far right activists, frequently changed page and group names, and operated fake accounts to engage in hate speech and spread divisive comments on both sides of the political debate in the UK.', 'These are the types of investigations that we focus our core investigative team on. Whenever we see a sophisticated actor that’s trying to evade our automated systems, those teams, which are made up of experts from law enforcement, the intelligence community, and investigative journalism, can find and reveal that behavior.', 'When we expose it, we announce it publicly and we remove it from the platform. Those expert investigators proactively hunt for evidence of these types of coordinated inauthentic behavior (CIB) operations around the world.', 'This team has not seen evidence of widespread foreign operations aimed at the UK. But we are continuing to search for this and we will remove and publicly share details of networks of CIB that we identify on our platforms.', 'As always with these takedowns, we remove these operations for the deceptive behavior they engaged in, not for the content they shared. This is that content/behavior distinction that I mentioned earlier. As we’ve improved our ability to disrupt these operations, we’ve also deepened our understanding of the types of threats out there and how best to counter them.', 'Based on these learnings, we’ve recently updated our inauthentic behavior policy which is posted publicly as part of our Community Standards, to clarify how we enforce against the spectrum of deceptive practices we see in our platforms, whether foreign or domestic, state or non state. For each investigation, we isolate any new behaviors we see and then we work to automate detection of them at scale. This connects to that second pillar of our integrity work.', 'And this slows down the bad guy and lets our investigators focus on improving our defenses against emerging threats. A good example of this work is our efforts to find and block fake accounts, which Rebecca mentioned.', 'We know bad actors use fake accounts as a way to mask their identity and inflict harm on our platforms. That’s why we’ve built an automated system to find and remove these fake accounts. And each time we conduct one of these takedowns, or any other of our enforcement actions, we learn more about what fake accounts look like and how we can have automated systems that detect and block them.', 'This is why we have these systems in place today that block millions of fake accounts every day, often within minutes of their creation. Because information operations often target multiple platforms as well as traditional media, I mentioned our collaborations with industry, civil society and government.', 'In addition to that, we are building increased transparency on our platform, so that the public along with open source researchers and journalists can find and expose more bad behavior themselves.', 'This effort on transparency is incredibly important. Rob will talk about this in detail, but I do want to add one point here, specifically around pages. Increasingly, we’re seeing people operate pages that clearly disclose the organization behind them as a way to make others think they are independent.', 'We want to make sure Facebook is used to engage authentically, and that users understand who is speaking to them and what perspective they are representing. We noted last month that we would be announcing new approaches to address this, and today we’re introducing a policy to require more accountability for pages that are concealing their ownership in order to mislead people.', 'If we find a page is misleading people about its purpose by concealing its ownership, we will require it to go through our business verification process, which we recently announced, and show more information on the page itself about who is behind that page, including the organization’s legal name and verified city, phone number, or website in order for it to stay up.', 'This type of increased transparency helps ensure that the platform continues to be authentic and the people who use the platform know who they’re talking to and understand what they’re seeing.', 'Rob Leathern, Director of Product, Business Integrity, Facebook', 'In addition to making pages more transparent as Nathaniel has indicated, we’ve also put a lot of effort into making political advertising on Facebook more transparent than it is anywhere else.', 'Every political and issue ad in the that runs on Facebook now goes into our Ad Library public archive that everyone can access, regardless of whether or not they have a Facebook account.', 'We launched this in the UK in October 2018 and, since then, there’s been over 116,000 ads related to politics, elections, and social issues placed in the UK Ad Library. You can find all the ads that a candidate or organization is running, including how much they spent and who saw the ad. And we’re storing these ads in the Ad Library for seven years.', 'Other media such as billboards, newspaper ads, direct mail, leaflets or targeted emails don’t today provide this level of transparency into the ad and who is seeing them. And as a result, we’ve seen a significant number of press stories regarding the election driven by the information in Facebook’s Ad Library.', 'We’re proud of this resource and insight into ads running on Facebook and Instagram and that it is proving useful for media and researchers. And just last month, we made even more changes to both the Ad Library and Ad Library Reports. These include adding details in who the top advertising spenders are in each country in the UK, as well as providing an additional view by different date ranges which people have been asking for.', 'We’re now also making it clear which Facebook platform an ad ran on. For example, if an ad ran on both Facebook and/or Instagram.', 'For those of you unfamiliar with the Ad Library, which you can see at Facebook.com/adlibrary, I thought I’d run through it quickly.', 'So this is the Ad Library. Here you see all the ads have been classified as relating to politics or issues. We keep them in the library for seven years. As I mentioned, you can find the Ad Library at Facebook.com/adlibrary.', 'You can also access the Ad Library through a specific page. For example, for this Page, you can see not only the advertising information, but also the transparency about the Page itself, along with the spend data.', 'Here is an example of the ads that this Page is running, both active as well as inactive. In addition, if an ad has been disapproved for violating any of our ad policies, you’re also able to see all of those ads as well.', 'Here’s what it looks like if you click to see more detail about a specific ad. You’ll be able to see individual ad spend, impressions, and demographic information.', 'And you’ll also be able to compare the individual ad spend to the overall macro spend by the Page, which is tracked in the section below. If you scroll back up, you’ll also be able to see the other information about the disclaimer that has been provided by the advertiser.', 'We know we can’t protect elections alone and that everyone plays a part in keeping the platform safe and respectful. We ask people to share responsibly and to let us know when they see something that may violate our Advertising Policies and Community Standards.', 'We also have the Ad Library API so journalists and academics can analyze ads about social issues, elections, or politics. The Ad Library application programming interface, or API, allows people to perform customized keyword searches of ads stored in the Ad Library. You can search data for all active and inactive issue, electoral or political ads.', 'You can also access the Ad Library and the data therein through the specific page or through the Ad Library Report. Here is the Ad Library report, this allows you to see the spend by specific advertisers and you can download a full report of the data.', 'Here we also allow you to see the spending by location and if you click in you can see the top spenders by region. So you can see, for example, in the various regions, who the top spenders in those areas are.', 'Our goal is to provide an open API to news organizations, researchers, groups and people who can hold advertisers and us more accountable.', 'We’ve definitely seen a lot of press, journalists, and researchers examining the data in the Ad Library and using it to generate these insights and we think that’s exactly a part of what will help hold both us and advertisers more accountable.', 'We hope these measures will build on existing transparency we have in place and help reporters, researchers and most importantly people on Facebook learn more about the Pages and information they’re engaging with.', 'Antonia Woodford, Product Manager, Misinformation, Facebook', 'We are committed to fighting the spread of misinformation and viral hoaxes on Facebook. It is a responsibility we take seriously.', 'To accomplish this, we follow a three-pronged approach which we call remove, reduce, and inform. First and foremost, when something violates the laws or our policies, we’ll remove it from the platform all together.', 'As Nathaniel touched on, removing fake accounts is a priority, of which the vast majority are detected and removed within minutes of registration and before a person can report them. This is a key element in eliminating the potential spread of misinformation.', 'The reduce and inform part of the equation is how we reduce the spread of problematic content that doesn’t violate the law or our community standards, while still ensuring freedom of expression on the platform and this is where the majority of our misinformation work is focused.', 'To reduce the spread of misinformation, we work with third party fact-checkers.', 'Through a combination of reporting from people on our platform and machine learning, potentially false posts are sent to third party fact-checkers to review. These fact-checkers review this content, check the facts, and then rate its accuracy. They’re able to review links in news articles as well as photos, videos, or text posts on Facebook.', 'After content has been rated false, our algorithm heavily downranks this content in News Feed so it’s seen by fewer people and far less likely to go viral. Fact-checkers can fact-check any posts they choose based on the queue we send them.', 'And lastly, as part of our work to inform people about the content they see on Facebook, we just launched a new design to better warn people when they see content that’s illegal, false, or partly false by our fact-checking partners.', 'People will now see a more prominent label on photos and videos that have been fact-checked as false or partly false. This is a grey screen that sits over a post and says ‘false information’ and points people to fact-checkers’ articles debunking the claims.', 'These clearer labels are what people have told us they want, what they have told us they expect Facebook to do, and what experts tell us is the right tactic for combating misinformation.', 'We’re rolling this change out in the UK this week for any photos and videos that have been rated through our fact-checking partnership. Though just one part of our overall strategy, fact-checking is a fundamental part of our strategy to combat this information and I want to share a little bit more about the program.', 'Our fact-checking partners are all accredited by the International Fact-Checking Network which requires them to abide by a code of principles such as nonpartisanship and transparency sources.', 'We currently have over 50 partners in over 40 languages around the world. As Rebecca outlined earlier, we don’t send content or ads from politicians and political parties to our third party fact-checking partners.', 'Here in the UK we work with Full Fact and FactCheckNI and I as part of our program. To recap we identify content that may be false using signals such as feedback from our users. This content is all submitted into a queue for our fact-checking partners to access. These fact-checkers then choose which content to review, check the facts, and rate the accuracy of the content.', 'These fact-checkers are independent organizations, so it is at their discretion what they choose to investigate. They can also fact-check whatever content they want outside of the posts we send their way.', 'If a fact-checker rates a story as false, it will appear lower in News Feed with the false information screen I mentioned earlier. This significantly reduces the number of people who see it.', 'Other posts that Full Fact and FactCheckNI choose to fact-check outside of our system will not be impacted on Facebook.', 'And finally, on Tuesday we announced a partnership with the International Fact-Checking Network to create the Fact-Checking Innovation Initiative. This will fund innovation projects, new formats, and technologies to help benefit the broader fact-checking ecosystem.', 'We are investing $500,000 into this new initiative, where organizations can submit applications for projects to improve fact-checkers’ scale and efficiency, increase the reach of fact-checks to empower more people with reliable information, build new tools to help combat misinformation, and encourage newsrooms to collaborate in fact-checking efforts.', 'Anyone from the UK can be a part of this new initiative.', 'Ella Fallows, Politics and Government Outreach Manager UK, Facebook', 'Our team’s role involves two main tasks: working with parties, MPs and candidates to ensure they have a good experience and get the most from our platforms; and looking at how we can best use our platforms to promote participation in elections.', 'I’d like to start with how MPs and candidates use our platforms.', 'There is, rightly, a focus in the UK about the current tone of political debate. Let me be clear, hate speech and threats of violence have no place on our platforms and we’re investing heavily to tackle them.', 'Additionally, for this campaign we have this week written to political parties and candidates setting out the range of safety measures we have in place and also to remind them of the terms and conditions and the Community Standards which govern our platforms.', 'As you may be aware, every piece of content on Facebook and Instagram has a report button, and when content is reported to us which violates our Community Standards – what is and isn’t allowed on Facebook – it is removed.', 'Since March of this year, MPs have also had access to a dedicated reporting channel to flag any abusive and threatening content directly to our teams. Now that the General Election is underway we’re extending that support to all prospective candidates, making our team available to anyone standing to allow them to quickly report any concerns across our platforms and have them investigated.', 'This is particularly pertinent to Tuesday’s news from the Government calling for a one stop shop for candidates. We have already set up our own one stop shop so that there is a single point of contact for candidates for issues across Facebook and Instagram.', 'But our team is not working alone; it’s backed up by our 35,000-strong global safety and security team that oversees content and behavior across the platform every day.', 'And our technology is also helping us to automatically detect more of this harmful content. For example, the proportion of hate speech we have removed before it’s reported to us has increased significantly over the last two years, and we will be releasing new figures on this later this month.', 'We also have a Government, Politics & Advocacy Portal which is a home for everything a candidate will need during the campaign, including ‘how to’ guides on subjects such as political advertising, campaigning on Facebook and troubleshooting guides for technical issues.', 'We’re working with the political parties to ensure candidates are aware of both the reporting channel to reach my team and the Government, Politics & Advocacy Portal.', 'We’re holding a series of sessions for candidates on safety and outlining the help available to address harassment on our platforms. We’ve already held dedicated sessions for female candidates in partnership with women’s networks within the parties to provide extra guidance. We want to ensure we’re doing everything possible to help them connect with their constituents, free from harassment.', 'Finally, we’re working with the Government to distribute to every candidate via returning officers in the General Election the safety guides we have put together, to ensure we reach everyone not just those attending our outreach sessions. Our safety guides include information on a range of tools we have developed:', 'We hope these steps help every candidate to reach their constituents, and get the most from our platforms. But our work doesn’t stop there.', 'The second area our team focuses on is promoting civic engagement. In addition to supporting and advising candidates, we also, of course, want to help promote voter participation in the election.', 'For the past five years, we’ve used badges and reminders at the top of people’s News Feeds to encourage people to vote in elections around the world. The same will be true for this campaign.', 'We’ll run reminders to register to vote, with a link to the gov.uk voter registration page, in the week running up to the voter registration deadline.', 'On election day itself, we’ll also run a reminder to vote with a link to the Electoral Commission website so voters can find their polling station and any information they need. This will include a button to share that you voted.', 'We hope that this combination of steps will help to ensure both candidates and voters engaging with the General Election on our platforms have the best possible experience.']\n",
            "55 ['Journalism plays a critical role in our democracy.When news is deeply-reported and well-sourced it gives people information they can rely on. When it’s not, we lose an essential tool for making good decisions.', 'People want and benefit from personalized experiences on Facebook, but we know there is reporting that transcends individual experience. We want to support both.', 'Today we’re starting to test Facebook News, a dedicated place for news on Facebook, to a subset of people in the US. News gives people more control over the stories they see, and the ability to explore a wider range of their news interests, directly within the Facebook app. It also highlights the most relevant national stories of the day. News articles will continue to appear in News Feed as they do today.', 'As we looked to build a place where people can find more news on Facebook, we changed our approach to gather insight from journalists and publishersbeforewe started developing a product.AsMark Zuckerberg said in a conversation with Mathias Döpfner,CEO of Europe’s largest publisher Axel Springer, we wanted to build this product in a consultative way, sharing our ideas and getting input from the industry.We talked to news organizations about what they’d like to see included in a news tab, how their stories should be presented and what analytics to provide.', 'As we talked to people and publishers, we identified key features to help make Facebook News valuable:', 'Regarding personalization, publishers worry that machine learning has limits and they’re right. We have progress to make before we can rely on technology alone to provide a quality news destination. We also aim to serve both people and news publishers, and not just the big national players. We want new forms of journalism in the digital age, including individual, independent journalism, to flourish. So we will continue to expand the algorithmic selection of stories driving the majority of Facebook News.', 'When we started talking to news organizations about building Facebook News earlier this year, they emphasized that original reporting is more expensive to produce and better recognized by seasoned journalists than by algorithms. So to help reward this kind of work, we formed a curation team to manage the Today’s Stories section of Facebook News. The team will have editorial independence and will select stories based on publicly available guidelines, which you can learn about at facebook.com/news.', 'What You Can Expect to See in Facebook News', 'Facebook News will feature a widerange of contentacross four categories of publishers: general, topical, diverse and local news. At the beginning of the year, we surveyed over 100,000 people on Facebook in the US about what topics they were most interested in and found that we were under-serving many topics people wanted most in their News Feeds, especially around categories like entertainment, health, business and sports. We took this into consideration as we identified publishers across those four categories.', 'How do we identify these publishers? They need to be in ourNews Page Index, which we developed in collaboration with the industry to identify news content. They also need to abide byFacebook’s Publisher Guidelines, these include a range of integrity signals in determining product eligibility, including misinformation — as identified based onthird-party fact checkers— community standards violations (e.g., hate speech), clickbait, engagement bait and others. We’ll continually check Pages’ integrity status to ensure eligibility criteria is consistently being met.Lastly, they must serve a sufficiently large audience, with different thresholds for the four categories of publishers.', 'Our criteria will evolve over time to make sure people are seeing sources that are valuable to them and that we’re including reporting across these topics.', 'During the initial test, we’ll showcase local original reporting by surfacing local publications from the largest major metro areas across the country, beginning with New York, Los Angeles, Chicago, Dallas-Fort Worth, Philadelphia, Houston, Washington DC, Miami, Atlanta and Boston. In the coming months, we’ll include local news from Today In, our local news and community information tab, whichrecently expanded to over 6,000 US towns and cities.', 'Facebook News was built to bring people closer to the stories that affect their lives. We’ll continue to learn, listen and improve News as it rolls out more broadly. We hope this work aids in our effort to sustain great journalism and strengthen democracy.']\n",
            "56 ['Learn more about how we’reprotecting the US 2020 elections.', 'Update on January 27, 2020 at 1:30PM PT:In order to continue running issue, electoral or political ads in the US, advertisers must assign a Page Owner. To help ensure all advertisers have time to complete this, we are extending our deadline to become compliant to February 8, 2020.', 'Original post on October 21, 2019:', 'We have a responsibility to stop abuse and election interference on our platform. That’s why we’ve made significant investments since 2016 to better identify new threats, close vulnerabilities and reduce the spread of viral misinformation and fake accounts.', 'Today, almost a year out from the 2020 elections in the US, we’re announcing several new measures to help protect the democratic process and providing an update on initiatives already underway:', 'Fighting foreign interference', 'Increasing transparency', 'Reducing misinformation', 'Combating Inauthentic Behavior', 'Over the last three years, we’ve worked to identify new and emerging threats and removecoordinated inauthentic behavioracross our apps. In the past year alone, we’ve taken down over 50 networks worldwide, many ahead of major democratic elections. As part of our effort to counter foreign influence campaigns, this morning we removed four separate networks of accounts, Pages and Groups on Facebook and Instagram for engaging in coordinated inauthentic behavior. Three of them originated in Iran and one in Russia. They targeted the US, North Africa and Latin America.We have identified these manipulation campaignsas part of our internal investigations into suspected Iran-linked inauthentic behavior, as well as ongoing proactive work ahead of the US elections.', 'We took down these networks based on their behavior, not the content they posted. In each case, the people behind this activity coordinated with one another and used fake accounts to misrepresent themselves, and that was the basis for our action. We have shared our findings with law enforcement and industry partners. More details can be foundhere.', 'As we’ve improved our ability to disrupt these operations, we’ve also built a deeper understanding of different threats and how best to counter them. We investigate and enforce against any type of inauthentic behavior. However, the most appropriate way to respond to someone boosting the popularity of their posts in their own country may not be the best way to counter foreign interference. That’s why we’re updating ourinauthentic behavior policyto clarifyhow we deal with the range of deceptive practices we see on our platforms, whether foreign or domestic, state or non-state.', 'Protecting the Accounts of Candidates, Elected Officials and Their Teams', 'Today, we’re launchingFacebook Protectto further secure the accounts of elected officials, candidates, their staff and others who may be particularly vulnerable to targeting by hackers and foreign adversaries. As we’ve seen in past elections, they can be targets of malicious activity. However, because campaigns are generally run for a short period of time, we don’t always know who these campaign-affiliated people are, making it harder to help protect them.', 'Beginning today, Page admins can enroll their organization’s Facebook and Instagram accounts in Facebook Protect and invite members of their organization to participate in the program as well. Participants will be required to turn on two-factor authentication, and their accounts will be monitored for hacking, such as login attempts from unusual locations or unverified devices. And, if we discover an attack against one account, we can review and protect other accounts affiliated with that same organization that are enrolled in our program. Read more about Facebook Protect and enrollhere.', '', 'Making Pages More TransparentWe want to make sure people are using Facebook authentically, and that they understand who is speaking to them. Over the past year, we’ve taken steps to ensure Pages are authentic and more transparent by showing people the Page’s primary country location and whether the Page has merged with other Pages. This gives people more context on the Page and makes it easier to understand who’s behind it.', 'Increasingly, we’ve seen people failing to disclose the organization behind their Page as a way to make people think that a Page is run independently. To address this, we’re adding more information about who is behind a Page, including a new “Organizations That Manage This Page” tab that will feature the Page’s “Confirmed Page Owner,” including the organization’s legal name and verified city, phone number or website.', 'Initially, this information will only appear on Pages with large US audiences that have gone through Facebook’sbusiness verification. In addition, Pages that have gone through the new authorization process to run ads about social issues, elections or politics in the US will also have this tab. And starting in January, these advertisers will be required to show their Confirmed Page Owner.', 'If we find a Page is concealing its ownership in order to mislead people, we will require it to successfully complete the verification process and show more information in order for the Page to stay up.', '', 'Labeling State-Controlled Media', 'We want to help people better understand the sources of news content they see on Facebook so they can make informed decisions about what they’re reading. Next month, we’ll begin labeling media outlets that are wholly or partially under the editorial control of their government as state-controlled media. This label will be on both their Page and in our Ad Library.', 'We will hold these Pages to a higher standard of transparency because they combine the opinion-making influence of a media organization with the strategic backing of a state.', 'We developed our own definition and standards for state-controlled media organizations with input from more than 40 experts around the world specializing in media, governance, human rights and development. Those consulted represent leading academic institutions, nonprofits and international organizations in this field, including Reporters Without Borders, Center for International Media Assistance, European Journalism Center, Oxford Internet Institute, Center for Media, Data and Society (CMDS) at the Central European University, the Council of Europe, UNESCO and others.', 'It’s important to note that our policy draws an intentional distinction between state-controlled media and public media, which we define as any entity that is publicly financed, retains a public service mission and can demonstrate its independent editorial control. At this time, we’re focusing our labeling efforts only on state-controlled media.', 'We will update the list of state-controlled media on a rolling basis beginning in November. And, in early 2020, we plan to expand our labeling to specific posts and apply these labels on Instagram as well. For any organization that believes we have applied the label in error, there will be an appeals process.', 'Making it Easier to Understand Political Ads', 'In addition to making Pages more transparent, we’re updating the Ad Library, Ad Library Report and Ad Library API to help journalists, lawmakers, researchers and others learn more about the ads they see. This includes:', 'In addition to updates to the Ad Library API, in November, we will begin testing a new database with researchers that will enable them to quickly download the entire Ad Library, pull daily snapshots and track day-to-day changes.', 'Visit our Help Center to learn more about the changesto Pagesandthe Ad Library.', 'Preventing the Spread of Viral MisinformationOn Facebook and Instagram, we work to keep confirmed misinformation from spreading. For example, we reduce its distribution so fewer people see it—on Instagram, we remove it from Explore and hashtags, and on Facebook, we reduce its distribution in News Feed.On Instagram, we also make content from accounts that repeatedly post misinformation harder to find by filtering content from that account from Explore and hashtag pages for example. And on Facebook,if Pages, domains or Groups repeatedly share misinformation, we’ll continue to reduce their overall distribution and we’ll place restrictions on the Page’s ability to advertise and monetize.', 'Over the next month, content across Facebook and Instagram that has been rated false or partly false by a third-party fact-checker will start to be more prominently labeled so that people can better decide for themselves what to read, trust and share. The labels below will be shown on top of false and partly false photos and videos, including on top of Stories content on Instagram, and will link out to the assessment from the fact-checker.', '', 'Much like we do on Facebook when people try to share known misinformation, we’re also introducing a new pop-up that will appear when people attempt to share posts on Instagram that include content that has been debunked by third-party fact-checkers.', '', 'In addition to clearer labels, we’re also working to take faster action to prevent misinformation from going viral, especially given that quality reporting and fact-checking takes time. In many countries, including in the US, if we have signals that a piece of content is false, we temporarily reduce its distribution pending review by a third-party fact-checker.', 'Fighting Voter Suppression and IntimidationAttempts to interfere with or suppress voting undermine our core values as a company, and we work proactively to remove this type of harmful content. Ahead of the 2018 midterm elections, we extended our voter suppression and intimidation policies to prohibit:', 'We remove this type of content regardless of who it’s coming from, andahead of the midterm elections, our Elections Operations Center removed more than 45,000 pieces of content that violated these policies—more than 90% of which our systems detected before anyone reported the content to us.', 'We also recognize that there are certain types of content, such as hate speech, that are equally likely to suppress voting. That’s why ourhate speech policiesban efforts to exclude people from political participation on the basis of things like race, ethnicity or religion (e.g., telling people not to vote for a candidate because of the candidate’s race, or indicating that people of a certain religion should not be allowed to hold office).', 'In advance of the US 2020 elections, we’re implementing additional policies and expanding our technical capabilities on Facebook and Instagram to protect the integrity of the election. Following up on a commitment we made in thecivil rights audit reportreleased in June, we have now implemented our policy banning paid advertising that suggests voting is useless or meaningless, or advises people not to vote.', 'In addition, our systems are now more effective at proactively detecting and removing this harmful content. We use machine learning to help us quickly identify potentially incorrect voting information and remove it.', 'We are also continuing to expand and develop our partnerships to provide expertise on trends in voter suppression and intimidation, as well as early detection of violating content. This includes working directly with secretaries of state and election directors to address localized voter suppression that may only be occurring in a single state or district. This work will be supported by our Elections Operations Center during both the primary and general elections.', 'Helping People Better Understand What They See Online', 'Part of our work to stop the spread of misinformation is helping people spot it for themselves. That’s why we partner with organizations and experts in media literacy.', 'Today, we’re announcing an initial investment of $2 million to support projects that empower people to determine what to read and share — both on Facebook and elsewhere.', 'These projects range from training programs to help ensure the largest Instagram accounts have the resources they need to reduce the spread of misinformation, to expanding a pilot program that brings together senior citizens and high school students to learn about online safety and media literacy, to public events in local venues like bookstores, community centers and libraries in cities across the country. We’re also supporting a series of training events focused on critical thinking among first-time voters.', 'In addition, we’re including a new series of media literacy lessons in our Digital Literacy Library. These lessons are drawn from the Youth and Media team at the Berkman Klein Center for Internet & Society at Harvard University, which has made them available for free worldwide under a Creative Commons license. The lessons, created for middle and high school educators, are designed to be interactive and cover topics ranging from assessing the quality of the information online to more technical skills like reverse image search.', 'We’ll continue to develop our media literacy efforts in the US and we’ll have more to share soon.']\n",
            "57 ['By Nick Clegg, VP of Global Affairs and Communications', 'Facebook gives everyone a voice, no matter what your political views may be, which candidates or parties you support, or which causes you advocate. So we take accusations of political bias made against us extremely seriously. Our policies, and how we apply them, can have a huge impact, so we have a responsibility to apply them evenly, without favoring one side or another and without devaluing the principle of free expression.', 'As announced last year, we asked an outside party – former Senator Jon Kyl, a respected Republican – to conduct a review of potential anti-conservative bias at Facebook. Former Senator Kyl and his team at the law firm Covington and Burling met with more than 130 leading conservative politicians and organizations and produceda reportthat outlines the concerns they heard raised about our policies and how we carry them out. This morning, Senator Kyl also publishedan op-edin the Wall Street Journal summarizing his findings.', 'While the issue of alleged anti-conservative bias has been in the headlines in recent weeks, this report has been long in the making.', 'We know we need to take these concerns seriously and adjust course if our policies are in fact limiting expression in an unintended way. The report highlights the changes Facebook has already made to address some of them. These include making our decisions more transparent by providing more information on why people are seeing specific posts on News Feed; ensuring Page managers can see when enforcement action takes place; launching an appeals process; and creating a new Oversight Board for content, made up of people with a diverse range of ideological views. It also recognizes changes we made earlier this year to our advertising policies around the labelling of ads about social issues, elections or politics, and to our policy on banning images of patients with medical tubes, which has been applied unevenly in the past.', 'This is the first stage of an ongoing process and Senator Kyl and his team will report again in a few months’ time.', 'This work is not an issue of personal political opinion. As at any large company, there is a diversity of political opinions at Facebook and plenty of people who would not describe themselves as conservatives. My own long-held political views have been a subject of public record for years. But regardless of one’s own political views, this is about whether we apply our own policies fairly to all sides, and whether those policies begin with an understanding of how core groups of users express their beliefs.', 'While we err on the side of free speech, there are critical exceptions: we don’t allow content that might encourage offline harm or is intended to intimidate, exclude or silence people. And we work to slow and reduce the spread of content like debunked hoaxes and clickbait by downranking it in News Feed. We know we need to listen more as we work to strike the right balance with these policies.', 'But even if we could craft them in a way that pleased all sides, when dealing with such nuanced issues, involving policies that apply to billions of posts, we will inevitably make some bad calls, some of which may appear to strike harder at conservatives. That’s why it is so important that we work to make sure this process is free of bias, intended or not. After all, we can say that we welcome political expression on our platform all we want, but it won’t mean much unless people trust that we craft and apply our rules fairly.', 'I would like to express my gratitude to Senator Kyl and his team for all the work they have done so far on this crucial, if sensitive, issue – and I look forward to working with him and with colleagues across Facebook to continue to examine, and where necessary adjust, our own policies and practices in the future.']\n",
            "58 ['By Travis Yeh, Product Manager', 'People come together on Facebook to talk about, advocate for, and connect around things like nutrition, fitness and health issues.But in order to help people get accurate health information and the support they need, it’s imperative that we minimize health content that is sensational or misleading.', 'In ourongoing effortsto improve the quality of information in News Feed, we consider ranking changes based on how they affect people, publishers and our community as a whole. We know thatpeople don’t like posts that are sensational or spammy, and misleading health content is particularly bad for our community. So, last month we made two ranking updates to reduce (1) posts with exaggerated or sensational health claims and (2) posts attempting to sell products or services based on health-related claims.', 'We handled this in a similar way to how we’vepreviouslyreduced low-quality content likeclickbait: by identifying phrases that were commonly used in these posts to predict which posts might include sensational health claims or promotion of products with health-related claims, and then showing these lower in News Feed.', 'We’ll continue working to minimize low-quality health content on Facebook.', 'Will This Impact My Page?', 'We anticipate that most Pages won’t see any significant changes to their distribution in News Feed as a result of this update.', 'Posts with sensational health claims or solicitation using health-related claims will have reduced distribution. Pages should avoid posts about health that exaggerate or mislead people and posts that try to sell products using health-related claims. If a Page stops posting this content, their posts will no longer be affected by this change.']\n",
            "59 ['By Guido Buelow, Facebook News Partnerships, EMEA', 'Fighting misinformation is an ever-evolving problem and we can’t do it alone. In 2016, Facebookstartedits third-party fact-checking program, working withIFCN-certifiedfact-checkers around the world torate and reviewthe accuracy of content on our platform. Since its launch, we havepartneredwith over 50 organizations with expertise in over 40 languages.', 'For the first of what will be an ongoing Q&A series, “Getting to Know our Third-Party Fact Checking Partners,” we spoke with Mevan Babakar, Head of Automated Factchecking atFull Factin the UK, about the organization and its approach to fighting false news – both on and off Facebook.', 'How would you describe Full Fact and its mission in a few sentences?Full Fact is the UK’s independent fact-checking charity. We’ve been factchecking since 2010. We check claims made by politicians, the media and other public bodies. We want to give you the power to decide what and who to believe, we do this by tracing back information to its primary sources to see if it stacks up. We also ask for corrections when mistakes are made, and campaign for bigger changes like improvements to data releases so mistakes don’t happen in the first place.', 'You began fact-checking content on Facebook at the beginning of 2019. What has this work focused on to date?Our third-party fact-checking work with Facebook has mostly been focusing on content with the most potential to cause harm, for example misleading health and safety advice that if believed could potentially cause real harm to people’s lives. We have also prioritised claims that have spread widely and claims that we think can help educate people on techniques for spotting false information online.', 'When many people think about fact-checking, they imagine traditional reporting: reviewing documents, making calls to sources and more. Yet for Full Fact, automation is also a key component of your work. How do the two fit together?Our team of fact-checkers do all those traditional fact-checking methods. It’s because we’ve been doing this ‘traditional’ work for almost a decade now that we’ve been able to identify ways to help speed up parts of the manual factchecking process with technology.', 'One example is spotting repetitions of claims we’ve already checked. With all the will in the world, we can’t spot every single time that something we know is false has been repeated. Our automated tools let us visualize the spread of bad information, enabling us to ask for corrections or take other follow-up action within hours, rather than weeks.', 'This is helping to make our fact-checking work more effective. We don’t just write and publish fact-checks and hope people see them — we take real action to stop false information spreading further and causing more harm.', 'When you think about what fact-checking will look like in a decade, what are some of the biggest shifts that you envision? What does technology have the biggest potential to change, and what won’t it change?There always has been – and always will be – misinformation in the world. It might change form and medium over time, but there will always be bad information, whether it’s spread maliciously or accidentally. Having said this, I do think that trusted and impartial information will become more accessible to people when they need it – it will be much easier to get access to trusted information, fact-checks and primary sources of information, for example.', 'In the next five to 10 years, I hope our work can help reduce the harm bad information causes by stopping the spread of misinformation that, if believed, has the potential to cause serious damage to people’s lives. No one should have their life savings conned out of them or risk their health by a fake cancer treatment for example.', 'Facebook is partnering with Full Fact to offer trainings for fact-checkers on ClaimReview, a markup tool that makes it easier for platforms & apps to scan the contents of fact-checks across the Internet. How are you using ClaimReview?ClaimReviewis a markup that has fields for ‘claim’, ‘conclusion’, ‘rating’ etc. that we use almost like a recipe for our fact-checks. Separating out the claim and conclusion, and many other fields, makes it easier for other tools and services to serve them to wider audiences.', 'At Full Fact, ClaimReview forms the basis of our automated fact-checking tools because we use it to pull in an organization’s claims. It makes working together much simpler when there’s a common and shared language.', 'Outside of Full Fact, what projects have you seen that get you excited about the intersection of fact-checking, automation and technology?In all honesty, what gets me really excited is when complex issues are discussed clearly and with minimal fuss. A great example of this is theNHS websitein the UK which gives people who are potentially quite distressed clear, impartial and always helpful information. Even if the issue is really difficult or complex they manage to make it surmountable.', 'So I think before we even think about how technology can help support fact-checking and automation, we have to think about the content we are giving people and how it can be as trusted, clear and effective as possible.', 'Learn more about Full Fact on theirwebsite, andsign upfor the Facebook Journalism Project newsletter to stay up-to-date on Facebook’s work with third-party fact-checkers.']\n",
            "60 ['By Antonia Woodford, Product Manager', 'Ahead of the European Parliament Elections in May, we have made fighting misinformation a top priority. One of the ways we reduce the spread of false news is by partnering with independent,third-party fact-checkersaround the world. Today we’re announcing the expansion of this program in the EU with five new local fact-checking partners:Ellinika Hoaxesin Greece,FactCheckNIin Northern Ireland,Faktografin Croatia,Observadorin Portugal andPatikrinta 15minin Lithuania. These organizations will review andrate the accuracyof content on Facebook.', 'Our fact-checking partners are all accredited by the International Fact-Checking Network (IFCN), which appliesstandardssuch as non-partisanship and transparency of sources.These partners are also part of a collaborative effort led by IFCN to fact-check content related to theEuropeanParliament elections, calledFactCheckEU. Starting today, nearly all FactCheckEU participants will able to rate and review claims on Facebook.(Updated on April 29, 2019 at 11AM PT to reflect the fact that nearly all, but not all, FactCheckEU participants will able to rate and review claims on Facebook.)', 'Our program now includes 21 partners fact-checking content in 14 European languages: Croatian, Danish, Dutch, English, French, German, Greek, Italian, Lithuanian, Norwegian, Polish, Portuguese, Spanish and Swedish. When a fact-checker rates a story as false, we show it lower in News Feed, significantly reducing its distribution. This reduces the spread of the story and the number of people who see it. In our experience, once a story is rated as false, we’ve been able to reduce its distribution by 80%. Pages and domains that repeatedly share false news will also see their distribution reduced and their ability to monetize and advertise removed. This helps curb the spread of financially motivated false news.', 'This program is part of ourthree-part frameworkto improve the quality and authenticity of stories in News Feed. Weremoveaccounts and content that violate ourCommunity Standardsorad policies,reducethe distribution of false news and inauthentic content like clickbait, andinformpeople by giving them more context on the posts they see. In line with this approach, we’re working on additional measures to protect elections in the EU, including:', 'Introducing a Click-Gap signal:Our News Feed ranking system uses many signals to ensure that people see stories that are relevant and interesting to them. Werecently introduceda new signal called click-gap, which can identify whether a website is producing low-quality content bylooking at the percentage of total Facebook clicks it gets, and comparing that number to its web graph — the clicks it gets from other sources, or its status within the broader internet. Sites that have a high click-gap ratio are likely to produce lower-quality content like misinformation.', 'Expanding thecontext button:To help people evaluate the credibility of an article, we provide abuttonthat displays more context about the article’s source, such as the publisher’s Wikipedia entry and where the article is being shared. We’re expanding this to indicate if a Page has a history of sharing misinformation, as well as “Trust Indicators,” which are publisher-provided links to a publication’s fact-checking principles, code of ethics, corrections policy, ownership/funding, and editorial team.', 'Informing publishers with new updates to the Page Quality Tab: To better inform Page managers about our policies around repeatedly sharing misinformation, we’re adding information about a Page’s misinformation violations to thePage Quality tab. If a Page has repeatedly published misinformation, we apply a demotion to all of that Page’s content on Facebook, and revoke that Page’s ability to advertise or use monetization products. The Page Quality Tab tells Page admins if they have repeatedly shared misinformation, if they haven’t, or if they’re at risk of reaching “repeat offender” status. We plan to addthe ability for Page admins to see if their Page is receiving anydemotions for sharing clickbaitas well.', 'Informing group administrators about our misinformation tools:We’ll soon let group admins know if a third-party fact-checker has rated content that was posted in their groups as false.We’ll demote group content in News Feed if a group repeatedly shares misinformation, much in the same way that Pages and domains get a demotion on all their content if they frequently share false news.', 'Finally,we’reimproving how we identify content that contains a claim that has already been debunkedby a fact-checker so we can demote that too.Publishers who share this content will receive a notification that they’ve shared misinformation, much in the way that people who shared that claim would.', 'Misinformation is a complex and evolving problem, and we have more work to do. We’re investing heavily to get ahead because we believe in providing a space for civic discourse during elections. We’ll continue to take steps to ensure this discourse is safe, authentic, and accurate.', 'You can read more about how we’re maintaining the integrity of information on Facebookhere.']\n",
            "61 ['By Guy Rosen, VP of Integrity, and Tessa Lyons, Head of News Feed Integrity', 'Since 2016, we have used a strategy called “remove, reduce, and inform” to manage problematic content across the Facebook family of apps. This involvesremovingcontent that violates our policies,reducingthe spread of problematic content that does not violate our policies andinformingpeople with additional information so they can choose what to click, read or share. This strategy applies not only during critical times likeelections, but year-round.', 'Today in Menlo Park, we met with a small group of journalists to discuss our latest remove, reduce and inform updates to keep people safe and maintain the integrity of information that flows through the Facebook family of apps:', 'REMOVE(read more)', 'REDUCE(read more)', 'INFORM(read more)', '', 'Facebook', 'We haveCommunity Standardsthat outline what is and isn’t allowed on Facebook. They cover things like bullying, harassment and hate speech, and we remove content that goes against our standards as soon as we become aware of it. Last year, we made it easier for people to understand what we take down bypublishing our internal enforcement guidelinesand giving people the right toappeal our decisionson individual posts.', 'The Community Standards apply to all parts of Facebook, but different areas pose different challenges when it comes to enforcement. For the past two years, for example, we’ve been working on something called the Safe Communities Initiative, with the mission of protecting people from harmful groups and harm in groups. By using a combination of the latest technology, human review and user reports, we identify and remove harmful groups, whether they are public, closed or secret. We can now proactively detect many types of violating content posted in groups before anyone reports them and sometimes before few people, if any, even see them.', 'Similarly, Stories presents its own set of enforcement challenges when it comes to both removing and reducing the spread of problematic content. The format’s ephemerality means we need to work even faster to remove violating content. The creative tools that give people the ability to add text, stickers and drawings to photos and videos can be abused to mask violating content. And because people enjoy stringing together multiple Story cards, we have to view Stories as holistic — if we evaluate individual story cards in a vacuum, we might miss standards violations.', 'In addition to describing this context and history, today we discussed how we will be:', 'For more information on Facebook’s “remove” work, see these videos on thepeopleandprocessbehind our Community Standards development.', '', 'Facebook', 'There are types of content that are problematic but don’t meet the standards for removal under ourCommunity Standards, such as misinformation and clickbait. People often tell us that they don’t like seeing this kind of content and while we allow it to be posted on Facebook, we want to make sure it’s not broadly distributed.', 'Over the last two years, we’ve focused heavily onreducing misinformationon Facebook. We’re getting better at enforcing againstfake accounts and coordinated inauthentic behavior; we’re using both technology and people to fight the rise inphoto and video-based misinformation; we’ve deployed new measures to help peoplespot false newsand get morecontextabout the stories they see in News Feed; and we’ve grown our third-party fact-checking program to include 45 certified fact-checking partners who review content in 24 languages.', 'Today, members of the Facebook News Feed team discussed how we will be:', 'For more information about how we set goals for our “reduce” initiatives on Facebook,read this blog post.', 'Instagram', 'Today we discussed how Instagram is working to ensure that the content we recommend to people is both safe and appropriate for the community. We have begun reducing the spread of posts that are inappropriate but do not go againstInstagram’s Community Guidelines, limiting those types of posts from being recommended on our Explore and hashtag pages. For example, a sexually suggestive post will still appear in Feed if you follow the account that posts it, but this type of content may not appear for the broader community in Explore or hashtag pages.', '', 'Facebook', 'We’re investing in features and products that give people more information to help them decide what to read, trust and share. In the past year, we began offering more information on articles in News Feed with theContext Button, which shows the publisher’s Wikipedia entry, the website’s age, and where and how often the content has been shared. We helped Page owners improve their content with thePage Quality tab, which shows them which posts of theirs were removed for violating our Community Standards or were rated“False,” “Mixture” or “False Headline”by third-party fact-checkers. We also discussed how we will be:', 'Messenger', 'At today’s event, Messenger highlighted new and updated privacy and safety features that give people greater control of their experience and help people stay informed.', '']\n",
            "62 ['By Henry Silverman, Operations Specialist', 'Over the last two years, we’ve greatly expanded our efforts tofight false news: we’re getting better at enforcing againstfake accounts and coordinated inauthentic behavior; we’re using both technology and people to fight the rise inphoto and video-based misinformation; we’ve deployed new measures to help peoplespot false newsand get morecontextabout the stories they see in News Feed; and we’ve grown our third-party fact-checking program to include 45 certified fact-checking partners who review content in 24 languages. And overall, we’re making progress:multiple research studiessuggest that these efforts are working and that misinformation on Facebook has been reduced since the US presidential elections in 2016.', 'But misinformation is a complex and evolving problem, and we have much more work to do. With more than a billion things posted to Facebook each day, we need to find additional ways to expand our capacity. The work our professional fact-checking partners do is an important piece of our strategy. But there are scale challenges involved with this work. There simply aren’t enough professional fact-checkers worldwide, and like all good journalism, fact-checking — especially when it involves investigation of more nuanced or complex claims — takes time. We want to be able to tackle more false news, more quickly.', 'So today, we’re kicking off a new collaborative process with outside experts that will help us hone in on new solutions to fight false news at scale.The goal of this process is to arrive at externally vetted, consistent approaches that have the potential to help us catch and reduce the distribution of greater quantities of misinformation, more efficiently.', 'We know this won’t be easy. Whatever we do next, we need to find solutions that support original reporting, promote trusted information and allow for people to express themselves freely. So the question is, how do we come up with a model where we’re serving people by giving them a chance to see the content they want, while also cutting down on misinformation, without having Facebook be the judge of what is true? How do we ensure a system complementary to our existing fact-checking programs, so that professional journalists can spend their time doing original reporting on the hardest cases? How we can build such a system that can’t be gamed or manipulated by coordinated groups of people? How can we avoid introducing personal biases into these systems? And what additional safeguards do we need in place to protect civil rights and minority voices?', 'Those are some of the issues we’ll be exploring in the months to come.', 'A Collaborative Process', 'As we’ve worked to expand our misinformation efforts over the past two years, we’ve also been doing extensive research and talking to outside experts to identify additional approaches that might bolster our defenses. One promising idea we’ve beenexploringwould involve relying on groups of people who use Facebook to point to journalistic sources that can corroborate or contradict the claims made in potentially false content, as discussed in this video.', 'Facebook’s head of research for News Feed Integrity, Apala Sabde, and University of Michigan professor Paul Resnick, a consultant to Facebook’s misinformation team and one of the many experts we’re working with on this topic, discuss our early explorations into community-driven approaches to misinformation.', 'Over the next few months, we’re going to build on the explorations we’ve started around this idea, consulting a wide range of academics, fact-checking experts, journalists, survey researchers and civil society organizations to understand the benefits and risks of ideas like this. We’re going to share with experts the details of the methodology we’ve been thinking about, to help these experts get a sense of where the challenges and opportunities are, and how they’ll help us arrive at a new approach. We’ll also share updates from these conversations throughout the process, and find ways to solicit broader feedback from people around the world who may not be in the core group of experts attending these roundtable events.', 'Taking the fight against misinformation to the next level is an important task for us. There are elections around the world month after month, only adding to the everyday importance of minimizing false news. We plan to move quickly with this work, sharing some of the data and ideas we’ve collected so far with the experts we consult so that we can begin testing new approaches as soon as possible.']\n",
            "63 ['Since 2016, we have used a strategy called “remove, reduce, and inform” to manage problematic content on Facebook. This involvesremovingcontent that violates ourCommunity Standards,reducingthe spread of problematic content that does not violate our standards, andinformingpeople with additional information so they can choose what to click, read or share.', 'Our “reduce” work on Facebook is largely centered on News Feed andhow we rank posts within it.When developing new “reduce” initiatives, we think about our goals in terms of the needs of three parties: people, publishers, and our community.', 'Responding to People’s Direct FeedbackWe’re always listening to people’s feedback about what they do and don’t like seeing on Facebook and making changes to News Feed in response.', 'Incentivizing Publishers to Invest in High-Quality ContentWe recognize that getting broad distribution in News Feed influences what publishers produce, and ultimately, what our community sees. We want people to have interesting, new material to engage with in the long term, so we’re working to set incentives that encourage the creation of these types of content.', 'Fostering a Safe CommunityThere is some content that individual people might want to see, and that don’t necessarily create bad incentives for publishers, but we have decided are problematic for our community. We’ll make this content difficult to encounter for people who aren’t actively trying to see it.', 'As we deliver on these and other plans, we’ll continue to rely on our corevaluesto keep the central experience of News Feed intact as it evolves.', 'To learn more about our latest work across our strategic remove, reduce, inform areas, seethis recap of our April 2019 event.']\n",
            "64 ['By Mia Garlick, Director of Policy for Australia and New Zealand', 'At Facebook, we’re focused on protecting elections and making sure people have a voice in the political process. We’ve learned a lot from our work around the world over the past few years and have built a robust approach to safeguarding elections on Facebook. Our approach is multi-faceted and includes finding and removing fake accounts, reducing misinformation, disrupting bad actors and increasing ads transparency.', 'Today, we’re sharing more on our efforts to protect the upcoming Federal Election in Australia.', 'Restricting Foreign Electoral Ads', 'Combating foreign interference is a key pillar of our approach to safeguarding elections on our platform. As part of this commitment, we’re temporarily not allowing electoral ads purchased from outside Australia ahead of the election in May.', 'The restriction will take effect the day after the election is called and will apply to ads we determine to be coming from foreign entities that are of an electoral nature, meaning they contain references to politicians, parties or election suppression. We also won’t allow foreign ads that include political slogans and party logos.', 'Greater Transparency for All Ads', 'Last week, as part of our commitment to advertising transparency, we updated theAd Libraryto make it easier to learn about all ads on Facebook and the Pages that run them. The Ad Library now includes all active ads any Page is running, along with more Page information such as creation date, name changes, Page merges and the primary country of people who manage Pages with large audiences. This information was previously only visible on a Page in the ‘Info and Ads’ section, but is now available to everyone through the Ad Library, including people who aren’t on Facebook.', 'Shining a brighter light on advertising and Pages makes both Facebook and advertisers more accountable, which is good for people and good for democracy.', 'Expanding Third Party Fact Checking to Australia', 'In many countries, we work with independent third-party fact checkers who review stories, check their facts andrate their accuracy. In Australia, we’ll launch third-party fact-checking in partnership with the international news agency Agence France-Presse (AFP) so we can continue to improve the accuracy of information on Facebook.', 'The independent fact-checkers we work with arecertifiedthrough the non-partisan International Fact-Checking Network (IFCN). Today, we have 43 partners fact-checking content in 24 languages globally, and we’re investing in ways to scale these efforts further.(Update on June 13, 2019 at 5PM PT:AAP Fact Check has also joined our third-party fact-checking program to fact-check content in Australia.)', 'Once a story is rated as false, we show it lower in News Feed, reducing its future views by more than 80% on average.', 'Growing Our Capacity to Address Misinformation', 'We want to make sure people see accurate information about the upcoming election. That’s why we continue to improve the quality and authenticity of information on Facebook to fight false news. We do this in three main ways:', 'Taking Action on Fake Accounts', 'Fake accounts are often behind harmful and misleading content and we work hard to keep them off Facebook. We block millions of fake accounts at registration every day. We also constantly improve our technical systems to make it easier to respond to reports of abuse; detect and remove spam; identify and eliminate fake accounts; and prevent accounts from being compromised. And we’ve made improvements to recognize these inauthentic accounts more easily by identifying patterns of activity, without assessing account content.', 'Globally,we took action on more than 1.5 billion fake accountsbetween April and September 2018, either during the registration process or within minutes of the account being created. We found 99.6% of these accounts using technology before anyone reported them to us.', 'Increasing our Safety and Security Efforts', 'W’re committed to tackling all kinds of inauthentic behavior and abuse on our platform from misinformation, misrepresentation and foreign interference, to phishing, harassment and violent threats. We know that all of these tactics can intensify during elections, which is why we invest in a combination of expert resources and technology to find, disrupt and remove this behavior.', 'We now have more than 30,000 people working on safety and security across Facebook, three times as many as we had in 2017. We have also improved our machine learning capabilities around political content and inauthentic behavior, which lets us to better find and removing violating behavior. Globally, we have removed thousands of Pages, groups and accounts that engaged incoordinated inauthentic behavioracross our platforms, includingrecent takedowns in Australia. We’re committed to making improvements and building stronger partnerships around the world to more effectively detect and stop this activity. We’re also providing safety and security guidance to help protect candidates and party Pages from hacking and impersonation.', 'Through this work, we want to make it harder to interfere with elections on the platform, and easier for people to make their voices legitimately heard in the political process. We have dedicated global teams working around the clock on every upcoming election around the world, including the Federal Election in Australia. For more on our work to protect elections around the world in 2019, seehere.']\n",
            "65 ['By Nathaniel Gleicher, Head of Cybersecurity Policy', 'We have removed Pages, Groups and accounts for violating Facebook’s policies oncoordinated inauthentic behavioror spam. Today’s action includes four separate takedowns—each distinct and unconnected.', 'We have detailed each of these actions below.', 'Coordinated Inauthentic Behavior Enforcement', 'The operations we found to be engaged in coordinated inauthentic behavior were two distinct sets of activity in India and one network in Pakistan. We didn’t find any links between the campaigns we’ve removed today, but they used similar tactics by creating networks of accounts to mislead others about who they were and what they were doing.', 'We are constantly working to detect and stop coordinated inauthentic behavior because we don’t want our services to be used to manipulate people.We’re taking down these Pages and accounts based on their behavior, not the content they posted.In each case detailed below, the people behind this activity coordinated with one another and used fake accounts to misrepresent themselves, and that was the basis for our action.', 'While we are making progress rooting out this abuse, as we’ve said before, it’s an ongoing challenge and we’re committed to continuously improving to stay ahead. That means building better technology, hiring more people and working more closely with law enforcement, security experts and other companies.', 'In each case below, we identified violating accounts and Pages through ongoing internal investigations into coordinated inauthentic behavior in the region ahead of the upcoming elections in India. We have shared relevant information with policymakers and technology platforms.', 'Pakistan', 'Today weremoved 103 Pages, Groups and accounts for engaging in coordinated inauthentic behavior on Facebook and Instagram as part of a network that originated in Pakistan. The individuals behind this activity used fake accountsto operate military fan Pages; general Pakistani interest Pages; Kashmir community Pages; and hobby and news Pages. They also frequently posted about local and political news including topics like the Indian government, political leaders and military. Although the people behind this activity attempted to conceal their identities, our investigation found that it was linked to employees of the ISPR (Inter-Service Public Relations) of the Pakistani military.', 'Below is a sample of the content posted by some of these Pages:', '', 'India', 'Today we removed two separate and unrelated networks of Pages, Groups and accounts that engaged in coordinated inauthentic behavior on Facebook and Instagram in India. The first was linked to individuals associated with the INC IT Cell, and the second was connected to individuals associated with an Indian IT firm, Silver Touch. Here are some details.', 'We removed 687 Facebook Pages and accounts for engaging in coordinated inauthentic behavior in India.The individuals behind this activity used fake accounts, the majority of which had already been detected and suspended by our automated systems, and joined various Groups to disseminate their content and increase engagement on their own Pages. The Page admins and account owners typically posted about local news and political issues, including topics like the upcoming elections, candidate views, the INC and criticism of political opponents including the Bharatiya Janata Party (BJP). While the people behind this activity attempted to conceal their identities, our review found that it was connected to individuals associated with an INC IT Cell.', 'Below is a sample of the content posted by some of these Pages:', '', 'Separately, we removed 15 Pages, Groups and accounts for engaging in coordinated inauthentic behavior on Facebook and Instagram in India.A small number of Page admins and account owners used a combination of authentic and fake accounts to share their content across a variety of Pages. They posted about local news and political events, including topics like the Indian government, the upcoming elections, the BJP and alleged misconduct of political opponents including the INC. Although the people behind this activity attempted to conceal their identities, our investigation found that this activity was linked to individuals associated with an Indian IT firm, Silver Touch.', 'Below is a sample of the content posted by some of these Pages:', 'Removing Additional Pages and Accounts that Violate our Spam and Misrepresentation Policies in India', 'We also removed 227 Pages and 94 accounts in India for violating our policies against spam and misrepresentation.These policies, outlined inFacebook’s Community Standards, are designed to help make sure people can trust the connections they make on Facebook and are not misled about the content they are seeing. These Pages and accounts were engaging in behaviors that expressly violate our policies. This included using fake accounts or multiple accounts with the same names; impersonating someone else; posting links to malware; and posting massive amounts of content across a network of Groups and Pages in order to drive traffic to websites they are affiliated with in order to make money. Unlike the takedowns for coordinated inauthentic behavior, this activity was not part of one coordinated operation.', 'We routinely remove accounts and Pages that engage in this type of harmful, often financially-motivated, behavior — like ads for fraudulent products or fake weight loss “remedies.” The people behind this behavior create Pages using fake accounts or multiple accounts with the same names. They post clickbait posts on these Pages to drive people to websites that are entirely separate from Facebook and seem legitimate, but are actually ad farms. The people behind the activity also post the same clickbait posts in dozens of Facebook Groups, often hundreds of times in a short period, to drum up traffic for their websites. And they often use their fake accounts to generate fake likes and shares. This artificially inflates engagement for their inauthentic Pages and the posts they share, misleading people about their popularity and improving their ranking in News Feed.', 'This activity goes against what people expect on Facebook and it violates our policies. This is why we continue to invest in people and resources to improve the technology we use to detect this type of harmful behavior, and we will continue to take action on an ongoing basis to address it.']\n",
            "66 ['ByMonika Bickert, VP, Global Policy Management', 'Update on September 4, 2019 at 8AM PT:We are starting to roll out more ways to connect people with authoritative information about vaccines on Facebook and Instagram.', '', 'Originally published on March 7, 2019 at 12PM PT:', 'We are working to tackle vaccine misinformation on Facebook by reducing its distribution and providing people with authoritative information on the topic. We are starting by taking a series of steps:', 'How This Will Work', 'Leading global health organizations, such as the World Health Organization and the US Centers for Disease Control and Prevention, have publicly identified verifiable vaccine hoaxes. If these vaccine hoaxes appear on Facebook, we will take action against them.', 'For example, if a group or Page admin posts this vaccine misinformation, we will exclude the entire group or Page from recommendations, reduce these groups and Pages’ distribution in News Feed and Search, and reject ads with this misinformation.', 'We also believe in providing people with additional context so they can decide whether to read, share, or engage in conversations about information they see on Facebook. We are exploring ways to give people more accurate information from expert organizations about vaccines at the top of results for related searches, on Pages discussing the topic, and on invitations to join groups about the topic. We will have an update on this soon.', 'We are fully committed to the safety of our community and will continue to expand on this work.']\n",
            "67 ['By Katie Harbath, Public Policy Director, Global Elections and Ruben Hattari, Head of Public Policy, Indonesia', 'At Facebook, we’re focused on protecting elections while also making sure people have a voice in the political process. Over the last two years, we’ve learned from elections around the world to create a robust approach to safeguard our platform. This includes removing fake accounts, reducing false news, disrupting bad actors and increasing ads transparency. And we’re doing this while also\\xa0supporting an informed and engaged electorate.', 'Today, we’re sharing more details on how we will protect the Indonesian elections in April.', 'Restricting Foreign Electoral Ads', 'Combating foreign interference is a key pillar of our approach to safeguarding election integrity on our platform. As part of this commitment, we’re temporarily disallowing electoral ads purchased from outside Indonesia ahead of the election. The restriction took effect this morning and will apply to any ad coming from an advertiser based outside of the country, if it references politicians or political parties or attempts to encourage or suppress voting.', 'We are using a mix of automated and human review to help us identify foreign electoral ads that should no longer be running on our platform.', 'Greater Transparency for All Ads', 'As part of our commitment to support an informed electorate, we’ve taken steps to provide more information about any ad a Page is running in the Page’s“Info and Ads” section. This includes electoral ads. People can also report an ad by tapping the three dots in the top right corner and selecting “Report Ad.” This section also offers more information about a Page, like when it was created and its previous names. This gives people a better understanding of the Page’s original purpose.', 'We’re also rolling outa set of global political advertising tools by the end of June.With each election, we’re learning which tools are most useful, so we can bring them to more countries, faster.', 'More Resources for Rapid Response', 'We are committed to tackling all kinds of inauthentic behavior and abuse on our platform — which we know often intensify during elections — from misinformation, misrepresentation and foreign interference, to phishing, harassment and violent threats. Our security team is working around the clock to help us stay a step ahead and uncover abuse. Globally, we’ve removed thousands of Pages, groups and accounts that engaged incoordinated inauthentic behavioracross our platforms. We are committed to making improvements and building stronger partnerships around the world to more effectively detect and stop this activity.', 'We’re also setting up an operations center in Singapore focused on election integrity ahead of key elections across Asia-Pacific. The center will be staffed by experts from Facebook, Instagram and WhatsApp, who will work cross-functionally with our threat intelligence, data science, engineering, research, community operations, legal and other teams. This center will work with our Menlo Park headquarters and in-country experts to serve as another line of defense against false news and misinformation, hate speech, voter suppression and election interference.', 'Our teams also work closely with lawmakers, election commissions, fact-checkers, researchers, academics and civil society groups to better integrate efforts on important issues related to election integrity.', 'Growing Our Capacity to Address Misinformation and False News', 'We also want to make sure people see accurate information about the upcoming election and the choices they’ll be making at the ballot box. That’s why we’ve taken steps — in Indonesia and around the world — to improve the quality and authenticity of information on our platform and fight false news. We do this in three main ways:', 'First, we remove content that violates ourCommunity Standards, which help enforce the safety and security of the platform. Then, for content that does not directly break our rules, but still undermines the authenticity of the platform — like clickbait or sensational material — wereduce its distributionin News Feed so less people see it. Finally, we inform people by giving them more context on the information they see. For instance, when someone comes across a story, they can tap on “About this article” to see more details on the article and the publisher.', 'We also want to empower people to decide for themselves what to read, trust and share. In Indonesia, we’re conducting the Think Before You Share school program in partnership with YCAB Foundation and Do Something Indonesia. Our goal is to educate more than 30,000 students, teachers and parents in seven provinces about critical thinking skills in the online world.', 'And through our Laju Digital program in East Indonesia, we’re training local government officials and community members in key digital skills.', 'Increasing our Safety and Security Efforts', 'We now have more than 30,000 people working on safety and security across the company, three times as many as we had in 2017. We have also improved our machine learning capabilities, which allows us to be more efficient and effective in finding and removing violating behavior. These improvements have helped in many ways, especially in our work to fightcoordinated inauthentic behavior,where we’ve used a mix of technology and our expert investigators to search for and take down more sophisticated networks.', 'While these efforts are global, we also customize our work to individual countries based on research and threat assessments that begin many months before ballots are cast. This means we have safety and security teams working to identify and disrupt any information operations we find, including in Indonesia. We’re also providing safety and security guidance to help protect candidates and party Pages from hacking and impersonation. Like we do for all elections, we will be proactively monitoring for impersonation or hacked accounts.', 'We want to make it harder to interfere with elections on the platform, and easier for people to make their voices legitimately heard in the political process. We have dedicated teams working on every upcoming election around the world, including Indonesia. For more on our work to protect elections around the world in 2019, seehere.']\n",
            "68 ['ByKatie Harbath, Global Politics and Government Outreach Director andRoy Tan, APAC Politics and Government Outreach Manager', 'Protecting the integrity of elections while making sure people can have a voice in the political process is a top priority for Facebook. Learning from every election over the last two years, we have increased our capabilities to take down fake accounts, reduce false news, disrupt bad actors, support an informed and engaged electorate, and increase ads transparency.', 'Today, we are sharing more details on how we will protect the Thai elections in March.', 'Greater Transparency for All Ads', 'People can already see any ad a Page is currently running today in its‘Info and Ads’ section— regardless of the nature of the ad, including those of an electoral nature. There, people can report an ad by tapping three dots in the top right corner and selecting “Report Ad.” This section also offers more information about a Page, like when it was created and its previous names. This helps people better understand the purpose for which the Page was originally created.', 'Restricting Foreign Electoral Ads', 'As part of our commitment to safeguard the integrity of elections, we will be temporarily expanding enforcement to not allow foreign electoral ads in Thailand in the lead up to the elections. This restriction is expected to take effect mid-February and will apply to electoral ads if they are being run by advertisers based outside of Thailand.', 'This change will apply to ads we determine to be coming from foreign entities which are of an electoral nature, meaning they contain references to politicians, parties, ‘getting out the vote,’ and/or election suppression. They also include political slogans and party logos.', 'We will be using a mix of automated and human review to help us identify ads that should no longer be running. We are also rolling outa set of global political advertising tools by the end of June.With each election, we’re learning which tools are most useful, so that we can bring them to more countries, faster.', 'These efforts help hold advertisers and us more accountable.', 'More Resources for Rapid Response', 'Our security team is working around the clock to help us stay a step ahead and uncover platform abuse. Globally, we have removed thousands of Pages, groups and accounts that engaged incoordinated inauthentic behavioracross our platforms. We are committed to making improvements and building stronger partnerships around the world to more effectively detect and stop this activity.', 'Building on the work of the last few months and to better coordinate the work in the final weeks before elections in Asia-Pacific, including Thailand, we are planning to set up new regional operations centers, focused on election integrity, including one in Singapore. This will further strengthen our coordination and rapid response capabilities, and allow our global teams to better work across regions. Working together with our teams in our Menlo Park headquarters and across the region, the new initiative will serve as an added layer of defense against false news and misinformation, hate speech, voter suppression and election interference.', 'This effort will house experts from Facebook, Instagram and WhatsApp, and will work cross-functionally with our threat intelligence, data science, engineering, research, community operations, legal and other teams.', 'It will also work closely with lawmakers, election commissions, fact-checkers, researchers, academics and civil society groups to continue the fight against fake news and misinformation; help prevent the spread of voter suppression efforts; and further integrate the large number of teams working on these important issues.', 'Growing Our Capacity to Address Misinformation and False News', 'Our work to fight fake news continues to improve. Across News Feed, we follow a three-part framework to improve the quality and authenticity of stories. First, we remove content that violates ourCommunity Standards, which help enforce the safety and security of the platform. Then, for content that does not directly violate our Community Standards, but still undermines the authenticity of the platform — like clickbait or sensational material — wereduce its distributionin News Feed, so less people see it. Finally, we inform people by giving them more context on the information they see in News Feed. For example, when someone comes across a story, they can tap on ‘About this article’to see more details on the article and the publisher.', 'We also want to empower people to decide for themselves what to read, trust, and share, and we do this by promotingnews literacyand providing people with more context. In Thailand, we are rolling out aTips to Spot False Newsadvertorial in partnership with local organizations such as Sure And Share Center of the Thai News Agency and Chulalongkorn University.', 'We are also committed to supporting Thailand’s news industry, especially during the elections period. We recently held training sessions for news publishers in Thailand to share best practices for newsrooms, including elections coverage, and training on tools such as CrowdTangle to help with their elections reporting.', 'Increasing our Safety and Security Efforts', 'We now have more than 30,000 people working on safety and security across the company, three times as many as we had in 2017. We have also improved our machine learning capabilities, which allows us to be more efficient and effective in finding and removing violating behavior. These improvements have helped in many ways, including our work to fightcoordinated inauthentic behavior,where we’ve used a mix of technology and our expert investigators to search for and take down more sophisticated networks. While these efforts are global, we also customize our work to individual countries based on research and threat assessments that begin many months before ballots are cast. This means we have safety and security teams working to identify and disrupt any Information Operations we find, including in Thailand. We’re also providing safety and security guidance to help protect candidates and party Pages from hacking and impersonation. Like we do for all elections, we will be proactively monitoring for any impersonation or hacked accounts.', 'Through these actions, we want to make it harder to interfere with elections on the platform, and easier for people to make their voices legitimately heard in the political process. We have dedicated teams working on every upcoming election around the world, including Thailand.\\xa0We are committed to tackling all kinds of inauthentic behavior and abuse on our platform – which we know often intensify during elections – from misinformation, misrepresentation and foreign interference, to phishing, harassment and violent threats. For more on our work to protect elections around the world in 2019, seehere.']\n",
            "69 ['ByKatie Harbath, Global Politics and Government Outreach Director andSamidh Chakrabarti, Director of Product Management, Civic Engagement', 'Over the past two years, we have made massive investments to help protect the integrity of elections — not only addressing threats we’ve seen on our platform in the past, but also anticipating new challenges and responding to new risks.', 'Our approach to this problem — like the problem itself — is multifaceted. Our tactics includeblocking and removing fake accounts; finding andremoving bad actors;limiting the spread of false news and misinformation; and bringing unprecedentedtransparency to political advertising. To support this work, we now have more than 30,000 people working on safety and security across the company, three times as many as we had in 2017. We have also improved our machine learning capabilities, which allows us to be more efficient and effective in finding and removing violating behavior. These improvements have helped in many ways, including our work to fightcoordinated inauthentic behavior. For example, technology advancements have allowed us to better identify and block bad activity, while our expert investigators manually search for and take down more sophisticated networks.', 'We do all of this whileworking closelywith law enforcement, regulators, election commissions, other technology companies, researchers, academics and civil society groups. While these efforts are global, we also customize our work to individual countries based on research and threat assessments that begin many months before ballots are cast.', 'Here are some of the additional ways we are working to strengthen our platform ahead of elections in 2019.', 'Expanding Our Political Advertising Transparency Policies', 'Earlier this month in Nigeria, we began temporarily disallowing electoral ads purchased from outside the country ahead of the election and will implement the same policy in Ukraine ahead of their election. In advance of the European Parliament election, in late March we will launch additional tools in the EU to help prevent foreign interference and make political and issue advertising on Facebook more transparent. Advertisers will need to be authorized to purchase political ads; we’ll give people more information about ads related to politics and issues; and we’ll create a publicly searchable library of these ads for up to seven years. The library will include information on the range of the ads’ budget, number of people they reached and demographics of who saw the ad, including age, gender and location. These transparency tools for electoral ads will also launch in India in February and in Ukraine and Israel before their elections, with a global expansion before the end of June.', 'More Resources for Rapid Response for Elections in Europe and Asia', 'To expand on work we did to fight misinformation in advance of the Brazil presidential election and the US midterms, we are planning to set up two new regional operations centers, focused on election integrity, located in our Dublin and Singapore offices. This will allow our global teams to better work across regions in the run-up to elections, and will further strengthen our coordination and response time between staff in Menlo Park and in-country. These teams will add a layer of defense against fake news, hate speech and voter suppression, and will work cross-functionally with our threat intelligence, data science, engineering, research, community operations, legal and other teams.', 'Growing Our Capacity to Address Misinformation and False News', 'Our work to fight fake news continues to improve. Across News Feed, we follow a three-part framework to improve the quality and authenticity of stories. First, we remove content that violates ourCommunity Standards, which help enforce the safety and security of the platform. Then, for content that does not directly violate our Community Standards, but still undermines the authenticity of the platform — like clickbait or sensational material — wereduce its distributionin News Feed, so less people see it. Finally, we inform people by giving them more context on the information they see in News Feed. For example, when someone comes across a story, they can tap on “About this article” to see more details on the article and the publisher.', 'We also continue to expand our third-party fact-checking program. Today, this program covers content in 16 languages, and we’ve rolled out the ability for fact-checkers to review photos and videos in addition to article links, because we know multimedia-based misinformation is making up a greater share of false news. When a fact-checker rates a post as false, we show it lower in News Feed to significantly reduce the number of people who see it and the likelihood it will spread further. Pages and domains that repeatedly share false news will be penalized with reduced distribution and they will not be able to monetize or advertise on Facebook. This helps curb the spread of financially-motivated false news.', 'While these efforts represent an improvement over the past few years, we know that improving security is never finished. There have always been people trying to undermine democracy. We are up against determined adversaries who try to attack on many fronts and we recognize our role and responsibility. We will never stop all the bad actors, but we’re making real progress and we are committed to continuing to improve.', 'For more on our work ahead of the\\xa0European Parliament Elections in May, seehere.']\n",
            "70 ['ByMark Zuckerberg, Founder, Chairman and Chief Executive Officer', 'Facebook\\xa0turns 15 next month. When I started Facebook, I wasn’t trying to build a global company. I realized you could find almost anything on the internet—music, books, information—except the thing that matters most: people. So I built a service people could use to connect and learn about each other. Over the years, billions have found this useful, and we’ve built more services that people around the world love and use every day.', 'Recently I’ve heard many questions about our business model, so I want to explain the principles of how we operate.', 'I believe everyone should have a voice and be able to connect. If we’re committed to serving everyone, then we need a service that is affordable to everyone. The best way to do that is to offer services for free, which ads enable us to do.', 'People consistently tell us that if they’re going to see ads, they want them to be relevant. That means we need to understand their interests. So based on what pages people like, what they click on, and other signals, we create categories—for example, people who like pages about gardening and live in Spain—and then charge advertisers to show ads to that category. Although advertising to specific groups existed well before the internet, online advertising allows much more precise targeting and therefore more-relevant ads.', 'The internet also allows far greater transparency and control over what ads you see than TV, radio or print. On Facebook, you have control over what information we use to show you ads, and you can block any advertiser from reaching you. You can find out why you’re seeing an ad and change your preferences to get ads you’re interested in. And you can use our transparency tools to see every different ad an advertiser is showing to anyone else.', 'Still, some are concerned about the complexity of this model. In an ordinary transaction, you pay a company for a product or service they provide. Here you get our services for free—and we work separately with advertisers to show you relevant ads. This model can feel opaque, and we’re all distrustful of systems we don’t understand.', 'Sometimes this means people assume we do things that we don’t do. For example, we don’t sell people’s data, even though it’s often reported that we do. In fact, selling people’s information to advertisers would be counter to our business interests, because it would reduce the unique value of our service to advertisers. We have a strong incentive to protect people’s information from being accessed by anyone else.', 'Some worry that ads create a misalignment of interests between us and people who use our services. I’m often asked if we have an incentive to increase engagement on Facebook because that creates more advertising real estate, even if it’s not in people’s best interests.', 'We’re very focused on helping people share and connect more, because the purpose of our service is to help people stay in touch with family, friends and communities. But from a business perspective, it’s important that their time is well spent, or they won’t use our services as much over the long term. Clickbait and other junk may drive engagement in the near term, but it would be foolish for us to show this intentionally, because it’s not what people want.', 'Another question is whether we leave harmful or divisive content up because it drives engagement. We don’t. People consistently tell us they don’t want to see this content. Advertisers don’t want their brands anywhere near it. The only reason bad content remains is because the people and artificial-intelligence systems we use to review it are not perfect—not because we have an incentive to ignore it. Our systems are still evolving and improving.', 'Finally, there’s the important question of whether the advertising model encourages companies like ours to use and store more information than we otherwise would.', 'There’s no question that we collect some information for ads—but that information is generally important for security and operating our services as well. For example, companies often put code in their apps and websites so when a person checks out an item, they later send a reminder to complete the purchase. But this type of signal can also be important for detecting fraud or fake accounts.', 'We give people complete control over whether we use this information for ads, but we don’t let them control how we use it for security or operating our services. And when we asked people for permission to use this information to improve their ads as part of our compliance with the European Union’s General Data Protection Regulation, the vast majority agreed because they prefer more relevant ads.', 'Ultimately, I believe the most important principles around data are transparency, choice and control. We need to be clear about the ways we’re using information, and people need to have clear choices about how their information is used. We believe regulation that codifies these principles across the internet would be good for everyone.', 'It’s important to get this right, because there are clear benefits to this business model. Billions of people get a free service to stay connected to those they care about and to express themselves. And small businesses—which create most of the jobs and economic growth around the world—get access to tools that help them thrive. There are more than 90 million small businesses on Facebook, and they make up a large part of our business. Most couldn’t afford to buy TV ads or billboards, but now they have access to tools that only big companies could use before. In a global survey, half the businesses on Facebook say they’ve hired more people since they joined. They’re using our services to create millions of jobs.', 'For us, technology has always been about putting power in the hands of as many people as possible. If you believe in a world where everyone gets an opportunity to use their voice and an equal chance to be heard, where anyone can start a business from scratch, then it’s important to build technology that serves everyone. That’s the world we’re building for every day, and our business model makes it possible.']\n",
            "71 ['We’re taking new steps in how we handle Page content that goes against our policies. First, starting tomorrow people who manage a Page will see a new tab that shows when we remove certain content that goes against our Community Standards and when we reduce the distribution of posts that have been rated false by a third-party fact-checker.', 'Second, we are updating our recidivism policy to better prevent those who have had Pages removed for violating our Community Standards from using duplicate Pages to continue the same activity. We’ll begin enforcing this policy in the weeks ahead.', 'Page Quality', 'The new Page Quality tab is designed to help people who manage Pages understand how well their Pages comply with our guidelines. The tab includes two sections:', '1. Content we recently removed for violating a subset of our Community Standards and;2. Content recently rated“False,” “Mixture” or “False Headline”by third-party fact-checkers.', '', 'We’ll be providing more information in the Page Quality tab over time. To start, we’re including content removed for policies likehate speech,graphic violence,harassmentandbullying, andregulated goods,nudity or sexual activity, andsupport or praiseof people and events that are not allowed to be on Facebook. While this tab provides greater insight into content that was removed or demoted, it is not a comprehensive accounting of all policy violations. For example, we won’t be showing content removals at this time for things like spam, clickbait, or IP violations.', 'We hope this will give people the information they need to police bad behavior from fellow Page managers, better understand our Community Standards, and, let us know if we’ve made an incorrect decision on content they posted.', 'Updates to Our Recidivism Policy', 'We’ve long prohibited people from creatingnewPages, groups, events, or accounts that look similar to those we’ve previously removed for violating our Community Standards. However, we’ve seen people working to get around our enforcement by usingexistingPages that they already manage for the same purpose as the Page we removed for violating our standards.', 'To address this gap, when we remove a Page or group for violating our policies, we may now also remove other Pages and Groups even if that specific Page or Group has not met the threshold to be unpublished on its own. To enforce this updated policy, we’ll look at a broad set of information, including whether the Page has the same people administering it, or has a similar name, to one we’re removing.']\n",
            "72 ['ByMeredith Carden,Head of News Integrity Partnerships', 'Today The Guardian published a story about ourthird-party fact-checking program. We’d like to provide a response, as the piece presents several inaccuracies, and is based primarily on the account of a single fact-checker who hasn’t been involved with the Facebook fact-checking program for six months. We provided information to The Guardian, but they chose not to include all of it.', 'We have been committed to fighting misinformation for years now and have strong relationships with our third-party fact-checking partners — we now have 35 partners in 24 countries around the world. We value our ongoing partnerships and the work that these journalists do, and we’re planning to expand the program to even more countries in 2019.', 'Ensuring Process Integrity and Avoiding Conflicts of Interest', 'Contrary to a claim in the story, we absolutely do not ask fact-checkers to prioritize debunking content about our advertisers.', 'In reality, here’s how fact-checking works: the primary way we surface potentially false news to third-party fact-checkers is viamachine learning, which relies on a number of signals likefeedbackfrom people who use Facebook and the number of comments expressing disbelief (e.g., “No way this is real!”). Fact-checkers then go through a list of this potentially false content and choose for themselves what to fact-check — they are under no obligation to fact-check anything from the list, and if they’d like, they can rate stories that Facebook hasn’t added to the list (which they often do). As soon as something is rated “false,” it is automatically de-prioritized in News Feed, and where it does appear, we’ll showRelated Articlesincluding the fact-checker’s article below it. These processes are automated.', 'Efficacy of Fact-Checking', 'Fact-checking is highly effective in fighting misinformation: when something is rated “false” by a fact-checker, we’re able to reduce future impressions of that content by an average of 80%. We also leverage these ratings to take action on Pages and websites that repeatedly share misinformation. We de-prioritizeallcontent from actors who repeatedly get “false” ratings on content they share, and we remove their advertising and monetization rights.', 'Three new separate pieces of researchhave all found that the overall volume of false news on Facebook is decreasing since we put our third-party fact-checking program and other anti-misinformation measures in place. We’re also providing independent researchers atSocial Science Onewith a privacy-protected data set that will help them study the effects of misinformation on social media and elections. This research may help us better measure volumes of false news — and our progress against it — over time.', 'We have heard feedback from our partners that they’d like more data on the impact of their efforts, so we’re starting to send fact-checkers quarterly reports that include customized statistics that reflect the work and impact of each fact-checker.', 'Safety of Journalists and Fact-Checking Partners', 'We take the safety of journalists seriously. Through theFacebook Journalism Project, we provide online safety resources, including information on how to turn on two-factor authentication, manage privacy settings, block harassment, control location sharing, report abusive content and impersonation, and more. OurCommunity Standardson credible violence aim to protect journalists and other vulnerable people or groups. We remove content, disable accounts, and work with local authorities when we become aware of content that we believe poses a genuine risk of physical harm or direct threats to safety.', 'Fact-Checking Ratings', 'We share specific rating guidelines with our third-party partners, and we make thesepublicly availableso publishers and others have insight into our program. We’ve also started to provide safety training as part of onboarding our new partners, and we’re working to expand this to our existing partners as well.', 'Misinformation is an ever-evolving problem that we’re committed to fighting globally, and the work that third-party fact-checkers do to help review content on Facebook is a valued and important piece of this effort.']\n",
            "73 ['Authenticity is a core value at Facebook. It’s why we ask that people use their real name and why we prohibit fake accounts and other tactics bad actors use to misrepresent their identity. Today, as part of our ongoing efforts to protect our community from this type of abuse, Facebook removed 68 Pages and 43 accounts associated with a Brazilian marketing group, Raposo Fernandes Associados (RFA), for violating our misrepresentation and spam policies.', 'The people behind RFA created Pages using fake accounts or multiple accounts with the same names, which violates our Community Standards. They then used those Pages to post massive amounts of clickbait intended to direct people to websites that are entirely separate from Facebook and appear legitimate, but are actually ad farms. Our decision to remove these Pages was based on the behavior of these actors – including using fake accounts and repeatedly posting spam – rather than on the type of content they were posting. This behavior was detected on Facebook but, as yet, we have not found similar misuse on Instagram or WhatsApp.', 'While spam commonly involves the offer of fraudulent products or services, we have seen spammers increasingly using sensational political content — across the political spectrum — to build an audience and drive traffic to their websites, earning money for every visitor to the site. The RFA assets we removed were engaging in this type of elicit behavior.', 'We are continuously working to uncover this kind of abuse, and we know that the people behind it — whether economically or politically motivated — are becoming increasingly more sophisticated in their tactics. Today’s announcement of the removal of these Pages is just one of the many steps we have taken to prevent bad actors from interfering with Brazil’s elections on Facebook. We will continue to invest heavily in safety and security in order to keep bad actors off of our platform and ensure that people can continue to trust the connections they make on Facebook.', 'Sample Pages', '']\n",
            "74 ['ByNathaniel Gleicher, Head of Cybersecurity Policy andOscar Rodriguez, Product Manager', 'People need to be able to trust the connections they make on Facebook. It’s why we have a policy banningcoordinated inauthentic behavior— networks of accounts or Pages working to mislead others about who they are, and what they are doing. This year, we’ve enforced this policy against many Pages, Groups and accounts created to stir up political debate, including in the US, the Middle East, Russia and the UK. But the bulk of the inauthentic activity we see on Facebook is spam that’s typically motivated by money, not politics. And the people behind it are adapting their behavior as our enforcement improves.', 'One common type of spam has been posts that hawk fraudulent products like fake sunglasses or weight loss “remedies.” But a lot of the spam we see today is different. The people behind it create networks of Pages using fake accounts or multiple accounts with the same names. They post clickbait posts on these Pages to drive people to websites that are entirely separate from Facebook and seem legitimate, but are actually ad farms. The people behind the activity also post the same clickbait posts in dozens of Facebook Groups, often hundreds of times in a short period, to drum up traffic for their websites. And they often use their fake accounts to generate fake likes and shares. This artificially inflates engagement for their inauthentic Pages and the posts they share, misleading people about their popularity and improving their ranking in News Feed. This activity goes against what people expect on Facebook, and it violates our policies against spam.', 'Topics like natural disasters or celebrity gossip have been popular ways to generate clickbait. But today, these networks increasingly use sensational political content – regardless of its political slant – to build an audience and drive traffic to their websites, earning money for every visitor to the site. And like the politically motivated activity we’ve seen, the “news” stories or opinions these accounts and Pages share are often indistinguishable from legitimate political debate. This is why it’s so important we look at these actors’behavior– such as whether they’re using fake accounts or repeatedly posting spam – rather than theircontentwhen deciding which of these accounts, Pages or Groups to remove.', 'Today, we’re removing 559 Pages and 251 accounts that have consistently broken our rules against spam and coordinated inauthentic behavior. Given the activity we’ve seen — and its timing ahead of the US midterm elections — we wanted to give some details about the types of behavior that led to this action. Many were using fake accounts or multiple accounts with the same names and posted massive amounts of content across a network of Groups and Pages to drive traffic to their websites. Many used the same techniques to make their content appear more popular on Facebook than it really was. Others were ad farms using Facebook to mislead people into thinking that they were forums for legitimate political debate.', 'Of course, there are legitimate reasons that accounts and Pages coordinate with each other — it’s the bedrock of fundraising campaigns and grassroots organizations. But the difference is that these groups are upfront about who they are, and what they’re up to. As we get better at uncovering this kind of abuse, the people behind it — whether economically or politically motivated — will change their tactics to evade detection. It’s why we continue to invest heavily, including in better technology, to prevent this kind of misuse. Because people will only share on Facebook if they feel safe and trust the connections they make here.']\n",
            "75 ['By Antonia Woodford, Product Manager', 'We know that people want to see accurate information on Facebook, so for the last two years, we’ve made fighting misinformation a priority. One of themany stepswe take to reduce the spread of false news is working with independent, third-partyfact-checkersto review andrate the accuracyof content. To date, most of our fact-checking partners have focused on reviewing articles. However, we have also been actively working to build new technology and partnerships so that we can tackle other forms of misinformation. Today, we’reexpanding fact-checking for photos and videos to all of our27 partnersin 17 countries around the world(and are regularly on-boarding new fact-checking partners). This will help us identify and take action against more types of misinformation, faster.', 'How does this work?Similar to our work for articles, we have built a machine learning model that uses various engagement signals, including feedback from people on Facebook, to identify potentially false content. We then send those photos and videos to fact-checkers for their review, or fact-checkers can surface content on their own. Many of our third-party fact-checking partners have expertise evaluating photos and videos and are trained in visual verification techniques, such as reverse image searching and analyzing image metadata, like when and where the photo or video was taken. Fact-checkers are able to assess the truth or falsity of a photo or video by combining these skills with other journalistic practices, like using research from experts, academics or government agencies.', 'As we get more ratings from fact-checkers on photos and videos, we will be able to improve the accuracy of our machine learning model. We are also leveraging other technologies to better recognize false or misleading content. For example, we useoptical character recognition(OCR) to extract text from photos and compare that text to headlines from fact-checkers’ articles. We are also working on new ways to detect if a photo or video has been manipulated. These technologies will help us identify more potentially deceptive photos and videos to send to fact-checkers for manual review. Learn more about how we approach this work inan interviewwith Tessa Lyons, Product Manager on News Feed.', 'How do we categorize false photos and videos?Based on several months of research and testing with a handful of partners sinceMarch, we know that misinformation in photos and videos usually falls into three categories: (1) Manipulated or Fabricated, (2) Out of Context, and (3) Text or Audio Claim. These are the kinds of false photos and videos that we see on Facebook and hope to further reduce with the expansion of photo and video fact-checking.', '', '(See more details on these examples from the fact-checkers’ debunking articles:Animal Politico,AFP,France 24, andBoom Live).', 'What’s different about photos and videos?People share millions of photos and videos on Facebook every day. We know that this kind of sharing is particularly compelling because it’s visual. That said, it also creates an easy opportunity for manipulation by bad actors. Based on research with people around the world, we know that false news spreads in many different forms, varying from country to country. For example, in the US, people say they see more misinformation in articles, whereas in Indonesia, people say they see more misleading photos. However, these categories are not distinct. The same hoax can travel across different content types, so it’s important to build defenses against misinformation across articles, as well as photos and videos.', '', 'What’s next?We know that fighting false news is a long-term commitment as the tactics used by bad actors are always changing. As we take action in the short-term, we’re also continuing to invest in more technology and partnerships so that we can stay ahead of new types of misinformation in the future. Learn more about our fight against misinformation inFacing Facts.']\n",
            "76 ['Hard Questions isa seriesfrom Facebook that addresses the impact of our products on society.', 'By Tessa Lyons, Product Manager', 'False news is a money maker for spammers and a weapon of state actors and agitators around the world. This has introduced important questions for society and new responsibilities for companies like Facebook.', 'Misinformation is bad for our community and bad for our business. It’s why we’re investing significant time and resources to fight it. As Iexplained in my last post, there are three main ways we’re doing this:', 'One part of our strategy that we get asked about a lot is our partnership with third-party fact-checking organizations. They help us identify false stories so we can stop them from spreading on Facebook. Overall, we’re making progress and have learned a lot. This year we expanded to more countries and started having fact-checkers review photos and videos, not just links. We’re also looking for more ways to be transparent about these efforts and to have independent researchersmeasureour results.', 'This program is just one part of our strategy, and we won’t be able to address this problem with human fact-checkers alone. Still, I wanted to share more on our work and the challenges ahead.', 'How Third-Party Fact-Checking WorksWe started the third-party fact-checking program inDecember 2016. Now we have25 partners in 14 countries, many with recent or upcoming elections. Our partners are independent andcertifiedthrough the non-partisan International Fact-Checking Network. When fact-checkers rate an article as false, we show it lower in News Feed — reducing future views by over 80% on average.', 'Here’s how it works:', 'The Limits of Fact-CheckingOver the last 18 months we’ve made good progress, but we’re also aware of the limits of this program. Fact-checkers don’t exist in all countries, and different places have different standards of journalism as well as varying levels of press freedom. Even where fact-checking organizations do exist, there aren’t enough to review all potentially false claims online. It can take hours or even days to review a single claim. And most false claims aren’t limited to one article — they spread to other sites. To make real progress, we have to keep improving our machine learning and trying other tactics that can work around the world.', 'There are other challenges, too, such as how to treat opinion and satire. We strongly believe that people should be able to debate different ideas, even controversial ones. We also recognize there can be a fine line between misinformation and satire or opinion. For example, sometimes people try to call their sites “satire” as cover for their true motivation — to spread fake stories. This can make it more difficult for fact-checkers to assess whether an article should be rated “false” or left alone.', '', 'Another question is what to do when publishers want to challenge a decision — especially after their article has already reached a lot of people. We allow publishers to contact fact-checkers to dispute their rating or offer a correction in order to restore their distribution in News Feed. If a fact-checker accepts the correction or changes their rating, we’ll remove the strike against a publisher. Our goal here is to prevent bad actors from exploiting loopholes without unduly punishing reputable publications that sometimes make mistakes.', 'And ultimately, it’s important that people trust the fact-checkers making these calls. While we work with the International Fact-Checking Network to approve all our partners and make sure they have high standards of accuracy, fairness and transparency, we continue to face accusations of bias. Which has left people asking, in today’s world, is it possible to have a set of fact-checkers that are widely recognized as objective? We’ve also made somechangesto how we let people know that a story is disputed so that they can learn more and come to their own conclusions.', 'It’s clear that even as we continue to improve this program, we need solutions beyond fact-checkers. That’s why we’re also working on removing fake accounts, which are often responsible for misinformation. And as we make it harder for fake stories to spread and we prevent malicious sites and Pages from using our tools to make money, we will break the business models that incentivize bad actors to share it. We also continue to invest in news literacy programs to help people better judge the publishers and articles they see on Facebook. It’s through the combination of all these things — and by collaborating with other companies and organizations — that we’ll be able to continue to make progress on false news.']\n",
            "77 ['ByJohn Hegeman, Head of News Feed', 'Over the last couple of years, we have been working hard to reduce the spread of false news on Facebook through a combination of technology and human review. Today, we have three announcements to share related to this work.', '‘Facing Facts’ Short FilmTo better communicate our approach, we’re releasing “Facing Facts,” a short film that provides an inside look at our fight against misinformation. To make the film, director Morgan Neville spent time with key members of the News Feed team to reveal how we’re thinking about this complex problem and marshaling forces against it. The film is one of the first pieces of content fromInside Feed, a new site dedicated to shedding light on the people and processes behind Facebook’s products and algorithms.', 'News Literacy CampaignAs the film outlines, misinformation is a nuanced and complicated problem that we’re combating from multiple angles. Building on previous work in this space, we’re also releasing an updated news literacy campaign that provides people with tips to spot false news and more information on the actions that we’re taking. This will appear at the top of News Feed and in print ads, starting in the US and reaching other countries throughout the year.', 'Measuring Misinformation Through Academic CommissionFinally, measuring progress in our fight against misinformation is challenging, but critically important. In April, Facebook announced anew initiativeto help provide independent research about the role of social media in elections, as well as democracy more generally. In the coming weeks, the commission will lead a request for proposals to measure the volume and effects of misinformation on Facebook. They will then manage a peer review process to select which scholars will receive funding for their research, and access to privacy-protected data sets from Facebook. This will help keep us accountable and track our progress over time.', 'You can read more about our strategy for stopping false newsin a new postin our Hard Questions series.']\n",
            "78 ['On May 16, PBS NewsHour aired the fourth and final segment of its series on “junk news.” The series features two in-depth visits with the Facebook team that’s fighting misinformation, as well as interviews with critics, academics, people who spread false news and those who consume it. Watch each segment below:', 'Part 1 –“How Facebook’s news feed can be fooled into spreading misinformation”', '', 'Part 2 –“Online anger is gold to this junk-news pioneer”', '', 'Part 3 –“Why we love to like junk news that reaffirms our beliefs”', '', 'Part 4 –“Inside Facebook’s race to separate news from junk”', '', 'See also:An In-Depth Update on False News, from the Product Manager Tackling ItThe Three-Part Recipe for Cleaning up Your News Feed']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "article_meta_ds_2['Text'] = scraped_dataset_misinfo\n",
        "\n",
        "article_meta_ds_2.to_excel('meta_content_misinfo.xlsx', index=False)\n",
        "\n",
        "files.download('meta_content_misinfo.xlsx')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "collapsed": true,
        "id": "Zva_u0n3BE_v",
        "outputId": "8f4aab57-cda5-4079-e06b-77a66449b0b4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_fda3c396-6a16-45c8-8d32-383123fe6478\", \"meta_content_misinfo.xlsx\", 176257)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data and Privacy"
      ],
      "metadata": {
        "id": "N642e2nv_W2F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data3 = []\n",
        "\n",
        "for i in range(0, 17):\n",
        "  request = requests.get(url=f\"https://about.fb.com/news/category/data-and-privacy/page/{i}/\")\n",
        "  parser = BeautifulSoup(request.content, \"html.parser\")\n",
        "\n",
        "  area_section = parser.find(\"div\", class_=\"archive-articles-container\")\n",
        "  article_section = area_section.find_all(\"div\", class_=\"uk-width-3-5 article-excerpt\")\n",
        "  for article in article_section:\n",
        "    try:\n",
        "        header = article.find(\"header\", class_=\"entry-header\")\n",
        "        link_source = header.find(\"a\", href=True)\n",
        "\n",
        "        article_title = link_source.get_text()\n",
        "        link = link_source.get(\"href\")\n",
        "\n",
        "        date_source = header.find(\"time\", class_=\"entry-date published\")\n",
        "        date_source2 = header.find(\"time\", class_=\"updated\")\n",
        "        date = date_source.get_text()\n",
        "        date2 = date_source2.get_text()\n",
        "\n",
        "        data3.append((link, article_title, date, date2))\n",
        "    except:\n",
        "        header = article.find(\"header\", class_=\"entry-header\")\n",
        "        link_source = header.find(\"a\", href=True)\n",
        "\n",
        "        article_title = link_source.get_text()\n",
        "        link = link_source.get(\"href\")\n",
        "\n",
        "        date_source = header.find(\"time\", class_=\"entry-date published updated\")\n",
        "        date = date_source.get_text()\n",
        "        date2 = None\n",
        "\n",
        "        data3.append((link, article_title, date, date2))\n",
        "\n",
        "article_meta_ds_3 = pd.DataFrame(data3, columns=[\"Link\", \"Article Title\" , \"Date\", \"Updated Date\"])\n",
        "\n",
        "print(article_meta_ds_3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "NnFhhwxW8U2H",
        "outputId": "b91d7f95-69b5-455f-d6e4-7795f54c50ba"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                                  Link  \\\n",
            "0    https://about.fb.com/news/2024/03/end-to-end-e...   \n",
            "1    https://about.fb.com/news/2024/01/investing-in...   \n",
            "2    https://about.fb.com/news/2023/12/default-end-...   \n",
            "3    https://about.fb.com/news/2023/11/new-tools-to...   \n",
            "4    https://about.fb.com/news/2023/10/collaboratin...   \n",
            "..                                                 ...   \n",
            "163  https://about.fb.com/news/2019/02/addressing-c...   \n",
            "164  https://about.fb.com/news/2019/01/a-discussion...   \n",
            "165  https://about.fb.com/news/2019/01/data-privacy...   \n",
            "166  https://about.fb.com/news/2019/01/designing-se...   \n",
            "167  https://about.fb.com/news/2019/01/what-kind-of...   \n",
            "\n",
            "                                         Article Title               Date  \\\n",
            "0         End-to-End Encryption on Messenger Explained     March 28, 2024   \n",
            "1                                 Investing In Privacy   January 25, 2024   \n",
            "2    Launching Default End-to-End Encryption on Mes...   December 6, 2023   \n",
            "3            New Tools to Support Independent Research  November 21, 2023   \n",
            "4    Feedback Is a Gift: How We Collaborate to Buil...    October 5, 2023   \n",
            "..                                                 ...                ...   \n",
            "163  What Is Facebook Doing to Address the Challeng...   February 4, 2019   \n",
            "164                       A Discussion with Nick Clegg   January 28, 2019   \n",
            "165                      Marking Data Privacy Day 2019   January 27, 2019   \n",
            "166                    Designing Security for Billions   January 25, 2019   \n",
            "167                  What Kind of Internet Do We Want?   January 20, 2019   \n",
            "\n",
            "           Updated Date  \n",
            "0        March 28, 2024  \n",
            "1     February 29, 2024  \n",
            "2     December 11, 2023  \n",
            "3    September 26, 2024  \n",
            "4      January 24, 2024  \n",
            "..                  ...  \n",
            "163   November 11, 2019  \n",
            "164    January 31, 2021  \n",
            "165    November 7, 2019  \n",
            "166     August 29, 2022  \n",
            "167    January 31, 2021  \n",
            "\n",
            "[168 rows x 4 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "scraped_dataset_privacy = []\n",
        "\n",
        "for idx, row in article_meta_ds_3.iterrows():\n",
        "  article_request = requests.get(url=row['Link'])\n",
        "  parser = BeautifulSoup(article_request.content, \"html.parser\")\n",
        "\n",
        "  text_section = parser.find(\"div\", class_=\"uk-width-2-3@m article-container\")\n",
        "  paragraphs = text_section.find_all(\"p\")\n",
        "\n",
        "  cleaned_text = [para.get_text(strip=True) for para in paragraphs]\n",
        "  scraped_dataset_privacy.append(cleaned_text)\n",
        "  print(idx, cleaned_text)"
      ],
      "metadata": {
        "collapsed": true,
        "id": "D7ONxsm2ANyD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "article_meta_ds_3['Text'] = scraped_dataset_privacy\n",
        "article_meta_ds_3.to_excel('meta_content_privacy.xlsx', index=False)\n",
        "files.download('meta_content_privacy.xlsx')"
      ],
      "metadata": {
        "id": "hRg3zbPDBAY4"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}